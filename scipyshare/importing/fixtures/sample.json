[{"pk": 1, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "numpy", "license": "BSD", "author": "NumPy Developers", "author_email": "numpy-discussion@scipy.org", "project_url": null, "maintainer_email": null, "home_page": "http://numpy.scipy.org", "version": "1.5.1", "platform": "Windows,Linux,Solaris,Mac OS-X,Unix", "keywords": null, "summary": "NumPy: array processing for numbers, strings, records, and objects.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "NumPy is a general-purpose array-processing package designed to\n        efficiently manipulate large multi-dimensional arrays of arbitrary\n        records without sacrificing too much speed for small multi-dimensional\n        arrays.  NumPy is built on the Numeric code base and adds features\n        introduced by numarray as well as an extended C-API and the ability to\n        create arrays of arbitrary type which also makes NumPy suitable for\n        interfacing with general-purpose data-base applications.\n        \n        There are also basic facilities for discrete fourier transform,\n        basic linear algebra and random number generation."}}, {"pk": 2, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Spear", "license": "GNU General Public License version 2", "author": "Michael G. Noll", "author_email": "michael[AT]quuxlabs[DOT]com", "project_url": null, "maintainer_email": null, "home_page": "http://www.quuxlabs.com/", "version": "1.0", "platform": "UNKNOWN", "keywords": "research SPEAR ranking folksonomies expertise HITS spam information retrieval", "summary": "The reference implementation of the SPEAR ranking algorithm in Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering\nTopic :: Sociology\nTopic :: Software Development :: Libraries :: Python Modules", "description": "The purpose of this implementation is to make the inner workings of\n    the algorithm easy to understand and not to distract or confuse\n    the reader with highly optimized code.\n\n    The SPEAR algorithm takes a list of user activities on resources\n    as input, and returns ranked lists of users by expertise scores\n    and resources by quality scores, respectively.\n\n    You can also use this library to simulate the HITS algorithm of\n    Jon Kleinberg. Simply supply a credit score function C(x) = 1 to\n    the SPEAR algorithm (see documentation of Spear.run()).\n\n    More information about the SPEAR algorithm is available at:\n    * http://www.spear-algorithm.org/\n    * \"Telling Experts from Spammers: Expertise Ranking in Folksonomies\"\n      Michael G. Noll, Ching-man Au Yeung, et al.\n      SIGIR 09: Proceedings of 32nd International ACM SIGIR Conference\n      on Research and Development in Information Retrieval, Boston, USA,\n      July 2009, pp. 612-619, ISBN 978-1-60558-483-6\n\n    The code is licensed to you under version 2 of the GNU General Public\n    License.\n\n    Copyright 2009-2010 Michael G. Noll <http://www.michael-noll.com/>\n                        Ching-man Au Yeung <http://www.albertauyeung.com/>"}}, {"pk": 3, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "simpletable", "license": "BSD", "author": "Brent Pedersen", "author_email": "bpederse@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://bitbucket.org/brentp/biostuff/", "version": "0.2.2", "platform": "UNKNOWN", "keywords": "hdf5 pytables tables numpy", "summary": "wrapper around pytables/hd5f to simplify using structured data", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database\nTopic :: Scientific/Engineering", "description": "SimpleTable: simple wrapper around `pytables`_ hdf5\r\n------------------------------------------------------------------------------\r\n\r\n.. _`pytables`: http://pytables.org\r\n\r\nThis module removes some of the boiler-plate code required to use the excellent \r\n`pytables`_\r\nmodule to save and access structured data.\r\n\r\nExample Usage::\r\n\r\n  >>> from simpletable import SimpleTable\r\n  >>> import tables\r\n\r\ndefine a table as a subclass of simple table.\r\n\r\n  >>> RGB = tables.Enum(list('RGB'))\r\n  >>> class ATable(SimpleTable):\r\n  ...     x = tables.Float32Col()\r\n  ...     y = tables.Float32Col()\r\n  ...     name = tables.StringCol(16)\r\n  ...     color = tables.EnumCol(RGB, 'R', 'uint8')\r\n\r\ninstantiate with: args: filename, tablename\r\n\r\n  >>> tbl = ATable('test_docs.h5', 'atable1')\r\n\r\ninsert as with pytables:\r\n\r\n  >>> row = tbl.row\r\n  >>> for i in range(50):\r\n  ...    row['x'], row['y'] = i, i * 10\r\n  ...    row['name'] = \"name_%i\" % i\r\n  ...    # NOTE how we have to manually translate the enum column.\r\n  ...    row['color'] = RGB['G']\r\n  ...    row.append()\r\n  >>> tbl.flush()\r\n\r\ncan have the enum cols automatically translated using `insert`\r\n\r\n  >>> data = {'x': 1000, 'y': 2000, 'color': 'G', 'name': 'flintstone'}\r\n  >>> tbl.insert(data, row)\r\n  >>> row.append()\r\n  >>> tbl.flush()\r\n\r\nthere is also `insert_many()` method with takes an iterable\r\nof dicts with keys matching the colunns (x, y, name) in this\r\ncase.\r\n\r\nquery the data (query() alias of tables' readWhere()\r\nnote that pytables sends back the data with enum cols as they were\r\nand does nothing to translate them to their original values.\r\n\r\n  >>> tbl.query('(x > 4) & (y < 70)') #doctest: +NORMALIZE_WHITESPACE\r\n  array([(1, 'name_5', 5.0, 50.0), (1, 'name_6', 6.0, 60.0)],\r\n         dtype=[('color', '|u1'), ('name', '|S16'), ('x', '<f4'), ('y', '<f4')])\r\n\r\nget translated enumcols in an iterator with the .q  method.\r\n\r\n  >>> r = tbl.q('x == 1000') # doctest: +NORMALIZE_WHITESPACE\r\n  >>> r # doctest: +ELLIPSIS\r\n  <generator ...>\r\n\r\n  >>> list(r)\r\n  [{'color': 'G', 'x': 1000.0, 'name': 'flintstone', 'y': 2000.0}]\r\n\r\nor use the `translate_enum` method\r\n\r\n  >>> for row_with_enum in tbl.query('(x > 4) & (y < 70)'):\r\n  ...     tbl.translate_enum(row_with_enum)\r\n  {'color': 'G', 'x': 5.0, 'name': 'name_5', 'y': 50.0}\r\n  {'color': 'G', 'x': 6.0, 'name': 'name_6', 'y': 60.0}\r\n\r\nNote that using `q` or `translate_enum` will affect performance."}}, {"pk": 4, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyvst", "license": "UNKNOWN", "author": "Matthieu Brucher", "author_email": "matthieu.brucher@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "0.1.0", "platform": "UNKNOWN", "keywords": null, "summary": "Python ctypes-based VST wrapper", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Plugins\nEnvironment :: Win32 (MS Windows)\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: Microsoft :: Windows\nTopic :: Multimedia :: Sound/Audio\nTopic :: Scientific/Engineering", "description": "UNKNOWN"}}, {"pk": 5, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "igo-python", "license": "MIT", "author": "Hideaki Takahashi", "author_email": "mymelo@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "https://launchpad.net/igo-python/", "version": "0.3a", "platform": "UNKNOWN", "keywords": "japanese,morphological analyzer", "summary": "Python port of Igo Japanese morphological analyzer", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nNatural Language :: Japanese\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX :: Linux\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Linguistic", "description": "================\n Igo for Python\n================\n\nAbout\n=====\n\nIgo_ is a Japanese morphological analyzer written in Java and Common Lisp.\nThis software is Python port of Igo(Java version).\n\n.. _Igo: http://igo.sourceforge.jp/\n\nNotice\n======\n\nDictionary builder is not provided. You need to use Igo Java version to build the dictionary for Igo.\n\n\nHow To Use\n==========\n\nYou can use Igo Python easily::\n\n >>> from igo.Tagger import Tagger\n >>> t = Tagger('ipadic')\n >>> for m in t.parse(u'\u3059\u3082\u3082\u3082\u3082\u3082\u3082\u3082\u3082\u306e\u3046\u3061'):\n ...     print m.surface, m.feature\n ...\n \u3059\u3082\u3082 \u540d\u8a5e,\u4e00\u822c,*,*,*,*,\u3059\u3082\u3082,\u30b9\u30e2\u30e2,\u30b9\u30e2\u30e2\n \u3082 \u52a9\u8a5e,\u4fc2\u52a9\u8a5e,*,*,*,*,\u3082,\u30e2,\u30e2\n \u3082\u3082 \u540d\u8a5e,\u4e00\u822c,*,*,*,*,\u3082\u3082,\u30e2\u30e2,\u30e2\u30e2\n \u3082 \u52a9\u8a5e,\u4fc2\u52a9\u8a5e,*,*,*,*,\u3082,\u30e2,\u30e2\n \u3082\u3082 \u540d\u8a5e,\u4e00\u822c,*,*,*,*,\u3082\u3082,\u30e2\u30e2,\u30e2\u30e2\n \u306e \u52a9\u8a5e,\u9023\u4f53\u5316,*,*,*,*,\u306e,\u30ce,\u30ce\n \u3046\u3061 \u540d\u8a5e,\u975e\u81ea\u7acb,\u526f\u8a5e\u53ef\u80fd,*,*,*,\u3046\u3061,\u30a6\u30c1,\u30a6\u30c1\n >>>\n\n\n\n\nChangelog for Igo-Python\n========================\n\n2010-11-25 -- 0.1\n    * first release.\n\n2010-11-27 -- 0.1a\n    * update package info only.\n\n2010-11-27 -- 0.2\n    * support Google App Engine(maybe)\n\n2010-11-27 -- 0.3\n    * drop mmap related code\n    * reduce memory footprint\n\n2010-11-28 -- 0.3a\n    * fix bugs(if a phrase ends with '\u305f' will causes error)"}}, {"pk": 6, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "neo", "license": "BSD", "author": "Samuel Garcia, Pierre Yger, Luc Estabanez, Andrew Davison , Yury V. Zaytsev", "author_email": "sgarcia at olfac.univ-lyon1.fr", "project_url": null, "maintainer_email": null, "home_page": "http://neuralensemble.org/trac/neo", "version": "0.1.0", "platform": "UNKNOWN", "keywords": null, "summary": "neo : objects and IO to manipulate electro-physiological (in vivo and/or simulated) data", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "NEO stands for Neural Ensemble Objects and is a project to provide a common set of base classes to be used\nin neural data analysis, with the aim of getting OpenElectrophy, NeuroTools and maybe other projects\nwith similar goals more close together.\n\nIt provide a set of basic class to manipulate electro-physiological (in vivo and/or simulated) data \nand an IO module to read/write as many as possible file format."}}, {"pk": 7, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "GeoAlchemy", "license": "MIT", "author": "Eric Lemoine", "author_email": "eric.lemoine@camptocamp.com", "project_url": null, "maintainer_email": null, "home_page": "http://geoalchemy.org/", "version": "0.5", "platform": "UNKNOWN", "keywords": "geo gis sqlalchemy orm", "summary": "Using SQLAlchemy with Spatial Databases", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Plugins\nIntended Audience :: Information Technology\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "==========\nGeoAlchemy\n==========\n\nGIS Support for `SQLAlchemy <http://www.sqlalchemy.org/>`_.\n\nIntroduction\n------------\nGeoAlchemy is an extension of SQLAlchemy. It provides support for\nGeospatial data types at the ORM layer using SQLAlchemy. It aims to\nsupport spatial operations and relations specified by the Open Geospatial\nConsortium (OGC). The project started under Google Summer of Code Program\nunder the mentorship of `Mark Ramm-Christensen <http://compoundthinking.com/blog/>`_.\n\nRequirements\n------------\nRequires SQLAlchemy > 0.6. Supported on Python 2.5 and Python 2.6.\nShould also work with Python 2.4 but has not been tested. It also\nrequires a supported spatial database.\n\n\nSupported Spatial Databases\n---------------------------\nAt present `PostGIS <http://postgis.refractions.net/>`_, `Spatialite\n<http://www.gaia-gis.it/spatialite/>`_, `MySQL <http://www.mysql.com/>`_,\n`Oracle <http://www.oracle.com/technology/software/products/database/index.html>`_,\nand `MS SQL Server 2008 <http://www.microsoft.com/sqlserver/2008/en/us/spatial-data.aspx?pf=true>`_\nare supported.\n\nSupport\n-------\nGeoAlchemy is at an early stage of development. Its mailing list is available on\n`Google Groups <http://groups.google.com/group/geoalchemy>`_. The source code can be \nfound on `BitBucket <http://bitbucket.org/geoalchemy/geoalchemy/>`_. Also, feel free to email \nthe author directly to send bugreports, feature requests, patches, etc.\n\n\nInstallation\n------------\nTo install type as usual::\n\n    $ easy_install GeoAlchemy\n\nOr, download the package, change into geoalchemy dir and type::\n\n    $ python setup.py install\n\n\nDocumentation\n-------------\nDocumentation is available online at http://geoalchemy.org.\nYou can also generate full documentation using sphinx by doing `make html`\nin the `doc` dir and pointing the browser to `doc/_build/index.html`.\n\n\nPackage Contents\n----------------\n\n  geoalchemy/\n      Source code of the project.\n\n  geoalchemy/tests/\n      Unittests for GeoAlchemy.\n\n  doc/\n      Documentation source.\n\n  examples/\n      A few examples demonstrating usage.\n\n\nLicense\n-------\n\nGeoAlchemy is released under the MIT License.\n\nContributors\n------------\n\nThe contributors to this project (in alphabetical order are):\n\n    Eric Lemoine\n    Frank Broniewski\n    Mark Hall\n    Michael Bayer\n    Mike Gilligan\n    Sanjiv Singh\n    Stefano Costa\n    Tobias Sauerwein"}}, {"pk": 8, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cdat-lite", "license": "http://www-pcmdi.llnl.gov/software-portal/cdat/docs/cdat-license", "author": "Stephen Pascoe", "author_email": "Stephen.Pascoe@stfc.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://proj.badc.rl.ac.uk/ndg/wiki/CdatLite", "version": "6.0.alpha-4", "platform": "UNKNOWN", "keywords": null, "summary": "Core components of the Climate Data Analysis tools.  This software is based on CDAT-6.0.alpha-4 and cdunfpp0.13.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: POSIX :: Linux\nTopic :: Scientific/Engineering :: Atmospheric Science", "description": "=========\n        CDAT-Lite\n        =========\n        \n        .. contents::\n        \n        .. sectnum::\n        \n        CDAT-Lite is a Python package for managing and analysing climate\n        science data.  It is a subset of the Climate Data Analysis Tools\n        (CDAT_) developed by PCMDI_ at Lawrence Livermore National Laboratory.\n        \n        CDAT-lite aims to compliment CDAT by focussing on it's core data\n        management and analysis components and by offering a radically\n        different installation system to CDAT.  As a result it is much more\n        lightweight (hence the name): CDAT's source distribution is the order\n        of 1Gb whereas CDAT-lite is under 5Mb.\n        \n        From 6.0-alpha-3 CDAT-lite no longer comes with the CF Checker.  This should be available as a separate easy_installable package shortly.\n        \n        .. _CDAT: http://www2-pcmdi.llnl.gov/cdat\n        .. _PCMDI: http://www2-pcmdi.llnl.gov/\n        \n        \n        Installing cdat-lite\n        ====================\n        \n        cdat-lite is distributed as a tarball available from the `cdat-lite\n        homepage`_ on the `NERC Data Grid wiki` .  It is also installable\n        using the ``easy_install`` tool.  If you are familiar with\n        ``easy_install`` try this super-quick installation recipe::\n        \n        $ export NETCDF_HOME=/usr/local/netcdf\n        # Required if using a NetCDF4 compiled with HDF5\n        $ export HDF5_HOME=/usr/local/hdf5\n        $ easy_install cdat_lite\n        \n        \n        Dependencies\n        ------------\n        \n        To install cdat-lite you will need:\n        \n        1. `Python 2.5.x`_.  cdat-lite has not been tested on 2.6 but may\n        work (feedback would be gratefully received).  It is unlikely to work on 3.0.\n        \n        2. `setuptools`_.  cdat-lite will attempt to download and install\n        setuptools if it is missing but it is safer to install it first.\n        \n        3. `NetCDF-3.x`_ or greater.  cdat-lite should work with any\n        relatively modern NetCDF3 installation on your system provided it is\n        compiled as a shared library.  It will also work with NetCDF4\n        configured in various different ways, including embedded OPeNDAP\n        mode.\n        \n        4. If you want to run the short test suite you will need nose_\n        \n        .. _`Python 2.5.x`: http://www.python.org/download/releases/2.5.4\n        .. _`setuptools`: http://pypi.python/org/setuptools\n        .. _`NetCDF-3.x`: http://www.unidata.ucar.edu/software/netcdf/\n        .. _nose: http://somethingaboutorange.com/mrl/projects/nose/\n        \n        Selecting your NetCDF installation\n        ----------------------------------\n        \n        cdat-lite will work with NetCDF3 or NetCDF4 but because it is\n        referenced by shared libraries (the python C extension modules) it\n        must be compiled as position independent code.  It is probably easiest\n        to install NetCDF as a shared library (use ``--enable-shared`` in the\n        NetCDF ``configure`` script).  Alternatively, you can configure NetCDF with::\n        \n        $ ./configure --with-pic ...\n        \n        If you are using NetCDF4 you will also need to configure HDF5 with ``--enable-shared`` or ``--with-pic``.\n        \n        cdat-lite will look for a NetCDF installation in several places and\n        prompt you if it can't find it.  If your NetCDF is installed somewhere\n        unusual, or if you want to select a specific installation, set the\n        NETCDF_HOME variable.  E.g.::\n        \n        # sh users\n        $ export NETCDF_HOME=/usr/local/netcdf\n        # csh users\n        $ setenv NETCDF_HOME /usr/local/netcdf\n        \n        If you are using NetCDF4 cdat-lite will also look for your HDF5\n        installation which you can configure in a similar way::\n        \n        # sh users\n        $ export HDF5_HOME=/usr/local/hdf5\n        # csh users\n        $ setenv HDF5_HOME /usr/local/hdf5\n        \n        Note, you don't need these environment variables set to run cdat_lite,\n        although the libraries must be findable by your system's dynamic\n        linker.  This can be configured by setting ``LD_LIBRARY_PATH`` or using ``ldconfig``.\n        \n        Running the installer\n        ---------------------\n        \n        If you have all the dependencies in place you can try using\n        ``easy_install`` to automatically download and install cdat_lite.  Make sure you have access to the internet, with the appropriate HTTP proxy settings, and do::\n        \n        $ easy_install cdat-lite\n        \n        Alternatively you might want to see what you are installing :-).  In\n        this case either download the tarball__ or use ``easy_install`` to do it for you::\n        \n        $ easy_install -eb . cdat-lite\n        # The cdat-lite tarball will be downloaded unpacked into you current directory\n        \n        Now from the distribution directory run the build and install steps separately::\n        \n        $ python setup.py bdist_egg\n        $ easy_install dist/cdat-lite*.egg\n        \n        __ `cdat-lite homepage`_\n        \n        \n        .. _`installing locally`:\n        \n        Installing as an unprivileged user\n        ----------------------------------\n        \n        If you don't have write access to your python distribution you can use\n        the tool virtualenv_ to create a local python environment with\n        it's own ``easy_install`` executable which you can then use to install\n        cdat-lite.  In combination with ``NETCDF_HOME``, ``HDF5_HOME`` and\n        ``LD_LIBRARY_PATH`` it should be possible to install all dependencies\n        of cdat-lite locally.  See the virtualenv_ for details on\n        installation or try this recipe after downloading the virtualenv::\n        \n        # From virtualenv distribution directory\n        $ ./virtualenv.py <virtualenv-path>\n        $ cd <virtualenv-path>\n        $ source bin/activate\n        (venv)$ easy_install cdat-lite\n        \n        .. _virtualenv: http://pypi.python.org/pypi/virtualenv\n        \n        Testing the installation\n        ========================\n        \n        cdat-lite ships with a small set of tests designed to verify that it\n        has been built successfuly.  These tests require the testing framework\n        nose_.  Once cdat-lite is installed just run::\n        \n        $ nosetests cdat_lite\n        \n        When run from cdat-lite's distribution directory nosetests will run\n        slightly differently, running some tests that are known to fail at the\n        moment.  To disable this behaviour do:\n        \n        $ nosetests --config=''\n        \n        .. _`cdat-lite homepage`: http://proj.badc.rl.ac.uk/ndg/wiki/CdatLite\n        .. _`NERC Data Grid wiki`: http://proj.badc.rl.ac.uk/ndg/wiki\n        \n        \n        \n        FAQ\n        ===\n        \n        What is CDAT?\n        -------------\n        \n        CDAT_ is a large suite of open source tools distributed by PCMDI_ for\n        the management and analysis of climate data.  It includes several\n        visualisation components and the graphical user interface VCDAT.\n        \n        What is the difference between CDAT and cdat-lite?\n        --------------------------------------------------\n        \n        Differences between CDAT and CDAT-lite can be classified as\n        differences in scope, i.e. which packages are included, and installation system.\n        \n        cdat-lite contains the 'cdms2' package and a few related\n        packages.  It does not include the 'vcs' visualisation package or the\n        VCDAT graphical user interface.  As of v5.1.1-0.3pre3 the included\n        packages are:\n        \n        * cdms2\n        \n        * cdtime\n        \n        * cdutil\n        \n        * genutil\n        \n        * ncml\n        \n        * Properties\n        \n        * regrid2\n        \n        * unidataa\n        \n        * xmgrace\n        \n        CDAT bundles virtually all dependencies together in it's source\n        distribution -- even Python itself.  This has it's advantages as it\n        simplifies satisfying dependencies and avoids version conflicts\n        between dependencies.  However, if you want to integrate CDAT's data\n        management components into your existing Python architecture CDAT can\n        be overkill.\n        \n        \n        What has changed between cdat-lite-4.x and cdat-lite-5.x?\n        ---------------------------------------------------------\n        \n        If you are a cdat-lite-4 user (or a CDAT 4 user) you have a big\n        migration job on your hands.  CDAT-4 uses the ``Numeric`` package for\n        arrays which has been out of date and unmaintained for a long time\n        now.  It is known to have problems on 64bit architectures.\n        \n        How does cdat-lite track changes to CDAT?\n        -----------------------------------------\n        \n        cdat-lite tries to release major new versions shortly after new\n        versions of CDAT.  Sometimes CDAT-trunk contains important fixes that\n        should be applied so that the latest cdat_lite can run ahead of\n        official CDAT releases (although sometimes CDAT recommends you build\n        from trunk anyway).\n        \n        The one exception is the UK Met. Office PP file support which is\n        usually updated in cdat_lite before CDAT.  In all cases the exact\n        build versions of CDAT and cdunifpp will be stated in the\n        distribution's ``setup.py`` file.\n        \n        How can I use CMOR2 with cdat-lite?\n        -----------------------------------\n        \n        We are interested to hear any with experience of using CMOR2 with\n        cdat-lite but it should be as simple as downloading the distribution\n        and installing it in parallel with::\n        \n        # From the CMOR install directory\n        $ python setup.py install\n        \n        How can I use OPeNDAP with cdat-lite?\n        -------------------------------------\n        \n        OPeNDAP support is an experimental feature of cdat-lite at the moment.\n        Unlike CDAT you don't select OPeNDAP explicitly during installation\n        but cdat-lite will inherit any OPeNDAP support embedded into the\n        NetCDF4 library.  Recent beta releases of NetCDF4 provides a switch to\n        transparently use OPeNDAP.\n        \n        How do I install cdat-lite as an unprivileged user?\n        ---------------------------------------------------\n        \n        See `installing locally`_\n        \n        Which versions of NetCDF does cdat-lite support?\n        ------------------------------------------------\n        \n        TODO"}}, {"pk": 9, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MDSplus", "license": "UNKNOWN", "author": "Tom Fredian,Josh Stillerman,Gabriele Manduchi", "author_email": "twf@www.mdsplus.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.mdsplus.org/", "version": "0.2", "platform": "('Any',)", "keywords": "('physics', 'mdsplus')", "summary": "MDSplus Python Objects", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "This module provides all of the functionality of MDSplus TDI natively in python.\n      All of the MDSplus data types such as signal are represented as python classes."}}, {"pk": 10, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nibabel", "license": "MIT license", "author": "Matthew Brett and Michael Hanke", "author_email": "nipy-devel@neuroimaging.scipy.org", "project_url": null, "maintainer_email": null, "home_page": "http://nipy.org/nibabel", "version": "1.0.1", "platform": "OS Independent", "keywords": null, "summary": "Access a multitude of neuroimaging data formats", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "=======\nNiBabel\n=======\n\nThis package provides read and write access to some common medical and\nneuroimaging file formats, including: ANALYZE_ (plain, SPM99, SPM2),\nGIFTI_, NIfTI1_, MINC_, as well as PAR/REC. NiBabel is the successor of\nPyNIfTI_.\n\n.. _ANALYZE: http://www.grahamwideman.com/gw/brain/analyze/formatdoc.htm\n.. _NIfTI1: http://nifti.nimh.nih.gov/nifti-1/\n.. _MINC: http://wiki.bic.mni.mcgill.ca/index.php/MINC\n.. _PyNIfTI: http://niftilib.sourceforge.net/pynifti/\n.. _GIFTI: http://www.nitrc.org/projects/gifti\n\nThe various image format classes give full or selective access to header (meta)\ninformation and access to the image data is made available via NumPy arrays.\n\nWebsite\n=======\n\nCurrent information can always be found at the NIPY nibabel website::\n\n    http://nipy.org/nibabel\n\nMailing Lists\n=============\n\nPlease see the developer's list here::\n\n    http://mail.scipy.org/mailman/listinfo/nipy-devel\n\nCode\n====\n\nYou can find our sources and single-click downloads:\n\n* `Main repository`_ on Github.\n* Documentation_ for all releases and current development tree.\n* Download as a tar/zip file the `current trunk`_.\n* Downloads of all `available releases`_.\n\n.. _main repository: http://github.com/nipy/nibabel\n.. _Documentation: http://nipy.org/nibabel\n.. _current trunk: http://github.com/nipy/nibabel/archives/master\n.. _available releases: http://github.com/nipy/nibabel/downloads\n\nLicense\n=======\n\nNibabel is licensed under the terms of the MIT license. Some code included with\nnibabel is licensed under the BSD license.  Please the COPYING file in the\nnibabel distribution."}}, {"pk": 11, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "lookup_table", "license": "LGPL", "author": "Tim Wegener", "author_email": "twegener@radlogic.com.au", "project_url": null, "maintainer_email": "", "home_page": "http://www.radlogic.com.au/downloads.htm", "version": "0.6", "platform": "", "keywords": "table lookup piece-wise linear interpolation", "summary": "a multidimensional lookup table class and functions for doing piece-wise-linear table lookups", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Electronic Design Automation (EDA)\nTopic :: Utilities", "description": "a multidimensional lookup table class and functions for doing piece-wise-linear\r\ntable lookups"}}, {"pk": 12, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyrels", "license": "GNU General Public Licence v3 (GPLv3)", "author": "Dinu Gherman", "author_email": "gherman@darwin.in-berlin.de", "project_url": null, "maintainer_email": null, "home_page": "http://www.dinu-gherman.net/", "version": "0.1.0", "platform": "Posix,Windows", "keywords": "visualizing,Python,relationships,references,namespaces", "summary": "A tool for displaying relationships between Python objects.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development", "description": "`Pyrels` is a tool for exploring and visualizing relationships between \nPython objects. It does so by analysing and converting Python namespaces \ninto `GraphViz <http://www.graphviz.org>`_ files in the \n`DOT <http://www.graphviz.org/doc/info/lang.html>`_ format. \nThat means it displays relationships like references between Python names \nand the objects they point to, as well as containment between Python \ncontainer objects (lists, tuples and dictionaries) and the respective \nobjects they contain.\n\nAt the moment `pyrels` is best used on Python data structures, but it is \nintended to develop it further so that it can also display other types of  relationships like inheritance, module imports, etc. \n\nOne target group for `pyrels` are article and/or book authors who wish to \nillustrate Python data structures graphically without spending a lot of \ntime for creating these illustrations manually. `Pyrels` can help you \nautomate this process."}}, {"pk": 13, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "wikidump", "license": "GPL3", "author": "Marco Lui", "author_email": "saffsd@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/saffsd/wikidump", "version": "0.1.2", "platform": "UNKNOWN", "keywords": "wikipedia", "summary": "Tools to manipulate and extract data from wikipedia dumps", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis", "description": "wikidump\n==========================\n\nIntroduction\n------------\n\nThis module contains code for manipulating wikipedia dumps available from\nhttp://download.wikimedia.org/backup-index.html\n\n\nInstallation\n------------\n\nThis module is published on `PyPI`_ and can be installed with easy_install\n\nFor example:\n\n  easy_install wikidump\n\nAlternatively, you can use pip:\n\n  pip install wikidump\n\nI highly recommend using `virtualenv`_ to isolate the install environment.\n\nFor those on ubuntu systems, a built package is available in a `PPA`_. \nPlease go to the PPA for details on how to install from it.\n\n\n.. _PyPI: http://pypi.python.org/pypi/wikidump\n.. _virtualenv: http://pypi.python.org/pypi/virtualenv\n.. _PPA: https://launchpad.net/~saffsd/+archive/wikidump\n\nConfiguration\n-------------\n\nUpon first importing the module, a file 'wikidump.cfg' will be created.\nModify the paths in this file to point to your data. \n\n- scratch : where indices are stores (must be writeable)\n- xml_dumps : where the xml dumps are located (can be read-only)\n\nUsage\n-----\n\nIn addition to python modules, wikidump also comes with a command-line\ntool to quickly access wikidump functionality. Run `wikidump help` \nfor a list of options.\n\nCredits\n-------\n\n- `Distribute`_\n- `Buildout`_\n- `modern-package-template`_\n\n.. _Buildout: http://www.buildout.org/\n.. _Distribute: http://pypi.python.org/pypi/distribute\n.. _`modern-package-template`: http://pypi.python.org/pypi/modern-package-template\n\n\n.. This is your project NEWS file which will contain the release notes.\n.. Example: http://www.python.org/download/releases/2.6/NEWS.txt\n.. The content of this file, along with README.rst, will appear in your\n.. project's PyPI page.\n\nNews\n====\n\n0.1\n---\n\n*Release date: 04-Aug-2010*\n\n* Initial release of wikidump module"}}, {"pk": 14, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.component.core", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.component.core", "version": "4.3", "platform": "any", "keywords": "utility", "summary": "The PyUtilib Component Architecture.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==============================\npyutilib.component.core README\n==============================\n\n--------\nOverview\n--------\n\nThis Python package provides a modular component framework, which \nconsists of the following core classes:\n\n:Interface:\n  Subclasses of this class declare component interfaces that are registered in the framework\n\n:ExtensionPoint:\n  A class used to declare extension points, which can access components with a particular interface\n\n:Plugin:\n  Subclasses of this class declare plugins, which can be used to provide services within this component framework.\n\n:SingletonPlugin:\n  Subclasses of this class declare singleton plugins, for which a single instance can be declared.\n\n:PluginEnvironment:\n  A class that maintains the registries for interfaces, extension points and components.\n\n:PluginGlobals:\n  A class that maintains global data concerning the set of environments that are currently being used.\n\n:PluginError:\n  The exception class that is raised when errors arise in this framework.\n\nThe outline of this framework is adapted from Trac (see the\n**trac.core** module).  This framework generalizes the Trac by supporting\nmulti-environment management of components, as well as non-singleton\nplugins.  For those familiar with Trac, the following classes roughly\ncorrespond with each other:\n\n    +-------------------+-------------------+ \n    | Trac              | PyUtilib          |\n    +===================+===================+ \n    | Interface         | Interface         |\n    +-------------------+-------------------+ \n    | ExtensionPoint    | ExtensionPoint    |\n    +-------------------+-------------------+ \n    | Component         | SingletonPlugin   |\n    +-------------------+-------------------+ \n    | ComponentManager  | PluginEnvironment |\n    +-------------------+-------------------+ \n\nSee `The PyUtilib Component Architecture Reference Manual <https://software.sandia.gov/svn/public/pyutilib/pyutilib.component.doc/trunk/doc/plugin/pca.pdf>`_ for a detailed description of PyUtilib components and examples of their use.\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 15, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "NEB", "license": "MIT", "author": "Paul J. Davis", "author_email": "davisp@neb.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/neb", "version": "0.0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Namespace package for NEB projects.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Top level namespace project for from New England Biolabs"}}, {"pk": 16, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "wp-download", "license": "GPLv3", "author": "Wolodja Wentland", "author_email": "wentland@cl.uni-heidelberg.de", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/babilen/wp-download", "version": "0.1.1", "platform": "UNKNOWN", "keywords": null, "summary": "Wikipedia database dump downloader", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Database\nTopic :: Scientific/Engineering", "description": "wp-download\n===========\n\nIt is a cumbersome task to administer local Wikipedia databases,\nespecially if you need access to multiple language versions of\nWikipedia.\n\nWith ``wp-download`` you can automatically download the newest\ndatabase dumps for all language edition you want::\n\n    $ wp-download --resume -v /path/to/wikipedia/dumps\n    Read configuration from: '/home/foobar/.wpdownloadrc'\n    Set timeout to 30s\n    Processing language: sw\n    Creating directory: /path/to/wikipedia/dumps/sw/20090821\n    Latest dump for (sw) is from Friday 21 August 2009\n    Skip: swwiki-20090821-redirect.sql.gz\n    Skip: swwiki-20090821-category.sql.gz\n    Resume: swwiki-20090821-pages-articles.xml.bz2\n    swwiki-20090821-pages-articles.xml.bz2 [****] 100% Time: 00:00:00   3.19 M/s\n    ...\n    ...\n\nInstallation\n------------\n\nThis distribution does *not* use setuptools but plain distutils, so you will\nhave to install requirements by yourself or by using the pip requirements file\nfrom the `homepage <http://github.com/babilen/wp-download>`_.\n\nRequirements:\n\n    * `progressbar <http://pypi.python.org/pypi/progressbar/2.2>`_\n\nDocumentation\n-------------\n\nDocumentation can be found `here <http://packages.python.org/wp-download/>`_"}}, {"pk": 17, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "geojson", "license": "BSD", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/lab/wiki/GeoJSON", "version": "1.0.1", "platform": "UNKNOWN", "keywords": "gis geography json", "summary": "Encoder/decoder for simple GIS features", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "geojson: encode/decode geodata\n==============================\n\nThis package contains:\n\n* The reference implementation of the Python geo interface:\n\n  http://trac.gispython.org/lab/wiki/PythonGeoInterface\n\n* Functions for encoding and decoding GeoJSON (http://geojson.org) formatted\n  data.\n\nGeojson provides geometry, feature, and collection classes, and supports\npickle-style dump and load of objects that provide the lab's Python geo\ninterface. Here's an example of a round-trip through the GeoJSON format::\n\n  >>> import geojson\n  >>> p = geojson.Point([0.0, 0.0])\n  >>> p\n  Point(coordinates=[0.0, 0.0])\n  >>> data = geojson.dumps(p)\n  >>> data\n  '{\"type\": \"Point\", \"coordinates\": [0.0, 0.0]}'\n  >>> q = geojson.loads(data, object_hook=geojson.GeoJSON.to_instance)\n  >>> q\n  Point(coordinates=[0.0, 0.0])\n\nThe geometry classes interoperate with Shapely via the geo interface::\n\n  >>> from shapely.geometry import asShape\n  >>> x = asShape(p)\n  >>> x.wkt\n  'POINT (0.0000000000000000 0.0000000000000000)'"}}, {"pk": 18, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pseudosugar", "license": "gpl", "author": "kai zhu", "author_email": "kaizhu256@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/pseudosugar", "version": "2010.01.01.README", "platform": "UNKNOWN", "keywords": null, "summary": "DESCRIPTION: pseudosugar - extend python with functional programming language features", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "DESCRIPTION: pseudosugar - extend python with functional programming language features\n\n  REQUIRES: LINUX OS AND PYTHON3.1\n\n  QUICK TEST: $ python3.1 setup.py build dev --quicktest\n\n  SUMMARY:\n  pseudosugar is a pure python module.\n  pseudosugar is a python ast tree hack, adding the following syntax sugars:\n\n  function<<<< aa, bb, cc, ... -> function(aa, bb, cc, ...)\n  aa, bb, cc, ... >>>>function -> function(aa, bb, cc, ...)\n\n  xx ..function(aa, bb, cc) -> function(xx, aa, bb, cc)\n  xx ...function(aa, bb, cc) -> function(aa, xx, bb, cc)\n  xx ....function(aa, bb, cc) -> function(aa, bb, xx, cc)\n  \nRECENT CHANGELOG:\n  20091231 - added <<<< and >>>> sugar\n  20091224 - added pseudomethod interactive console - revamped pseudomethod import hook\n  20091224 - modularized package - fix install issues - added sdist check\n  20091209 - improved documentation\n  20091205 - moved source code to c++\n  20091116 - package integrated\n\nDEMO USAGE:\n\n>>> ## start up the interactive console\n>>> from pseudosugar import *\n>>> pseudo_console().interact()\n\nPython 3.1.1 (r311:74480, Sep 13 2009, 17:17:12)\n[GCC 4.3.2] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n(pseudo_console)\npseudo_importer - adding hook <pseudosugar.pseudo_importer object at 0xb7ac754c> to sys.meta_path\n>>> from pseudosugar import *\n\n>>> #### QUICK EXAMPLES\n>>> ## prefix operator\n>>> print<<<< 'hello', 'world'\nhello world\n\n>>> ## postfix operator\n>>> 'hello', 'world' >>>>print\nhello world\n\n>>> ## pseudomethod\n>>> def function(aa, bb, cc): return (aa, bb, cc)\n>>> 1 ..function(0, 0) >>>>print\n(1, 0, 0)\n>>> 2 ...function(0, 0) >>>>print\n(0, 2, 0)\n>>> 3 ....function(0, 0) >>>>print\n(0, 0, 3)\n\n\n\n\n\n\n\n>>> ## '<<<<' CONVERTS FUNCTIONS INTO PREFIX OPERATORS\n>>> ## foo<<<< turns foo into a prefix operator\n>>> ## foo<<<< will take in everything to its right that is comma delimited\n>>> ## print<<<< is useful for making print statements\n>>> print<<<< 'bob says', 'hello ' + re.sub<<<< re.compile('(\\w+)'), '\\\\1!', 'world'\nbob says hello world!\n\n>>> ## '>>>>' CONVERTS FUNCTIONS INTO POSTFIX OPERATORS\n>>> ## it behaves almost exactly like '>>>>' except in reverse\n>>> ## it is useful for chaining together multiple operators\n>>> 'qwerty' >>>>list >>>>sorted >>>>enumerate >>>>dict >>>>print\n{0: 'e', 1: 'q', 2: 'r', 3: 't', 4: 'w', 5: 'y'}\n\n>>> ## OPERATOR PRECEDENCE\n>>> ## '>>>>' has higher operator precedence than '<<<<'\n>>> print( list<<<< 'abcd' >>>>tuple ) ## list(tuple('abcd'))\n['a', 'b', 'c', 'd']\n\n\n\n\n\n\n\n>>> #### PSEUDOMETHOD SYNTAX\n>>> ## DYNAMICALLY BIND FUNCTION CALLS TO OBJECTS\n>>> ## bind the function call print() to 'hello'\n>>> print('hello')\nhello\n>>> 'hello' ..print()\nhello\n>>> 'hello' ..print('world')\nhello world\n>>> 'hello' ..print('world', '!')\nhello world !\n>>> 'hello' ..print('world', '!', file = sys.stdout)\nhello world !\n\n>>> ## create a string pseudomethod which adds an exclamation or other endings\n>>> def add_ending(self, end = '!'): return self + end\n>>> 'hello' ..add_ending() ..print()\nhello!\n>>> 'hello'.upper() ..add_ending() ..print()\nHELLO!\n>>> 'hello'.upper() ..add_ending(' world') ..print()\nHELLO world\n>>> 'hello'.upper() ..add_ending(' world').lower() ..print()\nhello world\n>>> 'hello'.upper() ..add_ending(' world').lower() ..add_ending('!') ..print()\nhello world!\n>>> 'hello'.upper() ..add_ending(' world').lower() ..add_ending('!') ..add_ending(end = '!') ..print()\nhello world!!\n\n\n\n>>> ## OPERATOR PRECEDENCE\n>>> ## 'aa ..bb()' has the same operator precedence as the attribute operator 'a.b'\n>>> def add(aa, bb): return aa + bb\n>>> print( 2 * 3 ..add(4) + 5 == 2 * (3 + 4) + 5 )\nTrue\n>>> print( 3 == 1 ..add(2) )\nTrue\n>>> print( 0, 0 ..add(1), 0 )\n0 1 0\n\n\n\n>>> ## EXTEND RESTRICTED TYPES\n>>> ## the python code object type <class 'code'> cannot be subtyped nor will it accept any method binding.\n>>> ## however, we can extend it by dynamically binding ordinary functions.\n>>> ## here's a pseudomethod which disassembles an instance of the type to a specified output\n>>> import dis, io, sys\n>>> def disassemble(self, file):\n...   backup_stdout = sys.stdout ## backup sys.stdout\n...   try:\n...     sys.stdout = file\n...     dis.dis(self) ## disassemble self\n...     return file\n...   finally:\n...     sys.stdout = backup_stdout ## restore sys.stdout\n\n>>> code_source = 'print( \"hello\" )'; code_object = compile(code_source, '', 'exec'); exec( code_object )\nhello\n>>> code_object ..disassemble(file = io.StringIO()).getvalue() ..print()\n  1           0 LOAD_NAME                0 (print) \n              3 LOAD_CONST               0 ('hello') \n              6 CALL_FUNCTION            1 \n              9 POP_TOP              \n             10 LOAD_CONST               1 (None) \n             13 RETURN_VALUE         \n\n\n\n\n>>> ## '...' AND '....' SYNTAX\n>>> ## sometimes we instead want the 2nd or 3rd argument of a function bound to an object.\n>>> ## '...' and '....' will do this respectively\n>>> '2nd' ...print(0, 0)\n0 2nd 0\n>>> '3rd' ....print(0, 0)\n0 0 3rd\n\n>>> ## '....' is useful for chaining re.sub\n>>> ss = 'file = io.StringIO(); print 1, 2, 3 >> file; print file.getvalue()'; print( ss )\nfile = io.StringIO(); print 1, 2, 3 >> file; print file.getvalue()\n\n>>> print(\n...   re.sub('print (.*?)$', 'print( \\\\1 )',\n...          re.sub('print (.*) >> (.*?);', 'print( \\\\1, file = \\\\2 );', ss)\n...          )\n...   )\nfile = io.StringIO(); print( 1, 2, 3, file = file ); print( file.getvalue() )\n\n>>> ss ....re.sub('print (.*) >> (.*?);', 'print( \\\\1, file = \\\\2 );') \\\n...    ....re.sub('print (.*?)$', 'print( \\\\1 )') \\\n...    ..print()\nfile = io.StringIO(); print( 1, 2, 3, file = file ); print( file.getvalue() )\n\n>>> ## in fact, another primary use of pseudomethod is to flatten ugly, hard-to-read, lisp-like nested function calls\n>>> print( dict( enumerate( zip( 'abc',  sorted( 'abc bca cab'.split(' '), key = lambda x: x[1] ) ) ) ) )\n{0: ('a', 'cab'), 1: ('b', 'abc'), 2: ('c', 'bca')}\n\n>>> 'abc bca cab'.split(' ') ..sorted(key = lambda x: x[1]) ...zip('abc') ..enumerate() ..dict() ..print()\n{0: ('a', 'cab'), 1: ('b', 'abc'), 2: ('c', 'bca')}\n\n\n\n>>> ## IMPORT MODULES WRITTEN WITH PSEUDOMETHOD SYNTAX\n>>> ## create test_module.py\n>>> open('test_module.py', 'w').write('\"hello\" ..print()\\n') ..print('bytes written')\n18 bytes written\n\n>>> ## during import, insert the magic prefix 'pseudosugar.' before the last module\n>>> ## import pseudosugar.a\n>>> ## import a.pseudosugar.b\n>>> ## import a.b.pseudosugar.c\n>>> import pseudosugar.test_module\nhello"}}, {"pk": 19, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "edrn.theme", "license": "Proprietary", "author": "Andrew Hart", "author_email": "andrew.hart@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/edrn-theme", "version": "1.0.3", "platform": "UNKNOWN", "keywords": "web zope plone theme edrn cancer biomarkers", "summary": "Look and feel for websites of the Early Detection Research Network (EDRN).", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Software Development :: User Interfaces", "description": "**********\nedrn.theme\n**********\n\nThis is the basic look-and-feel for websites for the Early Detection Research\nNetwork (EDRN_), which loosely follows the style of the National Cancer\nInstitute (NCI_).  It was developed by the Informatics Center (IC_), operated\nby JPL_.\n\nAlthough intended for the EDRN public portal, this package may be used in any\nPlone_ 3 (or later) site.\n\n.. References:\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _IC: http://cancer.jpl.nasa.gov/\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://www.cancer.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``edrn.theme`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        edrn.theme\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        edrn.theme\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.  For issue IDs\nmentioned below, you can learn more about them by visiting the issue tracker\nat https://oodt.jpl.nasa.gov/jira/browse/CA.\n\n\n1.0.3 - Dark, Darker, Darko\n---------------------------\n\nThe only issue addressed this time 'round is:\n\n* CA-729 - Change the color of the hyperlinks on the Public Portal\n\n\n1.0.2 - The Little Dutch Boy\n----------------------------\n\nThe only issue addressed by this release is:\n\n* CA-632 - Portal 3 leaks memory?\n\n\n1.0.1 - Anal Retentiveness\n--------------------------\n\nThe only issue addressed by this release is:\n\n* CA-529 - Remove \"Valid XHTML\" and \"Valid CSS\" links\n\n\n1.0.0 - Fantasizing on Facetizing\n---------------------------------\n\nAfter being in production for several months we've decided to call it version\n1 at last.  However, this release also adds styling for future faceted\nnavigation features.  It also adds styling and imagery for the Members List\nbutton for the QuickLinks portlet.\n\nIt also addresses the following issues:\n\n* CA-642 - Create a new member page\n* CA-666 - Sites Page clean up\n\nYou can learn more about this issue by visiting the Informatics Center's issue\ntracker at https://oodt.jpl.nasa.gov/jira/browse/CA.\n\n\n0.0.6 - The Eleventh Hour\n-------------------------\n\nAfter viewing the new look-and-feel for EDRN across a variety of applications,\nmanagement suddenly realizes they don't like it.  This release attempts to\nsatisfy them.  See https://oodt.jpl.nasa.gov/jira/browse/CA-599 as well as\nhttps://oodt.jpl.nasa.gov/jira/browse/CA-600 for more details.\n\n\n0.0.5 - Unknown release\n-----------------------\n\nIt's a myyyyssteeeerrry!\n\n\n0.0.4 - Small Screens Welcome\n-----------------------------\n\nThe following issues have been addressed in this release:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-477 - Portal requires screen width\n  of 1280 to display all content\n* http://oodt.jpl.nasa.gov/jira/browse/CA-497 - Search results appearing as\n  separated from search result facet links\n\n\n0.0.3 - Quicklinks Portlet Look and Feel\n----------------------------------------\n\nThe following issues have been addressed in this release:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-466 - Change order of links on the\n  left side menu of the portal\n\n\n0.0.2 - Modernization and Metadata\n----------------------------------\n\n* Copious work by Andrew Hart to further modernize the look and feel for EDRN.\n* Updated project metadata.\n\n\n0.0.1 - FCS\n-----------\n\nThis is a first customer ship, though it should be considered a work in\nprogress.\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release.\n\n\nCopyright\n=========\n\nCopyright 2008-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 20, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "eke.knowledge", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/eke-knowledge", "version": "0.0.3", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers eke knowledge", "summary": "EDRN Knowledge Environment", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "*************\neke.knowledge\n*************\n\nThis product, ``eke.knowledge``, provides the basis for the Early Detection\nResearch Network (EDRN_) Knowledge Environment (EKE_).  EDRN uses the EKE to\nmake it easy to discover, share, search for, and retrieve all of EDRN's\ncollective knowledge, including cancers and other diseases, biomarkers,\npublications, specimens, investigators, participants, studies, protocols, and\neven more.\n\nAlthough intended for the EDRN public portal, it can be installed in any\nPlone_ compatible site.\n\nThis software is developed by the `EDRN Informatics Center`_  at JPL_,\noperated by the California Institute of Technology, for NCI_.\n\n.. References:\n.. _EDRN Informatics Center: http://cancer.jpl.nasa.gov/\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _EKE: http://cancer.jpl.nasa.gov/documents/applications/knowledge-environment\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://cancer.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``eke.knowledge`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        eke.knowledge\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        eke.knowledge\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.\n\n0.0.3 - Markup Toggling\n-----------------------\n\nThis release addresses the only issue below:\n\n* CA-733 - Ingest of science data should treat custodian field as plain text,\n  not marked up HTML\n\n\n0.0.2 - Defensive Ingest\n------------------------\n\nThis releases addresses the following issue:\n\n* https://oodt.jpl.nasa.gov/jira/browse/CA-571 - Make RDF ingest defensive\n  against inconsistent data\n\n\n0.0.1 - HTML Escaping\n---------------------\n\nThe sole issue addressed in this release is the following:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-472 - Protocols and other items seem\n  to still have encoded ASCII characters in the titles\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 21, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PMV", "license": "", "author": "", "author_email": "", "project_url": null, "maintainer_email": "", "home_page": "http://mgltools.scripps.edu", "version": "1.4.4", "platform": "", "keywords": "", "summary": "Python Molecular Viewer", "classifiers": "Topic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Scientific/Engineering :: Visualization", "description": "PMV is a powerful molecular viewer that has a number of customizable features\r\nand comes with many pluggable commands ranging from displaying molecular surface\r\nto running molecular dynamics simulation and energy minimization calculations."}}, {"pk": 22, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Shapely", "license": "BSD", "author": "Sean Gillies", "author_email": "sean.gillies@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/lab/wiki/Shapely", "version": "1.2.9", "platform": "UNKNOWN", "keywords": "geometry topology gis", "summary": "Geometric objects, predicates, and operations", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "======\nREADME\n======\n\n.. image:: http://farm3.static.flickr.com/2738/4511827859_b5822043b7_o_d.png\n   :width: 800\n   :height: 400\n\nShapely is a BSD-licensed Python package for manipulation and analysis of\nplanar geometric objects. It is not concerned with data formats or coordinate\nsystems.  It is based on the widely deployed GEOS_ (the engine of PostGIS_) and\nJTS_ (from which GEOS is ported) libraries. This C dependency is traded for the\nability to execute with blazing speed.\n\nIn a nutshell: Shapely lets you do PostGIS-ish stuff outside the context of a\ndatabase using idiomatic Python. For more details, see:\n\n* Shapely wiki_\n* Shapely manual_\n* Shapely `example apps`_\n\nDependencies\n------------\n\nShapely 1.2 depends on:\n\n* Python >=2.5,<3\n* libgeos_c >=3.1 (3.0 and below have not been tested, YMMV)\n\nInstallation\n------------\n\nWindows users should use the executable installer, which contains the required\nGEOS DLL. Other users should acquire libgeos_c by any means, make sure that it\nis on the system library path, and install from the Python package index::\n\n  $ pip install Shapely\n\nor from a source distribution with the setup script::\n\n  $ python setup.py install\n\nUsage\n-----\n\nHere is the canonical example of building an approximately circular patch by\nbuffering a point::\n\n  >>> from shapely.geometry import Point\n  >>> patch = Point(0.0, 0.0).buffer(10.0)\n  >>> patch\n  <shapely.geometry.polygon.Polygon object at 0x...>\n  >>> patch.area\n  313.65484905459385\n\nSee the manual_ for comprehensive usage snippets and the dissolve.py and\nintersect.py `example apps`_.\n\nIntegration \n-----------\n\nShapely does not read or write data files, but it can serialize and deserialize\nusing several well known formats and protocols. The shapely.wkb and shapely.wkt\nmodules provide dumpers and loaders inspired by Python's pickle module.::\n\n  >>> from shapely.wkt import dumps, loads\n  >>> dumps(loads('POINT (0 0)'))\n  'POINT (0.0000000000000000 0.0000000000000000)'\n\nAll linear objects, such as the rings of a polygon (like ``patch`` above),\nprovide the Numpy array interface.::\n\n  >>> from numpy import asarray\n  >>> ag = asarray(patch.exterior)\n  >>> ag\n  array([[  1.00000000e+01,   0.00000000e+00],\n         [  9.95184727e+00,  -9.80171403e-01],\n         [  9.80785280e+00,  -1.95090322e+00],\n         ...\n         [  1.00000000e+01,   0.00000000e+00]])\n\nThat yields a numpy array of [x, y] arrays. This is not always exactly what one\nwants for plotting shapes with Matplotlib, so Shapely 1.2 adds a `xy` property\nfor getting separate arrays of coordinate x and y values.::\n\n  >>> x, y = patch.exterior.xy\n  >>> ax = asarray(x)\n  >>> ax\n  array([  1.00000000e+01,   9.95184727e+00,   9.80785280e+00,  ...])\n\nNumpy arrays can also be adapted to Shapely linestrings::\n\n  >>> from shapely.geometry import asLineString\n  >>> asLineString(ag).length\n  62.806623139095073\n  >>> asLineString(ag).wkt\n  'LINESTRING (10.0000000000000000 0.0000000000000000, ...)'\n\nTesting\n-------\n\nShapely uses a Zope-stye suite of unittests and doctests, excercised via\nsetup.py.::\n\n  $ python setup.py test\n\nNosetests won't run the tests properly; Zope doctest suites are not currently\nsupported well by nose.\n\nSupport\n-------\n\nFor current information about this project, see the wiki_.\n\nIf you have questions, please consider joining our community list:\n\nhttp://trac.gispython.org/projects/PCL/wiki/CommunityList\n\nCredits\n-------\n\nShapely is written by:\n\n* Sean Gillies\n* Aron Bierbaum\n* Kai Lautaportti\n\nPatches contributed by:\n\n* Howard Butler\n* Fr |eaigue| d |eaigue| ric Junod\n* Eric Lemoine\n* Jonathan Tartley\n* Kristian Thy\n* Oliver Tonnhofer\n\nAdditional help from:\n\n* Justin Bronn (GeoDjango) for ctypes inspiration\n* Martin Davis (JTS)\n* Jaakko Salli for the Windows distributions\n* Sandro Santilli, Mateusz Loskot, Paul Ramsey, et al (GEOS Project)\n\nMajor portions of this work were supported by a grant (for Pleiades_) from the\nU.S. National Endowment for the Humanities (http://www.neh.gov).\n\n.. _JTS: http://www.vividsolutions.com/jts/jtshome.htm\n.. _PostGIS: http://postgis.org\n.. _GEOS: http://trac.osgeo.org/geos/\n.. _example apps: http://trac.gispython.org/lab/wiki/Examples\n.. _wiki: http://trac.gispython.org/lab/wiki/Shapely\n.. _manual: http://gispython.org/shapely/docs/1.2\n.. |eaigue| unicode:: U+00E9\n   :trim:\n.. _Pleiades: http://pleiades.stoa.org\n\n=======\nCHANGES\n=======\n\n1.2.9 (2011-03-31)\n------------------\n- Remove extra glob import.\n- Move examples to shapely.examples.\n- Add box() constructor for rectangular polygons.\n- Fix extraneous imports.\n\n1.2.8 (2011-12-03)\n------------------\n- New parallel_offset method (#6).\n- Support for Python 2.4.\n\n1.2.7 (2010-11-05)\n------------------\n- Support for Windows eggs.\n\n1.2.6 (2010-10-21)\n------------------\n- The geoms property of an empty collection yields [] instead of a ValueError\n  (#3).\n- The coords and geometry type sproperties have the same behavior as above.\n- Ensure that z values carry through into products of operations (#4).\n\n1.2.5 (2010-09-19)\n------------------\n- Stop distributing docs/_build.\n- Include library fallbacks in test_dlls.py for linux platform.\n\n1.2.4 (2010-09-09)\n------------------\n- Raise AttributeError when there's no backend support for a method.\n- Raise OSError if libgeos_c.so (or variants) can't be found and loaded.\n- Add geos_c DLL loading support for linux platforms where find_library doesn't\n  work.\n\n1.2.3 (2010-08-17)\n------------------\n- Add mapping function.\n- Fix problem with GEOSisValidReason symbol for GEOS < 3.1.\n\n1.2.2 (2010-07-23)\n------------------\n- Add representative_point method.\n\n1.2.1 (2010-06-23)\n------------------\n- Fixed bounds of singular polygons.\n- Added shapely.validation.explain_validity function (#226).\n\n1.2 (2010-05-27)\n----------------\n- Final release.\n\n1.2rc2 (2010-05-26)\n-------------------\n- Add examples and tests to MANIFEST.in.\n- Release candidate 2.\n\n1.2rc1 (2010-05-25)\n-------------------\n- Release candidate.\n\n1.2b7 (2010-04-22)\n------------------\n- Memory leak associated with new empty geometry state fixed.\n\n1.2b6 (2010-04-13)\n------------------\n- Broken GeometryCollection fixed.\n\n1.2b5 (2010-04-09)\n------------------\n- Objects can be constructed from others of the same type, thereby making\n  copies. Collections can be constructed from sequences of objects, also making\n  copies.\n- Collections are now iterators over their component objects.\n- New code for manual figures, using the descartes package.\n\n1.2b4 (2010-03-19)\n------------------\n- Adds support for the \"sunos5\" platform.\n\n1.2b3 (2010-02-28)\n------------------\n- Only provide simplification implementations for GEOS C API >= 1.5.\n\n1.2b2 (2010-02-19)\n------------------\n- Fix cascaded_union bug introduced in 1.2b1 (#212).\n\n1.2b1 (2010-02-18)\n------------------\n- Update the README. Remove cruft from setup.py. Add some version 1.2 metadata\n  regarding required Python version (>=2.5,<3) and external dependency\n  (libgeos_c >= 3.1).\n\n1.2a6 (2010-02-09)\n------------------\n- Add accessor for separate arrays of X and Y values (#210).\n\nTODO: fill gap here\n\n1.2a1 (2010-01-20)\n------------------\n- Proper prototyping of WKB writer, and avoidance of errors on 64-bit systems\n  (#191).\n- Prototype libgeos_c functions in a way that lets py2exe apps import shapely\n  (#189).\n\n=========================\n1.2 Branched (2009-09-19)\n=========================\n\n1.0.12 (2009-04-09)\n-------------------\n- Fix for references held by topology and predicate descriptors.\n\n1.0.11 (2008-11-20)\n-------------------\n- Work around bug in GEOS 2.2.3, GEOSCoordSeq_getOrdinate not exported properly\n  (#178).\n\n1.0.10 (2008-11-17)\n-------------------\n- Fixed compatibility with GEOS 2.2.3 that was broken in 1.0.8 release (#176).\n\n1.0.9 (2008-11-16)\n------------------\n- Find and load MacPorts libgeos.\n\n1.0.8 (2008-11-01)\n------------------\n- Fill out GEOS function result and argument types to prevent faults on a\n  64-bit arch.\n\n1.0.7 (2008-08-22)\n------------------\n- Polygon rings now have the same dimensions as parent (#168).\n- Eliminated reference cycles in polygons (#169).\n\n1.0.6 (2008-07-10)\n------------------\n- Fixed adaptation of multi polygon data.\n- Raise exceptions earlier from binary predicates.\n- Beginning distributing new windows DLLs (#166).\n\n1.0.5 (2008-05-20)\n------------------\n- Added access to GEOS polygonizer function.\n- Raise exception when insufficient coordinate tuples are passed to LinearRing\n  constructor (#164).\n\n1.0.4 (2008-05-01)\n------------------\n- Disentangle Python and topological equality (#163).\n- Add shape(), a factory that copies coordinates from a geo interface provider.\n  To be used instead of asShape() unless you really need to store coordinates\n  outside shapely for efficient use in other code.\n- Cache GEOS geometries in adapters (#163).\n\n1.0.3 (2008-04-09)\n------------------\n- Do not release GIL when calling GEOS functions (#158).\n- Prevent faults when chaining multiple GEOS operators (#159).\n\n1.0.2 (2008-02-26)\n------------------\n- Fix loss of dimensionality in polygon rings (#155).\n\n1.0.1 (2008-02-08)\n------------------\n- Allow chaining expressions involving coordinate sequences and geometry parts\n  (#151).\n- Protect against abnormal use of coordinate accessors (#152).\n- Coordinate sequences now implement the numpy array protocol (#153).\n\n1.0 (2008-01-18)\n----------------\n- Final release.\n\n1.0 RC2 (2008-01-16)\n--------------------\n- Added temporary solution for #149.\n\n1.0 RC1 (2008-01-14)\n--------------------\n- First release candidate"}}, {"pk": 23, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ICP", "license": "Python Software Foundation License", "author": "Avinash Kak", "author_email": "kak@purdue.edu", "project_url": null, "maintainer_email": null, "home_page": "http://RVL4.ecn.purdue.edu/~kak/distICP/ICP-1.1.html", "version": "1.1", "platform": "All platforms", "keywords": "image processing,image registration,computer vision", "summary": "An algorithm for registering a camera image with a database image", "classifiers": "Topic :: Scientific/Engineering :: Image Recognition", "description": "This module is a pure-Python implementation of the Iterative \nClosest Point algorithm for registering a camera image with a \ndatabase image.  \n\nAn application scenario would be the registration of an\nimage recorded by a UAV-mounted camera flying over a terrain\nwith an image extracted from GIS (Geographical Information\nSystem) database.\n\nVersion 1.1 includes a new option for the constructor that\nlets the system decide as to which image to use as the model\nand which image as the data.  In general, for color and\ngrayscale images, you get superior registration if the image\nthat results in fewer pixels for ICP processing is used as\nthe data image.\n\nTypical usage syntax:\n\n        import ICP  \n        icp = ICP( \n               model_image = \"modelterrain.jpg\",\n               data_image = \"cameraimage.jpg\",\n               binary_or_color = \"color\",\n               iterations = 40,\n               connectivity_threshold = 5,\n               output_image_size = 100,\n               display_step = 1,\n               debug = 1 )\n        icp.icp()\n        icp.display_results()\n\n    The module also includes a static method gendata() to illustrate how\n    one can create simple synthetic images to experiment with the code.\n    A call to this method looks like\n\n        import ICP\n        ICP.ICP.gendata(\"triangle\", (80,80), (10,10), 30, \"newtriangle2.jpg\" )\n\n    for creating an 80x80 image of a triangle whose position offset is (10,10)\n    and whose orientation is 30 degrees."}}, {"pk": 24, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.iris", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.7", "platform": "OS Independent", "keywords": "ObsPy,seismology,IRIS,Waveform", "summary": "IRIS web service client for ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.iris package contains a client for the DMC Web Services provided by\nIRIS (http://www.iris.edu/ws/). \n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology. \n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 25, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "collective.geo.kml", "license": "GPL", "author": "Giorgio Borelli", "author_email": "giorgio@giorgioborelli.it", "project_url": null, "maintainer_email": null, "home_page": "https://svn.plone.org/svn/collective/collective.geo.kml", "version": "0.2.2", "platform": "UNKNOWN", "keywords": "Zope Plone GIS KML Google Maps Bing Yahoo OpenLayers", "summary": "Kml view for collective.geo", "classifiers": "Framework :: Plone\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering :: GIS", "description": "collective.geo.kml\n==================\n\n.. contents:: Summary\n   :local:\n\nIntroduction\n------------\n\ncollective.geo.kml provides KML views for georeferenced objects, allowing Plone containers and collections to be visualized in Google Earth.\n\nIt also provides a map view to Plone Folder and Topic content types to display kml data.\n\nRequirements\n------------\n* Plone >= 4.0\n* collective.geo.geographer\n* collective.geo.mapwidget\n\nInstallation\n------------\nYou can install collective.geo.kml as part of a specific project's buildout, by having a buildout configuration such as: ::\n\n        [buildout]\n        ...\n        eggs = \n            collective.geo.kml\n        ...\n        [instance]\n        ...\n        zcml = \n            collective.geo.kml\n\n\nContributors\n------------\n\n* Sean Gillies \n* Giorgio Borelli\n* Silvio Tomatis\n* David Breitkreutz, rockdj\n\n\nChangelog\n=========\n\n0.2.2 (2011-02-20)\n------------------\n\n- added zoomToExtent to kml layer\n\n\n0.2.1 (2010-12-28)\n------------------\n\n- fixed UnicodeDecodeError in maplayers [gborelli]\n- Added dutch translations [robgietema]\n\n\n\n0.2 (2010-10-31)\n----------------\n* Removed zgeo.kml dependency\n* Removed Large Plone Folder configurations\n* Added ability to select what content properties to display either in the \n  Control Panel or on a per-content basis.  Properties can be changed at will\n  and likewise reordered as required.\n  [rockdj]\n* Display a Collection's saved rich text on the KML view, if it exists.\n  [rockdj]\n* Retrieve default customised styles from those set in the site's control\n  panel.\n  [rockdj]\n* Moved the link to the given content in the KML view to be the title.\n  [rockdj]\n* Added further unit tests to test the KML document view (in conjunction with\n  testing customised styles)\n  [rockdj]\n* Added ability to display custom styles for content in the KML-openlayers\n  view, with the styles managed through the relevant annotation.\n  [rockdj]\n* Added standard above-content elements to the KML-openlayers view\n  (byline, description, etc).\n  [rockdj]\n* Updated the kml_openlayers.js Javascript to handle the case of\n  accessing the KML-openlayers view directly.\n  [rockdj]\n* Changed KML links to content to point to the content's *View* action\n  if their portal type is set that way in the Site Properties.  This\n  follows in the same manner as views like the Folder Summary View.\n  [rockdj]\n* Added *dc* object to BrainPlacemark to allow access to original \n  content item in KML view.  This allows direct access to the content's\n  methods and properties (eg for image display, see below)\n  [rockdj]\n* Allowed KML feature/placemark description to display image thumbnail\n  if the content possesses such (eg Images and News Items).  Images are\n  displayed in same style as that of the Folder Summary View.\n  [rockdj]\n* Added extra metadata into KML feature/placemark output (item type, \n  modification date, creation date)\n  [rockdj]\n* Changed KML output to exclude feature/placemark description tag\n  on no content description being present.\n  [rockdj]\n* Added uninstall GenericSetup profile\n  [rockdj]\n* Added action for downloading KML to desktop (for Google Earth or \n  other applications)\n  [rockdj]\n* Added ability to set marker image size in control panel\n  [rockdj]\n* Allowed for marker image not have to be in the hard-coded /img/ directory.\n  This allows for custom markers to be specified anywhere in Plone.\n  img/marker.png is set as default to keep things the same.\n  [rockdj]\n* Changed linewidth to be able to accept float values.\n  [rockdj]\n* Integrated zgeo.plone.kml package.\n* Updated the kml_openlayers.js Javascript to use the current URL's\n  context to access @@kml-document.  Accessing this in a relative manner\n  represents problems for URLs being rewritten in a proxy (eg Deliverance).\n  [rockdj]\n* Renamed Kml Layer\n\n0.1 (2009-06-19)\n----------------\n\n* Initial release"}}, {"pk": 26, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nitime", "license": "Simplified BSD", "author": "Nipy Developers", "author_email": "nipy-devel@neuroimaging.scipy.org", "project_url": null, "maintainer_email": null, "home_page": "http://nipy.org/nitime", "version": "0.2", "platform": "OS Independent", "keywords": null, "summary": "Nitime: timeseries analysis for neuroscience data", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "===================================================\n Nitime: timeseries analysis for neuroscience data\n===================================================\n\nNitime contains a core of numerical algorithms for time-series analysis both in\nthe time and spectral domains, a set of container objects to represent\ntime-series, and auxiliary objects that expose a high level interface to the\nnumerical machinery and make common analysis tasks easy to express with compact\nand semantically clear code.\n\nWebsite\n=======\n\nCurrent information can always be found at the NIPY website is located\nhere::\n\n    http://nipy.org/nitime\n\nMailing Lists\n=============\n\nPlease see the developer's list here::\n\n    http://mail.scipy.org/mailman/listinfo/nipy-devel\n\nCode\n====\n\nYou can find our sources and single-click downloads:\n\n* `Main repository`_ on Github.\n* Documentation_ for all releases and current development tree.\n* Download as a tar/zip file the `current trunk`_.\n* Downloads of all `available releases`_.\n\n.. _main repository: http://github.com/nipy/nitime\n.. _Documentation: http://nipy.org/nitime\n.. _current trunk: http://github.com/nipy/nitime/archives/master\n.. _available releases: http://github.com/nipy/nitime/downloads\n\n       \nLicense information\n===================\n\nNitime is licensed under the terms of the new BSD license. See the file\n\"LICENSE\" for information on the history of this software, terms & conditions\nfor usage, and a DISCLAIMER OF ALL WARRANTIES.\n\nAll trademarks referenced herein are property of their respective holders.\n\nCopyright (c) 2006-2010, NIPY Developers\nAll rights reserved."}}, {"pk": 27, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "garlicsim_py3", "license": "LGPL v2.1", "author": "Ram Rachum", "author_email": "cool-rr@cool-rr.com", "project_url": null, "maintainer_email": null, "home_page": "http://garlicsim.org", "version": "0.6.2", "platform": "UNKNOWN", "keywords": null, "summary": "Pythonic framework for working with simulations", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nProgramming Language :: Python :: 3.2\nTopic :: Scientific/Engineering", "description": "GarlicSim is a platform for writing, running and analyzing simulations. It can\nhandle any kind of simulation: Physics, game theory, epidemic spread,\nelectronics, etc.\n\nVisit http://garlicsim.org for more info."}}, {"pk": 28, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "hygdas", "license": "GNU General Public License version 3", "author": "Maurice HT Ling", "author_email": "mauriceling@acm.org", "project_url": null, "maintainer_email": null, "home_page": "http://hygdas.sourceforge.net", "version": "0.0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Hypergraph Database Management System", "classifiers": "Development Status :: 1 - Planning\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Database Engines/Servers\nTopic :: Scientific/Engineering", "description": "HygDAS is a database management system based on \n      graph/hypergraph model as the underlying data model. At the lowest end of \n      a hypergraph-based model is a set of primitive nodes and its attributes \n      (data values). Primitive nodes can related to each other via edges (with \n      relevant attributes). Primitive nodes can also be aggregated into a set of\n      nodes, known as hypernodes, which can be linked to eachother via edges \n      (with relevant attributes). Related edges can be aggregated into a set of \n      edges, known as hyperedge."}}, {"pk": 29, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.talkbox", "license": "MIT", "author": "UNKNOWN", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "0.2.5", "platform": "UNKNOWN", "keywords": null, "summary": "Talkbox, a set of python modules for speech/signal processing", "classifiers": "Development Status :: 1 - Planning\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": "Talkbox, to make your numpy environment speech aware !\n\nTalkbox is set of python modules for speech/signal processing. The goal of this\ntoolbox is to be a sandbox for features which may end up in scipy at some\npoint. The following features are planned before a 1.0 release:\n\n    * Spectrum estimation related functions: both parametic (lpc, high\n    resolution methods like music and co), and non-parametric (Welch,\n    periodogram)\n    * Fourier-like transforms (DCT, DST, MDCT, etc...)\n    * Basic signal processing tasks such as resampling\n    * Speech related functionalities: mfcc, mel spectrum, etc..\n    * More as it comes\n\nI want talkbox to be useful for both research and educational purpose. As such,\na requirement is to have a pure python implementation for everything - for\neducational purpose and reproducibility - and optional C for speed."}}, {"pk": 30, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pygr", "license": "New BSD License", "author": "Christopher Lee", "author_email": "leec@chem.ucla.edu", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/pygr/", "version": "0.8.1", "platform": "UNKNOWN", "keywords": "", "summary": "Pygr, a Python graph-database toolkit oriented primarily on bioinformatics applications", "classifiers": "Development Status :: 5 - Production/Stable\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows :: Windows NT/2000\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "Pygr\r\n====\r\n\r\nPygr is an open source software project used to develop graph database \r\ninterfaces for the popular Python language, with a strong emphasis \r\non bioinformatics applications ranging from genome-wide analysis of \r\nalternative splicing patterns, to comparative genomics queries of \r\nmulti-genome alignment data."}}, {"pk": 31, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.handlers.cdms", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/handlers.html#cdms", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "GrADS grib ctl cdms opendap dods dap data science climate oceanography meteorology", "summary": "GrADS/grib handler for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This handler enables Pydap to serve GrADS gribbed files on the\nnetwork for Opendap clients."}}, {"pk": 32, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "metascript", "license": "UNKNOWN", "author": "Michael Hoffman", "author_email": "hoffman@ebi.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://www.ebi.ac.uk/~hoffman/software/metascript/", "version": "0.1.1", "platform": "UNKNOWN", "keywords": null, "summary": "Metascript retrieval and processing", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "UNKNOWN"}}, {"pk": 33, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "ffnet", "license": "GPL", "author": "Marek Wojciechowski", "author_email": "mwojc@p.lodz.pl", "project_url": null, "maintainer_email": "", "home_page": "http://ffnet.sourceforge.net", "version": "0.6.2", "platform": "Posix,Windows", "keywords": "neural network, neural networks, ann, python, fortran, f2py, feed-forward, feed forward", "summary": "Feed-forward neural network for python", "classifiers": "Development Status :: 4 - Beta\nOperating System :: OS Independent\nProgramming Language :: Fortran\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence", "description": "ffnet is a fast and easy-to-use feed-forward neural\r\nnetwork training solution for python.\r\n\r\nUnique features\r\n---------------\r\n1. Any network connectivity without cycles is allowed.\r\n2. Training can be performed with use of several optimization \r\n   schemes including: standard backpropagation with momentum, rprop,\r\n   conjugate gradient, bfgs, tnc, genetic alorithm based optimization.\r\n3. There is access to exact partial derivatives of network outputs \r\n   vs. its inputs.\r\n4. Automatic normalization of data.\r\n\r\nBasic assumptions and limitations:\r\n----------------------------------\r\n1. Network has feed-forward architecture.\r\n2. Input units have identity activation function, \r\n   all other units have sigmoid activation function.\r\n3. Provided data are automatically normalized, both input and output, \r\n   with a linear mapping to the range (0.15, 0.85).\r\n   Each input and output is treated separately (i.e. linear map is \r\n   unique for each input and output).\r\n4. Function minimized during training is a sum of squared errors \r\n   of each output for each training pattern.\r\n   \r\nPerformance\r\n-----------\r\nExcellent computational performance is achieved implementing core\r\nfunctions in fortran 77 and wrapping them with f2py. ffnet outstands\r\nin performance pure python training packages and is competitive to\r\n'compiled language' software. Moreover, a trained network can be \r\nexported to fortran sources, compiled and called from many\r\nprogramming languages.\r\n\r\nUsage\r\n-----\r\nBasic usage of the package is outlined below:\r\n\r\n>>> from ffnet import ffnet, mlgraph, savenet, loadnet, exportnet\r\n>>> conec = mlgraph( (2,2,1) )\r\n>>> net = ffnet(conec)\r\n>>> input = [ [0.,0.], [0.,1.], [1.,0.], [1.,1.] ]\r\n>>> target  = [ [1.], [0.], [0.], [1.] ]\r\n>>> net.train_tnc(input, target, maxfun = 1000)\r\n>>> net.test(input, target, iprint = 2)\r\n>>> savenet(net, \"xor.net\")\r\n>>> exportnet(net, \"xor.f\")\r\n>>> net = loadnet(\"xor.net\")\r\n>>> answer = net( [ 0., 0. ] )\r\n>>> partial_derivatives = net.derivative( [ 0., 0. ] )\r\n\r\nUsage examples with full description can be found in \r\nexamples directory of the source distribution or browsed\r\nat http://ffnet.sourceforge.net."}}, {"pk": 34, "model": "importing.pypicache", "fields": {"maintainer": "Aaron Garrett", "name": "ecspy", "license": "GNU General Public License version 3.0", "author": "Aaron Garrett", "author_email": "aaron.lee.garrett@gmail.com", "project_url": null, "maintainer_email": "aaron.lee.garrett@gmail.com", "home_page": "http://ecspy.googlecode.com", "version": "0.7", "platform": "", "keywords": "evolutionary computation genetic algorithm particle swarm multiobjective nsga", "summary": "Evolutionary Computations in Python", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Manufacturing\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Artificial Intelligence", "description": "ECsPy (Evolutionary Computations in Python) is a free, open source framework for \r\ncreating evolutionary computations in Python. Additionally, ECsPy provides an \r\neasy-to-use canonical genetic algorithm (GA), evolution strategy (ES), \r\nestimation of distribution algorithm (EDA), differential evolution algorithm \r\n(DEA), and particle swarm optimizer (PSO) for users who don't need much \r\ncustomization. Please see the full `documentation \r\n<http://mcis.jsu.edu/faculty/agarrett/ecspy>`_ for more information.\r\n\r\nUsage Example\r\n-------------\r\n\r\n::\r\n\r\n    from random import Random\r\n    from time import time\r\n    from ecspy import ec\r\n    from ecspy import terminators\r\n    from ecspy import observers\r\n\r\n\r\n    def generate_binary(random, args):\r\n        bits = args.get('num_bits', 8)\r\n        return [random.choice([0, 1]) for i in xrange(bits)]\r\n        \r\n    def evaluate_binary(candidates, args):\r\n        fitness = []\r\n        base = args.get('base', 2)\r\n        for cand in candidates:\r\n            num = 0\r\n            exp = len(cand) - 1\r\n            for c in cand:\r\n                num += c * (base ** exp)\r\n                exp -= 1\r\n            fitness.append(num)\r\n        return fitness\r\n\r\n    rand = Random()\r\n    rand.seed(int(time()))\r\n    ga = ec.GA(rand)\r\n    ga.observer = observers.screen_observer\r\n    ga.terminator = terminators.evaluation_termination\r\n    final_population = ga.evolve(evaluator=evaluate_binary,\r\n                                 generator=generate_binary,\r\n                                 max_evaluations=1000,\r\n                                 num_elites=1,\r\n                                 pop_size=100,\r\n                                 num_bits=10)\r\n    for individual in final_population:\r\n        print(individual)"}}, {"pk": 35, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.neries", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.7", "platform": "OS Independent", "keywords": "ObsPy,seismology,NERIES,Waveform,events,earthquakes", "summary": "NERIES web service client for ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.neries package contains a client for the Seismic Data Portal which was\ndeveloped under the European Commission-funded NERIES project. The Portal\nprovides a single point of access to diverse, distributed European earthquake\ndata provided in a unique joint initiative by observatories and research\ninstitutes in and around Europe.\n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology. \n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 36, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MapProxy", "license": "GNU Affero General Public License v3 (AGPLv3)", "author": "Oliver Tonnhofer", "author_email": "olt@omniscale.de", "project_url": null, "maintainer_email": null, "home_page": "http://mapproxy.org", "version": "1.0.1", "platform": "UNKNOWN", "keywords": null, "summary": "An accelerating proxy for web map services", "classifiers": "Development Status :: 5 - Production/Stable\nLicense :: OSI Approved :: GNU Affero General Public License v3\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Internet :: Proxy Servers\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering :: GIS", "description": "MapProxy is an open source proxy for geospatial data. It caches, accelerates and transforms data from existing map services and serves any desktop or web GIS client.\n\nMapProxy works like a simple tile cache, but also offers many new and innovative features like full support for WMS clients.\n\nMapProxy is actively developed and   supported by Omniscale, it is released under the GNU AGPL License 3.0, runs on Unix/Linux and Windows and is easy to install and to configure.\n\nGo to http://mapproxy.org/ for more information.\n\nThe documentation is available at: http://mapproxy.org/docs/latest/\n\nNote: The configuration format changed between 0.8.x and 0.9.x, so you have to make sure you configuration matches the new format if you're going to upgrade."}}, {"pk": 37, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "text-hr", "license": "UNKNOWN", "author": "Robert Lujo", "author_email": "trebor74hr@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/trebor74hr/text-hr/", "version": "0.17", "platform": "UNKNOWN", "keywords": null, "summary": "Morphological/Inflection/Lemmatization Engine for Croatian language, POS tagger, stopwords", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: Croatian\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP :: Indexing/Search\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Text Processing\nTopic :: Text Processing :: Indexing\nTopic :: Text Processing :: Linguistic", "description": "Morphological/Inflection/Lemmatization Engine for Croatian language\n===================================================================\n\"text-hr\" is Morphological/Inflectional/Lemmatization Engine for Croatian\nlanguage written in Python programming language. Includes stopwords and\nPart-Of-Speech tagging engine (POS tagging) based on inverse inflection\nalgorithm for detection.\n\nSince API is not freezed, this project is still in alpha.\n\nTAGS \n----\n    Croatian language, lemmatization, stemming, inflection, python, natural\n    language processing (NLP), Part-of-speech (POS) tagging, stopwords, inverse\n    inflection, morphological lexicon\n\n\nOZNAKE\n------\n    Hrvatski jezik, lematizacija, Python biblioteka, morfologija, infleksija,\n    obrnuta infleksija, prepoznavanje vrsta rije\u010di, ra\u010dunalna obrada govornog\n    jezika, zaustavne rije\u010di, morfolo\u0161ki leksikon\n\nAUTHOR\n======\nRobert Lujo, Zagreb, Croatia, find mail address in LICENCE\n\n\nFEATURES\n========\nTo name the most important:\n - inflection system - for producing all forms of one word\n - detection of word types (POS tagging) - from existing list of word forms\n - list of stopwords\n\nSystem is based on unicode strings, default codepage to convert from and to \nstring is cp-1250.\n\nCheck `Getting started`_.\n\nINSTALLATION\n============\nInstallation instructions - if you have installed pip package \nhttp://pypi.python.org/pypi/pip::\n\n    pip install text-hr\n\nIf not, then do it old-fashioned way:\n    - download zip from http://pypi.python.org/pypi/text-hr/\n    - unzip\n    - open shell\n    - go to distribution directory\n    - python setup.py install\n\n\nGETTING STARTED\n===============\nThere are three important parts that this project provides:\n - `Inflection system`_ - for producing all forms of one word\n - `Detection of word types (POS tagging)`_ - from existing list of word forms\n - `List of stopwords`_\n\nInflection system\n-----------------\nUsage example - start python shell::\n\n    >>> from text_hr import Verb\n    >>> v = Verb(\"platiti\")\n    >>> for k in sorted(v.forms.keys()):\n    ...     print k, v.forms[k]\n    ...\n    AOR/P/1 [u'platismo']\n    AOR/P/2 [u'platiste']\n    AOR/P/3 [u'plati\\u0161e']\n    AOR/S/1 [u'platih']\n    AOR/S/2 [u'plati']\n    AOR/S/3 [u'plati']\n    IMP/P/1 [u'platasmo', u'pla\\u0107asmo', u'platijasmo']\n    IMP/P/2 [u'plataste', u'pla\\u0107aste', u'platijaste']\n    IMP/P/3 [u'platahu', u'pla\\u0107ahu', u'platijahu']\n    ...\n    VA_PA//P_O+S+V+N [u'pla\\u0107eno']\n    X_INF// [u'platiti']\n    X_VAD_PAS// [u'plativ\\u0161i']\n    X_VAD_PRE// [u'plate\\u0107i']\n    X_VAD_PRE// [u'plate\\u0107i']\n\nDetection of word types (POS tagging)\n-------------------------------------\nTODO: to be done - check test_detect.txt for samples, and detect.py for the logic:\n\nFirst example in test_detect.txt::\n\n    >>> from text_hr.detect import WordTypeRecognizerExample\n    >>> def test_it(word_list, wt_filter=None, level=2):\n    ...     wdh = WordTypeRecognizerExample(word_list, silent=True)\n    ...     if not wt_filter is None:\n    ...         wdh.detect(wt_filter=wt_filter, level=level)  # e.g. wt_filter=[\"N\"]\n    ...     else:\n    ...         wdh.detect(level=level)  # all word types\n    ...     lines_file = LinesFile()\n    ...     wdh.dump_result(lines_file) # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n    ...     print \"\\n\".join(lines_file.lines)\n    ...     return wdh\n\n    >>> class LinesFile(object):\n    ...     def __init__(self):\n    ...         self.lines = []\n    ...     def write(self, s):\n    ...         self.lines.append(repr(s.rstrip()))\n\n    >>> word_list = [\n    ...   \"Broj    84\"\n    ... , \"broji   34\"\n    ... , \"Brojila  28\"\n    ... , \"broje   23\"\n    ... , \"broje\u0107i 22\"\n    ... , \"brojim   7\"\n    ... , \"brojimo  5\"\n    ... , \"broji\u0161   4\"\n    ... , \"brojahu  2\"\n    ... , \"broja\u0161e  1\"\n    ... , \"brojite  1\"\n    ... , \"-brijestovu 1\"\n    ... , \"brijestovi 1\"   #the only one checked with endswith, but all other will be checked with get_freq\n    ... , \"-brijestove 1\"\n    ... , \"-brijestova 1\"\n    ... ]\n\n    Lowest quality, but fastest\n    >>> wdh = test_it(word_list, level=4) # doctest: +ELLIPSIS\n    \" 10/  183 -> brojati              (u'V-XX_-_JATI-je\\\\u0107i-0') 84/broj,34/broji,23/broje,22/broje\\xe6i,7/brojim,5/brojimo,4/broji\\x9a,2/brojahu,1/brojite,1/broja\\x9ae\"\n\nList of stopwords\n-----------------\nIs located in std_words.txt, and you can read it directly from here\n\n    http://bitbucket.org/trebor74hr/text-hr/src/tip/text_hr/std_words.txt\n\nThe list can be updated like this::\n    \n    >>> import text_hr\n    >>> text_hr.dump_all_std_words()\n    Totaly 2904 word forms dumped to r:\\hg-clones\\python\\text-hr\\text_hr\\std_words.txt in codepage utf8\n\nIteration over all words goes like this::\n\n    from text_hr import get_all_std_words\n\n    for word_base, l_key, cnt, _suff_id, wform_key, wform in get_all_std_words():\n        print word_base, l_key, cnt, _suff_id, wform_key, wform\n\n\nFurther\n-------\nSince there is currently no good documentation, the best source of \nfurther information is by reading tests inside of modules and\ntests in tests directory (dev version). More information in `Running tests`_.\nYou can allways read a source.\n\n\nDOCUMENTATION\n=============\nCurrently there is no documentation. In progress ...\n\n\nSUPPORT\n=======\nSince this project is limited by my free time, support is limited. \n\n\nREPORT BUG OR REQUEST FEATURE\n-----------------------------\nIf you encounter bug, the best is to report it to the bitbucket web page\nhttp://bitbucket.org/trebor74hr/text-hr.\n\nIf there will be an interest for development for other inflection rich\nlanguages, I'd be glad to decouple language specific code and create new\nproject that will be capable to deal with multiple languages.\n\nThe best way to contact me is by mail (find in LICENCE).\n\nTODO list is in readme.txt (dev version).\n\n\nCONTRIBUTION\n============\nSince this project is not currently in the stable API phase, contribution\nshould wait for a while.\n\n\nRUNNING TESTS\n=============\nAll tests are doctests (not unittests). There are three type of tests in the\npackage: \n\n    1. doctests in each module - e.g. in verbs.py\n    2. doctests in tests/test_*.txt - only development version\n    3. tests which are not automatically compared - i.e. in special call mode\n       detect.py can produce output file which needs to be compared \n       manually with some existing file. Such test(s) are very slow. This needs\n       to be changed to be automatic.\n\nRunning each module directly will run 1. and 2. if running from development\nversion. To get development version\nTo use development version (http://bitbucket.org/trebor74hr/text-hr)::\n\n hg clone https://bitbucket.org/trebor74hr/text-hr\n\n\ncreate text_hr.pth in python site-packages directory with path to text-hr e.g.::\n\n    r:\\hg-clones\\python\\text-hr\n\nTo run all tests:\n    - go to tests directory\n    - run tests.py like (with sample output)::\n\n        > python tests.py\n        testing module   __init__\n        testing module   adjectives\n        ...\n        testing textfile R:\\hg-clones\\python\\text-hr\\tests\\test_adj.txt\n        ...\n        testing textfile R:\\hg-clones\\python\\text-hr\\tests\\test_verbs_type.txt\n  \nTo run tests for just one module:\n    - goto text_hr directory\n    - run tests by running module, e.g.::\n\n        > py pronouns.py\n        __main__: running doctests\n        ..\\tests\\test_pronouns.txt: running doctests\n\n    - in the case you're not running from dev version, you'll get output like\n      this::\n\n        > py pronouns.py\n        __main__: running doctests\n        ..\\tests\\test_pronouns.txt: Not found, skipping\n\nADDITIONAL\n==========\nMaster thesis pdf in Croatian (134 pages) with title::\n\n    Lociranje sli\u010dnih logi\u010dkih cjelina u tekstualnim \n    dokumentima na hrvatskome jeziku\n\ncan be found at:\n\n    http://bitbucket.org/trebor74hr/text-hr/downloads/magistarski-konacni.pdf\n\nTODO\n====\nvarious things, see readme.txt for details.\n\nCHANGES\n=======\n0.17 \n----\nulr1 100617 \n    - utf-8 setup \n\n0.16 \n----\nulr1 100617 \n    - master thesis pdf added to repository (in Croatian, 134 pages)\n\n0.15 \n----\nulr1 100617 \n    - minor changes\n\n0.14 \n----\nulr1 100617 \n    - beta release\n    - tags: lemmatization, stemming\n\n0.13 \n----\nulr1 100610:\n    - text_hr package reorganized (__init__.py with __all__ and imports ...)\n    - word_types.py removed\n    - std_words.txt\n\n0.12 \n----\nulr1 100608 :\n    - README\n    - enabled tests from tests.py for all \n    - enabled tests from directly from each modules\n\n0.11 \n----\nulr1 100607:\n    - recreated repo at bitbucket\n    - no .suff_registry.pickle and testing_*.out put in zip\n\n0.10\n----\nulr1 100605:\n    - first installable release"}}, {"pk": 38, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.component.loader", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.component.loader", "version": "3.3", "platform": "any", "keywords": "utility", "summary": "PyUtilib plugins for loading external packages", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "================================\npyutilib.component.loader README\n================================\n\nThis Python package includes plugins to support loading of \nPCA components from external Python packages and EGG files.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 39, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pandas", "license": "BSD", "author": "Wes McKinney", "author_email": "wesmckinn@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pandas.sourceforge.net", "version": "0.3.0", "platform": "any", "keywords": null, "summary": "Cross-section and time series data analysis toolkit", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nOperating System :: OS Independent\nProgramming Language :: Cython\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "pandas provides NumPy-based data structures and statistical tools for\ncommon time series and cross-sectional data sets. It is intended to\naccomplish the following:\n\n* Simplify working with possibly labeled 1, 2, and 3 dimensional\n  heterogeneous data sets commonly found in statistics, finance, and\n  econometrics.\n\n* Provide tools for working with dates, fixed-frequency custom date\n  ranges, and other necessary time series functionality\n\n* Provide IO utilities for getting data in and out of pandas\n\n* Implement common statistical and time series functionality with a\n  convenient interface, handling missing data and other common\n  problems associated with messy statistical data sets\n\nNote\n----\nWindows binaries built against NumPy 1.5.1"}}, {"pk": 40, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pygraphviz", "license": "BSD", "author": "Aric Hagberg", "author_email": "hagberg@lanl.gov", "project_url": null, "maintainer_email": null, "home_page": "http://networkx.lanl.gov/pygraphviz", "version": "1.1rc1", "platform": "Linux,Mac OSX", "keywords": "Networks,Graph Visualization,network,graph,graph drawing", "summary": "Python interface to Graphviz", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "A Python wrapper for the Graphviz Agraph data structure.\n\nPyGraphviz can be used to create and draw networks and graphs with Graphviz."}}, {"pk": 41, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "codetree", "license": "gpl", "author": "kai zhu", "author_email": "kaizhu256@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/codetree", "version": "2009.12.24.py3k.cpp", "platform": "UNKNOWN", "keywords": null, "summary": "codetree - directly hack compiled python code object", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "codetree - directly hack compiled python code object\n\n  REQUIRES PYTHON3.1\n\n  QUICK TEST: $ python3.1 setup.py build dev --quicktest\n\n  DESCRIPTION: codetree - directly hack compiled python code object\n\nSUMMARY:\ncodetree converts compiled python code objects into trees, which can be edited and recompiled\n\nRECENT CHANGELOG:\n20091224 - modularized package - fix install issues - added sdist check\n20091205 - moved source code to c++\n20091116 - package integrated\n\n  DEMO USAGE:\n\n>>> from codetree import *\n>>> ## source code\n>>> src = 'def foo(aa):\\n def closure():\\n  nonlocal aa\\n  aa += \"!\"\\n  print(aa)\\n return closure()\\nfoo(\"hello\")'; print( src )\ndef foo(aa):\n def closure():\n  nonlocal aa\n  aa += \"!\"\n  print(aa)\n return closure()\nfoo(\"hello\")\n\n>>> ## compile source code\n>>> codeobj = compile(src, '', 'exec')\n>>> exec( codeobj )\nhello!\n\n>>> ## convert code object into editable codetree\n>>> tree = codetree(codeobj)\n>>> for item in vars(tree).items(): print( item )\n('co_firstlineno', 1)\n('co_code', b'd\\x00\\x00\\x84\\x00\\x00Z\\x00\\x00e\\x00\\x00d\\x01\\x00\\x83\\x01\\x00\\x01d\\x02\\x00S')\n('co_freevars', [])\n('co_name', '<module>')\n('co_filename', '')\n('co_lnotab', b'\\t\\x06')\n('co_flags', 64)\n('co_nlocals', 0)\n('co_stacksize', 2)\n('co_argcount', 0)\n('co_cellvars', [])\n('co_kwonlyargcount', 0)\n('co_varnames', [])\n('co_names', ['foo'])\n\n>>> ## edit / compile / exec codetree\n>>> element, depth, index, subtree = tree.find('hello')\n>>> subtree[index] = 'goodbye'\n>>> exec( tree.compile() )\ngoodbye!\n\n>>> ## codetree structure\n>>> print( tree )\ncodetree(\n    co_argcount       0\n    co_kwonlyargcount 0\n    co_nlocals        0\n    co_stacksize      2\n    co_flags          64\n    co_code           b'd\\x00\\x00\\x84\\x00\\x00Z\\x00\\x00e\\x00\\x00d\\x01\\x00\\x83\\x01\\x00\\x01d\\x02\\x00S'\n    co_consts         \n                      codetree(\n                          co_argcount       1\n                          co_kwonlyargcount 0\n                          co_nlocals        2\n                          co_stacksize      2\n                          co_flags          3\n                          co_code           b'\\x87\\x00\\x00f\\x01\\x00d\\x01\\x00\\x86\\x00\\x00}\\x01\\x00|\\x01\\x00\\x83\\x00\\x00S'\n                          co_consts         \n                                            None\n                                            codetree(\n                                                co_argcount       0\n                                                co_kwonlyargcount 0\n                                                co_nlocals        0\n                                                co_stacksize      2\n                                                co_flags          19\n                                                co_code           b'\\x88\\x00\\x00d\\x01\\x007\\x89\\x00\\x00t\\x00\\x00\\x88\\x00\\x00\\x83\\x01\\x00\\x01d\\x00\\x00S'\n                                                co_consts         \n                                                                  None\n                                                                  !\n                                                co_names          ['print']\n                                                co_varnames       []\n                                                co_filename       ''\n                                                co_name           'closure'\n                                                co_firstlineno    2\n                                                co_lnotab         b'\\x00\\x02\\n\\x01'\n                                                co_freevars       ['aa']\n                                                co_cellvars       [])\n                          co_names          []\n                          co_varnames       ['aa', 'closure']\n                          co_filename       ''\n                          co_name           'foo'\n                          co_firstlineno    1\n                          co_lnotab         b'\\x00\\x01\\x0f\\x04'\n                          co_freevars       []\n                          co_cellvars       ['aa'])\n                      goodbye\n                      None\n    co_names          ['foo']\n    co_varnames       []\n    co_filename       ''\n    co_name           '<module>'\n    co_firstlineno    1\n    co_lnotab         b'\\t\\x06'\n    co_freevars       []\n    co_cellvars       [])\n\n>>> ## disassemble codetree\n>>> print( tree.dis() )\n  1           0 LOAD_CONST               0 (<code object foo at 0x922c848, file \"\", line 1>) \n              3 MAKE_FUNCTION            0 \n              6 STORE_NAME               0 (foo) \n\n  7           9 LOAD_NAME                0 (foo) \n             12 LOAD_CONST               1 ('goodbye') \n             15 CALL_FUNCTION            1 \n             18 POP_TOP              \n             19 LOAD_CONST               2 (None) \n             22 RETURN_VALUE         \n\n    2           0 LOAD_CLOSURE             0 (aa) \n                3 BUILD_TUPLE              1 \n                6 LOAD_CONST               1 (<code object closure at 0x922c890, file \"\", line 2>) \n                9 MAKE_CLOSURE             0 \n               12 STORE_FAST               1 (closure) \n  \n    6          15 LOAD_FAST                1 (closure) \n               18 CALL_FUNCTION            0 \n               21 RETURN_VALUE         \n  \n      4           0 LOAD_DEREF               0 (aa) \n                  3 LOAD_CONST               1 ('!') \n                  6 INPLACE_ADD          \n                  7 STORE_DEREF              0 (aa) \n    \n      5          10 LOAD_GLOBAL              0 (print) \n                 13 LOAD_DEREF               0 (aa) \n                 16 CALL_FUNCTION            1 \n                 19 POP_TOP              \n                 20 LOAD_CONST               0 (None) \n                 23 RETURN_VALUE"}}, {"pk": 42, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Pynu", "license": "GPLv3", "author": "Juho Veps\u00e4l\u00e4inen", "author_email": "bebraw@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/bebraw/pynu", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "graph,nodes", "summary": "Pynu provides utility classes that offer basic graph tree traversal and manipulation functionality.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "Pynu - Python Node Utilities\n============================\n\nThis library provides utility classes that offer basic graph tree traversal\nand manipulation functionality.\n\n* Documentation: http://packages.python.org/Pynu/ .\n\n* Source: http://github.com/bebraw/pynu\n\n* Issue Tracker: http://github.com/bebraw/pynu/issues\n\n\nChangelog\n=========\n\n\n0.1.1 (2010-01-29)\n------------------\n\n* Made code compatible with PEP 8.\n\n* Removed extraneous methods from NodeContainer (ie. children/parents\nattribute).\n\n\n0.1.0 (2010-01-27)\n------------------\n\n* Initial Release"}}, {"pk": 43, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pylibics", "license": "BSD", "author": "Andre Alexander Bell", "author_email": "pylibics@andre-bell.de", "project_url": null, "maintainer_email": null, "home_page": "http://www.andre-bell.de/en/projects/pylibics", "version": "1.5.2b1", "platform": "UNKNOWN", "keywords": "libics,Image Cytometry Standard,ICS,IDS,image file format", "summary": "Python wrapper for libics (Image Cytometry Standard).", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Image Recognition\nTopic :: Software Development :: Libraries", "description": "=============================\nInstalling and Using pylibics\n=============================\n\n.. contents:: **Table of Contents**\n\n------------\nIntroduction\n------------\n\nThe Image Cytometry Standard (ICS) is a file format for images, primarily in\nmicroscopy imaging. The file format has been described by `Dean1990`_. ICS\nfiles allow to store further information on the imaging system along with the\nactual image (e.g aperture, light setting, microscope, and camera). Moreover,\nthe file format allows to store several integer format, floating point images as\nwell as complex valued images.\n\nThe library `libics`_ is a C library to read an write ICS image files. This\nmodule wraps the functions provided by libics to Python. Actual image data are\nreturned as numpy arrays. Numpy array in turn can be written to ICS image files.\n\n.. _Dean1990: Dean, P.; Mascio, L.; Ow, D.; Sudar, D. & Mullikin, J.\n    'Proposed standard for image cytometry data files'\n    Cytometry, Part A, 1990, 11, (5), 561-569\n    doi: 10.1002/cyto.990110502\n.. _libics: http://libics.sourceforge.net\n\nLimitations and known bugs\n--------------------------\n\n - Ics data written as version 2.0 is broken\n - Accessing ics history entries with the iterator interface\n   seems not to work properly\n - Compression appears to be not working\n\n-------------------------\nInstallation instructions\n-------------------------\n\nYou can download the `source code package`_ to compile everything yourself or\nyou can use easy_install to install the precompiled package (py2.6, win32 and\nlinux, x86_64). To compile the package please follow the instructions provided\nin the README file.\n\nWindows\n-------\n\nInstalling with easy_install is done by calling from the windows command\nprompt (C:\\>):\n\n  C:\\> easy_install pylibics\n\nLinux\n-----\n\nInstalling with easy_install is done by calling from the command prompt:\n\n  > easy_install pylibics\n\n.. _source code package: http://www.andre-bell.de/projects/pylibics/downloads\n\n-----\nUsage\n-----\n\nPlease see the `project homepage`_ for usage examples. Also refer to the\nexamples provided in the source package.\n\n.. _project homepage: http://www.andre-bell.de/projects/pylibics\n\n---------------\nRelease Changes\n---------------\n\n1.5.2b1, Released 2010-11-23\n * Basic support for libics"}}, {"pk": 44, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "rnaspace", "license": "GNU General Public License (GPL)", "author": "see the AUTHORS joined file", "author_email": "contact@rnaspace.org", "project_url": null, "maintainer_email": null, "home_page": "http://rnaspace.org", "version": "1.0", "platform": "Unix", "keywords": "non-protein-coding RNA,ncRNA,annotation", "summary": "A collaborative platform for non-protein-coding RNA annotation", "classifiers": "Environment :: Web Environment\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "The platform allows running in an integrated environment a variety\n          of ncRNA gene finders, to explore results with dedicated tools for\n          comparison, visualization and edition of putative ncRNAs and to\n          export them in various formats (FASTA, GFF, RNAML).\n          \n          See http://rnaspace.org to have an idea of an open web site \n          without user authentification.\n\n          ``rnaspace`` requires ``CherryPy`` and ``Cheetah``."}}, {"pk": 45, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gazehound", "license": "GPL 2.0", "author": "Nathan Vack", "author_email": "njvack@wisc.edu", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/njvack/gazehound", "version": "0.2.2", "platform": "UNKNOWN", "keywords": "gazetracking eyetracking psychology science research", "summary": "Utilities for viewing and analyzing gaze tracking (and eyetracking) data", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Console\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis", "description": "UNKNOWN"}}, {"pk": 46, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "django-shapes", "license": "UNKNOWN", "author": "Dane Springmeyer", "author_email": "dbsgeo@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/springmeyer/django-shapes", "version": "0.2.0", "platform": "UNKNOWN", "keywords": null, "summary": "Upload and export shapefiles using GeoDjango.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Django\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Utilities", "description": "UNKNOWN"}}, {"pk": 47, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dana", "license": "BSD", "author": "Nicolas P. Rougier", "author_email": "Nicolas.Rougier@loria.fr", "project_url": null, "maintainer_email": null, "home_page": "http://dana.loria.fr", "version": "0.3.4", "platform": "any", "keywords": null, "summary": "Distributed (Asynchronous) Numerical Adaptive computing framework", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": "DANA (Distributed (asynchronous) Numerical and Adaptive computing) is a python\ncomputing framework based on numpy and scipy libraries whose primary goals\nrelate to computational neuroscience and artificial neural networks. However,\nthis framework can be used in several different areas like physic simulations,\ncellular automata or image processing.\n\nThe computational paradigm supporting the DANA framework is grounded on the\nnotion of a unit that is a set of arbitrary values that can vary along time\nunder the influence of other units and learning. Each unit can be linked to any\nother unit (including itself) using a weighted link and a group is a structured\nset of such homogeneous units."}}, {"pk": 48, "model": "importing.pypicache", "fields": {"maintainer": "Mason Swanson", "name": "Brainiac", "license": "Copyright (c) 2009 Mason Swanson\r\n\r\n Permission is hereby granted, free of charge, to any person\r\n obtaining a copy of this software and associated documentation\r\n files (the \"Software\"), to deal in the Software without\r\n restriction, including without limitation the rights to use,\r\n copy, modify, merge, publish, distribute, sublicense, and/or sell\r\n copies of the Software, and to permit persons to whom the\r\n Software is furnished to do so, subject to the following\r\n conditions:\r\n\r\n The above copyright notice and this permission notice shall be\r\n included in all copies or substantial portions of the Software.\r\n\r\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\r\n OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\r\n HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\r\n WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\r\n FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\r\n OTHER DEALINGS IN THE SOFTWARE.\r\n\r\nFURTHERMORE UPON ANY TYPE OF USE OF THIS SOFTWARE THE USER OF THE SOFTWARE\r\nAGREES TO RECOGNIZE THE COPYRIGHT HOLDER AS THE COPYRIGHT HOLDER OF THE SPECIFIC\r\nCOMPONENT USED.", "author": "Mason Swanson", "author_email": "masonswanson@gmail.com", "project_url": null, "maintainer_email": "masonswanson@gmail.com", "home_page": "http://code.google.com/p/brainiac/", "version": "0.0.2", "platform": "", "keywords": "", "summary": "Various Components For Use In An Artificial Intelligence System Which Are Totally Usable On Their Own", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nTopic :: Education\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Image Recognition\nTopic :: Software Development\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Application Frameworks\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System", "description": "Currently Brainiac Is Entirely Python, And Has Two Modules:\r\n1:dict: Dict Is A Python Style Diction Containing English Words As Keys, And\r\nTheir Definitions As Their Value. dict Also Contains A Few Functions For Using\r\nThis Information\r\n\r\n2:Writer:Writer Is Dependent On PIL, It Takes As Input A String And Outputs An\r\nImage File Containing The Given String Written In My Handwriting!\r\n\r\nIf You Can Help Me Out With The Development Of This Project It Is Hosted At\r\nGoogle Code"}}, {"pk": 49, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.arclink", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.6", "platform": "OS Independent", "keywords": "ObsPy,Seismology,ArcLink,MiniSEED,SEED,Inventory,Waveform", "summary": "ArcLink/WebDC request client for of ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "obspy.arclink - ArcLink/WebDC request client for of ObsPy\n\n    For more information visit http://www.obspy.org."}}, {"pk": 50, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "DOLFIN", "license": "", "author": "Anders Logg, Garth N. Wells, et. al.", "author_email": "", "project_url": null, "maintainer_email": "", "home_page": "https://launchpad.net/dolfin", "version": "0.9.10", "platform": "", "keywords": "", "summary": "C++/Python library for solving differential equations", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries", "description": "DOLFIN is the C++/Python interface of FEniCS, providing a consistent PSE\r\n(Problem Solving Environment) for ordinary and partial differential equations."}}, {"pk": 51, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "oldowan.mitomotifs-cmdline", "license": "MIT", "author": "Ryan Raaum", "author_email": "code@raaum.org", "project_url": null, "maintainer_email": null, "home_page": "http://mitomotifs.raaum.org", "version": "1.0.0", "platform": "Any", "keywords": "bioinformatics", "summary": "Command line scripts for the oldowan.mitomotifs package.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "oldowan.mitomotifs-cmdline provides the ``seq2sites`` and ``sites2seq`` command\nline scripts to covert human mitochondrial DNA sequences to lists of variant\nsites relative to the revised Cambridge Reference Seqeunce and vice versa.\nFurther information on the rCRS and variant site nomenclature for human mtDNA\nsequences is available at the MitoMotifs_ website. \n\nThis package is only the command line extension of the core oldwan.mitomotifs\nmodule. If you want just the Python libraries and not the command line tools,\nyou should go directly to that package.\n\nInstallation Instructions\n=========================\n\nThis package is pure Python and has only pure Python dependencies\n(oldowan.mitomotifs and oldowan.fasta) outside of the standard library. All of\nthese dependencies will be automatically installed if you use the setuptools_\n``easy_install`` tool.  This usually goes something like this::\n\n\t$ easy_install oldowan.mitomotifs-cmdline\n\nor on a unix-like system, assuming you are installing to the main Python\n``site-packages`` directory as a non-privileged user, this::\n\n\t$ sudo easy_install oldowan.mitomotifs-cmdline\n\nYou may also use the standard python distutils setup method. You will have to\ndownload ind install oldowan.fasta and oldowan.mitomotifs first. Then, download\nthe current source archive from the file list towards the bottom of this page,\nunarchive it, and install. On Mac OS X and many other unix-like systems, having\ndownloaded the archive and changed to the directory containing this archive in\nyour shell, this might go something like::\n\n\t$ tar xvzf oldowan.mitomotifs-cmdline*\n\t$ cd oldowan.mitomotifs-cmdline*\n\t$ python setup.py install\n\nQuick Start\n===========\n\nConvert sequences to sites::\n\n  $ seq2sites sequences.fasta\n\nConvert sequences to sites, saving the output to a file::\n\n  $ seq2sites sequences.fasta > sites.txt\n\nSequences must be contiguous! Separate runs of sequence, such as HVR1 and HVR2\nwithout the intervening sequence interval, must be analyzed separately.\n\nThere is also a cutoff on the number of ambigous sites (N) allowed in the\nsequence. By default, this is 10 - but this is an option that can be set::\n\n  $ seq2sites --ambig-cutoff=20 sequences.fasta\n\nConvert a list of variable sites to sequence. The input file should be a\ncomma-seprated-values list with one entry per line, with name, N, and sites.\nSites should be separated by whitespace::\n\n  $ cat hvr1_sites.txt\n  Seq1,1,16129A\n  Seq2,1,16129A 16223T\n  Seq3,2,16223T\n  $ sites2seq hvr1_sites.txt\n\nThe default range of sequence returned is HVR1, defined as positions 16023 to\n16365 on the rCRS. All predefined ranges are:\n\n- HVR1: 16024-16365\n- HVR2: 73-340\n- HVR1to2: 16024-340\n- coding: 577-15992\n- all: 1-16559\n\nSo, to convert a list of HVR2 sites to sequence::\n\n  $ sites2seq --region=hvr2 hvr2_sites.txt\n\nAn arbitrary range may be selected. If the stop value is smaller than the\nstart, it is assumed that the range runs through the origin::\n\n  $ sites2seq --begin=16024 --end=340 dloop_sites.txt\n\nThe rCRS sequence will can be selected with 'rCRS' as the sites value::\n\n  $ cat sites.txt\n  Seq1,1,rCRS\n  Seq2,1,16129A 16223T\n\nRelease History ===============\n\n1.0.0 (August 16, 2008)\n    initial release of module.\n\n\n.. _MitoMotifs: http://mitomotifs.raaum.org\n.. _setuptools: http://peak.telecommunity.com/DevCenter/EasyInstall"}}, {"pk": 52, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ruffus", "license": "MIT", "author": "Leo Goodstadt", "author_email": "ruffus@llew.org.uk", "project_url": null, "maintainer_email": null, "home_page": "http://ruffus.googlecode.com", "version": "2.2", "platform": "UNKNOWN", "keywords": "make task pipeline parallel bioinformatics science", "summary": "Light-weight Python Computational Pipeline Management", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Build Tools\nTopic :: Software Development :: Build Tools\nTopic :: Software Development :: Libraries\nTopic :: System :: Distributed Computing", "description": "***************************************\nOverview\n***************************************\n\n\n    The ruffus module is a lightweight way to add support \n    for running computational pipelines.\n    \n    Computational pipelines are often conceptually quite simple, especially\n    if we breakdown the process into simple stages, or separate **tasks**.\n    \n    Each stage or **task** in a computational pipeline is represented by a python function\n    Each python function can be called in parallel to run multiple **jobs**.\n    \n    Ruffus was originally designed for use in bioinformatics to analyse multiple genome\n    data sets.\n\n***************************************\nDocumentation\n***************************************\n    \n    Ruffus documentation can be found `here <http://wwwfgu.anat.ox.ac.uk/~lg/oss/ruffus/index.html>`_ ,\n    with an `download notes <http://wwwfgu.anat.ox.ac.uk/~lg/oss/ruffus/installation.html>`_ ,\n    a `short tutorial <http://wwwfgu.anat.ox.ac.uk/~lg/oss/ruffus/tutorials/simple_tutorial/simple_tutorial.html>`_ and\n    an `in-depth tutorial <http://wwwfgu.anat.ox.ac.uk/~lg/oss/ruffus/tutorials/manual/manual_introduction.html>`_ .\n\n\n***************************************\nBackground\n***************************************\n\n    The purpose of a pipeline is to determine automatically which parts of a multi-stage \n    process needs to be run and in what order in order to reach an objective (\"targets\")\n\n    Computational pipelines, especially for analysing large scientific datasets are\n    in widespread use. \n    However, even a conceptually simple series of steps can be difficult to set up and\n    to maintain, perhaps because the right tools are not available.\n\n***************************************\nDesign\n***************************************\n    The ruffus module has the following design goals:\n\n        * Simplicity. Can be picked up in 10 minutes\n        * Elegance\n        * Lightweight\n        * Unintrusive\n        * Flexible/Powerful\n\n***************************************\nFeatures\n***************************************\n\n    Automatic support for\n\n        * Managing dependencies\n        * Parallel jobs                         \n        * Re-starting from arbitrary points, especially after errors\n        * Display of the pipeline as a flowchart\n        * Reporting\n\n\n***************************************\nA Simple example\n***************************************\n\n        Use the **@follows(...)** python decorator before the function definitions::\n\n            from ruffus import *\n            import sys\n\n            def first_task():\n                print \"First task\"\n\n            @follows(first_task)\n            def second_task():\n                print \"Second task\"\n\n            @follows(second_task)\n            def final_task():\n                print \"Final task\"\n\n\n\n\n        the ``@follows`` decorator indicate that the ``first_task`` function precedes ``second_task`` in \n        the pipeline.\n\n********\nUsage\n********\n\n    Each stage or **task** in a computational pipeline is represented by a python function\n    Each python function can be called in parallel to run multiple **jobs**.\n    \n    1. Import module::\n            \n            import ruffus\n    \n\n    1. Annotate functions with python decorators\n\n    2. Print dependency graph if you necessary\n\n        - For a graphical flowchart in ``jpg``, ``svg``, ``dot``, ``png``, ``ps``, ``gif`` formats::\n\n            graph_printout ( open(\"flowchart.svg\", \"w\"),\n                             \"svg\",\n                             list_of_target_tasks)\n\n        This requires ``dot`` to be installed\n\n        - For a text printout of all jobs ::\n\n            pipeline_printout(sys.stdout, list_of_target_tasks)\n\n\n    3. Run the pipeline::\n\n        pipeline_run(list_of_target_tasks, [list_of_tasks_forced_to_rerun, multiprocess = N_PARALLEL_JOBS])"}}, {"pk": 53, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mingus", "license": "GPLv3", "author": "Bart Spaans", "author_email": "onderstekop@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://mingus.googlecode.com/", "version": "0.4.2.3", "platform": "UNKNOWN", "keywords": null, "summary": "mingus is a music package for Python", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Artistic Software\nTopic :: Education\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics :: Presentation\nTopic :: Multimedia :: Sound/Audio\nTopic :: Multimedia :: Sound/Audio :: Analysis\nTopic :: Multimedia :: Sound/Audio :: MIDI\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "mingus is a package for Python used by programmers, musicians, composers and researchers to make and investigate music. At the core of mingus is music theory, which includes topics like intervals, chords, scales and progressions. These components are \nrigurously tested and can be used to generate and recognize musical elements using convenient \nshorthand where possible (for example some acceptable chords are: CM7, Am6, Ab7, G7).\n\nOn top of that are several packages that deal  with classical notation, MIDI (sequencing, loading and saving), MusicXML, ASCII tablature, and many other useful and plain cool things like LilyPond and FluidSynth support. Everything is fully documentated, put into simple APIs and has a tutorial making it easy to jump straight in.\n\nhttp://mingus.googlecode.com"}}, {"pk": 54, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "noaadata-py", "license": "GPL v3", "author": "Kurt Schwehr", "author_email": "kurt@ccom.unh.edu", "project_url": null, "maintainer_email": null, "home_page": "http://vislab-ccom.unh.edu/~schwehr/software/noaadata", "version": "0.43", "platform": "All platforms", "keywords": "axis,soap,marine,NOAA,AIS,N-AIS,binary messages,NMEA", "summary": "Encode/decode NOAA co-ops marine data and marine AIS", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Communications\nTopic :: Database\nTopic :: Scientific/Engineering :: GIS\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Code Generators\nTopic :: System :: Networking", "description": "Library for handling marine Automatic Identification System (AIS)\nmessages and NOAA marine data messages from http://opendap.co-ops.nos.noaa.gov/axis/. \nHas extensions to handle the USCG N-AIS receive fields.  The SOAP code is a bit rusty and now\nuses pydap.\n\nFor AIS ship traffic, noaadata provides bridges to sqlite3 and\npostgresql/postgis databases.  Is able to generate Google Earth KML\nfiles for AIS.\n\nPart of the UNH/NOAA Chart of the Future project.\n\nStill in development.  Some rough edges."}}, {"pk": 55, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pypol_", "license": "GNU GPL v3", "author": "Michele Lacchia", "author_email": "michelelacchia@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pypol.altervista.org/", "version": "0.5", "platform": "any", "keywords": null, "summary": "Python polynomial library", "classifiers": "Intended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: Mathematics", "description": "UNKNOWN"}}, {"pk": 56, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "simplekml", "license": "GNU General Public License", "author": "Kyle Lancaster", "author_email": "kyle.lan@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/simplekml/", "version": "0.1.1", "platform": "UNKNOWN", "keywords": null, "summary": "A Simple KML creator", "classifiers": "Development Status :: 3 - Alpha\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 57, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "balloon", "license": "Apache License, Version 2.0", "author": "Alexey Petrov", "author_email": "alexey.petrov.nnov@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://sourceforge.net/projects/balloon-foam", "version": "0.03-alfa", "platform": "linux", "keywords": null, "summary": "Set of cloud computing automation utilities", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Apache Software License\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "These utilities provide seemless mode for:\n        - accessing to cloud;\n        - deploying user specified data and functionality to be run on this data;\n        - launching of the cloud specified task;\n        - storing of output data into cloud;\n        - fectching of these output results from cloud;\n        - other miscellaneous functions"}}, {"pk": 58, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mccdaq", "license": "Python", "author": "Philippe Dalet", "author_email": "philippe.dalet@voila.fr", "project_url": null, "maintainer_email": null, "home_page": "http://gpib82357a.sourceforge.net/mccdaq.htm", "version": "0.1", "platform": "Windows", "keywords": null, "summary": "USB-DAQ interface MCCDAQ .", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python Software Foundation License\nOperating System :: Microsoft :: Windows\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Software Development :: Libraries :: Python Modules", "description": "MCCDAQ is an interface USB-DAQ running only on windows (XP pro,W2K,Me,W98)\n- Connect MCCDAQ (USB-1208LS) on USB port\n- Install driver (see CDROM for MCCDAQ)\n- Install this python package mccdaq."}}, {"pk": 59, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "GraphPath", "license": "GNU General Public License (GPL)", "author": "Arnold deVos", "author_email": "adv@langdale.com.au", "project_url": null, "maintainer_email": null, "home_page": "http://www.langdale.com.au/GraphPath/", "version": "0.7", "platform": "UNKNOWN", "keywords": null, "summary": "A little-language for analysing graph-structured data, especially RDF.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Markup :: XML", "description": "A little-language for analysing RDF, \r\nthe syntax of the GraphPath is reminiscent of Xpath. \r\nThe graphpath package provides a query evaluator \r\nand a goal-driven inference engine for this language, \r\nwhich work together to perform graph analysis. The package \r\ncan be teamed up with your favourite python RDF API \r\n(e.g. Redland, rdflib, or your own API)."}}, {"pk": 60, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ChiantiPy", "license": "UNKNOWN", "author": "Ken Dere", "author_email": "kdere@gmu.edu", "project_url": null, "maintainer_email": null, "home_page": "http://chiantipy.sourceforge.net", "version": "0.3.0", "platform": "UNKNOWN", "keywords": null, "summary": "a Python interface to the CHIANTI atomic database for astrophysical spectroscopy", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Physics", "description": "======================\n Welcome to ChiantiPy\n======================\n\nChanges from 0.2 to 0.3\n=======================\n\nAdded class mspectrum to calculate spectra using multiple processors.\n\nBug fixes\n\n\nWhat is ChiantiPy\n=================\n\nChiantiPy is the Python interface to the CHIANTI atomic database for astrophysical spectroscopy\n\nDetailed information can be found at http://chiantipy.sourceforge.net\n\nWhat is CHIANTI\n===============\n\n\nCHIANTI provides a database of atomic data that can be used to interpret the emission of spectral lines and continuua emitted from high-temperature, optically-thin astrophysical sources.  The CHIANTI project provides a suite of routines written in Interactive Data Language (IDL) to access the database and calculate various quantities for use in interpreting observed spectra or producing synthetic spectra.\n\n==============================                                                                                                                \nGetting started with ChiantiPy                                                                                                                \n==============================                                                                                                                \n\nPrerequisites\n=============\n\n* Python ( latest 2.X version; not compatible with version 3.X )\n\n* Numpy\n\n* Scipy\n\n* Matplotlib\n\n* [Optional] PyQt4 or wxPython\n\n* CHIANTI_, the atomic database for astrophysical spectroscopy\n\n.. _CHIANTI: http://www.chiantidatabase.org\n\nIn addition, the FortranFormat module from Scientific Python, developed by Konrad Hinsen of the Centre de Biophysique Moleculaire (http://dirac.cnrs-orleans.fr/ScientificPython/), is included in this distribution for simplicity.\n\nInstalling the CHIANTI database\n-------------------------------\n\nThe gzipped *data* tar ball can be downloaded from the CHIANTI website_\n\n.. _website: http://www.chiantidatabase.org/download.html\n\n*  put the file in a convenient directory, cd to the directory and untar the file\n\n* ChiantiPy uses the environment variable *XUVTOP* to find the database.  Set XUVTOP to the name of the directory where the CHIANTI data tarball was placed.  For example\n\n> setenv XUVTOP /data1/xuv/directory.where.the.tarball.was.placed\n\nSome sites have the CHIANTI database maintained as part of a SolarSoft distribution.  In that case, simply set XUVTOP to the directory were it exists, usually something like $SSW/packages/chianti/dbase\n\n\nInstalling the ChiantiPy package\n--------------------------------\n\nThe ChiantiPy package can be downloaded from the ChiantiPy, untar it, cd to the directory where it was unpacked, and then, as root\n\n> python setup.py install\n\nIf you do not have root privileges, simply put the ChiantiPy directory (simply called 'chianti') in your PYTHONPATH\n\n\nRunning ChiantiPy\n-----------------\n\nThe documentation can be found on its web page ChiantiPy_\n\n.. _ChiantiPy:  http://chiantipy.sourceforge.net/\n\nIn particular, a quick start guide is included which should get you up and running fairly quickly.\n\n\nKeeping track of ChiantiPy\n--------------------------\n\nThere is a mailing list that you can subscribe to at https://lists.sourceforge.net/lists/listinfo/chiantipy-users.  In order to subscribe it is first necessary to obtain a user account from sourceforge.net.  This is a straightforward process."}}, {"pk": 61, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "zgeo.geographer", "license": "BSD", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/projects/PrimaGIS/wiki/zgeo.geographer", "version": "0.3.1", "platform": "UNKNOWN", "keywords": "gis geography geospatial", "summary": "Geographic annotation for Zope", "classifiers": "Development Status :: 3 - Alpha\nFramework :: Plone\nFramework :: Zope3\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Describes an interfaces for annotating objects with geographic location metadata and provides a standard annotator.\n      \n Version 0.3 is not compatible with 0.2.\n\nChanges\n=======\n\n0.3.1: 2008-09-02\n-----------------\n- Declare namespace for package.\n\n0.3: 2008-02-18\n---------------\n- Created separate interfaces for georeferencing read and write."}}, {"pk": 62, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "eke.site", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/eke-site", "version": "1.0.4", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers eke member site staff investigator people peon minion", "summary": "Site and staff information for the EDRN Knowledge Environment", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Communications\nTopic :: Internet :: WWW/HTTP\nTopic :: Office/Business\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "********\neke.site\n********\n\nThis product, ``eke.site``, provides display and RDF ingest of participating\nsites that have joined the Early Detection Research Network (EDRN_).  Sites,\nstaff members, and investigators are integral parts of the EDRN Knowledge\nEnvironment (EKE_).  EDRN uses the EKE to make it easy to discover, share,\nsearch for, and retrieve all of EDRN's collective knowledge, including cancers\nand other diseases, biomarkers, specimens, participants, studies, protocols,\nand-as in the case of this product-sites and staff.\n\nAlthough intended for the EDRN public portal, it can be installed in any\nPlone_ compatible site.\n\nThis software is developed by the `EDRN Informatics Center`_  at JPL_,\noperated by the California Institute of Technology, for NCI_.\n\n.. References:\n.. _EDRN Informatics Center: http://cancer.jpl.nasa.gov/\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _EKE: http://cancer.jpl.nasa.gov/documents/applications/knowledge-environment\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://cancer.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``eke.site`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        eke.site\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        eke.site\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nA retrospective of the various releases this component has had, what's been\nchanged, what's been fixed, and so forth, follows.  You can find out more\nabout the issue numbers listed below by visiting the project's issue tracker\nat https://oodt.jpl.nasa.gov/jira/browse/CA.\n\n1.0.4 - Context Sensitive People\n--------------------------------\n\nThe two issues addressed in this release are:\n\n* CA-725 - Vocabularies eke.site.People and eke.site.PeopleWithNoReference are\n  context-dependent\n* CA-728 - Remove \"Other Misc.  Sites\" category from Sites and show each\n  category in list at top of page\n\n\n1.0.3 - Organsmic Organ Sites\n-----------------------------\n\n* CA-680 - Change Clinical Validation Center to Clinical Validation Centers\n  (plural)\n* CA-691 - Allow BDLs to have multiple organ sites\n* CA-693 - Members List - Collapse all Associate Members Bs and Cs into single\n  B and C groups\n* CA-694 - Associate Members A showing 0 members\n* CA-695 - Add Informatics Center to list of anointed sites\n* CA-697 - Change Member Type Header SPORE to SPOREs on Sites and Member List\n\n\n1.0.2 - Reorganization\n----------------------\n\nThere's some new arrangement of EDRN member sites, so this release tackled\nthese two issues:\n\n* CA-667 - Reorganize BDLs and CVCs\n* CA-670 - Collapse all Type C's and Type B's EDRN Sites into a single Type C\n  and Type B section respectively\n\n\n1.0.1 - Dynamic UI\n------------------\n\nThis time around, we implement a snazzy AJAX based browsing capability for\nsites and people at those sites.  We also address the following issues:\n\n* CA-657 - Add \"Clinical Validation Center\" as one of the anointed, special\n  sites\n* CA-659 - Add Site ID to Site view\n* CA-666 - Sites Page clean up\n\nTake a look at the issue tracker at https://oodt.jpl.nasa.gov/jira/browse/CA\nfor more details.\n\n\n1.0.0 - Prime Time\n------------------\n\nThis release addresses a number of issues that make this component (and some\nof its selected counterparts) \"prime time\" for the operational NCI portal.\n\nThis release addresses the following issues:\n\n* CA-528 Automatic periodic ingest of RDF\n\nYou can find the issue tracker at https://oodt.jpl.nasa.gov/jira/browse/CA\n\n\n0.0.3 - Ordering\n----------------\n\nThis release addresses the following issue:\n\n* CA-609 - Do not show \"Unknown Type\" from Sites List and notify DMCC\n* CA-610 - Sort Other Misc.  Sites within the grouped Site Type - alpha by\n  Site Name\n\nFor details on issues, visit the issue tracker at\nhttps://oodt.jpl.nasa.gov/jira/browse/CA.\n\n\n0.0.2 - Linky Defense\n---------------------\n\nThis release addresses the following issues:\n\n* https://oodt.jpl.nasa.gov/jira/browse/CA-557 - PI - email needs to be link.\n* https://oodt.jpl.nasa.gov/jira/browse/CA-571 - Make RDF ingest defensive\n  against inconsistent data\n\n\n0.0.1 - Investigators & HTML Formatting\n---------------------------------------\n\nThe following issues are addressed in this release:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-483 - Sort Site List by Investigator\n  w/i Scientific Components\n* http://oodt.jpl.nasa.gov/jira/browse/CA-468 - Sites - Co-Investigators and\n  Staff are not correct - and investigators duplicated in Sites subsection\n* http://oodt.jpl.nasa.gov/jira/browse/CA-472 - Protocols and other items seem\n  to still have encoded ASCII characters in the titles\n\n\nRelease 0.0.0\n-------------\n\nBeta release. This release is destined to become the FCS_.\n\n\n.. References:\n.. _FCS: http://en.wikipedia.org/wiki/Development_stage\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 63, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "SOLVCON", "license": "GPL", "author": "Yung-Yu Chen", "author_email": "yyc@solvcon.net", "project_url": null, "maintainer_email": null, "home_page": "http://solvcon.net/", "version": "0.0.4", "platform": "Linux,Windows", "keywords": null, "summary": "A supercomputing framework for solving PDEs by hybrid parallelism.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Application Frameworks", "description": "SOLVCON: a multi-physics, supercomputing software framework for high-fidelity\nsolutions of partial differential equations (PDEs) by hybrid parallelism.\n\nSOLVCON facilitates rapid devlopment of PDE solvers for massively parallel\ncomputing.  C or CUDA_ is used for fast number-crunching.  SOLVCON is designed\nfor extension to various physical processes.  Numerical algorithms and physical\nmodels are pluggable.  Sub-package ``solvcon.kerpak`` contains default\nimplementations.  The default numerical algorithm in SOLVCON is the space-time\nConservation Element and Solution Element (CESE_) method, which was originally\ndeveloped by Sin-Chung Chang at NASA Glenn Research Center.  The CESE_ method\nsolves generic, first-order, hyperbolic PDEs.\n\nSOLVCON is released under `GNU GPLv2\n<http://www.gnu.org/licenses/gpl-2.0.html>`_, and developed by `Yung-Yu Chen\n<mailto:yyc@solvcon.net>`_ and `Sheng-Tao John Yu <mailto:yu.274@osu.edu>`_.\n\nKey Features\n============\n\n- **Multi-physics**: Pluggable physical models by the built-in CESE_ solvers\n- **Complex geometry**: 2/3D unstructured mesh consisting of mixed shapes\n- **Massively parallel**: Automatic domain decomposition with MPI or socket\n- **GPGPU computing**: Hybrid parallelism with CUDA_\n- **Large data set**: In situ visualization by VTK_ and parallel I/O\n- **I/O formats**: VTK, GAMBIT Neutral, CUBIT Genesis/ExodosII, etc.\n- **Productive work flow**: Integration to batch systems, e.g., Torque\n\nInstall\n=======\n\nThe C codes in SOLVCON are intentionally made to be standard shared libraries\nrather than Python extension modules.  SOLVCON uses ctypes_ to load and call\nthese binary codes.  In this way, the binary codes can be flexibly built and\noptimized for performance.  Hence, installing SOLVCON requires building these\nlibraries.  SOLVCON uses SCons_ as the binary builder.\n\nFor SOLVCON to be built and run, it requires the following packages: (i)\nPython_ 2.6, (ii) SCons_, (iii) a C compiler, gcc_ or icc is OK, (iv) Numpy_,\n(v) LAPACK_, (vi) NetCDF_ higher than version 4, and (vii) METIS_ version 4 for\ngraph partitioning (SOLVCON will download it for you on building).  Optional\ndependencies include: (i) SCOTCH_ (higher than version 5.1) as an alternative\nof METIS, (ii) Nose_ for running unit tests, (iii) Epydoc_ for generating API\ndocumentation, and (iv) VTK_ for in situ visualization.  64-bits Linux is\nrecommended.  For Debian_ or Ubuntu_ users, they can use the following command\nto install the dependencies::\n\n  $ sudo apt-get install scons build-essential gcc liblapack-pic\n    libnetcdf-dev libnetcdf6 netcdf-bin\n    python2.6 python2.6-dev python-profiler python-numpy\n    libscotch-5.1 python-nose python-epydoc python-vtk\n\nCUDA_ needs to be separately installed and configured.  For using meshes with\nmore then 35 million cells, SCOTCH-5.1 is recommended.  METIS-4 has issues on\nmemory allocation for large graphs.\n\nThe three steps to install:\n\n1. Obtain the latest release from\n   https://bitbucket.org/yungyuc/solvcon/downloads .  Unpack the source\n   tarball.  Let ``$SCSRC`` indicate the root directory of unpacked source\n   tree.\n\n2. Get into the source tree and run SCons_ to build the binary codes::\n\n     $ cd $SCSRC\n     $ scons --download --extract --apply-patches=metislog2\n\n3. Install everything::\n\n     $ python setup.py install\n\n   Optionally, you can install SOLVCON to your home directory.  It is useful\n   when you don't have the root permission on the system.  To do this, add the\n   ``--user`` when invoking the ``setup.py`` script::\n\n     $ python setup.py install --user\n\nThe option ``--download`` used above asks the building script to download\nnecessary external source packages, e.g., METIS_, from Internet.  Option\n``--extract`` extracts the downloaded packages.  Since METIS is incompatible to\nthe current release of gcc, a patch is supplied with SOLVCON and can be\nautomatically applied to the downloaded METIS source with the\n``--apply-patches`` option.\n\nInstall from Repository\n=======================\n\nTo use the latest source from the code repository, you need to use Mercurial_\nto clone the repository to your local disk::\n\n  $ sudo apt-get install mercurial\n  $ hg clone https://bitbucket.org/yungyuc/solvcon\n\nand then follow steps 2 and 3.\n\nRebuild/Reinstall\n=================\n\nIf you want to rebuild and reinstall, you can run::\n\n  $ cd $SCSRC\n  $ scons\n  $ python setup.py install\n\nwithout using the options ``--download``, ``--extract``, and\n``--apply-patches``.  If you want a clean rebuild, run ``scons -c`` before\n``scons``.  Note, ``scons -c`` does not remove the unpacked source, so you\ndon't need to reapply the patches unless you manually deleted it.\n\nUnit Test\n=========\n\nIf you have Nose_ installed, you can run::\n\n  $ nosetests\n\ninside the source tree for unit tests.  To test installed version, use the\nfollowing command instead::\n\n  $ python -c 'import solvcon; solvcon.test()'\n\nWhen testing installed version, make sure your current directory does not have\na sub-directory named as ``solvcon``.\n\nBecause SOLVCON uses ssh_ as its default approach for remote procedure call\n(RPC), you need to set up the public key authentication for ssh, or some of the\nunit tests for RPC could fail.  Some tests using optional libraries could be\nskipped (indicated by S), if you do not have the libraries installed.\nEverything else should pass.\n\nResources\n=========\n\n- Portal (with API document): http://solvcon.net/\n- Mailing list: http://groups.google.com/group/solvcon\n- Downloads: http://bitbucket.org/yungyuc/solvcon/downloads\n\n.. _CESE: http://www.grc.nasa.gov/WWW/microbus/\n.. _SCons: http://www.scons.org/\n.. _Python: http://www.python.org/\n.. _gcc: http://gcc.gnu.org/\n.. _Numpy: http://www.numpy.org/\n.. _LAPACK: http://www.netlib.org/lapack/\n.. _NetCDF: http://www.unidata.ucar.edu/software/netcdf/index.html\n.. _METIS: http://glaros.dtc.umn.edu/gkhome/views/metis/\n.. _SCOTCH: http://www.labri.fr/perso/pelegrin/scotch/\n.. _Epydoc: http://epydoc.sf.net/\n.. _CUDA: http://www.nvidia.com/object/cuda_home_new.html\n.. _Mercurial: http://mercurial.selenic.com/\n.. _ssh: http://www.openssh.com/\n.. _Nose: http://somethingaboutorange.com/mrl/projects/nose/\n.. _VTK: http://vtk.org/\n.. _ctypes: http://docs.python.org/library/ctypes.html\n.. _Debian: http://debian.org/\n.. _Ubuntu: http://ubuntu.com/"}}, {"pk": 64, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nebpack", "license": "MIT", "author": "Paul Joseph Davis", "author_email": "davisp@neb.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/davisp/nebpack", "version": "0.0.3", "platform": "any", "keywords": "bioinformatics git annotations", "summary": "Store annotations in Git repositories.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "nebpack\n=======\n\nStoring biological annotations in Git repositories."}}, {"pk": 65, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "intermine", "license": "LGPL", "author": "Alex Kalderimis", "author_email": "dev@intermine.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.intermine.org/", "version": "0.96.00", "platform": "UNKNOWN", "keywords": "webservice,genomic,bioinformatics", "summary": "InterMine WebService client", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules", "description": "InterMine Webservice Client\n----------------------------\n\nProvides access routines to datawarehouses powered \nby InterMine technology."}}, {"pk": 66, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "simplenlp", "license": "http://www.gnu.org/copyleft/gpl.html", "author": "MIT Media Lab, Software Agents group", "author_email": "conceptnet@media.mit.edu", "project_url": null, "maintainer_email": null, "home_page": "http://csc.media.mit.edu/", "version": "0.9.0", "platform": "any", "keywords": null, "summary": "UNKNOWN", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Text Processing :: Linguistic", "description": "This package accomplishes many basic NLP tasks without dependencies on NLTK or parsers, for use in projects such as ConceptNet."}}, {"pk": 67, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "paida", "license": "Python Software Foundation License", "author": "Koji Kishimoto", "author_email": "korry@users.sourceforge.net", "project_url": null, "maintainer_email": "", "home_page": "http://paida.sourceforge.net/", "version": "3.2.1_2.10.1", "platform": "any", "keywords": "", "summary": "A pure Python package for the scientific data analysis and plotting", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python Software Foundation License\nOperating System :: OS Independent\nProgramming Language :: Java\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "PAIDA is pure Python scientific analysis package.\r\nThe main features are:\r\n\r\n - Pure Python! (so works on both Python and Jython)\r\n - AIDA (Abstract Interfaces for Data Analysis) support\r\n - Creating/Plotting the histogram, ntuple, profile and cloud\r\n - Function fitting (parameter optimization) with constraints and its parabolic and asymmetric errors \r\nevaluation\r\n - XML based storing\r\n - Matrix calculation\r\n\r\nPAIDA web site:\r\nhttp://paida.sourceforge.net/\r\n\r\nAIDA project has other implementations like Java (JAIDA), C++ etc. (Open Scientist and Anaphe).\r\nFor more information about AIDA itself, please refer to\r\nhttp://aida.freehep.org/"}}, {"pk": 68, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cdx.dav", "license": "===========\n Copyright\n===========\n\nCopyright \u00a9 2008 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission.", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cdx.jpl.nasa.gov/software/cdx-dav", "version": "0.0.0", "platform": "UNKNOWN", "keywords": "climate data cdx python webdav", "summary": "CDX WebDAV Server", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Front-Ends\nTopic :: Internet :: WWW/HTTP :: HTTP Servers\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Atmospheric Science\nTopic :: Software Development :: Libraries :: Python Modules", "description": "CDX WebDAV Server provides a filesystem-like view of CDX\ndatasets.  CDX is the Climate Data Exchange, an effort of the Jet Propulsion\nLaboratory to create a virtual environment for the sharing of climate data."}}, {"pk": 69, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "gdaltokmz", "license": "GPL", "author": "Imran Haque", "author_email": "ihaque@cs.stanford.edu", "project_url": null, "maintainer_email": "", "home_page": "http://gecensus.stanford.edu/gcensus-gt", "version": "1.0", "platform": "UNKNOWN", "keywords": "", "summary": "Allows conversion from GDAL-supported raster geographic formats to the KMZ format used by the free Google Earth client.", "classifiers": "License :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nTopic :: Multimedia :: Graphics :: Graphics Conversion\nTopic :: Scientific/Engineering :: GIS\nTopic :: Utilities", "description": "gdaltokmz allows converting from any GDAL-supported raster geographic\r\n        format to the KMZ format used by the free Google Earth visualization\r\n        tool.\r\n        \r\n        To perform the conversion, call::\r\n        \r\n        gdaltokmz.convert_gdal_to_kmz(gdalfile,kmzfile)\r\n        \r\n        Where gdalfile is the path to the input file, and kmzfile is the name\r\n        of the file to be output.\r\n        \r\n        This module requires that the gdal and osr python modules be installed.\r\n        More information on these can be found at http://www.gdal.org.\r\n        \r\n        This module requires the presence of ImageMagick's \"convert\" tool. Its\r\n        location is hardcoded into the library as /usr/lib/convert; make sure\r\n        to change it if your copy lives somewhere else (e.g., on a Windows\r\n        machine). See http://www.imagemagick.org.\r\n        \r\n        To view the output files requires Google's free Google Earth program.\r\n        See http://earth.google.com."}}, {"pk": 70, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "taurus", "license": "LGPL", "author": "Tiago Coutinho", "author_email": "tcoutinho@cells.es", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/taurus", "version": "2.1.1", "platform": "Linux,Windows XP/2000/NT,Windows 95/98/ME", "keywords": "CLI,GUI,PyTango,Tango,Shell", "summary": "A library designed to provide an abstraction layer over PyTango.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: User Interfaces\nTopic :: Software Development :: Widget Sets", "description": "Taurus stands for TAngo User interface 'R' US. It\nis a python framework for both CLI and GUI tango applications.\nIt is build on top of PyTango and PyQt."}}, {"pk": 71, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ETS", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/tool-suite.php", "version": "3.6.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "The Enthought Tool Suite meta-project.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The Enthought Tool Suite (ETS) is a collection of components developed by\nEnthought and our partners, which we use every day to construct custom\nscientific applications.\n\nThis project is a \"meta-project wrapper\" that bundles up all the other projects\nin ETS."}}, {"pk": 72, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.vectorplot", "license": "BSD", "author": "Anne Archibald", "author_email": "peridot.faceted@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://projects.scipy.org/scipy/scikits", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Vector fields plotting algorithms.", "classifiers": "Development Status :: 1 - Planning\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": "Algorithms to plot vector fields. \nFor the moment, it only contains the line integral convolution\nalgorithm."}}, {"pk": 73, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mediantracker", "license": "MIT License", "author": "John Kleint", "author_email": "mediantracker-general@lists.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://sourceforge.net/projects/mediantracker/", "version": "1.0", "platform": "UNKNOWN", "keywords": "median statistics online incremental dynamic mathematics", "summary": "Tracks the overall median of a stream of values \"on-line\" in reasonably efficient fashion.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Mathematics", "description": "Track the median of a stream of values \"on-line\" in reasonably efficient \nfashion.\n\nUsage::\n\n    from mediantracker import MedianTracker\n    tracker = MedianTracker()\n    tracker.add(1)\n    tracker.add(2)\n    tracker.add(3)\n    tracker.add(4)\n    assert tracker.lower_median() == 2\n    assert tracker.upper_median() == 3\n    \n``MedianTracker`` supports efficient median queries on and dynamic\nadditions to a list of values. It provides both the lower and upper median\nof all values seen so far. Any ``__cmp__()``-able object can be tracked,\nin addition to numeric types. ``add()`` takes *log(n)* time for a tracker\nwith *n* items; ``lower_median()`` and ``upper_median()`` run in constant\ntime. Since all values must be stored, memory usage is proportional to the\nnumber of values added (*O(n)*).\n\nThe values can be accessed via iteration over the ``MedianTracker``,\nthough they are not ordered in any particular way::\n\n    sum = 0.0\n    for val in tracker:\n        sum += val\n    mean = sum / len(tracker) \n\nUse this module if you are processing values \"on-line,\" one at a time, as\nthey arrive, and need to know the new median after each new value (or\nbatch of values). If you just want the median of a whole list, there are\nmuch more efficient linear-time median (or more general k-th smallest\nselection) algorithms. Using this module will take *O(nlogn)* time and an\nextra *O(n)* space to compute the median of *n* items. On the other hand,\na ``MedianTracker`` will only take *O(nlogn + m)* time for any sequence of\n*n* adds and *m* median queries, whereas running a traditional\nnon-incremental median algorithm *m* times would take *O(n*m)*.\n\nFinally, some sources define the median of an even-length list to be the\naverage of the middle two values. This is easily and efficiently computed\n(in constant time)::\n\n    tracker = MedianTracker([1, 2, 3, 4])\n    median = (tracker.lower_median() + tracker.upper_median()) / 2.0\n    assert median == 2.5"}}, {"pk": 74, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "toureditor", "license": "UNKNOWN", "author": "Frank P\u00e4hlke", "author_email": "frank@kette-links.de", "project_url": null, "maintainer_email": null, "home_page": "http://www.kette-links.de/technik/", "version": "1.1.0", "platform": "UNKNOWN", "keywords": null, "summary": "Editor for GPX/CRP tour files and height profiles", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "UNKNOWN"}}, {"pk": 75, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "DXF-Converter", "license": "BSD style", "author": "Uwe Schmitt", "author_email": "schmitt@num.uni-sb.de", "project_url": null, "maintainer_email": "schmitt@num.uni-sb.de", "home_page": "http://www.procoders.net/en/Procoders/open%20source/dxf%20converter", "version": "1.0", "platform": "", "keywords": "DXF, Autocad, PDF, Converter", "summary": "Converts Autocad Files v11 and v12 to pdf", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nLicense :: Freely Distributable\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Text Processing :: General", "description": ""}}, {"pk": 76, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.plugins", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/coopr/coopr.plugins", "version": "2.6.1", "platform": "any", "keywords": "optimization", "summary": "Plugins that are typically bundled with Coopr", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "====================\ncoopr.plugins README\n====================\n\nThis Python package includes plugins used within Coopr.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * coopr-forum@googlegroups.com\n    - The main list for help and announcements\n  * coopr-developers@googlegroups.com\n    - Where developers of Coopr discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 77, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydee", "license": "MIT", "author": "Pierre Raybaut", "author_email": "contact@pythonxy.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/pydee/", "version": "0.4.23", "platform": "any", "keywords": "PyQt4 shell console widgets IDE", "summary": "Pydee development environment and its PyQt4-based IDE tools: interactive Python shell, Python code editor, workspace (dict/list/string/array editor), doc viewer, history log, environment variables editor, ...", "classifiers": "Development Status :: 3 - Alpha\nLicense :: OSI Approved :: MIT License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Widget Sets", "description": "pydeelib is intended to be an extension to PyQt4 providing a simple development environment named \"Pydee\" - a powerful alternative to IDLE (see screenshots: http://pydee.googlecode.com) based on independent widgets interacting with each other: workspace (globals explorer with dict/list editor and numpy arrays editor), docstring viewer (calltip), history log, multiline code editor (support drag and drop, autocompletion, syntax coloring, ...), environment variables editor (including a Windows-specific editor to change current user environement variables) and working directory browser."}}, {"pk": 78, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MeshPy", "license": "MIT for the wrapper/non-commercial MIT for the meshers", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/meshpy", "version": "0.91.2", "platform": "UNKNOWN", "keywords": null, "summary": "Triangular and Tetrahedral Mesh Generator", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: Free for non-commercial use\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: C++\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nTopic :: Multimedia :: Graphics :: 3D Modeling\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries", "description": "MeshPy offers quality triangular and tetrahedral mesh\n          generation for Python. Meshes of this type are chiefly used\n          in finite-element simulation codes, but also have many\n          other applications ranging from computer graphics to\n          robotics.\n\n          In order to generate 2D and 3D meshes, MeshPy provides\n          Python interfaces to two well-regarded mesh generators,\n          `Triangle <http://www.cs.cmu.edu/~quake/triangle.html>`_ by\n          J.  Shewchuk and `TetGen <http://tetgen.berlios.de/>`_ by\n          Hang Si. Both are included in the package in slightly\n          modified versions.\n\n          MeshPy uses `Boost.Python <http://www.boost.org>`_. \n\n          As of Version 0.91.2, MeshPy also works with Python 3.\n\n          Documentation\n          =============\n\n          See the `MeshPy Documentation <http://tiker.net/doc/meshpy>`_ page."}}, {"pk": 79, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.gdp", "license": "BSD", "author": "John Siirola", "author_email": "jdsiiro@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/coopr/coopr.gdp", "version": "1.0", "platform": "any", "keywords": "optimization", "summary": "Generalized Disjunctive Programming (GDP) extensions to the Pyomo environment", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "================\ncoopr.gdp README\n================\n\nTODO: description here.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * Coopr is managed with the Acro Project. A separate checkins mailing\n    list is managed for Coopr, but otherwise the main Acro mailing lists\n    are used to manage the development of this software:\n\n    - acro-developers@software.sandia.gov\n    - acro-users@software.sandia.gov\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 80, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "CDF", "license": "UNKNOWN", "author": "Matt Born", "author_email": "mattborn@ssl.berkeley.edu", "project_url": null, "maintainer_email": null, "home_page": "http://efw.ssl.berkeley.edu/packages/cdf", "version": "0.32", "platform": "UNKNOWN", "keywords": null, "summary": "This package handles files in NASA Common Data Format", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Apache Software License\nTopic :: Scientific/Engineering :: Astronomy", "description": "UNKNOWN"}}, {"pk": 81, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "networkx", "license": "BSD", "author": "NetworkX Developers", "author_email": "networkx-discuss@googlegroups.com", "project_url": null, "maintainer_email": null, "home_page": "http://networkx.lanl.gov/", "version": "1.4", "platform": "Linux,Mac OSX,Windows,Unix", "keywords": "Networks,Graph Theory,Mathematics,network,graph,discrete mathematics,math", "summary": "Python package for creating and manipulating graphs and networks", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nProgramming Language :: Python :: 3.2\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "NetworkX is a Python package for the creation, manipulation, and\nstudy of the structure, dynamics, and functions of complex networks."}}, {"pk": 82, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyregion", "license": "MIT", "author": "Jae-Joon Lee", "author_email": "lee.j.joon@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://leejjoon.github.com/pyregion/", "version": "1.0.1", "platform": "Linux,MacOS X", "keywords": null, "summary": "python parser for ds9 region files", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy", "description": "UNKNOWN"}}, {"pk": 83, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nebgb", "license": "MIT", "author": "Paul Joseph Davis", "author_email": "davisp@neb.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/davisp/nebgb", "version": "0.1.2", "platform": "any", "keywords": "bioinformatics genbank parser", "summary": "Genbank file parser.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "nebgb - Genbank File Parser\n===========================\n\nUsage:\n\n    >>> import nebgb\n    >>> rec = nebgb.parse_file(\"./test/data/simple-1.gb\").next()\n    >>> rec.locus[\"name\"]\n    'NP_034640'\n    >>> rec.locus[\"length\"]\n    182\n    >>> rec.keywords[\"source\"][\"name\"]\n    'house mouse'\n    >>> rec.features[1][\"properties\"][\"product\"]\n    'interferon beta, fibroblast'\n    >>> for seq in rec.seqiter:\n    ...    print seq\n    mnnrwilhaafllcfsttalsinykqlqlqertnirkcqelleqlngkinltyradfkip\n    memtekmqksytafaiqemlqnvflvfrnnfsstgwnetivvrlldelhqqtvflktvle\n    ekqeerltwemsstalhlksyywrvqrylklmkynsyawmvvraeifrnfliirrltrnf\n    qn\n\nAlternatively you can use `nebgb.parse()` to parse a string or iterator that yields lines of a Genbank file."}}, {"pk": 84, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "Sumatra", "license": "CeCILL http://www.cecill.info", "author": "Andrew P. Davison", "author_email": "andrewpdavison@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://neuralensemble.org/sumatra/", "version": "0.3.0", "platform": "UNKNOWN", "keywords": "computational science neuroscience simulation analysis project-management", "summary": "A tool for automated tracking of computation-based scientific projects", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: Web Environment\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering", "description": "=============\r\nAbout Sumatra\r\n=============\r\n\r\nSumatra is a tool for managing and tracking projects based on numerical\r\nsimulation and/or analysis, with the aim of supporting reproducible research.\r\nIt can be thought of as an automated electronic lab notebook for computational\r\nprojects.\r\n\r\nIt consists of:\r\n\r\n * a command-line interface, smt, for launching simulations/analyses with\r\n   automatic recording of information about the experiment, annotating these\r\n   records, linking to data files, etc.\r\n * a web interface with a built-in web-server, smtweb, for browsing and\r\n   annotating simulation/analysis results.\r\n * a Python API, on which smt and smtweb are based, that can be used in your own\r\n   scripts in place of using smt, or could be integrated into a GUI-based\r\n   application.\r\n\r\nSumatra is currently alpha code, and should be used with caution and frequent\r\nbackups of your records.\r\n\r\nFor documentation, see http://packages.python.org/Sumatra/ and http://neuralensemble.org/sumatra/\r\n\r\n    \r\nIntended functionality (not all implemented yet):\r\n\r\n    * launch simulations and analyses, and record various pieces of information,\r\n      including:\r\n\r\n        - the executable (identity, version)\r\n        - the script (identity, version)\r\n        - the parameters\r\n        - the duration (execution time)\r\n        - console output\r\n        - links to all data (whether in files, in a database, etc.) produced by\r\n          the simulation/analysis\r\n        - the reason for doing the simulation/analysis\r\n        - the outcome of the simulation/analysis\r\n\r\n    * allow browsing/searching/visualising the results of previous experiments\r\n    * allow the re-running of previous simulations/analyses with automatic\r\n      verification that the results are unchanged\r\n    * launch single or batch experiments, serial or parallel\r\n    \r\n\r\n============\r\nRequirements\r\n============\r\n\r\nSumatra requires Python versions 2.5, 2.6 or 2.7. The web interface requires\r\nDjango (>= 1.2) and the django-tagging package.\r\nSumatra requires that you keep your own code in a version control\r\nsystem (currently Subversion, Mercurial, Git and Bazaar are supported). If you\r\nare already using Mercurial or Bazaar there is nothing else to install. If you\r\nare using Subversion you will need to install the pysvn package. If you using\r\nGit, you will need to install git-python bindings.\r\n\r\n\r\n============\r\nInstallation\r\n============\r\n\r\nThese instructions are for Unix, Mac OS X. They may work on Windows as well, but\r\nit hasn't been tested.\r\n\r\nIf you have downloaded the source package, Sumatra-0.3.0.tar.gz::\r\n\r\n    $ tar xzf Sumatra-0.3.0.tar.gz\r\n    $ cd Sumatra-0.3.0\r\n    # python setup.py install\r\n\r\nThe last step may have to be done as root.\r\n\r\n\r\nAlternatively, you can install directly from the Python Package Index::\r\n\r\n    $ pip install sumatra\r\n\r\nor::\r\n\r\n    $ easy_install sumatra"}}, {"pk": 85, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "GPolyEncode", "license": "UNKNOWN", "author": "Robert Coup", "author_email": "robert.coup@koordinates.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/py-gpolyencode/", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "gis,geospatial,google-maps,gmaps,mapping", "summary": "Google Maps Polyline encoding (pure Python)", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Utilities", "description": "Encode line & polygon coordinates for use in Google Maps."}}, {"pk": 86, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "wafo", "license": "GPL", "author": "WAFO-group", "author_email": "wafo@maths.lth.se", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/pywafo/", "version": "0.1.2", "platform": "Windows", "keywords": "", "summary": "Toolbox for statistical analysis and simulation of random waves and random loads.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: Microsoft :: Windows\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Mathematics", "description": "WAFO\r\n----\r\nWAFO is a toolbox Python routines for statistical analysis and simulation of random waves and random loads. \r\nWAFO is freely redistributable software, see WAFO licence, cf. the GNU General Public License (GPL) and contain tools for:\r\n\r\nFatigue Analysis\r\n----------------\r\n-Fatigue life prediction for random loads\r\n-Theoretical density of rainflow cycles\r\n\r\nSea modelling\r\n-------------\r\n-Simulation of linear and non-linear Gaussian waves\r\n-Estimation of seamodels (spectrums)\r\n-Joint wave height, wave steepness, wave period distributions\r\n\r\nStatistics\r\n------------\r\n-Extreme value analysis\r\n-Kernel density estimation\r\n-Hidden markov models\r\n\r\n WAFO consists of several subpackages and classes with short descriptions below.\r\n\r\n Classes:\r\n TimeSeries  - Data analysis of time series. Example: extraction of \r\n              turning points, estimation of spectrum and covariance function. \r\n              Estimation transformation used in transformed Gaussian model.\r\n CovData     - Computation of spectral functions, linear \r\n              and non-linear time series simulation. \r\n SpecData    - Computation of spectral moments and covariance functions, linear \r\n              and non-linear time series simulation. \r\n              Ex: common spectra implemented, directional spectra, \r\n              bandwidth measures, exact distributions for wave characteristics.\r\n  \r\n           \r\n CyclePairs  - Cycle counting, discretization, and crossings, calculation of \r\n              damage. Simulation of discrete Markov chains, switching Markov\r\n              chains, harmonic oscillator. Ex:  Rainflow cycles and matrix, \r\n              discretization of loads. Damage of a rainflow count or \r\n              matrix, damage matrix, S-N plot.\r\n \r\n \r\nSubpackages:\r\n TRANSFORM  - Modelling with linear or transformed Gaussian waves. Ex:\r\n STATS      - Statistical tools and extreme-value distributions.\r\n              Ex: generation of random numbers, estimation of parameters,\r\n              evaluation of pdf and cdf\r\n KDETOOLS   - Kernel-density estimation.\r\n MISC       - Miscellaneous routines. \r\n DOCS       - Documentation of toolbox, definitions. An overview is given \r\n              in the routine wafomenu. \r\n DATA       - Measurements from marine applications.\r\n \r\n WAFO homepage: <http://www.maths.lth.se/matstat/wafo/>\r\n On the WAFO home page you will find:\r\n  - The WAFO Tutorial\r\n  - New versions of WAFO to download.\r\n  - Reported bugs.\r\n  - List of publications related to WAFO."}}, {"pk": 87, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "hachoir-subfile", "license": "GNU GPL v2", "author": "Victor Stinner", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": "", "home_page": "http://bitbucket.org/haypo/hachoir/wiki/hachoir-subfile", "version": "0.5.3", "platform": "UNKNOWN", "keywords": "", "summary": "Find subfile in any binary stream", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Disassemblers\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Filesystems\nTopic :: Utilities", "description": "hachoir-subfile is a tool based on hachoir-parser to find subfiles in any binary stream.\n\nWebsite: http://bitbucket.org/haypo/hachoir/wiki/hachoir-subfile\n\nChangelog\n=========\n\nVersion 0.5.3 (2008-04-01):\n\n * Catch StreamError on file copy\n * Use \"#!/usr/bin/env python\" as shebang for FreeBSD\n\nVersion 0.5.2 (2007-07-13):\n\n * Fix shebang: use \"#!/usr/bin/python\"\n * Only import hachoir_core.profiler with --profiler command line\n   option is used, so hachoir-subfile do not depends on 'profiler'\n   Python module\n\nVersion 0.5.1 (2007-07-12):\n\n * Fix setup.py: also install script 'hachoir-subfile'\n\nVersion 0.5 (2007-07-11):\n\n * Publication of the first public version\n\nUsage\n=====\n\nSearch JPEG images:\n\n    hachoir-subfile input --parser=jpeg\n\nSearch images:\n\n    hachoir-subfile input --category=image\n\nSearch images, videos and SWF files:\n\n    hachoir-subfile input --category=image,video --parser=swf\n\nSearch all subfiles and store them in /tmp/subfiles/:\n\n    hachoir-subfile input /tmp/subfiles/\n\nOther options:\n\n * --offset: start search at specified offset in bytes\n * --size: limit search to specified size in bytes\n\nSearch speed is proportional to the number of used parsers.\n\nExamples\n========\n\nFind files in a hard drive:\n\n    $ hachoir-subfile /dev/sda --size=34200100 --quiet\n    [+] Start search (32.6 MB)\n\n    [+] Found file at 0: MS-DOS hard drive with Master Boot Record (MBR)\n    [+] Found file at 32256: FAT16 filesystem\n    [+] Found file at 346112 size=308280 (301.1 KB): Microsoft Bitmap version 3\n    [+] Found file at 32157696: MS-DOS executable\n    [+] Found file at 32483328: MS-DOS executable\n    [+] Found file at 32800768: MS-DOS executable\n    [+] Found file at 32851968: MS-DOS executable\n    [+] Found file at 32872448: MS-DOS executable\n    [+] Found file at 33058816: MS-DOS executable\n    [+] Found file at 33112064: MS-DOS executable\n    [+] Found file at 33142784: MS-DOS executable\n    [+] Found file at 33949936: Microsoft Windows Portable Executable: Intel 80386 or greater\n\n    [+] Search done -- offset=34200100 (32.6 MB)\n    Total time: 20.08 sec -- 1.6 MB/sec\n\n\nPowerPoint document:\n\n    $ hachoir-subfile chiens.PPS\n    [+] Start search (828.5 KB)\n\n    [+] Found file at 0: Microsoft Office document\n    [+] Found file at 537 size=28449 (27.8 KB): JPEG picture: 433x300 pixels\n    [+] Found file at 29011 size=34761 (33.9 KB): JPEG picture: 433x300 pixels\n    [+] Found file at 63797 size=40326 (39.4 KB): JPEG picture: 433x300 pixels\n    [+] Found file at 104148 size=30641 (29.9 KB): JPEG picture: 433x300 pixels\n    [+] Found file at 134814 size=22782 (22.2 KB): JPEG picture: 384x325 pixels\n    [+] Found file at 157621 size=24744 (24.2 KB): JPEG picture: 443x313 pixels\n    [+] Found file at 182390 size=27241 (26.6 KB): JPEG picture: 443x290 pixels\n    [+] Found file at 209656 size=27407 (26.8 KB): JPEG picture: 443x336 pixels\n    [+] Found file at 237088 size=30088 (29.4 KB): JPEG picture: 388x336 pixels\n    [+] Found file at 267201 size=30239 (29.5 KB): JPEG picture: 366x336 pixels\n    [+] Found file at 297465 size=81634 (79.7 KB): JPEG picture: 630x472 pixels\n    [+] Found file at 379124 size=36142 (35.3 KB): JPEG picture: 599x432 pixels\n    [+] Found file at 415291 size=28801 (28.1 KB): JPEG picture: 443x303 pixels\n    [+] Found file at 444117 size=28283 (27.6 KB): JPEG picture: 433x300 pixels\n    [+] Found file at 472425 size=95913 (93.7 KB): PNG picture: 433x431x8\n    [+] Found file at 568363 size=219252 (214.1 KB): PNG picture: 532x390x8\n    [+] Found file at 811308 size=20644 (20.2 KB): Microsoft Windows Metafile (WMF) picture\n\n    [+] Search done -- offset=848384 (828.5 KB)\n    Total time: 1.30 sec -- 635.1 KB/sec"}}, {"pk": 88, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "graphing_calc", "license": "http://www.opensource.org/licenses/mit-license.html", "author": "Jesse Weinstein", "author_email": "jessw@netwood.net", "project_url": null, "maintainer_email": null, "home_page": "http://purl.oclc.org/NET/JesseW/Python", "version": "1.1", "platform": "UNKNOWN", "keywords": null, "summary": "A module implementing a mathamatical graph generator.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization", "description": "Usage:\n    * Import the module; a Tk window will appear. (If you accidently destroy the\n        window, you can restore it with graphing_calc.make_interface())\n    * If you want to change any parameters, use graphing_calc.change().\n    * To graph an equation, use graphing_calc.a_graph().\nFor specific information on each function, see appropriete doc string."}}, {"pk": 89, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyssf", "license": "LGPL", "author": "UNKNOWN", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": null, "home_page": "http://pyssf.sourceforge.net", "version": "0.3.1", "platform": "UNKNOWN", "keywords": "REST,RESTful,OCCI,LSF,Platform,Cloud,Grid,Cluster,HPC", "summary": "Service Sharing Facility", "classifiers": "Development Status :: 2 - Pre-Alpha\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: System :: Distributed Computing\nTopic :: Utilities", "description": "A set of Python modules to integrate you existing or future applications with Clouds, Grids and Clusters. Includes an implementation of the OCCI specification."}}, {"pk": 90, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "CoreBio", "license": "UNKNOWN", "author": "Gavin Crooks", "author_email": "gec@threeplusone.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/corebio/", "version": "0.5.0", "platform": "UNKNOWN", "keywords": null, "summary": "A python toolkit for computational biology.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "CoreBio is a python toolkit for computational biology. It includes code to read and write biological sequence formats, access computational and database resources, and to perform sequence alignment and other computational analysis."}}, {"pk": 91, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "sympycore", "license": "http://sympycore.googlecode.com/svn/trunk/LICENSE", "author": "Pearu Peterson, Fredrik Johansson", "author_email": "sympycore@googlegroups.com", "project_url": null, "maintainer_email": null, "home_page": "http://sympycore.googlecode.com", "version": "0.1", "platform": "All", "keywords": null, "summary": "SympyCore: an efficient pure Python Computer Algebra System", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "SympyCore project provides a pure Python package sympycore for\nrepresenting symbolic expressions using efficient data structures as\nwell as methods to manipulate them. Sympycore uses a clear algebra\noriented design that can be easily extended."}}, {"pk": 92, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "katcp", "license": "BSD", "author": "Simon Cross", "author_email": "simon.cross@ska.ac.za", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/katcp", "version": "0.3.1", "platform": "OS Independent", "keywords": "kat kat7 ska", "summary": "Karoo Array Telescope Communication Protocol library", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 93, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.db", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.0.5", "platform": "OS Independent", "keywords": "ObsPy,seismology,seismogram,database,SeisHub", "summary": "A seismic waveform indexer and database for ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.db package contains a waveform indexer collecting metadata from a\nfile based waveform archive and storing in into a standard SQL database.\nSupported waveform formats depend on installed ObsPy packages.\n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology. \n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 94, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dynts", "license": "BSD", "author": "Luca Sbardella", "author_email": "luca@quantmind.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/quantmind/dynts/", "version": "0.4.0", "platform": "UNKNOWN", "keywords": null, "summary": "Quantitative financial timeseries analysis", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Plugins\nIntended Audience :: Developers\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: JavaScript\nProgramming Language :: Python\nTopic :: Office/Business :: Financial\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics", "description": ".. rubric:: A statistic package for python with enphasis on timeseries analysis.\r\n            Built around numpy_, it provides several back-end timeseries classes\r\n            including R-based objects via rpy2_.\r\n            It is shipped with a domain specific language for timeseries analysis\r\n            and manipulation.\r\n\r\n--\r\n\r\n:Documentation: http://packages.python.org/dynts/\r\n:Dowloads: http://pypi.python.org/pypi/dynts/\r\n:Source: http://github.com/quantmind/dynts\r\n:Keywords: timeseries, quantitative, finance, statistics, numpy, R, web\r\n\r\n--\r\n\r\n\r\n.. contents::\r\n    :local:\r\n\r\n\r\nTimeserie Object\r\n========================\r\n\r\nTo create a timeseries object directly::\r\n\r\n\t>>> from dynts import timeseries\r\n\t>>> ts = timeseries('test')\r\n\t>>> ts.type\r\n\t'zoo'\r\n\t>>> ts.name\r\n\t'test'\r\n\t>>> ts\r\n\tTimeSeries:zoo:test\r\n\t>>> str(ts)\r\n\t'test'\r\n\r\n\r\nDSL\r\n=======\r\nAt the core of the library there is a Domain-Specific-Language (DSL_) dedicated\r\nto timeserie analysis and manipulation. DynTS makes timeserie manipulation easy and fun.\r\nThis is a simple multiplication::\r\n\t\r\n\t>>> import dynts\r\n\t>>> e = dynts.parse('2*GOOG')\r\n\t>>> e\r\n\t2.0 * goog\r\n\t>>> len(e)\r\n\t2\r\n\t>>> list(e)\r\n\t[2.0, goog]\r\n\t>>> ts = dynts.evaluate(e).unwind()\r\n\t>>> ts\r\n\tTimeSeries:zoo:2.0 * goog\r\n\t>>> len(ts)\r\n\t251\r\n\r\n\r\nRequirements\r\n=====================\r\nThere are several requirements that must be met:\r\n\r\n* python_ 2.6 or later. Support for Python 3 series is under development and should be completed soon.\r\n* numpy_ version 1.5.1 or higher for arrays and matrices.\r\n* ply_ version 3.3 or higher, the building block of the DSL_.\r\n* rpy2_ if an R_ TimeSeries back-end is used (default).\r\n* ccy_ for date and currency manipulation.\r\n\r\nDepending on the back-end used, additional dependencies need to be met.\r\nFor example, there are back-ends depending on the following R packages:\r\n\r\n* zoo_ and PerformanceAnlytics_ for the ``zoo`` back-end (currently the default one)\r\n* timeSeries_ for the ``rmetrics`` back-end \r\n\r\nInstalling rpy2_ on Linux is straightforward, on windows it requires the\r\n`python for windows`__ extension library.\r\n\r\nOptional Requirements\r\n===============================\r\n\r\n* cython_ for performance. The library is not strictly dependent on cython, however its usage\r\n  is highly recommended. If available several python modules will be replaced by more efficient compiled C code.\r\n* xlwt_ to create spreadsheet from timeseries.\r\n* matplotlib_ for plotting.\r\n* djpcms_ for the ``web.views`` module.\r\n\r\n__ http://sourceforge.net/projects/pywin32/files/\r\n\r\n\r\n.. _running-tests:\r\n\r\nRunning Tests\r\n=================\r\nThere are three types of tests available:\r\n\r\n* ``regression`` for unit and regression tests.\r\n* ``profile`` for analysing performance of different backends and impact of cython_.\r\n* ``bench`` same as ``profile`` but geared towards speed rather than profiling.\r\n  \r\nFrom the distribution directory type::\r\n\t\r\n\tpython runtests.py\r\n\t\r\nThis will run by default the regression tests. To run a profile test\r\ntype::\r\n\r\n\tpython runtests.py -t profile <test-name>\r\n\t\r\nwhere ``<test-name>`` is the name of a profile test.\r\nTo obtain a list of available tests for each test type, run::\r\n\r\n\tpython runtests.py --list\r\n\r\nfor regression, or:: \r\n\r\n\tpython runtests.py -t profile --list\r\n\t\r\nfor profile, or::\r\n\r\n\tpython runtests.py -t bench --list\r\n\t\r\nfrom benchmarks.\r\n\t\r\nIf you access the internet behind a proxy server, pass the ``-p`` option, for example::\r\n\r\n\tpython runtests.py -p http://myproxy.com:80\r\n\r\nIt is needed since during tests some data is fetched from google finance.\r\n\r\nTo access coverage of tests you need to install the coverage_ package and run the tests using::\r\n\r\n\tcoverage run runtests.py\r\n\t\r\nand to check out the coverage report::\r\n\r\n\tcoverage report -m\r\n\t\r\n\r\nKudos\r\n===========\r\n* numpy_ developers.\r\n\r\n\r\nCommunity\r\n=================\r\nTrying to use an IRC channel **#dynts** on ``irc.freenode.net``\r\n(you can use the webchat at http://webchat.freenode.net/).\r\n\r\nIf you find a bug or would like to request a feature, please `submit an issue`__.\r\n\r\n__ http://github.com/quantmind/dynts/issues\r\n    \r\n.. _numpy: http://numpy.scipy.org/\r\n.. _ply: http://www.dabeaz.com/ply/\r\n.. _rpy2: http://rpy.sourceforge.net/rpy2.html\r\n.. _DSL: http://en.wikipedia.org/wiki/Domain-specific_language\r\n.. _R: http://www.r-project.org/\r\n.. _ccy: http://code.google.com/p/ccy/\r\n.. _zoo: http://cran.r-project.org/web/packages/zoo/index.html\r\n.. _PerformanceAnlytics: http://cran.r-project.org/web/packages/PerformanceAnalytics/index.html\r\n.. _timeSeries: http://cran.r-project.org/web/packages/timeSeries/index.html\r\n.. _Python: http://www.python.org/\r\n.. _xlwt: http://pypi.python.org/pypi/xlwt\r\n.. _matplotlib: http://matplotlib.sourceforge.net/\r\n.. _djpcms: http://djpcms.com\r\n.. _coverage: http://nedbatchelder.com/code/coverage/\r\n.. _cython: http://www.cython.org/"}}, {"pk": 95, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PyChem", "license": "GNU General Public Licence", "author": "Roger Jarvis", "author_email": "roger.jarvis@manchester.ac.uk", "project_url": null, "maintainer_email": "", "home_page": "http://pychem.sf.net/", "version": "3.0.5", "platform": "Windows,Unix", "keywords": "multivariate analysis, chemometrics, genetic  algorithm", "summary": "A platform-independent graphical environment for multivariate analysis incorporating a number of categorical and quanitative multivariate modelling routines", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Scientific/Engineering :: GIS\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Visualization", "description": "A graphical univariate and multivariate analysis package for WinXP and Linux.\r\nFeatures ANOVA & Kruskal-Wallis tests, principal components analysis (PCA),\r\ndiscriminant function analysis (DFA), cluster analysis, partial least squares DA\r\nand regression, genetic algorithms for feature selection."}}, {"pk": 96, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "GDAL", "license": "MIT", "author": "Howard Butler", "author_email": "hobu.inc@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.gdal.org", "version": "1.7.1", "platform": "UNKNOWN", "keywords": null, "summary": "GDAL: Geospatial Data Abstraction Library", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Scientific/Engineering :: Information Analysis", "description": "GDAL/OGR in Python\n==================\n \nThis Python package and extensions are a number of tools for programming and \nmanipulating the GDAL_ Geospatial Data Abstraction Library.  Actually, it is \ntwo libraries -- GDAL for manipulating geospatial raster data and OGR for \nmanipulating geospatial vector data -- but we'll refer to the entire package \nas the GDAL library for the purposes of this document.\n\nThe GDAL project (primarily Howard Butler) maintains SWIG generated Python \nbindings for GDAL and OGR. Generally speaking the classes and methods mostly \nmatch those of the GDAL and OGR C++ classes. There is no Python specific \nreference documentation, but the `GDAL API Tutorial`_ includes Python examples.\n\nDependencies\n------------\n \n * libgdal (1.7.0 or greater) and header files (gdal-devel)\n * numpy (1.0.0 or greater) and header files (numpy-devel) (not explicitly \n   required, but many examples and utilities will not work without it)\n\nInstallation\n------------\n\nUnix\n~~~~~~~~~~~~~\n\nThe GDAL Python bindings support both distutils and setuptools, with a \npreference for using setuptools.  If setuptools can be imported, setup will \nuse that to build an egg by default.  If setuptools cannot be imported, a \nsimple distutils root install of the GDAL package (and no dependency \nchaining for numpy) will be made.  \n\neasy_install\n~~~~~~~~~~~~\n\nGDAL can be installed from the Python CheeseShop::\n\n  $ sudo easy_install GDAL\n\nIt may be necessary to have libgdal and its development headers installed \nif easy_install is expected to do a source build because no egg is available \nfor your specified platform and Python version.\n\nsetup.py\n~~~~~~~~~\n\nMost of setup.py's important variables are controlled with the setup.cfg \nfile.  In setup.cfg, you can modify pointers to include files and libraries.  \nThe most important option that will likely need to be modified is the \ngdal_config parameter.  If you installed GDAL from a package, the location \nof this program is likely /usr/bin/gdal-config, but it may be in another place \ndepending on how your packager arranged things.  \n\nAfter modifying the location of gdal-config, you can build and install \nwith the setup script::\n  \n  $ python setup.py build\n  $ python setup.py install\n\nIf you have setuptools installed, you can also generate an egg::\n  \n  $ python setup.py bdist_egg\n\nBuilding as part of the GDAL library source tree\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nYou can also have the GDAL Python bindings built as part of a source \nbuild by specifying --with-python as part of your configure line::\n\n  $ ./configure --with-python\n\nUse the typical make and make install commands to complete the installation:: \n  \n  $ make\n  $ make install\n\nA note about setuptools\n.......................\n\n./configure attempts to detect if you have setuptools installed in the tree \nof the Python binary it was given (or detected on the execution path), and it \nwill use an egg build by default in that instance.  If you have a need to \nuse a distutils-only install, you will have to edit setup.py to ensure that \nthe HAVE_SETUPTOOLS variable is ultimately set to False and proceed with a \ntypical 'python setup.py install' command.\n\nWindows\n~~~~~~~~~~~~\n\nYou will need the following items to complete an install of the GDAL Python\nbindings on Windows:\n\n* `GDAL Windows Binaries`_ The basic install requires the gdalwin32exe###.zip \n  (### is the version number).  Other files you see in the directory are \n  for various optional plugins and development headers/include files. After \n  downloading the zip file, extract it to the directory of your choosing.\n\n* GDAL Python Bindings available at the `Python Cheeseshop`_.  An executable \n  installer is available for both Python 2.4 or 2.5 or as a Python egg.\n\nAs explained in the README_EXE.txt file, after unzipping the GDAL binaries you \nwill need to modify your system path and variables. If you're not sure how to \ndo this, read the `Microsoft KnowledgeBase doc`_ \n\n1. Add the installation directory bin folder to your system PATH, remember \n   to put a semicolon in front of it before you add to the existing path.\n\n   ::\n  \n     C:\\gdalwin32-1.7\\bin\n\n2. Create a new user or system variable with the data folder from \n   your installation.\n\n   ::\n  \n     Name : GDAL_DATA\n     Path : C:\\gdalwin32-1.7\\data\n\nSkip down to the `Usage`_ section to test your install. Note, a reboot \nmay be required.\n\nSWIG\n----\n\nThe GDAL Python package is built using SWIG_. The earliest version of SWIG_ \nthat is supported to generate the wrapper code is 1.3.39.  It is possible \nthat usable bindings will build with a version earlier than 1.3.39, but no \ndevelopment efforts are targeted at versions below it.  You should not have \nto run SWIG in your development tree to generate the binding code, as it \nis usually included with the source.  However, if you do need to regenerate, \nyou can do so with the following make command from within the ./swig/python\ndirectory::\n\n  $ make generate\n\nTo ensure that all of the bindings are regenerated, you can clean the \nbindings code out before the generate command by issuing::\n\n  $ make veryclean\n\nUsage\n-----\n\nImports\n~~~~~~~\n\nThere are five major modules that are included with the GDAL_ Python bindings.::\n\n  >>> from osgeo import gdal\n  >>> from osgeo import ogr\n  >>> from osgeo import osr\n  >>> from osgeo import gdal_array\n  >>> from osgeo import gdalconst\n\nAdditionally, there are five compatibility modules that are included but \nprovide notices to state that they are deprecated and will be going away.  \nIf you are using GDAL 1.7 bindings, you should update your imports to utilize \nthe usage above, but the following will work until at least GDAL 2.0. ::\n\n  >>> import gdal\n  >>> import ogr\n  >>> import osr\n  >>> import gdalnumeric\n  >>> import gdalconst\n\nIf you have previous code that imported the global module and still need to \nsupport the old import, a simple try...except import can silence the \ndeprecation warning and keep things named essentially the same as before::\n\n  >>> try:\n  ...     from osgeo import gdal\n  ... except ImportError:\n  ...     import gdal\n\nDocstrings\n~~~~~~~~~~\n\nCurrently, only the OGR module has docstrings which are generated from the \nC/C++ API doxygen materials.  Some of the arguments and types might not \nmatch up exactly with what you are seeing from Python, but they should be \nenough to get you going.  Docstrings for GDAL and OSR are planned for a future \nrelease.\n\nThe History of Using GDAL/OGR in Python\n---------------------------------------\n\nPython was the first set of bindings supported by GDAL/OGR and though the \nbindings were generated with SWIG (1.1 series), the process was very Python \nspecific and contained a significant amount of hand written wrapper code. In \n2005, Kevin Ruland launched an effort for a set of next generation bindings \ngenerated with SWIG (1.3 series) and supported by a variety of languages. \nWith GDAL 1.4.0 the various bindings became fairly mature, and for GDAL 1.5.0, \nthe \"next-generation\" bindings become the default bindings.  The previous, \n\"old-generation,\" bindings will continue to be available, but they will not \nbe widely supported and no new development will be targeted at them.  From \nthe viewpoint of a user, with GDAL 1.7.0 and above, you should not have to \nworry very much about the distinction between these two development efforts.\n\nNumpy/Numeric\n-------------\n\nOne advanced feature of the GDAL Python bindings not found in the other \nlanguage bindings (C#, Perl) is integration with the Python numerical array \nfacilities. The gdal.Dataset.ReadAsArray() method can be used to read raster \ndata as numerical arrays, ready to use with the Python numerical array \ncapabilities.\n\nThese facilities have evolved somewhat over time. In the past the package was \nknown as \"Numeric\" and imported using \"import Numeric\". A new generation is \nimported using \"import numpy\". Currently the old generation bindings only \nsupport the older Numeric package, and the new generation bindings only \nsupport the new generation numpy package. They are mostly compatible, and \nby importing gdalnumeric (or osgeo.gdal_array) you will get whichever is\nappropriate to the current bindings type.\n\nExamples\n~~~~~~~~\n\nOne example of GDAL/numpy integration is found in the `val_repl.py`_ script.\n\nPerformance Notes\n~~~~~~~~~~~~~~~~~\n\nReadAsArray expects to make an entire copy of a raster band or dataset unless \nthe data are explicitly subsetted as part of the function call. For large \ndata, this approach is expected to be prohibitively memory intensive.\n\n.. _GDAL API Tutorial: http://www.gdal.org/gdal_tutorial.html\n.. _GDAL Windows Binaries: http://download.osgeo.org/gdal/win32/1.5/\n.. _Microsoft KnowledgeBase doc: http://support.microsoft.com/kb/310519\n.. _Python Cheeseshop: http://pypi.python.org/pypi/GDAL/\n.. _val_repl.py: http://trac.osgeo.org/gdal/browser/trunk/gdal/swig/python/samples/val_repl.py\n.. _GDAL: http://www.gdal.org\n.. _SWIG: http://www.swig.org"}}, {"pk": 97, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "openallure", "license": "LICENSE.txt", "author": "John Graves", "author_email": "john.graves@aut.ac.nz", "project_url": null, "maintainer_email": null, "home_page": "http://openallureds.org", "version": "0.1d17", "platform": "Windows,Linux,Mac", "keywords": null, "summary": "Voice-and-vision enabled dialog system", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Education\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Education\nTopic :: Multimedia :: Sound/Audio :: Speech\nTopic :: Multimedia :: Video :: Capture\nTopic :: Scientific/Engineering :: Human Machine Interfaces", "description": "===========\nOpen Allure\n===========\n\nOpen Allure is a voice-and-vision enabled dialog system\n\nFor the latest version, please check http://openallureds.org\n\nDependencies\n============\n\nThese may vary depending on the platform\n\ndragonfly\nhttp://code.google.com/p/dragonfly/\n\nPygame\nhttp://www.pygame.org/download.shtml\nVersion 1.9.1 was used during development of Open Allure\n\nBeautifulSoup\nhttp://www.crummy.com/software/BeautifulSoup/download/3.x/BeautifulSoup-3.0.8.tar.gz\nVersion 3.0.8 was used during development of Open Allure\n(easy_install BeautifulSoup)\n\nNLTK\nhttp://www.nltk.org/download\nSteven Bird, <sb@csse.unimelb.edu.au>\n\nLicense\n=======\n\nCopyright (c) 2010 John Graves\n\nMIT License.  See LICENSE.txt\n\n\nContributors\n============\nJohn Graves, <john.graves@aut.ac.nz>\nBrian Thorne, <brian.thorne@canterbury.ac.nz>"}}, {"pk": 98, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "logtools", "license": "UNKNOWN", "author": "Adam Ever-Hadani", "author_email": "adamhadani@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/adamhadani/logtools", "version": "0.6", "platform": "UNKNOWN", "keywords": "logging,sampling,geoip,filterbots,aggregate,logparse,logmerge,logjoin,urlparse,logplot,qps,filter", "summary": "Log analysis and filtering tools", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: Apache Software License\nOperating System :: POSIX\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nTopic :: Internet :: Log Analysis\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Text Processing :: Filters\nTopic :: Utilities", "description": "A log files analysis / filtering framework.\n\nlogtools encompasses of a few easy-to-use, easy to configure command-line\ntools, typically used in conjunction with Apache logs.\n\nThe idea is to standardize log parsing and filtering using a coherent\nconfiguration methodology and UNIX command-line interface (STDIN input streaming, command-line piping etc.)\nso as to create a consistent environment for creating reports, charts and other such\nlog mining artifacts that are typically employed in a Website context.\n\nThis software is distributed under the Apache 2.0 license."}}, {"pk": 99, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.component.executables", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.component.executables", "version": "3.4", "platform": "any", "keywords": "utility", "summary": "PyUtilib plugin for managing executables", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "====================================\npyutilib.component.executable README\n====================================\n\nA PyUtilib plugin for managing executables in an application.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\n* pyutilib.component.core"}}, {"pk": 100, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyke", "license": "MIT License", "author": "Bruce Frederiksen", "author_email": "dangyogi@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://sourceforge.net/projects/pyke", "version": "1.1.1", "platform": "UNKNOWN", "keywords": "expert system forward backward chaining backtracking plans", "summary": "Python Knowledge Engine and Automatic Python Program Generator", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: Log Analysis\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Code Generators", "description": "Both forward-chaining and backward-chaining rules (which may include\n        python code) are compiled into python. Can also automatically assemble\n        python programs out of python functions which are attached to\n        backward-chaining rules."}}, {"pk": 101, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.misc", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.misc", "version": "4.5.2", "platform": "any", "keywords": "utility", "summary": "Miscellaneous PyUtilib utilities", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "====================\npyutilib.misc README\n====================\n\nThis Python package includes miscellaneous utilities.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\n+ pyutilib.common"}}, {"pk": 102, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyreport", "license": "BSD", "author": "Gael Varoquaux", "author_email": "gael.varoquaux@normalesup.org", "project_url": null, "maintainer_email": null, "home_page": "http://gael-varoquaux.info/computers/pyreport/", "version": "0.3.4c", "platform": "any", "keywords": null, "summary": "Pyreport makes notes out of a python script. It can run the script in a sandbox and capture its output. It allows for embedding RestructuredText or LaTeX comments in the code for literate programming and generates a report made of the literate comments, the code, pretty printed, and the output of the script (pyreport can capture pylab figures). This is useful for documentations, making tutorials, but also for sharing python-based calculations with colleagues.", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "UNKNOWN"}}, {"pk": 103, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mpi4py", "license": "BSD", "author": "Lisandro Dalcin", "author_email": "dalcinl@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://mpi4py.googlecode.com/", "version": "1.2.2", "platform": "Mac OS X,Linux,Solaris,Unix,Windows", "keywords": "scientific computing,parallel computing,message passing,MPI", "summary": "MPI for Python", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nOperating System :: POSIX :: SunOS/Solaris\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Cython\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Distributed Computing", "description": "This package provides MPI support for Python scripting in parallel\nenvironments. It is constructed on top of the MPI-1/MPI-2\nspecification, but provides an object oriented interface which closely\nfollows the MPI-2 C++ bindings.\n\nThis module supports point-to-point (send, receive) and collective\n(broadcast, scatter, gather, reduction) communications of any\n*picklable* Python object.\n\nFor objects exporting single-segment buffer interface (strings, NumPy\narrays, etc.), blocking/nonbloking/persistent point-to-point,\ncollective and one-sided (put, get, accumulate) communications are\nfully supported, as well as parallel I/O (blocking and nonbloking,\ncollective and noncollective read and write operations using explicit\nfile offsets, individual file pointers and shared file\npointers).\n\nThere is also full support for group and communicator (inter, intra,\nCartesian and graph topologies) creation and management, as well as\ncreating user-defined datatypes. Additionally, there is almost\ncomplete support for dynamic process creation and management (spawn,\nname publishing)."}}, {"pk": 104, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "regex", "license": "Python Software Foundation License", "author": "Matthew Barnett", "author_email": "regex@mrabarnett.plus.com", "project_url": null, "maintainer_email": null, "home_page": "http://bugs.python.org/issue2636", "version": "0.1.20110315", "platform": "UNKNOWN", "keywords": null, "summary": "Alternate regular expression module, to replace re.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: Python Software Foundation License\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3.1\nProgramming Language :: Python :: 3.2\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing\nTopic :: Text Processing :: General", "description": "Notes\n-----\n\nFor testing and comparison with the current 're' module the new implementation is in the form of a module called 'regex'.\n\nPlease note that certain aspects of this module have changed from those of previous versions to make it conform better to the 're' module.\n\nPlease also note that ``matchobject.captures`` and the related methods now return a **list** (or a tuple of lists for the multi-group versions) instead of a tuple as previously.\n\n\nFlags\n-----\n\nThere are 2 kinds of flag: scoped and global. Scoped flags can apply to only part of a pattern and can be turned on or off; global flags apply to the entire pattern and can only be turned on.\n\nThe scoped flags are: ``IGNORECASE``, ``MULTILINE``, ``DOTALL``, ``VERBOSE``, ``WORD``.\n\nThe global flags are: ``ASCII``, ``LOCALE``, ``NEW``, ``REVERSE``, ``UNICODE``.\n\nIf neither the ASCII, LOCALE nor UNICODE flag is specified, the default is UNICODE if the regex pattern is a Unicode string and ASCII if it's a bytestring.\n\nThe ``NEW`` flag turns on the new behaviour of this module, which can differ from that of the 're' module, such as splitting on zero-width matches, inline flags affecting only what follows, and being able to turn inline flags off.\n\n\nNotes on named capture groups\n-----------------------------\n\nAll capture groups have a group number, starting from 1.\n\nGroups with the same group name will have the same group number, and groups with a different group name will have a different group number.\n\nThe same group name can be used on different branches of an alternation because they are mutually exclusive, eg. ``(?P<foo>first)|(?P<foo>second)``. They will, of course, have the same group number.\n\nGroup numbers will be reused, where possible, across different branches of a branch reset, eg. ``(?|(first)|(second))`` has only group 1. If capture groups have different group names then they will, of course, have different group numbers, eg. ``(?|(?P<foo>first)|(?P<bar>second))`` has group 1 (\"foo\") and group 2 (\"bar\").\n\n\nMultithreading\n--------------\n\nThe regex module releases the GIL during matching on instances of the built-in (immutable) string classes, enabling other Python threads to run concurrently. It is also possible to force the regex module to release the GIL during matching by calling the matching methods with the keyword argument ``concurrent=True``. The behaviour is undefined if the string changes during matching, so use it *only* when it is guaranteed that that won't happen.\n\n\nBuilding for 64-bits\n--------------------\n\nIf the source files are built for a 64-bit target then the string positions will also be 64-bit. (The 're' module appears to limit string positions to 32 bits, even on a 64-bit build.)\n\n\nUnicode\n-------\n\nThis module supports Unicode 6.0.0.\n\n\n\nAdditional features\n-------------------\n\n* regex.escape (issue #2650)\n\n    regex.escape has an additional keyword parameter ``special_only``. When True, only 'special' regex characters, such as '?', are escaped.\n\n    Examples:\n\n        >>> regex.escape(\"foo!?\")\n        'foo\\\\!\\\\?'\n        >>> regex.escape(\"foo!?\", special_only=True)\n        'foo!\\\\?'\n\n* Repeated captures (issue #7132)\n\n    A match object has additional methods which return information on all the successful matches of a repeated capture group. These methods are:\n\n    ``matchobject.captures([group1, ...])``\n\n        Returns a list of the strings matched in a group or groups. Compare with ``matchobject.group([group1, ...])``.\n\n    ``matchobject.starts([group])``\n\n        Returns a list of the start positions. Compare with ``matchobject.start([group])``.\n\n    ``matchobject.ends([group])``\n\n        Returns a list of the end positions. Compare with ``matchobject.end([group])``.\n\n    ``matchobject.spans([group])``\n\n        Returns a list of the spans. Compare with ``matchobject.span([group])``.\n\n    Examples:\n\n        >>> m = regex.search(r\"(\\w{3})+\", \"123456789\")\n        >>> m.group(1)\n        '789'\n        >>> m.captures(1)\n        ['123', '456', '789']\n        >>> m.start(1)\n        6\n        >>> m.starts(1)\n        [0, 3, 6]\n        >>> m.end(1)\n        9\n        >>> m.ends(1)\n        [3, 6, 9]\n        >>> m.span(1)\n        (6, 9)\n        >>> m.spans(1)\n        [(0, 3), (3, 6), (6, 9)]\n\n* Atomic grouping (issue #433030)\n\n    ``(?>...)``\n\n    If the following pattern subsequently fails, then the subpattern as a whole will fail.\n\n* Possessive quantifiers.\n\n    ``(?:...)?+`` ; ``(?:...)*+`` ; ``(?:...)++`` ; ``(?:...){min,max}+``\n\n    The subpattern is matched up to 'max' times. If the following pattern subsequently fails, then all of the repeated subpatterns will fail as a whole. For example, ``(?:...)++`` is equivalent to ``(?>(?:...)+)``.\n\n* Scoped flags (issue #433028)\n\n    ``(?flags-flags:...)``\n\n    The flags will apply only to the subpattern. Flags can be turned on or off.\n\n* Inline flags (issue #433024, issue #433027)\n\n    ``(?flags-flags)``\n\n    If the ``NEW`` flag is turned on then the flags will apply to the end of the group or pattern and can be turned on or off. If the ``NEW`` flag isn't turned on then the flags will be global and can't be turned off.\n\n* Repeated repeats (issue #2537)\n\n    A regex like ``((x|y+)*)*`` will be accepted and will work correctly, but should complete more quickly.\n\n* Definition of 'word' character (issue #1693050)\n\n    The definition of a 'word' character has been expanded for Unicode. This applies to ``\\w``, ``\\W``, ``\\b`` and ``\\B``.\n\n* Groups in lookahead and lookbehind (issue #814253)\n\n    Groups and group references are permitted in both lookahead and lookbehind.\n\n* Variable-length lookbehind\n\n    A lookbehind can match a variable-length string.\n\n* Correct handling of charset with ignore case flag (issue #3511)\n\n    Ranges within charsets are handled correctly when the ignore-case flag is turned on.\n\n* Unmatched group in replacement (issue #1519638)\n\n    An unmatched group is treated as an empty string in a replacement template.\n\n* 'Pathological' patterns (issue #1566086, issue #1662581, issue #1448325, issue #1721518, issue #1297193)\n\n    'Pathological' patterns should complete more quickly.\n\n* Flags argument for regex.split, regex.sub and regex.subn (issue #3482)\n\n    ``regex.split``, ``regex.sub`` and ``regex.subn`` support a 'flags' argument.\n\n* Pos and endpos arguments for regex.sub and regex.subn\n\n    ``regex.sub`` and ``regex.subn`` support 'pos' and 'endpos' arguments.\n\n* 'Overlapped' argument for regex.findall and regex.finditer\n\n    ``regex.findall`` and ``regex.finditer`` support an 'overlapped' flag which permits overlapped matches.\n\n* Unicode escapes (issue #3665)\n\n    The Unicode escapes ``\\uxxxx`` and ``\\Uxxxxxxxx`` are supported.\n\n* Large patterns (issue #1160)\n\n    Patterns can be much larger.\n\n* Zero-width match with regex.finditer (issue #1647489)\n\n    ``regex.finditer`` behaves correctly when it splits at a zero-width match.\n\n* Zero-width split with regex.split (issue #3262)\n\n    ``regex.split`` can split at a zero-width match if the ``NEW`` flag is turned on. When the flag is turned off the current behaviour is unchanged because the BDFL thinks that some existing software might depend on it.\n\n* Splititer\n\n    ``regex.splititer`` has been added. It's a generator equivalent of ``regex.split``.\n\n* Subscripting for groups\n\n    A match object accepts access to the captured groups via subscripting and slicing:\n\n    >>> m = regex.search(r\"(?P<before>.*?)(?P<num>\\d+)(?P<after>.*)\", \"pqr123stu\")\n    >>> print m[\"before\"]\n    pqr\n    >>> print m[\"num\"]\n    123\n    >>> print m[\"after\"]\n    stu\n    >>> print len(m)\n    4\n    >>> print m[:]\n    ('pqr123stu', 'pqr', '123', 'stu')\n\n* Named groups\n\n    Groups can be named with ``(?<name>...)`` as well as the current ``(?P<name>...)``.\n\n* Group references\n\n    Groups can be referenced within a pattern with ``\\g<name>``. This also allows there to be more than 99 groups.\n\n* Named characters\n\n    ``\\N{name}``\n\n    Named characters are supported.\n\n* Unicode codepoint properties, blocks and scripts\n\n    ``\\p{name}`` ; ``\\P{name}``\n\n    Unicode properties, blocks and scripts are supported. ``\\p{name}`` matches a character which has property 'name' and ``\\P{name}`` matches a character which doesn't have property 'name'.\n\n    In order to avoid ambiguity, block names should start with ``In`` and script names should start with ``Is``. If a name lacks such a prefix and it could be a block or a script, script will take priority, for example:\n\n    1. ``InBasicLatin`` or ``BasicLatin``, the 'BasicLatin' **block**.\n\n    2. ``IsLatin`` or ``Latin``, the 'Latin' **script**.\n\n    3. ``InCyrillic``, the 'Cyrillic' **block**.\n\n    4. ``IsCyrillic`` or ``Cyrillic``, the 'Cyrillic' **script**.\n\n* POSIX character classes\n\n    ``[[:alpha:]]``\n\n    POSIX character classes are supported.\n\n* Search anchor\n\n    ``\\G``\n\n    A search anchor has been added. It matches at the position where each search started/continued and can be used for contiguous matches or in negative variable-length lookbehinds to limit how far back the lookbehind goes:\n\n    >>> regex.findall(r\"\\w{2}\", \"abcd ef\")\n    ['ab', 'cd', 'ef']\n    >>> regex.findall(r\"\\G\\w{2}\", \"abcd ef\")\n    ['ab', 'cd']\n\n    1. The search starts at position 0 and matches 2 letters 'ab'.\n\n    2. The search continues at position 2 and matches 2 letters 'cd'.\n\n    3. The search continues at position 4 and fails to match any letters.\n\n    4. The anchor stops the search start position from being advanced, so there are no more results.\n\n* Reverse searching\n\n    Searches can now work backwards:\n\n    >>> regex.findall(r\".\", \"abc\")\n    ['a', 'b', 'c']\n    >>> regex.findall(r\"(?r).\", \"abc\")\n    ['c', 'b', 'a']\n\n    Note: the result of a reverse search is not necessarily the reverse of a forward search:\n\n    >>> regex.findall(r\"..\", \"abcde\")\n    ['ab', 'cd']\n    >>> regex.findall(r\"(?r)..\", \"abcde\")\n    ['de', 'bc']\n\n* Matching a single grapheme\n\n    ``\\X``\n\n    The grapheme matcher is supported. It's equivalent to ``\\P{M}\\p{M}*``.\n\n* Branch reset\n\n    (?|...|...)\n\n    Capture group numbers will be reused across the alternatives.\n\n* Default Unicode word boundary\n\n    The ``WORD`` flag changes the definition of a 'word boundary' to that of a default Unicode word boundary. This applies to ``\\b`` and ``\\B``.\n\n    Please note: I'm unsure whether I've understood the specification correctly, so if you're using this feature I'd be interested in any feedback.\n\n* SRE engine do not release the GIL (issue #1366311)\n\n    The regex module can release the GIL during matching (see the above section on multithreading).\n\n    Iterators can be safely shared across threads."}}, {"pk": 105, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nested_dict", "license": "MIT", "author": "Leo Goodstadt", "author_email": "pypi@llew.org.uk", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "1.0.9", "platform": "UNKNOWN", "keywords": "make task pipeline parallel bioinformatics science", "summary": "defaultdict extension for dictionaries with multiple levels of nesting", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "Hosted at http://code.google.com/p/nested-dict/\n(Documentation at http://nested-dict.googlecode.com/hg/doc/build/html/index.html)\n\n***************************************\nnested dictionaries\n***************************************\n    **nested_dict** extends `collections.defaultdict <http://docs.python.org/library/collections.html#defaultdict-objects>`_\n    to allow dictionaries with multiple levels of nesting to be created on the fly::\n\n\n        from nested_dict import *\n\n        nd = nested_dict()\n\n        nd[\"a\"][\"b\"][\"c\"] = 311\n        nd[\"d\"][\"e\"] = 311\n\n    Each nested level is create magically when accessed, a process known as\n    `\"auto-vivification\" <http://en.wikipedia.org/wiki/Autovivification>`_ in perl.\n\n\n******************************************************************************\nnested dictionaries of sets / lists and other collections\n******************************************************************************\n    **nested_dict** also extends `collections.defaultdict <http://docs.python.org/library/collections.html#defaultdict-objects>`_\n    to allow dictionaries of lists, sets or other collections with a specified level of nesting level.\n\n\n==================================================\n    1) The old fashioned way using ugly syntax\n==================================================\n    ::\n\n        d = dict()\n\n        d.setdefault(\"\"1st group\", []).append(3)\n        d.setdefault(\"\"2nd group\", []).append(5)\n        d.setdefault(\"\"2nd group\", []).append(8)\n        d.setdefault(\"\"1st group\", []).append(4)\n        d.setdefault(\"\"2nd group\", []).append(5)\n\n====================================================================================================\n    2) ``default_dict`` adds ``list``\\ s automatically when required\n====================================================================================================\n    ::\n\n        from collections import defaultdict\n\n        dd = defaultdict(list)\n\n        dd[\"1st group\"].append(3)\n        dd[\"2nd group\"].append(5)\n        dd[\"2nd group\"].append(8)\n        dd[\"1st group\"].append(4)\n        dd[\"2nd group\"].append(5)\n\n====================================================================================================\n    3) ``nested_dict`` adds ``list``\\ s automatically when required for nested dictionaries\n====================================================================================================\n    ::\n\n        from nested_dict import nested_dict\n\n        # specify two levels of nesting\n        nd = nested_dict(2, list)\n\n        nd[\"1st group\"][\"subset a\"].append(3)\n        nd[\"2nd group\"][\"subset a\"].append(5)\n        nd[\"2nd group\"][\"subset b\"].append(8)\n        nd[\"1st group\"][\"subset a\"].append(4)\n        nd[\"2nd group\"][\"subset b\"].append(5)\n\n        print nd\n\n    gives::\n\n            {'1st group': {'subset a': [3, 4]},\n             '2nd group': {'subset b': [8, 5],\n                           'subset a': [5]}}\n\n\n*********************************\nMore examples:\n*********************************\n\n==================================\n    \"Auto-vivifying\" nested dict\n==================================\n        ::\n\n            nd= nested_dict()\n            nd[\"mouse\"][\"chr1\"][\"+\"] = 311\n            nd[\"mouse\"][\"chromosomes\"]=\"completed\"\n            nd[\"mouse\"][\"chr2\"] = \"2nd longest\"\n            nd[\"mouse\"][\"chr3\"] = \"3rd longest\"\n\n            for k, v in nd.iteritems_flat():\n                 print \"%-30s=-%20s\" % (k,v)\n\n        Gives\n            ::\n\n                ('mouse', 'chr3')             =-         3rd longest\n                ('mouse', 'chromosomes')      =-           completed\n                ('mouse', 'chr2')             =-         2nd longest\n                ('mouse', 'chr1', '+')        =-                 311\n\n====================================================================\n    Specifying the autovivified object\n====================================================================\n    If you wish the nested dictionary to hold a collection rather than a scalar,\n    you have to write::\n\n            nd[\"mouse\"][\"chr2\"] = list()\n            nd[\"mouse\"][\"chr2\"].append(12)\n\n    or::\n\n            nd[\"mouse\"][\"chr2\"] = set()\n            nd[\"mouse\"][\"chr2\"].add(84)\n\n    Which doesn't seem very \"auto\" at all!\n\n    Instead, specify the collection in the constructor of **nested_dict**::\n\n        # two levels of nesting\n        nd2 = nested_dict(2, list)\n        nd2[\"mouse\"][\"chr2\"].append(12)\n\n        # three levels of nesting\n        nd3 = nested_dict(3, set)\n        nd3[\"mouse\"][\"chr2\"][\"categorised\"].add(3)\n\n        # counts\n        nd4 = nested_dict(2, int)\n        nd4[\"mouse\"][\"chr2\"]+=4\n        nd4[\"human\"][\"chr1\"]+=3\n        nd4[\"human\"][\"chr3\"]+=4"}}, {"pk": 106, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.fissures", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.6", "platform": "OS Independent", "keywords": "ObsPy,seismology,fissures,DHI,IRIS,CORBA", "summary": "DHI/Fissures request client for of ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "obspy.fissures - DHI/Fissures request client for of ObsPy\n    \n    The Data Handling Interface (DHI) is a CORBA data access framework\n    allowing users to access seismic data and metadata from IRIS DMC\n    and other participating institutions directly from a DHI-supporting\n    client program. The effect is to eliminate the extra steps of\n    running separate query interfaces and downloading of data before\n    visualization and processing can occur. The information is loaded\n    directly into the application for immediate use.\n    http://www.iris.edu/dhi/\n    \n    Detailed information on network_dc and seismogram_dc servers:\n     * http://www.seis.sc.edu/wily\n     * http://www.iris.edu/dhi/servers.htm"}}, {"pk": 107, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyepix", "license": "GPL", "author": "Andrew Sterian", "author_email": "steriana@claymore.engineer.gvsu.edu", "project_url": null, "maintainer_email": null, "home_page": "http://claymore.engineer.gvsu.edu/~steriana/Python", "version": "6-1.0.4", "platform": "UNKNOWN", "keywords": null, "summary": "Python Interface for the ePiX mathematical plotting library", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "Pyepix_ is a wrapper package for the ePiX_ mathematical plotting library. The\nePiX_ library supports C++ programs for creating mathematically accurate plots for use in LaTeX documents.\nPyepix_ provides a Python wrapper to this library thus allowing integration with Python's extensive\nbuilt-in library and extension packages. In addition, Pyepix_ frees the user from needing to learn C++,\nobtaining a C++ compiler, and fighting with the C++ language.\n\n.. _Pyepix: http://claymore.engineer.gvsu.edu/~steriana/Python\n.. _ePiX: http://mathcs.holycross.edu/~ahwang/current/ePiX.html"}}, {"pk": 108, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.services", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.services", "version": "3.3", "platform": "any", "keywords": "utility", "summary": "General PyUtilib services that are supported by plugins.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "========================\npyutilib.services README\n========================\n\nThis Python package defines general services that are supported by\nPyUtilib plugins.  For example, PyUtilib plugins are used to manage\ntemporary files in a general manner.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n  * ChangeLog: https://software.sandia.gov/svn/public/pyutilib/pyutilib.services/trunk/CHANGELOG.txt\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 109, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "altgraph", "license": "MIT", "author": "Rponald Oussoren", "author_email": "ronaldoussoren@mac.com", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/altgraph", "version": "0.9", "platform": "any", "keywords": null, "summary": "Python graph (network) package", "classifiers": "Intended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "altgraph is a fork of graphlib: a graph (network) package for constructing\ngraphs, BFS and DFS traversals, topological sort, shortest paths, etc. with\ngraphviz output.\n\naltgraph includes some additional usage of Python 2.3+ features and\nenhancements related to modulegraph and macholib.\n\n\nRelease history\n===============\n\n0.9\n---\n\nThis is a minor bugfix release\n\nFeatures:\n\n- Added ``altgraph.ObjectGraph.ObjectGraph.nodes``, a method\n  yielding all nodes in an object graph.\n\nBugfixes:\n\n- The 0.8 release didn't work with py2app when using\n  python 3.x.\n\n\n0.8\n-----\n\nThis is a minor feature release. The major new feature\nis a extensive set of unittests, which explains almost\nall other changes in this release.\n\nBugfixes:\n\n- Installing failed with Python 2.5 due to using a distutils\n  class that isn't available in that version of Python\n  (issue #1 on the issue tracker)\n\n- ``altgraph.GraphStat.degree_dist`` now actually works\n\n- ``altgraph.Graph.add_edge(a, b, create_nodes=False)`` will\n  no longer create the edge when one of the nodes doesn't\n  exist.\n\n- ``altgraph.Graph.forw_topo_sort`` failed for some sparse graphs.\n\n- ``altgraph.Graph.back_topo_sort`` was completely broken in \n  previous releases.\n\n- ``altgraph.Graph.forw_bfs_subgraph`` now actually works.\n\n- ``altgraph.Graph.back_bfs_subgraph`` now actually works.\n\n- ``altgraph.Graph.iterdfs`` now returns the correct result\n  when the ``forward`` argument is ``False``.\n\n- ``altgraph.Graph.iterdata`` now returns the correct result\n  when the ``forward`` argument is ``False``.\n\n\nFeatures:\n\n- The ``altgraph.Graph`` constructor now accepts an argument\n  that contains 2- and 3-tuples instead of requireing that\n  all items have the same size. The (optional) argument can now \n  also be any iterator.\n\n- ``altgraph.Graph.Graph.add_node`` has no effect when you\n  add a hidden node.\n\n- The private method ``altgraph.Graph._bfs`` is no longer\n  present.\n\n- The private method ``altgraph.Graph._dfs`` is no longer\n  present.\n\n- ``altgraph.ObjectGraph`` now has a ``__contains__`` methods,\n  which means you can use the ``in`` operator to check if a \n  node is part of a graph.\n\n- ``altgraph.GraphUtil.generate_random_graph`` will raise\n  ``GraphError`` instead of looping forever when it is \n  impossible to create the requested graph.\n\n- ``altgraph.Dot.edge_style`` raises ``GraphError`` when\n  one of the nodes is not present in the graph. The method\n  silently added the tail in the past, but without ensuring\n  a consistent graph state.\n\n- ``altgraph.Dot.save_img`` now works when the mode is\n  ``\"neato\"``.\n\n0.7.2\n-----\n\nThis is a minor bugfix release\n\nBugfixes:\n\n- distutils didn't include the documentation subtree\n\n0.7.1\n-----\n\nThis is a minor feature release\n\nFeatures:\n\n- Documentation is now generated using `sphinx <http://pypi.python.org/pypi/sphinx>`_\n  and can be viewed at <http://packages.python.org/altgraph>.\n\n- The repository has moved to bitbucket \n\n- ``altgraph.GraphStat.avg_hops`` is no longer present, the function had no\n  implementation and no specified behaviour.\n\n- the module ``altgraph.compat`` is gone, which means altgraph will no\n  longer work with Python 2.3.\n\n\n0.7.0\n-----\n\nThis is a minor feature release.\n\nFeatures:\n\n- Support for Python 3\n\n- It is now possible to run tests using 'python setup.py test'\n\n  (The actual testsuite is still very minimal though)"}}, {"pk": 110, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "GraphCanvas", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/", "version": "3.0.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Interactive Graph (network) Visualization", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "GraphCanvas is an library for interacting with visualizations of complex\ngraphs. The aim is to allow the developer to declare the graph by the\nsimplest means and be able to visualize the graph immediately.\n\nFor example::\n\n    from enthought.graphcanvas.api import GraphView, graph_from_dict\n    g = {'a':['b'], 'b':['c', 'd'], 'c':[], 'd':[]}\n    GraphView(graph=graph_from_dict(g)).configure_traits()\n\n\nPrerequisites\n-------------\n* `NetworkX <http:://networkx.lanl.gov>`_\n* `setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_"}}, {"pk": 111, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "yaposib", "license": "Copyright (c) 2010-2011, Christophe-Marie Duquesne <chm.duquesne@gmail.com>\r\n\r\nThis code is provided under the terms of the Eclipse Public License. See\r\nbelow for a copy of this license or visit\r\nhttp://www.eclipse.org/legal/epl-v10.html\r\n\r\n--\r\n\r\nEclipse Public License -v 1.0\r\n\r\nTHE ACCOMPANYING PROGRAM IS PROVIDED UNDER THE TERMS OF THIS ECLIPSE\r\nPUBLIC LICENSE (\"AGREEMENT\"). ANY USE, REPRODUCTION OR DISTRIBUTION OF THE\r\nPROGRAM CONSTITUTES RECIPIENT'S ACCEPTANCE OF THIS AGREEMENT.\r\n\r\n1. DEFINITIONS\r\n\r\n\"Contribution\" means:\r\n\r\na) in the case of the initial Contributor, the initial code and\r\ndocumentation distributed under this Agreement, and\r\n\r\nb) in the case of each subsequent Contributor:\r\n\r\ni) changes to the Program, and\r\n\r\nii) additions to the Program;\r\n\r\nwhere such changes and/or additions to the Program originate from and are\r\ndistributed by that particular Contributor. A Contribution 'originates'\r\nfrom a Contributor if it was added to the Program by such Contributor\r\nitself or anyone acting on such Contributor's behalf. Contributions do not\r\ninclude additions to the Program which: (i) are separate modules of\r\nsoftware distributed in conjunction with the Program under their own\r\nlicense agreement, and (ii) are not derivative works of the Program.\r\n\r\n\"Contributor\" means any person or entity that distributes the Program.\r\n\r\n\"Licensed Patents \" mean patent claims licensable by a Contributor which\r\nare necessarily infringed by the use or sale of its Contribution alone or\r\nwhen combined with the Program.\r\n\r\n\"Program\" means the Contributions distributed in accordance with this\r\nAgreement.\r\n\r\n\"Recipient\" means anyone who receives the Program under this Agreement,\r\nincluding all Contributors.\r\n\r\n2. GRANT OF RIGHTS\r\n\r\na) Subject to the terms of this Agreement, each Contributor hereby grants\r\nRecipient a non-exclusive, worldwide, royalty-free copyright license to\r\nreproduce, prepare derivative works of, publicly display, publicly\r\nperform, distribute and sublicense the Contribution of such Contributor,\r\nif any, and such derivative works, in source code and object code form.\r\n\r\nb) Subject to the terms of this Agreement, each Contributor hereby grants\r\nRecipient a non-exclusive, worldwide, royalty-free patent license under\r\nLicensed Patents to make, use, sell, offer to sell, import and otherwise\r\ntransfer the Contribution of such Contributor, if any, in source code and\r\nobject code form. This patent license shall apply to the combination of\r\nthe Contribution and the Program if, at the time the Contribution is added\r\nby the Contributor, such addition of the Contribution causes such\r\ncombination to be covered by the Licensed Patents. The patent license\r\nshall not apply to any other combinations which include the Contribution.\r\nNo hardware per se is licensed hereunder.\r\n\r\nc) Recipient understands that although each Contributor grants the\r\nlicenses to its Contributions set forth herein, no assurances are provided\r\nby any Contributor that the Program does not infringe the patent or other\r\nintellectual property rights of any other entity. Each Contributor\r\ndisclaims any liability to Recipient for claims brought by any other\r\nentity based on infringement of intellectual property rights or otherwise.\r\nAs a condition to exercising the rights and licenses granted hereunder,\r\neach Recipient hereby assumes sole responsibility to secure any other\r\nintellectual property rights needed, if any. For example, if a third party\r\npatent license is required to allow Recipient to distribute the Program,\r\nit is Recipient's responsibility to acquire that license before\r\ndistributing the Program.\r\n\r\nd) Each Contributor represents that to its knowledge it has sufficient\r\ncopyright rights in its Contribution, if any, to grant the copyright\r\nlicense set forth in this Agreement.\r\n\r\n3. REQUIREMENTS\r\n\r\nA Contributor may choose to distribute the Program in object code form\r\nunder its own license agreement, provided that:\r\n\r\na) it complies with the terms and conditions of this Agreement; and\r\n\r\nb) its license agreement:\r\n\r\ni) effectively disclaims on behalf of all Contributors all warranties and\r\nconditions, express and implied, including warranties or conditions of\r\ntitle and non-infringement, and implied warranties or conditions of\r\nmerchantability and fitness for a particular purpose;\r\n\r\nii) effectively excludes on behalf of all Contributors all liability for\r\ndamages, including direct, indirect, special, incidental and consequential\r\ndamages, such as lost profits;\r\n\r\niii) states that any provisions which differ from this Agreement are\r\noffered by that Contributor alone and not by any other party; and\r\n\r\niv) states that source code for the Program is available from such\r\nContributor, and informs licensees how to obtain it in a reasonable manner\r\non or through a medium customarily used for software exchange.\r\n\r\nWhen the Program is made available in source code form:\r\n\r\na) it must be made available under this Agreement; and\r\n\r\nb) a copy of this Agreement must be included with each copy of the\r\nProgram.\r\n\r\nContributors may not remove or alter any copyright notices contained\r\nwithin the Program.\r\n\r\nEach Contributor must identify itself as the originator of its\r\nContribution, if any, in a manner that reasonably allows subsequent\r\nRecipients to identify the originator of the Contribution.\r\n\r\n4. COMMERCIAL DISTRIBUTION\r\n\r\nCommercial distributors of software may accept certain responsibilities\r\nwith respect to end users, business partners and the like. While this\r\nlicense is intended to facilitate the commercial use of the Program, the\r\nContributor who includes the Program in a commercial product offering\r\nshould do so in a manner which does not create potential liability for\r\nother Contributors. Therefore, if a Contributor includes the Program in a\r\ncommercial product offering, such Contributor (\"Commercial Contributor\")\r\nhereby agrees to defend and indemnify every other Contributor\r\n(\"Indemnified Contributor\") against any losses, damages and costs\r\n(collectively \"Losses\") arising from claims, lawsuits and other legal\r\nactions brought by a third party against the Indemnified Contributor to\r\nthe extent caused by the acts or omissions of such Commercial Contributor\r\nin connection with its distribution of the Program in a commercial product\r\noffering. The obligations in this section do not apply to any claims or\r\nLosses relating to any actual or alleged intellectual property\r\ninfringement. In order to qualify, an Indemnified Contributor must: a)\r\npromptly notify the Commercial Contributor in writing of such claim, and\r\nb) allow the Commercial Contributor to control, and cooperate with the\r\nCommercial Contributor in, the defense and any related settlement\r\nnegotiations. The Indemnified Contributor may participate in any such\r\nclaim at its own expense.\r\n\r\nFor example, a Contributor might include the Program in a commercial\r\nproduct offering, Product X. That Contributor is then a Commercial\r\nContributor. If that Commercial Contributor then makes performance claims,\r\nor offers warranties related to Product X, those performance claims and\r\nwarranties are such Commercial Contributor's responsibility alone. Under\r\nthis section, the Commercial Contributor would have to defend claims\r\nagainst the other Contributors related to those performance claims and\r\nwarranties, and if a court requires any other Contributor to pay any\r\ndamages as a result, the Commercial Contributor must pay those damages.\r\n\r\n5. NO WARRANTY\r\n\r\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, THE PROGRAM IS PROVIDED\r\nON AN \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER\r\nEXPRESS OR IMPLIED INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR\r\nCONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A\r\nPARTICULAR PURPOSE. Each Recipient is solely responsible for determining\r\nthe appropriateness of using and distributing the Program and assumes all\r\nrisks associated with its exercise of rights under this Agreement ,\r\nincluding but not limited to the risks and costs of program errors,\r\ncompliance with applicable laws, damage to or loss of data, programs or\r\nequipment, and unavailability or interruption of operations.\r\n\r\n6. DISCLAIMER OF LIABILITY\r\n\r\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, NEITHER RECIPIENT NOR ANY\r\nCONTRIBUTORS SHALL HAVE ANY LIABILITY FOR ANY DIRECT, INDIRECT,\r\nINCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING\r\nWITHOUT LIMITATION LOST PROFITS), HOWEVER CAUSED AND ON ANY THEORY OF\r\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\r\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OR DISTRIBUTION\r\nOF THE PROGRAM OR THE EXERCISE OF ANY RIGHTS GRANTED HEREUNDER, EVEN IF\r\nADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\r\n\r\n7. GENERAL\r\n\r\nIf any provision of this Agreement is invalid or unenforceable under\r\napplicable law, it shall not affect the validity or enforceability of the\r\nremainder of the terms of this Agreement, and without further action by\r\nthe parties hereto, such provision shall be reformed to the minimum extent\r\nnecessary to make such provision valid and enforceable.\r\n\r\nIf Recipient institutes patent litigation against any entity (including a\r\ncross-claim or counterclaim in a lawsuit) alleging that the Program itself\r\n(excluding combinations of the Program with other software or hardware)\r\ninfringes such Recipient's patent(s), then such Recipient's rights granted\r\nunder Section 2(b) shall terminate as of the date such litigation is\r\nfiled.\r\n\r\nAll Recipient's rights under this Agreement shall terminate if it fails to\r\ncomply with any of the material terms or conditions of this Agreement and\r\ndoes not cure such failure in a reasonable period of time after becoming\r\naware of such noncompliance. If all Recipient's rights under this\r\nAgreement terminate, Recipient agrees to cease use and distribution of the\r\nProgram as soon as reasonably practicable. However, Recipient's\r\nobligations under this Agreement and any licenses granted by Recipient\r\nrelating to the Program shall continue and survive.\r\n\r\nEveryone is permitted to copy and distribute copies of this Agreement, but\r\nin order to avoid inconsistency the Agreement is copyrighted and may only\r\nbe modified in the following manner. The Agreement Steward reserves the\r\nright to publish new versions (including revisions) of this Agreement from\r\ntime to time. No one other than the Agreement Steward has the right to\r\nmodify this Agreement. The Eclipse Foundation is the initial Agreement\r\nSteward. The Eclipse Foundation may assign the responsibility to serve as\r\nthe Agreement Steward to a suitable separate entity. Each new version of\r\nthe Agreement will be given a distinguishing version number. The Program\r\n(including Contributions) may always be distributed subject to the version\r\nof the Agreement under which it was received. In addition, after a new\r\nversion of the Agreement is published, Contributor may elect to distribute\r\nthe Program (including its Contributions) under the new version. Except as\r\nexpressly stated in Sections 2(a) and 2(b) above, Recipient receives no\r\nrights or licenses to the intellectual property of any Contributor under\r\nthis Agreement, whether expressly, by implication, estoppel or otherwise.\r\nAll rights in the Program not expressly granted under this Agreement are\r\nreserved.\r\n\r\nThis Agreement is governed by the laws of the State of New York and the\r\nintellectual property laws of the United States of America. No party to\r\nthis Agreement will bring a legal action under this Agreement more than\r\none year after the cause of action arose. Each party waives its rights to\r\na jury trial in any resulting litigation.", "author": "Christophe-Marie Duquesne", "author_email": "chm.duquesne@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "https://code.google.code/p/yaposib/", "version": "0.2.6", "platform": "UNKNOWN", "keywords": "Optimization,Linear Programming,Operations Research", "summary": "Yaposib is a python binding to OSI, the Open Solver Interface from       COIN-OR. It intends to give access to various solvers through       python. Yaposib was created in order to be integrated in pulp-or       (http://code.google.com/p/pulp-or).", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nNatural Language :: English\nTopic :: Scientific/Engineering :: Mathematics", "description": "Documentation can be found at https://code.google.code/p/yaposib/\r\n\r\nExported Classes:\r\n    Problem, YaposibVectorError\r\n\r\nExported Functions:\r\n    vec, test, available_solvers"}}, {"pk": 112, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Chaco", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/chaco", "version": "3.4.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Interactive 2-Dimensional Plotting", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "Chaco is a Python plotting application toolkit that facilitates writing\nplotting applications at all levels of complexity, from simple scripts with\nhard-coded data to large plotting programs with complex data interrelationships\nand a multitude of interactive tools. While Chaco generates attractive static\nplots for publication and presentation, it also works well for interactive data\nvisualization and exploration.\n\nFeatures\n--------\n- **Flexible drawing and layout**: Plots consist of graphical components which\n  can be placed inside nestable containers for layout, positioning, and event\n  dispatch. Every component has a configurable rendering loop with distinct\n  layers and backbuffering. Containers can draw cooperatively so that layers\n  span across the containment hierarchy.\n- **Modular and extensible architecture**: Chaco is object-oriented from the\n  ground up for ease of extension and customization. There are clear interfaces\n  and abstract classes defining extension points for writing your own custom\n  behaviors, from custom tools, plot types, layouts, etc. Most classes are\n  also \"subclass-friendly\", so that subclasses can override one or two methods\n  and everything else just works.\n- **Data model for ease of extension and embedding**: Chaco separates the data\n  from any transformations of the data that are needed for displaying it. This\n  separation makes it easier to extend Chaco, or embed it in applications.\n\nPrerequisites\n-------------\nYou must have the following libraries installed before building or installing\nChaco:\n\n* `Numpy <http://pypi.python.org/pypi/numpy/1.1.1>`_ version 1.1.0 or later is\n  preferred. Version 1.0.4 will work, but some tests may fail.\n* `setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_"}}, {"pk": 113, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pylo", "license": "MIT", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/pylo", "version": "0.92", "platform": "UNKNOWN", "keywords": null, "summary": "Large-scale Visualization Data Storage", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics :: 3D Modeling\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries", "description": "NOTE: Pylo has been retired in favor of `pyvisfile <http://pypi.python.org/pypi/pyvisfile>`_.\n\n            Pylo allows you to write Silo visualization files, as\n            introduced by LLNL's \n            `MeshTV <https://wci.llnl.gov/codes/meshtv/>`_ and\n            more recently used by the \n            `VisIt <https://wci.llnl.gov/codes/visit/>`_ \n            large-scale visualization program. Check the\n            `VisIt source page <https://wci.llnl.gov/codes/visit/source.html>`_\n            for the latest Silo source code.\n\n            Pylo supports the majority of datatypes allowed in \n            Silo files, such as unstructured and rectangular\n            structured meshes, particle meshes, as well as \n            scalar and vector variables on them. In addition,\n            Pylo supports expressions of scalar variables and\n            semi-automatic writing of parallelization-segmented\n            Silo files.\n\n            Pylo uses `Boost.Python <http://www.boost.org>`_ and `PyUblas\n            <http://mathema.tician.de/software/pyublas>`_.  To build it, please\n            refer to the `PyUblas documentation <http://tiker.net/doc/pyublas>`_\n            for build instructions first. After that, building pylo should be\n            straightforward."}}, {"pk": 114, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "slow", "license": "UNKNOWN", "author": "Stefan Behnel", "author_email": "scoder@users.berlios.de", "project_url": null, "maintainer_email": null, "home_page": "http://developer.berlios.de/projects/slow/", "version": "0.3.3", "platform": "UNKNOWN", "keywords": null, "summary": "SLOW - The SLOSL Overlay Workbench", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Communications\nTopic :: Internet\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Code Generators\nTopic :: System :: Distributed Computing\nTopic :: System :: Networking", "description": "SLOW - The SLOSL Overlay Workbench\n\nWhat is SLOW?\n-------------\n\nSLOW is a visual, integrated, rapid development environment for Internet\noverlay networks and Peer-to-Peer systems.  It is strongly focused on the\ndesign of local topology decisions based on SLOSL and concepts from the\ndatabase area.  SLOW allows you to visually design and specify topologies and\nprotocols in a platform and language neutral way.  You can test them against\ndifferent scenarios from within the workbench before you bet your money on\ntheir implementation.  At any time, you can save the specification in OverML\nand generate a source code implementation from it.\n\nWhat are SLOSL and OverML?\n--------------------------\n\nSLOW is based on the domain specific languages OverML_ and SLOSL_.  The\nOverlay Modelling Language OverML is an XML language for the specification of\noverlay protocols, topologies and node data.  The SQL-Like Overlay\nSpecification Language SLOSL is the topology specification language of OverML.\nIt is based on SQL.  There is also some `additional information`_ on the web.\n\n.. _`additional information`: http://www.dvs1.informatik.tu-darmstadt.de/research/OverML/\n\n.. _OverML: http://www.dvs1.informatik.tu-darmstadt.de/publications/pdf/behnel2005overlaylanguages.pdf\n.. _SLOSL:  http://www.dvs1.informatik.tu-darmstadt.de/publications/pdf/behnel2005overlayspecification.pdf\n\nCurrent status of SLOW:\n-----------------------\n\nThe workbench is currently in alpha state.  Some screenshots_ from the\nrunning system are on the Berlios developer site.\n\n.. _screenshots: http://developer.berlios.de/screenshots/?group_id=5525\n\nThe complete workflow for design and testing is implemented, a number of\noverlay topologies were implemented (see the file example.xod in the\nsource distribution).  There is a preliminary Python execution environment\nfor the specified overlays.  Source code generation is unfinished.  It\nobviously requires a generator for the target language.  Current focus is\non the languages Java and Python.\n\nRequirements:\n-------------\n\nThe workbench is written in Python 2.4.  It requires PyQt3_, lxml_ and\nMathDOM_.  Note that PyQt cannot be automatically installed by easy_install_.\nIf it is not yet available on your platform, you must install it manually\nbefore installing slow.\n\n.. _Python:  http://www.python.org/\n.. _PyQt3:   http://www.riverbankcomputing.co.uk/pyqt/\n.. _lxml:    http://codespeak.net/lxml/\n.. _MathDOM: http://mathdom.sourceforge.net/\n\nSLOW 0.3.2 and later require lxml 0.9 and MathDOM 0.7. Note that lxml\nrequires libxml2_ and libxslt_ to be installed.\n\n.. _libxml2: http://xmlsoft.org/\n.. _libxslt: http://xmlsoft.org/XSLT/\n\nRunning SLOW:\n-------------\n\nTo run it, install the egg distribution with easy_install_. This should\ngenerate a runnable script for your platform.  On Linux, this is commonly\n/usr/bin/slow or ~/bin/slow or something similar.  On all supported systems,\nthe installation should generate the right type of script and tell you where\nit was put.\n\n.. _easy_install: http://peak.telecommunity.com/DevCenter/EasyInstall"}}, {"pk": 115, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pyinterval", "license": "UNKNOWN", "author": "Stefano Taschini", "author_email": "taschini@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pyinterval.googlecode.com/", "version": "1.0b21", "platform": "UNKNOWN", "keywords": "", "summary": "Interval arithmetic in Python", "classifiers": "Development Status :: 4 - Beta\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "This library provides a Python implementation of an algebraically\r\nclosed interval system on the extended real number set. An interval\r\nobject consists of a finite union of closed, possibly unbound,\r\nmathematical intervals.\r\n\r\nInstallation\r\n------------\r\n\r\nThe most convenient way to install this library is by means of `easy_install`_::\r\n\r\n    easy_install pyinterval\r\n\r\nAlternatively, it is possible to download the sources from PyPI_ and invoking ::\r\n\r\n    python setup.py install\r\n\r\nin the unpacked directory. Note that you need the crlibm_ library\r\ninstalled on your system. It is also possible to check-out the sources\r\nfrom the subversion repository::\r\n\r\n    svn checkout http://pyinterval.googlecode.com/svn/trunk/ pyinterval\r\n\r\n.. _easy_install: http://peak.telecommunity.com/DevCenter/EasyInstall\r\n.. _pypi: http://pypi.python.org/pypi/pyinterval/\r\n.. _crlibm: http://lipforge.ens-lyon.fr/www/crlibm/\r\n\r\nDocumentation\r\n-------------\r\n\r\nFull documentation is available at\r\nhttp://pyinterval.googlecode.com/svn/trunk/html/index.html"}}, {"pk": 116, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyWxSVG", "license": "BSD", "author": "Max Kolosov", "author_email": "saxi@nm.ru", "project_url": null, "maintainer_email": null, "home_page": "http://saxi.nm.ru", "version": "0.3", "platform": "ALL", "keywords": "svg,svgz,wx,canvas,viewer,converter,bitmap,image", "summary": "SVG canvas for wxPython", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Desktop Environment\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "View and print svg file or svg content, convert svg to raster graphics. Open svg, svgz file as wx.Image, use wx.BITMAP_TYPE_SVG, wx.BITMAP_TYPE_SVGZ type. Partial support svg format. Tested with Python 2.5 and wxPython 2.8.9.2. Path parser and elliptical arc approximation from Enable."}}, {"pk": 117, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.misc", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/coopr/coopr.misc", "version": "2.5.1", "platform": "any", "keywords": "optimization", "summary": "Miscellaneous Coopr utilities", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "=================\ncoopr.misc README\n=================\n\nThis Python package defines miscellaneous Coopr utilities.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * coopr-forum@googlegroups.com\n    - The main list for help and announcements\n  * coopr-developers@googlegroups.com\n    - Where developers of Coopr discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 118, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "rogues", "license": "MIT", "author": "Don MacMillen", "author_email": "don@macmillen.net", "project_url": null, "maintainer_email": "", "home_page": "UNKNOWN", "version": "0.2.0", "platform": "UNKNOWN", "keywords": "numpy scipy matplotlib linalg", "summary": "Python and numpy port of Nicholas Higham's m*lab test matrices", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nTopic :: Scientific/Engineering :: Mathematics", "description": "Rogues is a Python and numpy/scipy port of Nicholas Higham's m*lab test matrices.\r\n\r\nThese matrices are a collection of interesting matrices that appear\r\nin m*lab's 'gallery' collection.  This collection was originally defined\r\nand implemented by Prof. Nicholas Higham of Manchester University and is\r\nmore fully discussed in \"The Test Matrix Toolbox for Matlab (Version 3.0)\",\r\nN.J. Higham, Numerical Analysis Report No. 276, September 1995 and can be\r\nfound at\r\n\r\nhttp://www.maths.manchester.ac.uk/~nareports\r\n\r\nBy 'interesting' we mean that these matrices either present some challenges\r\nto numerical algorithms or have some a set of interesting properties. The\r\ndocumentation of the individual functions contains much more info, as well\r\nas references.\r\n\r\nAlso included are a set of matrix utility functions that are needed for \r\ngenerating some of members of the collection as well as a few functions\r\nfrom Prof. Higham's matrixcomp package.  One of the more interesting \r\nroutines here is mdsmax, a direct search optimization algorithm.\r\n\r\nThe rogues package depends on numpy and scipy, both of which must be installed.\r\nAdditionally, there are a few routines that deal with plotting, and these\r\nuse matplotlib.  While ipython is not strictly necessary, it is a very\r\nconvenient environment for numpy / scipy / matplotlib. Finally, the unit \r\ntests utilize the nose package and the numpy wrappers around nose. To run \r\nthe tests from inside ipython, for example, type the following::\r\n\r\nimport rogues.matrices.tests at rmt\r\nimport rogues.utils.tests as rut\r\nrmt.check()\r\nrut.check()\r\n\r\nThe inluded matrix generation functions are:\r\n\r\n*   cauchy    Cauchy matrix\r\n*   chebspec  Chebyshev spectral differentiation matrix\r\n*   chebvand  Vandermonde-like matrix for the Chebyshev polynomials\r\n*   chow      Chow matrix - a singular Toeplitz lower Hessenberg matrix\r\n*   clement   Clement matrix - tridiagonal with zero diagonal entries\r\n*   comp      Comparison matrices\r\n*   compan    Companion matrix\r\n*   condex    Counterexamples to matrix condition number estimators\r\n*   cycol     Matrix whose columns repeat cyclically\r\n*   dingdong  Dingdong matrix - a symmetric Hankel matrix\r\n*   dorr      Dorr matrix - diagonally dominant, ill conditioned, tridiagonal.\r\n*   dramadah  A (0,1) matrix whose inverse has large integer entries\r\n*   fiedler   Fiedler matrix - symmetric\r\n*   forsythe  Forsythe matrix - a perturbed Jordan block\r\n*   frank     Frank matrix - ill conditioned eigenvalues.\r\n*   gearm     Gear matrix\r\n*   gfpp      Matrix giving maximal growth factor for GW with partial pivoting\r\n*   grcar     Grcar matrix - a Toeplitz matrix with sensitive eigenvalues.\r\n*   hadamard  Hadamard matrix\r\n*   hankel    Hankel matrix\r\n*   hanowa    A matrix whose eigenvalues lie on a vertical line in C\r\n*   hilb      Hilbert matrix\r\n*   invhess   Inverse of an upper Hessenberg matrix\r\n*   invol     An involutory matrix\r\n*   ipjfact   A Hankel matrix with factorial elements\r\n*   jordbloc  Jordan block matrix\r\n*   kahan     Kahan matrix - upper trapezoidal\r\n*   kms       Kar-Murdock-Szego Toeplitz matrix\r\n*   krylov    Krylov matrix\r\n*   lauchli   Lauchli matrix - rectangular\r\n*   lehmer    Lehmer matrix - symmetric positive definite\r\n*   lesp      A tridiagonal matrix with real, sensitve eigenvalues\r\n*   lotkin    Lotkin matrix\r\n*   minij     Symmetric positive definite matrix min(i,j)\r\n*   moler     Moler matrix symmetric positive definite\r\n*   neumann   Singular matrix from the descrete Neumann problem (sparse)\r\n*   ohess     Random, orthogonal upper Hessenberg matrix\r\n*   parter    Parter matrix - a Toeplitz matrix with singular values near pi\r\n*   pascal    Pascal matrix\r\n*   pdtoep    Symmetric positive definite Toeplitz matrix\r\n*   pei       Pei matrix\r\n*   pentoep   Tentadiagonal Toeplitz matrix (sparse)\r\n*   poisson   Block tridiagonal matrix from Poisson's equation (sparse)\r\n*   prolate   Prolate matrix - symmetric, ill-conditioned Toeplitz matrix\r\n*   qmult     Pre-multiply by random orthogonal matrix\r\n*   rando     Random matrix with elements -1, 0, or 1\r\n*   randsvd   Random matrix with pre-assigned singular values\r\n*   redheff   A (0,1) matrix of Redheffer associated with the Riemann hypothesis\r\n*   riemann   A matrix associated with the Riemann hypothesis\r\n*   smoke     Smoke matrix - complex, with a 'smoke ring' pseudospectrum\r\n*   triw      Upper triangular matrix discussed by Wilkinson and others\r\n*   wathen    Wathen matrix - a finite element matrix (sparse, random entries)\r\n*   wilk      Various specific matrices devised /discussed by Wilkenson\r\n*   wilkinson Wilkinson matrix of size n, where n must be odd\r\n\r\nSome of generally useful matrix utility functions:\r\n\r\n*   augment   Agumented system matrix\r\n*   bandred   Band reduction by two-sided unitary transformations\r\n*   cgs       Classical Gram-Schmidt QR factorization\r\n*   cond      Matrix condition number in 1,2,Frobenius, or infinity norm\r\n*   condeig   Condition numbers for eigenvalues of a matrix\r\n*   cpltaxes  Determine suitable axis for plot of complex vector\r\n*   dual      Dual vector with respect to Holder p-norm\r\n*   ge        Gaussian elimination without pivoting\r\n*   hankel    Given first row, returns a Toeplitz type matrix\r\n*   house     Householder matrix\r\n*   mdsmax    Multidimensional search method for direct search optimization\r\n*   mgs       Modified Gram-Schmidt QR factorization\r\n*   pow2      Vector whose i-th element is 2 ** x[i], where x[] is input\r\n*   ps        Dot plot of a pseudospectrum\r\n*   repmat    Simple re-implementation of m*lab's repmat function\r\n*   rq        Rayleigh quotient \r\n*   skewpart  Skew-symmetric (skew-Hermitian) part\r\n*   sparsify  Randomly sets matrix elements to zero\r\n*   sub       Principal submatrix\r\n*   symmpart  Symmetric (Hermitian) part\r\n*   toeplitz  Returns toeplitz matrix given first row of the matrix\r\n*   treshape  Reshape vector to or from (unit) triangular matrix\r\n*   tridiag   Sparse tridiagonl matrix given the diagonals\r\n*   vand      Vandermonde matrix\r\n*   vecperm   Vector permutation matrix\r\n\r\n   More information is available on any of these functions by typing\r\n   \"help <funcname>\"\r\n\r\nRelease 0.2.0 Notes\r\nThe unit tests are now included in the distribution.  They work with nosetests\r\nand if you have installed the source (not the zip'd egg file) you can do the\r\nfollowing\r\n\r\nimport rogues.matrices.tests as rmt\r\nrmt.check()\r\nimport rogues.utils.tests as rut\r\nrut.check()\r\nrut.check_see()    # matrix visualization\r\nrut.check_ps()     # matrix visualization\r\n\r\nSadly, this does not work with zipped egg files.\r\n\r\nFixed several small bugs in the use of np.max.  Added matrix visualization\r\nrouting 'see'"}}, {"pk": 119, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pykbool", "license": "", "author": "Emmanuel Decitre", "author_email": "", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/pykbool/", "version": "0.1.1", "platform": "", "keywords": "", "summary": "Cython wrapper for the kbool library (graph based polygon clipper)", "classifiers": "Development Status :: 4 - Beta\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: POSIX :: Linux\nProgramming Language :: Cython\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 3\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "pykbool is a Cython wrapper exposing the kbool API to Python 2/3. \r\n\r\nkbool is a polygon clipper provided with the wxArt2D library. One of kbool's feature is to provide connected keyhole polygons, which can be useful when rendering with Tk.\r\n\r\npykbool was tested with py 2.6/3.1/3.2 and Cython_ 0.14\r\n\r\n.. _Cython: http://pypi.python.org/pypi/Cython"}}, {"pk": 120, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.ply", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/trac/pyutilib/pyutilib.ply", "version": "3.0.5", "platform": "any", "keywords": "utility", "summary": "PyUtilib utilities that use Ply", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "===================\npyutilib.ply README\n===================\n\nThis Python package includes utilities that use Ply.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone"}}, {"pk": 121, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pysds", "license": "GPL", "author": "Gabriel Gellner", "author_email": "ggellner@uoguelph.ca", "project_url": null, "maintainer_email": null, "home_page": "https://code.launchpad.net/~ggellner/psl/pysds", "version": "0.1", "platform": "UNKNOWN", "keywords": "dataframe numerical scientific spreadsheet statistics", "summary": "Scientific Data Structures in Python", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "UNKNOWN"}}, {"pk": 122, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "booleano", "license": "MIT X License (http://www.opensource.org/licenses/mit-license.php)", "author": "Gustavo Narea", "author_email": "me@gustavonarea.net", "project_url": null, "maintainer_email": null, "home_page": "http://code.gustavonarea.net/booleano/", "version": "1.0a1", "platform": "UNKNOWN", "keywords": "boolean expression natural language condition conditions", "summary": "Boolean Expressions Interpreter", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: Libraries\nTopic :: Text Processing :: Linguistic", "description": "Booleano: Boolean Expressions Interpreter\n=========================================\n\n**Booleano** is an interpreter of `boolean expressions\n<http://en.wikipedia.org/wiki/Boolean_expression>`_, a library to **define\nand run filters** available as text (e.g., in a natural language) or in\n`Python <http://python.org/>`_ code.\n\nIn order to handle text-based filters, Booleano ships with a fully-featured\nparser whose grammar is `adaptive\n<http://en.wikipedia.org/wiki/Adaptive_grammar>`_: Its properties\ncan be overridden using simple configuration directives.\n\nOn the other hand, the library exposes a pythonic API for filters written\nin pure Python. These filters are particularly useful to build reusable\nconditions from objects provided by a third party library.\n\nLinks\n-----\n\n* `Web site <http://code.gustavonarea.net/booleano/>`_.\n* `Mailing list <http://groups.google.com/group/booleano>`_.\n* `Bug reports <https://bugs.launchpad.net/booleano>`_."}}, {"pk": 123, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PuLP", "license": "Copyright (c) 2002-2005, Jean-Sebastien Roy (js@jeannot.org)\nModifications Copyright (c) 2007- Stuart Anthony Mitchell (s.mitchell@auckland.ac.nz)\n\nPermission is hereby granted, free of charge, to any person obtaining a\ncopy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be included\nin all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\nOR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.", "author": "J.S. Roy and S.A. Mitchell", "author_email": "s.mitchell@auckland.ac.nz", "project_url": null, "maintainer_email": null, "home_page": "http://pulp-or.googlecode.com/", "version": "1.4.7", "platform": "UNKNOWN", "keywords": "Optimization,Linear Programming,Operations Research", "summary": "PuLP is an LP modeler written in python. PuLP can generate MPS or LP files\nand call GLPK, COIN CLP/CBC, CPLEX, and GUROBI to solve linear\nproblems.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "# Copyright J.S. Roy (js@jeannot.org), 2003-2005\r\n# Copyright Stuart A. Mitchell (stu@stuartmitchell.com)\r\n# See the LICENSE file for copyright information.\r\n\r\nPuLP is an LP modeler written in python. PuLP can generate MPS or LP files\r\nand call GLPK[1], COIN CLP/CBC[2], CPLEX[3], and GUROBI[4] to solve linear\r\nproblems.\r\n\r\nSee the examples directory for examples.\r\n\r\nPuLP requires Python >= 2.5.\r\n\r\nThe examples require at least a solver in your PATH or a shared library file.\r\n\r\nDocumentation is found on https://www.coin-or.org/PuLP/.\r\nA comprehensive wiki can be found at https://www.coin-or.org/PuLP/\n\nUse LpVariable() to create new variables. To create a variable 0 <= x <= 3\n>>> x = LpVariable(\"x\", 0, 3)\n\nTo create a variable 0 <= y <= 1\n>>> y = LpVariable(\"y\", 0, 1)\n\nUse LpProblem() to create new problems. Create \"myProblem\"\n>>> prob = LpProblem(\"myProblem\", LpMinimize)\n\nCombine variables to create expressions and constraints and add them to the\nproblem. \n>>> prob += x + y <= 2\n\nIf you add an expression (not a constraint), it will\nbecome the objective.\n>>> prob += -4*x + y\n\nChoose a solver and solve the problem. ex:\n>>> status = prob.solve(GLPK(msg = 0))\n\nDisplay the status of the solution\n>>> LpStatus[status]\n'Optimal'\n\nYou can get the value of the variables using value(). ex:\n>>> value(x)\n2.0\n\nExported Classes:\n    - LpProblem -- Container class for a Linear programming problem\n    - LpVariable -- Variables that are added to constraints in the LP\n    - LpConstraint -- A constraint of the general form \n      a1x1+a2x2 ...anxn (<=, =, >=) b \n    - LpConstraintVar -- Used to construct a column of the model in column-wise \n      modelling\n\nExported Functions:\n    - value() -- Finds the value of a variable or expression\n    - lpSum() -- given a list of the form [a1*x1, a2x2, ..., anxn] will construct \n      a linear expression to be used as a constraint or variable\n    - lpDot() --given two lists of the form [a1, a2, ..., an] and \n      [ x1, x2, ..., xn] will construct a linear epression to be used \n      as a constraint or variable\r\n\nComments, bug reports, patches and suggestions are welcome.\r\npulp-or-discuss@googlegroups.com\r\n\nReferences:\r\n[1] http://www.gnu.org/software/glpk/glpk.html\r\n[2] http://www.coin-or.org/\r\n[3] http://www.cplex.com/\r\n[4] http://www.gurobi.com/"}}, {"pk": 124, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pysal", "license": "BSD License", "author": "PySAL Developers", "author_email": "pysal-dev@googlegroups.com", "project_url": null, "maintainer_email": null, "home_page": "http://pysal.org/", "version": "1.1.0", "platform": "UNKNOWN", "keywords": null, "summary": "PySAL: Python Spatial Analysis Library", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "UNKNOWN"}}, {"pk": 125, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "openopt", "license": "new BSD", "author": "('Dmitrey Kroshko',)", "author_email": "dmitrey-at-openopt-dot-org", "project_url": null, "maintainer_email": null, "home_page": "http://openopt.org", "version": "0.33", "platform": "UNKNOWN", "keywords": null, "summary": "A python module for numerical optimization", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": ""}}, {"pk": 126, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "camxes", "license": "Simplified BSD", "author": "Dag Odenhall", "author_email": "dag.odenhall@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "https://github.com/dag/python-camxes", "version": "0.2", "platform": "UNKNOWN", "keywords": null, "summary": "Python interface to camxes.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Java\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3.1\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Text Processing :: Linguistic", "description": "Python interface to camxes\n==========================\n\nTo install, you need a Java runtime environment as a ``java`` command on\nyour ``$PATH``, Python 2.6+ (including 3.1) and python-setuptools (or\ndistribute). Then you can simply install this package from PyPI with\n``easy_install`` or ``pip``, or as a dependency in your own ``setup.py``.\nThe parser itself is bundled with this package so you don't need to worry\nabout that.\n\n::\n\n    easy_install camxes\n\n\nParsing Lojban\n--------------\n\nThe ``parse()`` function returns a parse tree of named nodes.\n\n>>> import camxes\n>>> print camxes.parse(\"coi rodo\")\ntext\n `- free\n     +- CMAVO\n     |   `- COI\n     |       `- u'coi'\n     `- sumti5\n         +- CMAVO\n         |   `- PA\n         |       `- u'ro'\n         `- CMAVO\n             `- KOhA\n                 `- u'do'\n\nTurn a tree back into Lojban with the ``lojban`` property.\n\n>>> camxes.parse(\"coi rodo!\").lojban\nu'coi ro do'\n\nThis joins the leaf nodes with a space, but you can preserve spaces and\npunctuation by passing ``spaces=True`` to ``parse()``.\n\n>>> camxes.parse(\"coi rodo!\", spaces=True).lojban\nu'coi rodo!'\n\nChild nodes can be accessed by name as attributes, giving a list of such\nnodes. If there are no child nodes with that name an exception is raised.\n\n>>> print camxes.parse(\"coi rodo\").free[0].sumti5[0].CMAVO[1]\nCMAVO\n `- KOhA\n     `- u'do'\n\nYou can also access nodes by sequential position without giving the name.\n\n>>> print camxes.parse(\"coi rodo\")[0][1]\nsumti5\n +- CMAVO\n |   `- PA\n |       `- u'ro'\n `- CMAVO\n     `- KOhA\n         `- u'do'\n\nNodes iterate over their children.\n\n>>> list(camxes.parse(\"coi rodo\")[0][1])\n[<CMAVO {ro}>, <CMAVO {do}>]\n\nThey also know their name.\n\n>>> camxes.parse(\"coi rodo\")[0][1].name\nu'sumti5'\n\n\nVerifying grammatical validity\n------------------------------\n\n``parse()`` is able to parse some ungrammatical input by processing as much\nas is grammatical. It is therefore unreliable for checking if some text is\ngrammatical. For this purpose, there is the ``isgrammatical()`` predicate.\n\n>>> camxes.isgrammatical(\"coi rodo\")\nTrue\n>>> camxes.isgrammatical(\"mupli cu fliba\")\nFalse\n>>> print camxes.parse(\"mupli cu fliba\")\ntext\n `- BRIVLA\n     `- gismu\n         `- u'mupli'\n\n\nDeconstructing compound words into affixes\n------------------------------------------\n\n``decompose()`` gives you the affixes and hyphens of a compound.\n\n>>> camxes.decompose(\"genturfa'i\")\n(u'gen', u'tur', u\"fa'i\")\n\nIt will complain for input that is not a single, valid compound.\n\n>>> camxes.decompose(\"camxes\")\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nValueError: invalid compound 'camxes'\n\n\nParsing only morphology\n-----------------------\n\nThe ``morphology()`` function works much like ``parse()``.\n\n>>> print camxes.morphology(\"coi\")\ntext\n `- CMAVO\n     `- COI\n         +- c\n         |   `- u'c'\n         +- o\n         |   `- u'o'\n         `- i\n             `- u'i'\n\n\nTree traversal\n--------------\n\nSearch for nodes with the ``find()`` method. It takes any number of arguments\nthat are wildcard-matched against node names. This operation recurses down\neach branch until a match is found, but does not search children of\nmatching nodes.\n\n>>> camxes.parse(\"coi rodo\").find('sumti*')\n(<sumti5 {ro do}>,)\n\n>>> camxes.parse(\"coi rodo\").find('PA', 'KOhA')\n(<PA {ro}>, <KOhA {do}>)\n\nKey access on nodes is a shortcut for the first match of a find.\n\n>>> camxes.parse(\"la camxes genturfa'i fi la lojban\")['cmene']\n<cmene {camxes}>\n\nThe ``leafs`` property is a tuple of all leaf nodes, which should be the\nunicode lexemes.\n\n>>> camxes.parse(\"coi rodo\").leafs\n(u'coi', u'ro', u'do')\n\nThe ``branches()`` method finds the parents of nodes whose leafs match the\narguments. This lets you search for the branches a sequence of lexemes\nbelong to.\n\n>>> camxes.parse(\"lo ninmu cu klama lo tcadu\").branches(\"lo\")\n(<sumti6 {lo ninmu}>, <sumti6 {lo tcadu}>)\n>>> camxes.parse(\"lo ninmu cu klama lo tcadu\").branches(\"ninmu\")\n(<sumti6 {lo ninmu}>,)\n>>> camxes.parse(\"lo ninmu cu klama lo tcadu\").branches(\"klama\", \"lo\", \"tcadu\")\n(<sentence {lo ninmu cu klama lo tcadu}>,)\n\nA generalization of these is called ``filter()`` and takes a predicate\nfunction that decides if a node should be listed. ``filter()`` is a\ngenerator so we use ``list()`` here to see the results.\n\n>>> leafparent = lambda node: not isinstance(node[0], camxes.Node)\n>>> list(camxes.parse(\"coi rodo\").filter(leafparent))\n[<COI {coi}>, <PA {ro}>, <KOhA {do}>]\n\n\nTree transformation\n-------------------\n\nYou can transform a node, recursively, into a tuple of strings, where the\nfirst item is the name of the node and the rest are the child nodes. This\nproperty is called ``primitive`` and can be useful if you're serializing a\nparse tree to a more \u201cdumb\u201d format such as JSON.\n\n>>> from pprint import pprint\n>>> pprint(camxes.parse(\"coi rodo\").primitive)\n(u'text',\n (u'free',\n  (u'CMAVO', (u'COI', u'coi')),\n  (u'sumti5', (u'CMAVO', (u'PA', u'ro')), (u'CMAVO', (u'KOhA', u'do')))))\n\n>>> import json\n>>> print json.dumps(camxes.parse(\"coi\").primitive, indent=2)\n[\n  \"text\", \n  [\n    \"CMAVO\", \n    [\n      \"COI\", \n      \"coi\"\n    ]\n  ]\n]\n\nThe generalization of ``primitive`` is called ``map()`` and takes a\ntransformer function that in turn takes a node. The transformation is then\nmapped recursively on all nodes and a nested tuple, similar to that of\n``primitive``, is returned.\n\n>>> camxes.parse(\"coi rodo\").map(len)\n(1, (2, (1, (1, 3)), (2, (1, (1, 2)), (1, (1, 2)))))"}}, {"pk": 127, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "seven_segs", "license": "LGPL", "author": "Tim Wegener", "author_email": "twegener@radlogic.com.au", "project_url": null, "maintainer_email": "", "home_page": "http://www.radlogic.com.au/downloads.htm", "version": "0.8", "platform": "", "keywords": "seven segment display lcd led character digits", "summary": "Generate seven segment display element settings for displaying characters.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Electronic Design Automation (EDA)\nTopic :: Software Development :: Embedded Systems\nTopic :: Utilities", "description": "Generate rough equivalents of letters for a seven segment display."}}, {"pk": 128, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "mtspec", "license": "GNU General Public License (GPL)", "author": "Moritz Beyreuther, Lion Krischer and German A. Prieto", "author_email": "beyreuth@geophysik.uni-muenchen.de", "project_url": null, "maintainer_email": "", "home_page": "https://svn.geophysik.uni-muenchen.de/trac/mtspecpy/wiki", "version": "0.2.6", "platform": "OS Independent", "keywords": "mtspec,multitaper,seismology,waveform,signal,processing,taper,wigner,ville", "summary": "Python Bindings for multitaper `mtspec` f90 Library", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "Python-ctypes wrapper for multitaper `mtspec` f90 Library of German A.\r\n    Prieto::\r\n\r\n        Prieto, G. A., R. L. Parker, F. L. Vernon. (2009),\r\n        A Fortran 90 library for multitaper spectrum analysis,\r\n        Computers and Geosciences, 35, pp. 1701-1710.\r\n\r\n    For more information see:\r\n    https://svn.geophysik.uni-muenchen.de/trac/mtspecpy/wiki\r\n\r\n    ::\r\n\r\n        Main Changes in 0.2.6\r\n        ---------------------\r\n        * Bugfix #6, access violation on windows\r\n        * Refactoring parts of the underlying fortran code, now memchecked\r\n        * Bugfix for NaNs in spectra\r\n        * Bugfix RMS calculation in tests"}}, {"pk": 129, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "eke.biomarker", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/eke-biomarker", "version": "1.0.2", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers eke knowledge", "summary": "Biomarkers for the EDRN Knowledge Environment", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "*************\neke.biomarker\n*************\n\nThis product, ``eke.biomarker``, provides display and RDF_ ingest of the\nbiomarkers being studied by the Early Detection Research Network (EDRN_).\nBiomarkers are chemical indicators for disease, and in the case of EDRN, the\ndisease being pursued is cancer.  This package lets a researcher browse,\nsearch for, and discover interesting biomarkers, determine how research\nprogress is being made, find out statistical values of the biomarkers, and so\nforth.  These features are integral to the EDRN Knowledge Environment (EKE_).\nEDRN uses the EKE to make it easy to discover, share, search for, and retrieve\nall of EDRN's collective knowledge, including cancers and other diseases,\nprotocols, specimens, participants, staff, and |---| as in the case of this\nproduct |---| biomarkers.\n\nAlthough intended for the EDRN public portal, it can be installed in any\nPlone_ compatible site.\n\nThis software is developed by the `EDRN Informatics Center`_  at JPL_,\noperated by the California Institute of Technology, for NCI_.\n\n.. References:\n.. _EDRN Informatics Center: http://cancer.jpl.nasa.gov/\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _EKE: http://cancer.jpl.nasa.gov/documents/applications/knowledge-environment\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://cancer.gov/\n.. _Plone: http://plone.org/\n.. _RDF: http://w3.org/RDF/\n.. |---| unicode:: U+2014 .. EM DASH\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``eke.biomarker`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        eke.biomarker\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        eke.biomarker\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.  Where issue IDs\nare listed below, you can find out more about them by visiting the issue\ntracker at https://oodt.jpl.nasa.gov/jira/browse/CA.\n\n\n1.0.2 - A Mixed Bag\n-------------------\n\nThe following issues were addressed in this release:\n\n* CA-620 - Locks appear on biomarkers listed under a protocol incorrectly\n  (test exposure)\n* CA-698 - \"Structural\" objects appear in searches\n\n\n1.0.1 - Sweeping Views\n----------------------\n\nThis release adds a number of improvements to the biomarker views to\nreflect requests made by NCI that more specific details be captured in\neach annotated biomarker.\n\nThis release addresses the following issues:\n\n* CA-674 - Add PerformanceComment to the biomarker organ tab\n* CA-675 - Portal: Change name of sensitivity/specificity and add specific assay type attribute\n* CA-676 - Portal: Add decision rule attribute to biomarker-organ-study information\n\n\n1.0.0 - Prime Time\n------------------\n\nThis release addresses a number of issues \nthat make this component (and some of its\nselected counterparts) \"prime time\" for\nthe operational NCI portal. \n\nThis release addresses the following issues:\n\n* CA-528 Automatic periodic ingest of RDF\n\nYou can find the issue tracker at https://oodt.jpl.nasa.gov/jira/browse/CA\n\n\n0.0.6 - Open Door Policy\n------------------------\n\nFor this release, we're exposing more information about biomarkers.  Instead\nof making unapproved biomarkers private and requiring a log in to view them,\nyou can now view basic information about them.  Full details require a login.\nFor more information, see https://oodt.jpl.nasa.gov/jira/browse/CA-650.\n\n\n0.0.5 - Eleventh Hour\n---------------------\n\nThis release includes some look-and-feel changes, specifically to support\nhttps://oodt.jpl.nasa.gov/jira/browse/CA-600.\n\n\n0.0.4 - Padlocked!\n------------------\n\nThis release addresses the following issue:\n\n* https://oodt.jpl.nasa.gov/jira/browse/CA-551 - Add lock icon to biomarkers\n  and science data that are \"secure\" to protocol pages\n\n\n0.0.3 - The unnamed release\n---------------------------\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-511 - Need to index alternative\n  biomarker names\n\n\n0.0.2 - Various \"CYA\" Fixes\n---------------------------\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-499 - Disclaimer needed on\n  biomarker list.\n* http://oodt.jpl.nasa.gov/jira/browse/CA-500 - Show unpublished\n  biomarkers in a biomarker folder.\n* http://oodt.jpl.nasa.gov/jira/browse/CA-510 - Lock box for science data and\n  biomarkers should disappear if a user has access to the object\n\n\n0.0.1 - Security Ingest\n-----------------------\n\nThe sole issue addressed in this release is:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-475 - \"Public\" should only see\n  biomarkers and science data that have QAState=Accepted.  Disregard Security\n  flag.\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 130, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/", "version": "2.2.6.7", "platform": "UNKNOWN", "keywords": "dap opendap dods data science climate meteorology oceanography", "summary": "DAP (Data Access Protocol) client and server for Python.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Implementation of the `Data Access Protocol <http://opendap.org>`_. \n\nThis is a Python implementation of the Data Access Protocol, a\nscientific protocol for data access developed by the OPeNDAP team\n(http://opendap.org). This implementation is developed from scratch,\nfollowing the latest specification of the protocol (DAP 2.0 Draft\nCommunity Standard 2005/04/27) and based on my experience with\nOPeNDAP servers on the wild.\n\nUsing this module one can access hundreds of scientific datasets\nfrom Python programs, accessing data in an efficient, transparent\nand pythonic way. Arrays are manipulated like normal multi-dimensional\narrays (like numpy.array, e.g.), with the fundamental difference\nthat data is downloaded on-the-fly when a variable is sliced.\nSequential data can be filtered on the server side before being\ndownloaded, saving bandwith and time.\n\nThe module also implements a DAP server, allowing datasets from a\nmultitude of formats (netCDF, Matlab, CSV, GrADS/GRIB files, SQL\nRDBMS) to be served on the internet. The server specifies a plugin\nAPI for supporting new data formats in an easy way. The DAP server\nis implemented as a WSGI application (see PEP 333), running on a\nvariery of servers, and can be combined with WSGI middleware to\nsupport authentication, gzip compression and much more.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/dap#egg=dap-dev>`_."}}, {"pk": 131, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "latimes-pluggablemaps-uscounties", "license": "MIT", "author": "Ben Welsh", "author_email": "ben.welsh@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/datadesk/latimes-pluggablemaps-uscounties", "version": "alpha-0.1.8", "platform": "UNKNOWN", "keywords": "gis geographical maps earth usa counties boundaries", "summary": "L.A. Times Pluggable Maps: U.S. Counties", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 132, "model": "importing.pypicache", "fields": {"maintainer": "Ales Erjavec", "name": "Orange", "license": "GNU General Public License (GPL)", "author": "Bioinformatics Laboratory, FRI UL", "author_email": "orange@fri.uni-lj.si", "project_url": null, "maintainer_email": "ales.erjavec@fri.uni-lj.si", "home_page": "http://www.ailab.si/orange", "version": "2.0.0b", "platform": "UNKNOWN", "keywords": "data mining,machine learning,artificial intelligence", "summary": "Orange data mining library for python.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Visualization", "description": "Orange data mining library\r\n==========================\r\n\r\nOrange is a scriptable environment for fast prototyping of new\r\nalgorithms and testing schemes. It is a collection of Python-based modules\r\nthat sit over the core library and implement some functionality for\r\nwhich execution time is not crucial and which is easier done in Python\r\nthan in C++. This includes a variety of tasks such as pretty-print of\r\ndecision trees, attribute subset, bagging and boosting, and alike.\r\n\r\nOrange also includes a set of graphical widgets that use methods from core\r\nlibrary and Orange modules. Through visual programming, widgets can be assembled\r\ntogether into an application by a visual programming tool called Orange Canvas."}}, {"pk": 133, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ctlib", "license": "UNKNOWN", "author": "Guillem Borrell", "author_email": "guillemborrell@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "0.2", "platform": "UNKNOWN", "keywords": null, "summary": "Library for parallel computaion of derivatives properties", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: C++\nProgramming Language :: Python :: 2.6\nTopic :: Office/Business :: Financial\nTopic :: Scientific/Engineering :: Mathematics", "description": "ctlib, for Continuous Trading, is a small project intended as a small test case.\n\nIts goal is to integrate several technologies and to apply them in a single supercomputing application:\n\n* Python scripting\n\n* Extension modules and Swig\n\n* MPI\n\n* OpenMP\n\n* Grid applications with twisted\n\n* Multiplatform development.\n\nThe application computes the value of some derivatives (very few) using a client server paraigm with Twisted.  You need both the server and the client to value derivatives."}}, {"pk": 134, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.xseed", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.7", "platform": "OS Independent", "keywords": "ObsPy,seismology,SEED,Dataless SEED,XML-SEED,XSEED,RESP,response file,dataless", "summary": "Dataless SEED, RESP and XML-SEED read and write support for ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.xseed package contains methods in order to read, write and convert\nseismological meta data files in the Dataless SEED, RESP and XML-SEED format.\n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology. \n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 135, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "CompleteGenomicsTools", "license": "GPL-2", "author": "Sean Davis", "author_email": "seandavi@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "https://github.com/seandavi/CompleteGenomicsTools", "version": "0.1.1dev", "platform": "UNKNOWN", "keywords": "genomics biology bioinformatics sequencing", "summary": "Tools for manipulating and visualizing data from Complete Genomics", "classifiers": "Operating System :: OS Independent\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "UNKNOWN"}}, {"pk": 136, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ipda", "license": "Copyright and License\n*********************\n\nCopyright 2006-2009 California Institute of Technology. ALL RIGHTS\nRESERVED. U.S. Government Sponsorship acknowledged.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and ANY USE OR\nREDISTRIBUTION BY ANY PERSON, ORGANIZATION, OR OTHER ENTITY WITHOUT PRIOR,\nSPECIFIC WRITTEN PERMISSION IS PROHIBITED.", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://planetarydata.org/projects/data-access/ipda-library", "version": "0.0.3", "platform": "UNKNOWN", "keywords": "('votable data grid discovery query catalog index metadata pds psa nasa esa ipda',)", "summary": "IPDA Library", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: No Input/Output (Daemon)\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Front-Ends\nTopic :: Internet :: WWW/HTTP :: HTTP Servers\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Atmospheric Science\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "**************\n IPDA Library\n**************\n\n.. contents::\n\nThe International Planetary Data Alliance (IPDA_) supports cross-institution\ndata search, data discover, data retrieval, etc.  It uses the Agile OODT (Object\nOriented Data Technology) library to handle profile metadata search/retrieval\nand product search/retrieval. It also provides utilities to create, manipulate,\nand serialize VOTables_.\n\n.. References:\n.. _IPDA: http://planetarydata.org/\n.. _VOTables: http://www.ivoa.net/Documents/latest/VOT.html\n\nInstallation\n************\n\nThis document tells you how to install the IPDA Library.\n\n\nQuick Instructions\n==================\n\nAs a user with administrative privileges, run::\n\n    easy_install ipda\n\nThat's it.\n\n\nFull Instructions\n=================\n\nThe IPDA Library requires the Python_ programming language.  We recommend\nversion 2.4 or later.  As of this writing, 2.6 is the latest stable version.\nIf Python is not yet installed on your system, you can find binary and and\nsource distributions from the Python website.\n\nTo test if a correct version of Python is available on your system, run::\n\n    python -V\n    \nYou should see output similar to::\n\n    Python 2.6\n    \nindicating the version of Python installed.  The IPDA Library also requires\n`Agile OODT`_.  OODT_ is Object Oriented Data Technology, a framework for\nmetadata and data grids.  Agile OODT is a Python version of OODT that supports\nhigher performance and easier integration than the Java_ version.\n\nBy far the easiest, recommended, and encouraged way to install the IPDA\nLibrary is to use EasyInstall_.  If your Python installation has EasyInstall\navailable to it, then this one command is all you need to run in order to\ndownload, build, install, and generate command-line tools all in one go for\nall users on your system::\n\n    easy_install ipda\n    \nBe sure to run that command as an administrative user.  For example, on Mac OS\nX and other Unix systems, you might need to run::\n\n    sudo easy_install ipda\n\nThat will also download and install all dependencies, including Agile OODT.\n\n\nExecutables\n-----------\n\nThere are currently no executables within the IPDA Library at this time.  It\nsolely provides VOTable_ and PDAP_ functions.\n\n\nInstalling EasyInstall\n----------------------\n\nIf you happen to be on a system where your Python installation lacks easy\ninstall, worry not!  Upgrading your system to gain EasyInstall's abilities is\nquite simple.  Follow these instructions:\n\n1.  Download http://peak.telecommunity.com/dist/ez_setup.py\n2.  As an administrative user, run the freshly-downloaded ez_setup.py file\n    using your system's Python.\n\nEasyInstall and its necessary libraries will be downloaded, built, and\ninstalled for you, and the ``easy_install`` executable generated.  The\nlocation of the ``easy_install`` executable is in your platform's standard\nlocation for Python scripts, and is usually where the ``python`` executable is\nitself.  For example, on Mac OS X_ 10.5, the directory is::\n\n    /Library/Frameworks/Python.framework/Versions/Current/bin\n\n\nInstalling Without EasyInstall\n------------------------------\n\nIf EasyInstall is not available on your system, you can still make a proper\ninstallation of the IPDA Library. Follow these instructions:\n\n1.  Download the Agile OODT source distribution from\n    http://oodt.jpl.nasa.gov/dist/agile-oodt/oodt-0.0.1.tar.gz.\n    Substitute version numbers as appropriate.\n2.  Download the IPDA Library source distribution from\n    http://oodt.jpl.nasa.gov/dist/ipda-library/ipda-0.0.1.tar.gz.\n    Substitute version numbers as appropriate.\n3.  Unpack each archive.\n4.  Change the current working directory to each newly-created subdirectory,\n    ``oodt-0.0.1`` and ``ipda-0.0.1``, again substituting version\n    numbers as appropriate.\n5.  As an administrative user, run:  ``python setup.py install`` in each\n    subdirectory.\n\n\nIssues and Questions\n====================\n\nTo report any problems with or ask for help about the IPDA Library, visit our\ncontact_ web page.\n\n\n.. References:\n.. _Agile OODT: http://agility.jpl.nasa.gov/\n.. _contact: http://planetarydata.org/contact-info\n.. _EasyInstall: http://peak.telecommunity.com/DevCenter/EasyInstall\n.. _Java: http://tinyurl.com/5kng2h\n.. _OODT: http://oodt.jpl.nasa.gov/\n.. _PDAP: http://planetarydata.org/projects/data-access/documents/pdap-versions\n.. _Python: http://python.org/\n.. _VOTable: http://www.ivoa.net/Documents/latest/VOT.html\n.. _X: http://apple.com/macosx/\n\nChangelog\n*********\n\n0.0.3 - Bug Fix\n===============\n\nIrma Trejo at New Mexico State University observed that the \"DATA_SET_NAME\"\nprofile element wasn't being set.  This release updates the unit tests to\ncheck for that, and repairs the problem.\n\n\n0.0.2 - Bug Fix\n===============\n\nThis release addresses the special case of the handling of the PDS resource\nclass \"dataset\" to the PDAP resource class \"DATA_SET\" (with an underscore).\nIt now properly adds the underscore.\n\n\n0.0.1 - FCS\n===========\n\nFirst customer ship includes PDS-to-PDAP query capabilities.\n\n\n0.0.0 - Unreleased\n==================\n\nThis is an initial proof-of-Python implementation that provides minimal\nfunction of:\n\n* VOTables in Python\n* GRS data access"}}, {"pk": 137, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "sdd", "license": "BSD License", "author": "Alexandre Hamez and Alban Linard", "author_email": "alexandre.hamez@lip6.fr", "project_url": null, "maintainer_email": "", "home_page": "http://sdd.lip6.fr", "version": "0.7", "platform": "Any", "keywords": "", "summary": "A module to manipulate Hierarchical Set Decision Diagrams", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: C++\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering", "description": "A package to use SDDs.\r\nYou will need g++ 4.3 and boost 1.37 to compile it."}}, {"pk": 138, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pmi", "license": "GPL", "author": "Olaf Lenz", "author_email": "olenz@icp.uni-stuttgart.de", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/olenz/pmi/", "version": "1.0", "platform": "OS Independent", "keywords": "mpi,parallel", "summary": "Parallel Method Invocation", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Other Environment\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries\nTopic :: System :: Clustering", "description": "Parallel Method Invocation\n--------------------------\n\nPMI is a pure python module that allows libraries to provide functions\nthat are parallelized using MPI but that can nontheless be called from\nserial Python scripts.\n\nPMI requires Python 2.4+ and is compatible to Python 3, furthermore it\nrequires a working MPI module (e.g. mpi4py or boostmpi)."}}, {"pk": 139, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Luminoso", "license": "http://www.gnu.org/copyleft/gpl.html", "author": "MIT Media Lab, Software Agents group", "author_email": "conceptnet@media.mit.edu", "project_url": null, "maintainer_email": null, "home_page": "http://launchpad.net/luminoso/", "version": "1.3.1", "platform": "any", "keywords": null, "summary": "A Python GUI for semantic analysis using Divisi", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Text Processing :: Linguistic", "description": "UNKNOWN"}}, {"pk": 140, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "seishub.plugins.exupery", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "Robert Barsch", "author_email": "barsch@lmu.de", "project_url": null, "maintainer_email": null, "home_page": "http://www.seishub.org", "version": "1.2.1", "platform": "OS Independent", "keywords": "SeisHub,seismology", "summary": "Exupery package for SeisHub.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "seishub.plugins.exupery - Exupery package for SeisHub.\n\n    For more information visit http://www.seishub.org."}}, {"pk": 141, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "OpenOPC", "license": "GNU GPL + linking exception", "author": "Barry Barnreiter", "author_email": "", "project_url": null, "maintainer_email": "", "home_page": "http://openopc.sourceforge.net", "version": "1.1.0", "platform": "", "keywords": "", "summary": "OPC library for Python", "classifiers": "Development Status :: 5 - Production/Stable\nTopic :: Communications\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "OpenOPC for Python is an easy to use OPC (OLE for Process Control) library for\r\nuse with the Python programming language. The project includes a Windows gateway\r\nservice allowing non-Windows clients to also access OPC-DA calls."}}, {"pk": 142, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "veusz", "license": "GPL", "author": "Jeremy Sanders", "author_email": "jeremy@jeremysanders.net", "project_url": null, "maintainer_email": null, "home_page": "http://home.gna.org/veusz/", "version": "1.11", "platform": "UNKNOWN", "keywords": null, "summary": "A scientific plotting package", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Visualization", "description": "Veusz is a scientific plotting package, designed to create\n        publication-ready Postscript, PDF and SVG output. It features GUI,\n        command-line, and scripting interfaces. Graphs are constructed from\n        \"widgets\", allowing complex layouts to be designed. Veusz supports\n        plotting functions, data with errors, keys, labels, stacked plots,\n        multiple plots, and fitting data."}}, {"pk": 143, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "simplerandom", "license": "MIT", "author": "Craig McQueen", "author_email": "python@craig.mcqueen.id.au", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/cmcqueen1975/simplerandom/", "version": "0.10.0", "platform": "UNKNOWN", "keywords": "simple random pseudorandom RNG PRNG", "summary": "Simple random number generators", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Cython\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nProgramming Language :: Python :: 3.2\nTopic :: Scientific/Engineering :: Mathematics", "description": "=============\nSimple Random\n=============\n\n:Author: Craig McQueen\n:Contact: http://craig.mcqueen.id.au/\n:Copyright: 2010 Craig McQueen\n\n\nSimple pseudo-random number generators.\n\n-----\nIntro\n-----\n\nThe ``simplerandom`` package is provided, which contains modules containing\nclasses for various simple pseudo-random number generators.\n\nOne module provides Python iterators, which generate simple unsigned 32-bit\nintegers identical to their C counterparts.\n\nAnother module provides random classes that are sub-classed from the class\n``Random`` in the ``random`` module of the standard Python library.\n\nWhy use this package? These random number generators are very simple, which\nhas two main advantages:\n\n* It is easy to port them to a different platform and/or language. It can be\n  useful to be able to implement the identical algorithm on multiple\n  platforms and/or languages.\n* Small and simple generators can be more appropriate for small embedded\n  systems, with limited RAM and ROM.\n\nAn equivalent C implementation (of the Python ``simplerandom.iterators``\nmodule) has been created. See:\n\n    http://bitbucket.org/cmcqueen1975/simplerandom\n\nAlgorithms\n``````````\n\nMost algorithms were obtained from two newsgroup posts by George Marsaglia\n[#marsaglia1999]_ [#marsaglia2003]_. However, some modifications have been\nmade. From [#rose]_, it seems that the SHR3 algorithm defined in\n[#marsaglia1999]_ is flawed and should not be used. It doesn't actually have a\nperiod of 2**32-1 as expected, but has 64 different cycles, some with very\nshort periods. The SHR3 in the 2003 post is very similar, but with two shift\nvalues swapped. It has a period of 2**32-1 as expected.\n\nWe still find KISS from [#marsaglia1999]_ useful mainly because it uses 32-bit\ncalculations for MWC, which can be more suitable for small embedded systems.\nSo we define KISS that uses a MWC based on [#marsaglia1999]_, but the Cong and\nSHR3 from [#marsaglia2003]_.\n\nFrom Pierre L'Ecuyer [#lecuyer1999]_ [#lecuyer1996]_, the Combined LFSR\n(Tausworthe) LFSR113 algorithm [#lfsr113]_ and LFSR88 (aka Taus88) have been\nimplemented.\n\n\nReferences\n``````````\n\n.. [#marsaglia1999] | `Random Numbers for C\\: End, at last?`__\n                    | George Marsaglia\n                    | Newsgroup post, sci.stat.math and others, Thu, 21 Jan 1999\n\n.. __:\n.. _Random Numbers for C\\: End, at last?:\n    http://www.cse.yorku.ca/~oz/marsaglia-rng.html\n\n.. [#marsaglia2003] | `RNGs`__\n                    | George Marsaglia\n                    | Newsgroup post, sci.math, 26 Feb 2003\n\n.. __:\n.. _RNGs:\n    http://groups.google.com/group/sci.math/msg/9959175f66dd138f\n\n.. [#rose]          | `KISS: A Bit Too Simple`__\n                    | Greg Rose\n                    | Qualcomm Inc.\n\n.. __:\n.. _KISS\\: A Bit Too Simple:\n    http://eprint.iacr.org/2011/007.pdf\n\n.. [#lecuyer1999]   | `Tables of Maximally-Equidistributed Combined LFSR Generators`__\n                    | Pierre L'Ecuyer\n                    | Mathematics of Computation, 68, 225 (1999), 261\u2013269.\n\n.. __:\n.. _Tables of Maximally-Equidistributed Combined LFSR Generators:\n    http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.3639\n\n.. [#lfsr113]       | `LFSR113 C double implementation`__\n                    | Pierre L'Ecuyer\n\n.. __:\n.. _LFSR113 C double implementation:\n    http://www.iro.umontreal.ca/~simardr/rng/lfsr113.c\n\n.. [#lecuyer1996]   | `Maximally Equidistributed Combined Tausworthe Generators`__\n                    | P. L'Ecuyer\n                    | Mathematics of Computation, 65, 213 (1996), 203\u2013213. \n\n.. __:\n.. _Maximally Equidistributed Combined Tausworthe Generators:\n    http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.4155\n\n\n----------------\nModules Provided\n----------------\n\n==========================  ===========================================================================\nModule                      Description\n==========================  ===========================================================================\n``simplerandom.iterators``  Iterator classes, which generate unsigned 32-bit integers.\n``simplerandom.random``     Classes that conform to standard Python ``random.Random`` API.\n==========================  ===========================================================================\n\n\nRandom Number Generators Provided\n`````````````````````````````````\n\nIn ``simplerandom.iterators``, the following pseudo-random number generators are provided:\n\n==========================  ===========================================================================\nGenerator                   Notes\n==========================  ===========================================================================\n``MWC1``                    Two 32-bit MWCs combined. From [#marsaglia1999]_.\n``MWC2``                    Very similar to ``MWC1``, but slightly modified to improve its statistical properties.\n``Cong``                    From [#marsaglia2003]_.\n``SHR3``                    From [#marsaglia2003]_.\n``LFIB4``                   From [#marsaglia1999]_.\n``SWB``                     From [#marsaglia1999]_.\n``MWC64``                   A single 64-bit multiply-with-carry calculation. From [#marsaglia2003]_.\n``KISS``                    Combination of MWC2, Cong and SHR3. Based on [#marsaglia1999]_ but using Cong and SHR3 from [#marsaglia2003]_, and a modified MWC2.\n``KISS2``                   Combination of MWC64, Cong and SHR3. From [#marsaglia2003]_.\n``LFSR113``                 Combined LFSR (Tausworthe) random number generator by L'Ecuyer. From [#lecuyer1999]_ [#lfsr113]_.\n``LFSR88``                  Combined LFSR (Tausworthe) random number generator by L'Ecuyer. From [#lecuyer1996]_.\n==========================  ===========================================================================\n\nThese generators are Python iterators, of infinite length (they never raise\n``StopIteration``). They implement the ``next()`` method (``__next__()`` in\nPython 3.x) to generate the next random integer. All the generators output\n32-bit unsigned values, and take one or more 32-bit seed values during\ninitialisation/seeding.\n\n\nIn ``simplerandom.random``, pseudo-random number generators are provided which\nhave the same names as those in ``simplerandom.iterators``, but these\ngenerators implement the standard Python ``random.Random`` API. However the\n``jumpahead()`` function (Python 2.x) is not implemented in all cases. Each\ngenerator uses the iterator of the same name in ``simplerandom.iterators`` to\ngenerate the random bits used to produce the random floats.\n\n\n-----\nUsage\n-----\n\nIterators\n`````````\n\n    >>> import simplerandom.iterators as sri\n    >>> rng = sri.KISS(123958, 34987243, 3495825239, 2398172431)\n    >>> next(rng)\n    702862187L\n    >>> next(rng)\n    13888114L\n    >>> next(rng)\n    699722976L\n\nRandom class API\n````````````````\n\n    >>> import simplerandom.random as srr\n    >>> rng = srr.KISS(258725234)\n    >>> rng.random()\n    0.773460115942927\n    >>> rng.random()\n    0.012115143213983215\n    >>> rng.random()\n    0.8954136598708136\n\n\n-------------------------\nSupported Python Versions\n-------------------------\n\nCurrently this has had basic testing on Ubuntu 10.04 32-bit and\nWindows XP 32-bit. It passes the basic ``simplerandom.iterators.test`` unit\ntests, as well as basic manual testing of ``simplerandom.random``. A more\nthorough unit test suite is needed.\n\nIn Ubuntu, it has been tested on Python 2.6 and 3.1 and passes.\n\nIn Windows, it has been tested on Python 2.4, 2.5, 2.6, 2.7, 3.1 and 3.2.\nIt passes under these versions.\n\nThe pure Python code is expected to work on 64-bit platforms, but has not been\ntested. The Cython version of ``simplerandom.iterators`` should work on 64-bit\nplatforms, but has not been tested.\n\n\n-------------\nUse of Cython\n-------------\n\n`Cython`_ is used to make a fast implementation of ``simplerandom.iterators``.\nCython creates a ``.c`` file that can be compiled into a Python binary\nextension module.\n\nThe ``simplerandom`` source distribution package includes a ``.c`` file that\nwas created with Cython, so it is not necessary to have Cython installed to\ninstall ``simplerandom``.\n\nThe Cython ``.pyx`` file is also included, if you want to modify the Cython\nsource code, in which case you do need to have Cython installed. But by\ndefault, ``setup.py`` builds the extension from the ``.c`` file (to ensure\nthat the build doesn't fail due to particular Cython version issues). If you\nwish to build using Cython from the included ``.pyx`` file, you must set\n``USE_CYTHON=True`` in ``setup.py``.\n\n.. _Cython:\n    http://cython.org/\n\n\n------------\nInstallation\n------------\n\nThe simplerandom package is installed using ``distutils``.  If you have the tools\ninstalled to build a Python extension module, run the following command::\n\n    python setup.py install\n\nIf you cannot build the C extension, you may install just the pure Python\nimplementation, using the following command::\n\n    python setup.py build_py install --skip-build\n\n\n------------\nUnit Testing\n------------\n\nBasic unit testing of the iterators is in ``simplerandom.iterators.test``. It\nduplicates the tests of the C algorithms given in the original newsgroup post\n[#marsaglia1999]_, as well as other unit tests.\n\nTo run it on Python >=2.5::\n\n    python -m simplerandom.iterators.test\n\nAlternatively, in the ``test`` directory run::\n\n    python test_iterators.py\n\nA more thorough unit test suite is needed.\n\n\n-------\nLicense\n-------\n\nThe code is released under the MIT license. See LICENSE.txt for details."}}, {"pk": 144, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coards", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://dealmeida.net/projects/coards", "version": "0.2.2", "platform": "UNKNOWN", "keywords": "data time coards netcdf", "summary": "Convert COARDS time specification to a datetime object.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This module converts between a given COARDS time specification and a\nPython datetime object, which is much more useful. Suppose you have an\nArray of values [1,2,3] and units \"days since 1998-03-01 12:00:00\"::\n\n    >>> a = [1, 2, 3]\n    >>> units = 'days since 1998-03-01 12:00:00'\n    >>> b = [from_udunits(value, units) for value in a]\n    >>> print b[0].year\n    1998\n    >>> b[1] > b[0]\n    True\n    >>> print b[1] - b[0]\n    1 day, 0:00:00\n\nThe list ``b`` now contains objects which can be compared and manipulated in\na consistent way.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/coards#egg=coards-dev>`_."}}, {"pk": 145, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "remote-microscope", "license": "UNKNOWN", "author": "The MEMS Exchange", "author_email": "microscope-feedback@mems-exchange.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.mems-exchange.org/software/microscope/", "version": "2.0a3", "platform": "UNKNOWN", "keywords": null, "summary": "A daemon that makes a Leica semiconductor\ninspection microscope remotely controllable using\nan HTTP/HTML-based interface.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Web Environment\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python License (CNRI Python License)\nOperating System :: POSIX :: Linux\nTopic :: Internet\nTopic :: Scientific/Engineering", "description": "UNKNOWN"}}, {"pk": 146, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PyNN", "license": "CeCILL http://www.cecill.info", "author": "The NeuralEnsemble Community", "author_email": "pynn@neuralensemble.org", "project_url": null, "maintainer_email": "", "home_page": "http://neuralensemble.org/PyNN/", "version": "0.7.0", "platform": "UNKNOWN", "keywords": "computational neuroscience simulation neuron nest pcsim brian neuroml", "summary": "A Python package for simulator-independent specification of neuronal network models", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "In other words, you can write the code for a model once, using the PyNN API and the Python programming language, and then run it without modification on any simulator that PyNN supports (currently NEURON, NEST, PCSIM and Brian).\r\n\r\nThe API has two parts, a low-level, procedural API (functions create(), connect(), set(), record(), record_v()), and a high-level, object-oriented API (classes Population and Projection, which have methods like set(), record(), setWeights(), etc.). \r\n\r\nThe low-level API is good for small networks, and perhaps gives more flexibility. The high-level API is good for hiding the details and the book-keeping, allowing you to concentrate on the overall structure of your model.\r\n\r\nThe other thing that is required to write a model once and run it on multiple simulators is standard cell and synapse models. PyNN translates standard cell-model names and parameter names into simulator-specific names, e.g. standard model IF_curr_alpha is iaf_neuron in NEST and StandardIF in NEURON, while SpikeSourcePoisson is a poisson_generator in NEST and a NetStim in NEURON.\r\n\r\nEven if you don't wish to run simulations on multiple simulators, you may benefit from writing your simulation code using PyNN's powerful, high-level interface. In this case, you can use any neuron or synapse model supported by your simulator, and are not restricted to the standard models.\r\n\r\nPyNN is a work in progress, but is already being used for several large-scale simulation projects."}}, {"pk": 147, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "edittag", "license": "BSD", "author": "Brant Faircloth", "author_email": "brant.faircloth+edittag@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://baddna.github.com/edittag/", "version": "1.0rc5", "platform": "UNKNOWN", "keywords": null, "summary": "Design and check sets of edit metric sequence tags.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "edittag\n=======\n\nCopyright (c) 2009\u20132011 Brant C. Faircloth. All rights reserved.\n\n-  See ``LICENSE.md`` for standard, 2-clause BSD license covering\n   computer code.\n-  Sequence tags available from\n   `https://github.com/BadDNA/edittag/downloads`_ are licensed under\n   `Creative Commons Attribution 3.0 United States License`_.\n\nDescription\n-----------\n\nedittag is a software collection for designing sets of edit metric\nsequence tags, checking sequence tags for conformation to the edit\nmetric, and integrating sequence tags to platform-specific sequencing\nadapters and PCR primers. edittag differs from other approaches:\n\n-  edittag generates arbitrary lengths of edit-metric sequence tags in\n   reasonable time frames using multiprocessing\n-  edittag produces edit metric sequence tag sets conform to the edit\n   distance selected\n-  edittag used primer3 to integrate sequence tags to PCR primers\n\nWe provide several large sets of edit metric sequence tags designed\nusing edittag in the following formats:\n\n-  text_ - this file is in an appropriate format for\n   ``check_levenshtien_distance.py``\n-  csv_\n-  `sqlite database`_\n\nCitation\n--------\n\nFaircloth BC, Glenn TC.  Large sets of edit-metric sequence identification \ntags to facilitate large-scale multiplexing of reads from massively \nparallel sequencing.  `http://precedings.nature.com/documents/5672/version/1`_\n\nDependencies\n------------\n\n-  `Python 2.7.x`_ (should work on 2.6.x)\n-  `numpy`_ (tested with 1.5.1)\n-  `py-levenshtein`_ [optional but strongly recommended]\n-  `mod-primer3`_ [optional]\n-  `nose`_ [optional - for unittests]\n\nAvailability\n------------\n\n-  tar.gz\n-  repository\n-  Amazon Machine Instance # (coming soon)\n\nInstallation\n------------\n\neasy_install\n~~~~~~~~~~~~\n\n::\n\n    easy_install edittag\n\ntar.gz\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    wget package.tar.gz\n    tar -xzf package.tar.gz\n    python setup.py install\n\nrepository\n~~~~~~~~~~\n\n::\n\n    git clone git://github.com/baddna/edittag.git edittag\n\n\noptional package (py-levenshtein)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    wget http://pylevenshtein.googlecode.com/files/python-Levenshtein-0.10.1.tar.bz2\n    tar -xzvf python-Levenshtein-0.10.1.tar.bz2\n    python setup.py install\n\n\noptional package (primer3)\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIf you wish to design primers incorporating edit metric sequence tags, you \nneed to first install a modified version of primer3:\n\n::\n\n    git clone git://github.com/baddna/mod-primer3.git\n    cd mod-primer3/src\n    make\n    make install\n\nEnsure that you move the binaries from mod-primer3 to a location in your\npath (move at least ``primer3-long`` and ``primer3_config`` into identical \ndirectories in your path).\n\nTesting\n-------\n\n::\n\n    # Testing requires numpy and nose\n    import edittag\n    edittag.test()\n\n\nAlternatives sources\n--------------------\n\nAmazon Machine Instance (not yet implemented)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n1. Create an account on Amazon EC2.\n2. Start AMI # xxxxx\n\n::\n    \n    # activate the edittag virtualenv\n    % workon edittag\n    \n    # generate some tags\n    % design_edit_metric_tags.py --tag-length=6 --edit-distance=3 \\\n        --no-polybase --gc --comp --min-and-greater --output tmp/tags.txt\n    \n    # validate the 6 nucleotide, edit distance 3 tag set\n    % validate_edit_metric_tags.py \n        --input=tmp/tags.txt\n        --section='6nt ed3'\n        --verbose\n    \n    # add those tags to a primer set\n    % add_tags_to_primers.py --left-primer=GTTATGCATGAACGTAATGCTC --right-primer=CGCGCATGGTGGATTCACAATCC \\\n        --input tmp/tags.txt --section='6nt ed3'\n        --sort=pair_hairpin_either,pair_penalty,cycles \\\n        --remove-common --keep-database \\\n        --output tmp/trnH_tagged_with_10_nt_ed_5_tags.csv\n    \n\n.. _`https://github.com/BadDNA/edittag/downloads`: https://github.com/BadDNA/edittag/downloads\n.. _`http://precedings.nature.com/documents/5672/version/1`: http://precedings.nature.com/documents/5672/version/1\n.. _Creative Commons Attribution 3.0 United States License: http://creativecommons.org/licenses/by/3.0/us/\n.. _text: https://github.com/downloads/BadDNA/edittag/edit_metric_tags.txt\n.. _csv: https://github.com/downloads/BadDNA/edittag/edit_metric_tags.csv\n.. _sqlite database: https://github.com/downloads/BadDNA/edittag/edit_metric_tags.sqlite.zip\n.. _Python 2.7.x: http://www.python.org/\n.. _numpy: http://numpy.scipy.org\n.. _py-levenshtein: http://pylevenshtein.googlecode.com\n.. _mod-primer3: https://github.com/BadDNA/mod-primer3\n.. _nose: http://somethingaboutorange.com/mrl/projects/nose/1.0.0/"}}, {"pk": 148, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dipy", "license": "BSD license", "author": "Eleftherios Garyfallidis", "author_email": "nipy-devel@neuroimaging.scipy.org", "project_url": null, "maintainer_email": null, "home_page": "http://dipy.org", "version": "0.5.0", "platform": "OS Independent", "keywords": null, "summary": "Diffusion MRI utilities in python", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "======\n DiPy\n======\n\nDipy is a python toolbox for analysis of MR diffusion imaging.\n\nDipy is for research only; please do not use results from dipy for\nclinical decisions.\n\nWebsite\n=======\n\nCurrent information can always be found at the NIPY dipy website -\nhttp://nipy.org/dipy - or directly from the DIPY website - http://dipy.org\n\nMailing Lists\n=============\n\nPlease see the developer's list at http://mail.scipy.org/mailman/listinfo/nipy-devel\n\nCode\n====\n\nYou can find our sources and single-click downloads:\n\n* `Main repository`_ on Github.\n* Documentation_ for all releases and current development tree.\n* Download as a tar/zip file the `current trunk`_.\n* Downloads of all `available releases`_.\n\n.. _main repository: http://github.com/Garyfallidis/dipy\n.. _Documentation: http://dipy.org\n.. _current trunk: http://github.com/Garyfallidis/dipy/archives/master\n.. _available releases: http://github.com/Garyfallidis/dipy/downloads\n\nLicense\n=======\n\ndipy is licensed under the terms of the BSD license. Some code included with\ndipy is also licensed under the BSD license.  Please the LICENSE file in the\ndipy distribution."}}, {"pk": 149, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "keytree", "license": "BSD", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://atlantides.org/svn/pleiades/pleiades.keytree", "version": "0.2.1", "platform": "UNKNOWN", "keywords": "KML etree ElementTree", "summary": "KML utilities for the ElementTree API", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "Keytree\n=======\n\nKeytree provides several functions for manipulating KML using the ElementTree API. Elements can be adapted to the Python geo interface and then used with packages like Shapely_::\n\n  >>> data = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n  ... <kml xmlns=\"http://www.opengis.net/kml/2.2\">\n  ...   <Document>\n  ...     <Placemark>\n  ...       <name>point</name>\n  ...       <description>Point test</description>\n  ...       <Point>\n  ...         <coordinates>\n  ...           -122.364383,37.824664,0\n  ...         </coordinates>\n  ...       </Point>\n  ...     </Placemark>\n  ...   </Document>\n  ... </kml>\n  ... \"\"\"\n  >>> from xml.etree import ElementTree\n  >>> tree = ElementTree.fromstring(data)\n  >>> kmlns = tree.tag.split('}')[0][1:]\n  >>> placemarks = tree.findall('*/{%s}Placemark' % kmlns)\n  >>> p0 = placemarks[0]\n  >>> import keytree\n  >>> f = keytree.feature(p0)\n  >>> from shapely.geometry import asShape\n  >>> shape = asShape(f.geometry)\n  >>> shape.buffer(1.5).exterior.length\n  9.4209934708642571\n\nObjects like those from geojson_ that provide the Python geo interface can also be converted to ElementTree API Elements::\n\n  >>> from geojson import Feature\n  >>> f = Feature('1', \n  ...             geometry={\n  ...                 'type': 'Point', \n  ...                 'coordinates': (-122.364383, 37.824663999999999)\n  ...                 },\n  ...             title='Feature 1', \n  ...             summary='The first feature', \n  ...             content='Blah, blah, blah.'\n  ...             )\n\nA Shapely (or geojson) geometry could also be used in place of the dict::\n\n  >>> from shapely.geometry import Point\n  >>> f = Feature('1', \n  ...             geometry=Point(-122.364383, 37.824664),\n  ...             title='Feature 1', \n  ...             summary='The first feature', \n  ...             content='Blah, blah, blah.'\n  ...             )\n  \nThe first argument to the keytree.element function is an XML context, the created element will have the same namespace as that element::\n\n  >>> elem = keytree.element(tree, f)\n  >>> import pprint\n  >>> pprint.pprint((elem.tag, elem.text, list(elem)))\n  ('{http://www.opengis.net/kml/2.2}Placemark',\n   None,\n   [<Element {http://www.opengis.net/kml/2.2}name at ...>,\n    <Element {http://www.opengis.net/kml/2.2}Snippet at ...>,\n    <Element {http://www.opengis.net/kml/2.2}description at ...>,\n    <Element {http://www.opengis.net/kml/2.2}Point at ...>])\n  >>> pprint.pprint(list((e.tag, e.text, list(e)) for e in elem))\n  [('{http://www.opengis.net/kml/2.2}name', 'Feature 1', []),\n   ('{http://www.opengis.net/kml/2.2}Snippet', 'The first feature', []),\n   ('{http://www.opengis.net/kml/2.2}description', 'Blah, blah, blah.', []),\n   ('{http://www.opengis.net/kml/2.2}Point',\n    None, \n    [<{http://www.opengis.net/kml/2.2}Element coordinates at ...>])]\n  \n.. _Shapely: http://pypi.python.org/pypi/Shapely\n.. _geojson: http://pypi.python.org/pypi/geojson"}}, {"pk": 150, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PokerSleuth", "license": "BSD", "author": "Stutzbach Enterprises, LLC", "author_email": "daniel@stutzbachenterprises.com", "project_url": null, "maintainer_email": "", "home_page": "http://pokersleuth.com/programmable-poker-calculator.shtml", "version": "2.1.0.47", "platform": "UNKNOWN", "keywords": "poker equity calculator odds", "summary": "A wrapper for the Poker Sleuth Scriptable Equity Calculator", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Win32 (MS Windows)\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nOperating System :: Microsoft :: Windows\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nProgramming Language :: Python :: 3.2\nTopic :: Games/Entertainment\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Python wrapper for the Poker Sleuth Scriptable Equity Calculator\n================================================================\n\nThis module provides a Python interface to the `Poker Sleuth`__\n`scriptable Texas Hold'em Equity Calculator`__.  Tell it what hands\nyour opponents may have, and it calculates your odds of winning at the\nshowdown if no one folds.\n\nFor example, to compute the odds of winning when you have a pair of\nJacks, your opponent has the Ace and 5 of diamonds, and the board\ncards are the 3 of diamonds, 5 of clubs, and 9 of diamonds:\n\n::\n\n    >>> import pokersleuth\n    >>> pokersleuth.calculate_equity('3d5c9d', ('JJ', 'Ad5d')\n    [0.48225, 0.51775]\n\nThe module can also be used directly from the command line:\n\n::\n\n    C:\\>python -m pokersleuth 3d5c9d JJ Ad5d\n    [0.48225, 0.51775]\n\n__ http://pokersleuth.com/\n__ http://pokersleuth.com/poker-equity-calculator.shtml"}}, {"pk": 151, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "mpy", "license": "BSD", "author": "Yung-Yu Chen", "author_email": "yyc+mpy@seety.org", "project_url": null, "maintainer_email": "", "home_page": "http://bitbucket.org/yungyuc/mpy/", "version": "0.1", "platform": "Linux", "keywords": "", "summary": "MPI for Python.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: No Input/Output (Daemon)\nIntended Audience :: Developers\nIntended Audience :: Education\nLicense :: OSI Approved :: BSD License\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: System :: Distributed Computing", "description": "MPY stands for \"MPi for pYthon\", is a single-module wrapper for any MPI\r\nlibrary.  Just copy the mpy.py then it works (needless to say, after you have\r\nMPI installed on a cluster).  MPY has no external dependency other than a\r\nworking MPI installation and a standard Python.  The MPI installation has to\r\nbe built with shared object since MPY uses ctypes as interface.\r\n\r\nAll the functions in the MPI library can be accessed by\r\nMPI().Name_Without_Leading_MPI(), and you must manually convert the arguments\r\nfrom Python objects to ctypes objects.  Shorthand APIs and Pythonic APIs are\r\nalso provided.  Shorthand APIs use Python objects and can return Python\r\nobjects, with the same naming convention as MPI, but all lower-cased.  Pythonic\r\nAPIs are Pythonic.\r\n\r\nYou can verify the \"installation\" of MPY by running::\r\n\r\n  $ mpiexec -n 2 python mpy.py"}}, {"pk": 152, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "EnvisageCore", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/envisage/", "version": "3.2.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Extensible Application Framework", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "Envisage is a Python-based framework for building extensible applications,\nthat is, applications whose functionality can be extended by adding \"plug-ins\".\nEnvisage provides a standard mechanism for features to be added to an\napplication, whether by the original developer or by someone else. In fact,\nwhen you build an application using Envisage, the entire application consists\nprimarily of plug-ins. In this respect, it is similar to the Eclipse and\nNetbeans frameworks for Java applications.\n\nEach plug-in is able to:\n\n- Advertise where and how it can be extended (its \"extension points\").\n- Contribute extensions to the extension points offered by other plug-ins.\n- Create and share the objects that perform the real work of the application\n  (\"services\").\n\nThe EnvisageCore project provides the basic machinery of the Envisage\nframework. This project contains no plug-ins. You are free to use:\n\n- plug-ins from the EnvisagePlugins project\n- plug-ins from other ETS projects that expose their functionality as plug-ins\n- plug-ins that you create yourself\n\nPrerequisites\n-------------\nIf you want to build EnvisageCore from source, you must first install\n`setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 153, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "musicbutler", "license": "UNKNOWN", "author": "Michael Gundlach", "author_email": "gundlach@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://musicbutler.googlecode.com/", "version": "0.1.7", "platform": "UNKNOWN", "keywords": "speech recognition music stereo control mp3 robot butler", "summary": "A robot that receives voice commands to play albums from your MP3 collection", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Win32 (MS Windows)\nLicense :: OSI Approved :: Apache Software License\nOperating System :: Microsoft :: Windows\nProgramming Language :: Python\nTopic :: Desktop Environment\nTopic :: Home Automation\nTopic :: Multimedia :: Sound/Audio\nTopic :: Multimedia :: Sound/Audio :: Speech\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: Libraries :: Python Modules", "description": "-----------\nMusicButler\n-----------\n\n*** NOTE: This is an alpha product.  The example.py file can get you\ngoing, but it has no GUI and the underlying mp3play module doesn't\nwork with all mp3s yet for some reason.***\n\nWhen MusicButler has been told what albums you own, a spoken\nconversation with it might go like this:\n\n  * \"Afred, what albums do I have?\"\n  * \"Here are 3 out of your 58 albums: In Rainbows by Radiohead, Deja Vu by Crosby Stills Nash and Young, and Atlanta by Alison Krauss.\"\n  * \"Afred, what Radiohead albums do I have?\"\n  * \"You have 2 albums by Radiohead: In Rainbows, and OK Computer.\"\n  * \"Afred, play me some Alison Krauss, any album.\"\n  * \"Playing New Favorite by Alison Krauss.\"\n\nRequirements\n-----------------\nRequires Windows XP, and Python2.5.  Windows XP because it uses\nthe 'speech' module -- see that on pypi for prerequisites.  And\nPython2.5 because it uses the mp3play module -- which is still in\nalpha too so don't be surprised if some songs don't play properly.\n\nPlease let me know if you like or use this module - it would make\nmy day!"}}, {"pk": 154, "model": "importing.pypicache", "fields": {"maintainer": "Tim Cera", "name": "Pyslice", "license": "", "author": "Tim Cera", "author_email": "timcera@earthlink.net", "project_url": null, "maintainer_email": "timcera@earthlink.net", "home_page": "http://pyslice.sourceforge.net", "version": "1.6.4", "platform": "", "keywords": "", "summary": "Pyslice is a special purpose templating system to create input datasets for simulations.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: System :: Clustering\nTopic :: System :: Distributed Computing\nTopic :: Text Processing", "description": "Pyslice is a specialized templating system that replaces a variable in a\r\ntemplate with a number taken from a series of numbers. It creates a dataset for\r\neach number in the series. \r\n\r\nThe main function of Pyslice is to provide utility functions for parametric\r\nmodeling. Parametric modeling is a process of varying many inputs to a model. A\r\ndrawback to parametric modeling is that there are usually hundreds to thousands\r\nof data sets to prepare and a corresponding number of model runs. Pyslice will\r\ncreate the model data sets and manage the model runs, or place the model runs in\r\na queue managed by other software. Pyslice is also useful in establishing the\r\nsensitivity of a model to changing parameters."}}, {"pk": 155, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Divisi", "license": "http://www.gnu.org/copyleft/gpl.html", "author": "MIT Media Lab, Software Agents group", "author_email": "conceptnet@media.mit.edu", "project_url": null, "maintainer_email": null, "home_page": "http://divisi.media.mit.edu/", "version": "0.6.10", "platform": "any", "keywords": null, "summary": "Divisi: Commonsense Reasoning over Semantic Networks", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Text Processing :: Linguistic", "description": "Divisi is a library for reasoning by analogy and association over\nsemantic networks, including common sense knowledge. Divisi uses a\nsparse higher-order SVD and can help find related concepts, features,\nand relation types in any knowledge base that can be represented as a\nsemantic network. By including common sense knowledge from ConceptNet,\nthe results can include relationships not expressed in the original\ndata but related by common sense. See http://divisi.media.mit.edu/ for\nmore info."}}, {"pk": 156, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "scikits.statsmodels", "license": "BSD License", "author": "Skipper Seabold, Josef Perktold", "author_email": "pystatsmodels@googlegroups.com", "project_url": null, "maintainer_email": "", "home_page": "http://statsmodels.sourceforge.net/", "version": "0.2.0", "platform": "UNKNOWN", "keywords": "numpy, scipy, statistics, econometrics, data analysis", "summary": "Statistical computations and models for use with SciPy", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.4\nTopic :: Scientific/Engineering", "description": "Statsmodels is a python package that provides a complement to scipy for \r\nstatistical computations including descriptive statistics and \r\nestimation of statistical models.\r\n\r\nscikits.statsmodels provides classes and functions for the estimation of \r\nseveral categories of statistical models. These currently include linear \r\nregression models, OLS, GLS, WLS and GLS with AR(p) errors, generalized \r\nlinear models for six distribution families, M-estimators for robust \r\nlinear models, and regression with discrete dependent variables, Logit, \r\nProbit, MNLogit, Poisson, based on maximum likelihood estimators. \r\nAn extensive list of result statistics are avalable for each estimation \r\nproblem.\r\n\r\nWe welcome feedback: \r\nmailing list at http://groups.google.com/group/pystatsmodels?hl=en  or\r\nour bug tracker at https://bugs.launchpad.net/statsmodels\r\n\r\nFor updated versions between releases, we recommend our repository at\r\nhttp://code.launchpad.net/statsmodels\r\n\r\nMain Changes in 0.2.0\r\n---------------------\r\n\r\n* Improved documentation and expanded and more examples\r\n* Added four discrete choice models: Poisson, Probit, Logit, and Multinomial Logit.\r\n* Added PyDTA. Tools for reading Stata binary datasets (*.dta) and putting \r\n  them into numpy arrays.\r\n* Added four new datasets for examples and tests.\r\n* Results classes have been refactored to use lazy evaluation.\r\n* Improved support for maximum likelihood estimation.\r\n* bugfixes\r\n* renames for more consistency\r\n  RLM.fitted_values -> RLM.fittedvalues\r\n  GLMResults.resid_dev -> GLMResults.resid_deviance\r\n\r\nSandbox\r\n-------\r\n\r\nWe are continuing to work on support for systems of equations models, panel data \r\nmodels, time series analysis, and information and entropy econometrics in the \r\nsandbox. This code is often merged into trunk as it becomes more robust."}}, {"pk": 157, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "itcc", "license": "OSI Approved :: GNU General Public License (GPL)", "author": "LI Daobing", "author_email": "lidaobing@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/itcc", "version": "0.9.2", "platform": "UNKNOWN", "keywords": null, "summary": "my collection of scripts on computational chemistry", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: POSIX\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Chemistry", "description": "UNKNOWN"}}, {"pk": 158, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "tau", "license": "GPL", "author": "Tiago Coutinho", "author_email": "tcoutinho@cells.es", "project_url": null, "maintainer_email": "", "home_page": "http://www.tango-controls.org/static/tau/latest/doc/html/index.html", "version": "1.2.0", "platform": "Linux,Windows XP/2000/NT,Windows 95/98/ME", "keywords": "CLI,PyTango,Tango,Shell", "summary": "A library designed to provide an abstraction layer over PyTango.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "UNKNOWN"}}, {"pk": 159, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.datasmooth", "license": "BSD", "author": "('Jonathan Stickel',)", "author_email": "jjstickel@vcn.com", "project_url": null, "maintainer_email": null, "home_page": "http://scikits.appspot.com/", "version": "0.5", "platform": "UNKNOWN", "keywords": null, "summary": "Scikits data smoothing package", "classifiers": "Development Status :: 1 - Planning\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": "This is a scikit intended to include numerical methods for smoothing\ndata."}}, {"pk": 160, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dynrules", "license": "Public Domain", "author": "Marcus von Appen", "author_email": "marcus@sysfault.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.sysfault.org/dokuwiki/projects:dynrules", "version": "0.0.13", "platform": "UNKNOWN", "keywords": null, "summary": "Simple dynamic ruleset system for adaptive AI", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: Public Domain\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Libraries :: Python Modules", "description": "dynrules is a dynamic ruleset scripting package for Python. It uses the Dynamic\nScripting technique to create adaptive AI scripts automatically from predefined\nrulesets."}}, {"pk": 161, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "edrnsite.portlets", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/edrnsite-portlets", "version": "1.0.2", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers portlet", "summary": "Portlets for the EDRN Public Portal", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "*****************\nedrnsite.portlets\n*****************\n\nThis product, ``edrnsite.portlets``, implements the various portlets used\naround the public portal of the Early Detection Research Network (EDRN_).\n\nAlthough intended for the EDRN public portal, it can be installed in any\nPlone_ compatible site.\n\nThis software is developed by the `EDRN Informatics Center`_  at JPL_,\noperated by the California Institute of Technology, for NCI_.\n\n.. References:\n.. _EDRN Informatics Center: http://cancer.jpl.nasa.gov/\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://cancer.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``edrnsite.portlets`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        edrnsite.portlets\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        edrnsite.portlets\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.  For issues\nmentioned below, you can learn more about them by visiting the issue tracker\nat https://oodt.jpl.nasa.gov/jira/browse/CA.\n\n\n1.0.2 - Flip Flop\n-----------------\n\nThis release fixes the following single issue:\n\n* CA-692 - Modify top Portlet on left side to link to EDRN Secure Site\n\n\n1.0.1 - Missing Button\n----------------------\n\nThought Leader Dan said he wanted Specimens to be treated as a first class\ncitizen in the portal, which means it should be a global navigation tab across\nthe top and not a button on the QuickLinks portlet.  This release removes the\nSpecimens button.  (There is no issue ID; this requirement was conveyed via\ntelephone.)\n\n\n1.0.0 - New Button\n------------------\n\nThis release adds a button to the QuickLinks portlet that takes you to the\nnifty Members List search page.  It also addresses the following issues:\n\n* CA-642 - Create a new member page\n\nYou can learn more about this issue by visiting the Informatics Center's issue\ntracker at https://oodt.jpl.nasa.gov/jira/browse/CA.\n\n\n0.0.2 - Short URLs Bad, Long URLs Good?\n---------------------------------------\n\nThis release addresses the following issue:\n\n* https://oodt.jpl.nasa.gov/jira/browse/CA-562 - Biomarker Informatics\n  Standards - button should take you directly to the wiki page\n\n\n0.0.1 - Quicklinks Reordering\n-----------------------------\n\nThe following issues have been addressed in this release:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-466 - Change order of links on the\n  left side menu of the portal\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 162, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "python2-biggles", "license": "GPL", "author": "Mike Nolta", "author_email": "mike@nolta.net", "project_url": null, "maintainer_email": "", "home_page": "http://biggles.sourceforge.net/", "version": "1.6.5", "platform": "UNKNOWN", "keywords": "", "summary": "scientific plotting module", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: X11 Applications\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Visualization", "description": "Biggles is a Python module for creating publication-quality 2D scientific\r\nplots. It supports multiple output formats (postscript, x11, png, svg, gif),\r\nunderstands simple TeX, and sports a high-level, elegant interface. It's\r\nintended for technical users with sophisticated plotting needs."}}, {"pk": 163, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "rdkit", "license": "BSD", "author": "Greg Landrum", "author_email": "glandrum@users.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://www.rdkit.org/", "version": "2009.Q1b1", "platform": "Windows,Linux,Mac OS-X", "keywords": null, "summary": "RDKit Cheminformatics Library", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Chemistry", "description": "Data structures, algorithms, and scripts for cheminformatics."}}, {"pk": 164, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "radsunpath", "license": "GNU GPL", "author": "De Luminae", "author_email": "contact@deluminaelab.com", "project_url": null, "maintainer_email": null, "home_page": "www.deluminaelab.com", "version": "1.0", "platform": "UNKNOWN", "keywords": null, "summary": "Calculation of Radiance images for specified date, with specified time step and generation of animated gif output.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications :: GTK\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: Microsoft :: Windows :: Windows NT/2000\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics :: Viewers\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Visualization", "description": "Calculation of Radiance images for specified date, with specified time step and generation of animated gif output."}}, {"pk": 165, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "bein", "license": "UNKNOWN", "author": "Fred Ross", "author_email": "madhadron@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://madhadron.com/bein", "version": "1.0rc7", "platform": "UNKNOWN", "keywords": null, "summary": "Miniature LIMS and workflow manager for bioinformatics", "classifiers": "Topic :: Scientific/Engineering :: Bio-Informatics\nTopic :: System :: Shells", "description": "UNKNOWN"}}, {"pk": 166, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "emma", "license": "Eve Software Utilities Licence", "author": "Eve Software Utilities", "author_email": "information@eveutilities.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.eveutilities.com/products/emma", "version": "1.0", "platform": "OS Independent", "keywords": null, "summary": "Operational research tools", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Healthcare Industry\nIntended Audience :: Information Technology\nIntended Audience :: Legal Industry\nIntended Audience :: Manufacturing\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nIntended Audience :: Telecommunications Industry\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Emma is a Python package designed for solving optimization problems. It contains a group of utilities that will help you model the problem and efficient use your knowledge of it to solve it.\n\nOne of Emma\u2019s modules deals with constraint programming. Constraint Programming is a branch of operational research specialized in combinatorial problems. Its main porpoise is to solve constraint satisfaction problems, CSP\u2019s, that is, finding feasible solutions of problems without considering objectives functions. This module gives you tools to model operational research problems, an algorithm to solve CSP\u2019s, a set of search utilities to find good solutions, and when possible optimize your problem."}}, {"pk": 167, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "CoordSys", "license": "LGPL", "author": "Joerg Raedler", "author_email": "jr@j-raedler.de", "project_url": null, "maintainer_email": null, "home_page": "http://www.j-raedler.de/pages/software/coordsys.php", "version": "0.52", "platform": "UNKNOWN", "keywords": null, "summary": "cartesian coordinate system transformation", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: Freely Distributable\nOperating System :: OS Independent\nProgramming Language :: C\nTopic :: Scientific/Engineering :: Mathematics", "description": "CoordSys is for the fast transformation of points between\n        cartesian coordinate systems. It's usually used to transform points\n        from 3D to 2D and back."}}, {"pk": 168, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "asciiporn", "license": "gpl", "author": "kai zhu", "author_email": "kaizhu256@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pypi.python.org/pypi/asciiporn", "version": "2009.05.01", "platform": "UNKNOWN", "keywords": "", "summary": "view color images & 3d scientific plots in ssh terminal   (screenshots using putty ssh terminal included)", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics\nTopic :: Multimedia :: Graphics :: 3D Modeling\nTopic :: Multimedia :: Graphics :: 3D Rendering\nTopic :: Multimedia :: Graphics :: Graphics Conversion\nTopic :: Multimedia :: Graphics :: Viewers\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Image Recognition\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "################################################################################\r\noriginally an ascii art graphics library for ssh terminal,\r\nbut expanded to include scientific visualization.\r\n\r\nthis package has 2 main files:\r\n  asciiporn/__init__.py ## initialize custom import hook to load main.py\r\n  asciiporn/main.py     ## contains EVERYTHING\r\n\r\nhow to enable 256 color in putty:  http://www.emacswiki.org/emacs/PuTTY#toc2\r\nhow to enable 256 color in xterm:  http://www.frexx.de/xterm-256-notes/\r\nhow to enable 256 color in screen: http://www.frexx.de/xterm-256-notes/\r\n\r\n~   L_        '_-s+     _   ?}@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\r\n'   `{' _~ ` 't` 7~-- `  ^  f@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@M@@@@@@@@@@@@@@@@@@@@\r\n_,-),?j{WY+=+j ` ^7^   ` `   H@@@@@@@@@@@@@@@@@@@@@@@MQk9ZIV7=?IM@@@@@@@@@@@@@@@\r\nt' ~``nvi;f*o7L? `L~     `   &#M@M$@@@@@@@@@@@@@@@@@P`/r`,_S^?`>^JT@{M@@@@@@@@@@\r\nrr| + _` _^^LFFLW#W5| > '__`{PRy$y@Wf$N)i'fRM@@@@MM$r`^]g@`{~]{{rg>!'`}@@@@@@@@@\r\n  *'    '`^!_ ^@&My;r,'p&#MV` 'ujmr)` `Lr( {_`R?@r= `_^'MPM#&B$f1Bp=` -]@@@@@@@@\r\n    -r,r9` `_`J]3@$[`P`AVN-   -=yE `  _i ` ^`Li~i !YL `kj`'@MNMg@#Wggp{#@@@@@@@@\r\n'`  i' l|'  F _]I]/#P )vAL >pqA}&_`  !J x?g1>LV'i~l+ _  ?Vu__|V@@@@@$${1@@@@@@@@\r\n `       '`` '-h$g@@@&$w])#R[X/NF^>-t,r-=`/hTW=~x!'!^`+gg@@&M#&W@@@@Mu#M@@@@@@@@\r\n      `  _'  jg@@@@@M@@@@Mwm@p`#gj/c^ `' 9`   v `` _Vg@M@@@@@@M@@M@@@gD{kM@@@@@@\r\n`      _ _3H##&@Mg#@@@@@@p#N4@Wu9Mx`` _ `!1 !`|   (&@@@W@@@@@@@@$M@M@M@Wj`}M@@@@\r\n!| !_   _[2c3d@M&@@Q$&p@@$@WWM@Wb)/` s-+c `s '   g@$@@$M@@@@@@@M$$@@M$M@$p_=@@@@\r\n  _``  +^lYSiH@M@@@@@@Md@@5=aa=EMVp`/`iNL +r  `r@&@@@@M$@@@@@@$W@@@@#&#@@@W=(MMM\r\n``, +  F'c{^)(@@@@@@@@@@M@=]I7=w])$=_ _J^x``_  q$@@@@@M&g@@@@@#&&&&&&&&@W$$K]J^V\r\n_>!{z-L7Ji_HLYE={[$@@@$$$&=jA][b^^VJ=++v=l_`-Cu@@@&M@MM@@M@MM$M@VMMW@@@@#W&1   =\r\n   ~?LcY=sVcmggmmA6pk]Q#IVd$==]1scY[ {|){7i!=(q@@EE$@@M$@M&AMM#@@MMN$$$M&M@W  'v\r\n      {-L#MMPP%9PM@#&$MWW},`'rUWB|i#!)i_J|V|Vf%AM$MWG@WEg]jyy]{gg]YI?)l{A#@@e _`\r\n   `` !tl^    `  ` '?A@@#@Ewy'`^[=kEi}^ !^`v_ dQ=]jw###M@&$$$@$$@@M&mgp1}g]&#  +\r\n     ?         '  `    ^#$W$g&wa{8Vh=r_VJ,?_` ]i_g@@@@M@@@@W@#@@@#MM@@@@@@R (WRT\r\n'   `           `  '     ' ?@#d3^``e~,V(-`!  r`g&@M@F5``' `^^`ff@M@@@@@@@M_ a}i \r\n    _ ,       ``~  `   {`    ``,   ^_,i-+2 7)_pMF^ '   's_^ ```   '`>=EM&g[g[A  \r\n    _ j `>`'  {  icx_T^'|  VV]?/ `  gy`J*|gypPgp    ! ` '__        ,_w&&$$N@Mm  \r\n_     j ]>' _ ` T/|nr_'   '_*wj? `(`-'_g&&@@M#@$Nu!    `   '  `  ` !XW@@@$#bd$  \r\n    ,_=!tRL!>^  '~^~`    `~ v#&6^- xr@W@&@M@@$@M@hc  ^^    T=f3~-({GW$@@@@M@&M  \r\n'   ' M'j{>vL {  ]^R{(!  ,Lc]Age}Lv+^]I{$F}][L^jjRCn!x_ `i_wgW{y/=[@@$@M@@@@@$^ \r\n+  '   9[M0P{,,_V/dQL+rVi-wd$##$}yAn@'` _V>'^s')~^W@[c9yCnM&&$$QQ_J@@W@@@&$M#^  \r\n   !    3#aF]T~^/V4M&4[w{W&WMM5&$Vtt`   _t7=yL+VV]@W&73^i7E=p#]&]}b9#MM@MM$`    \r\n        gEPVCc>]=&M@Wg&Y^kV]@@{#{'``   )NwEe+#Vy]$R[^kk/zL9gwq#&&#U}&@@MN@@p   `\r\n        ~AR-`^}wlvBMVEL{+'/^V^jW=r`V` ' @M@EWMqWP^'=Mj{Vri}2g&NMhgmp@W$@$@M$ + `\r\n   `   ^ ^MJ__`}~_^)v~It>L' )'-|`  T`   W$W@W&*T`   sZ=m@csX8&NM@@&@#E@AW@@@p{_'\r\n    '     J{^i+`L`|iLXC _>|^_' >`      I@6BW@K j#&ELoll=mEILVM@M&&M%M@MMW@@@$ojL\r\n           'izzzv>!|_^(`}+J'YY`      '3X@MM@@FS@@WN@B_!{#e@E[ggg@@@&MM]#@@@@@B@g\r\n             !_=[j>_[z{p{o_^J=XS;/1__}&MgpWgpj#mgpp{GY  sQq#&wMW@@@B$N###@M@M@@@\r\n             `kW{AA[}@#tts |`31&]WwaW]AV$A@@M@M@@&@M@C   '=YWV[Q[F$G&a@@@@MM@@@@\r\n             'C|VC=)t>)^!  ~`^^3pIJ}Wg==}P[@$FEMA@V$wVT  !!1,>(||`s=@M#$@@@@@@@@\r\n          '&[ Y['(v^^ J` _``*J^dYVe]_={y$=@>=[L'wVI&Ae _{=NgZ(ccg##=WWMM@@@@#MWP\r\n     ' |]!@WR }u{cc!L '{>{|`7^ iJC}}JM+xY^Y9'`^_`YzYVA1{@X@@M==^IXe@W@@@M@@@@@l=\r\n  ,__wkV'L'#M_`JYC(i'C_Y+cj '` ``o]=!V^|-^jjxCr^(`M'T'&Aq#MW@bk@a$8$&@#@$@@R'i=]\r\nyWV=y??T)+!?XE`_')*c/|vJ^^    ^~s r+ri` /vtt ^`^-s(^(oVw]$#$dmB&$A8#q&M@#Wl+'-{A\r\n@$4=a])=VJ'L>>^+ '-C-ir{i__ >~>'`t`)r^>(i-J7_?~  ,i}z==VY=&]e49@#@@A&@@l^(^_?}^T\r\nWGiY/[kzt'=^r_` _   (}__ C  `  {`>rLx' ~=(n~`'Y'_r_Jc`,'(`wVC7^Y0M$VJ !'-x_^^Y +\r\n&J|-~vVr^'{ '|| >L       Ji`' _ l^ ^  i'''vT ' _~` ! ` ^~7W[V^ J__' i`|`7>>ju^C-\r\n=[`+T+! `'`_!{x_?+'`  L _J  ^i~iJ` `V~']=(sCY+>   '~ s(1]@-Ll'  _>`!| ` l, L^!VF\r\nL-~'| - 'Jt!!t-^`` t{J'^` `t`'c!C^`V'^ VkLL/r'   >''i]+' |';V'_-`Y^s!L{+ ,tTi{rr\r\nX2!^` {V(_?*/C~`|'Y ```>'~'`~`l'`{?|+7tVliiiJ{ - c   ^)' r  `-`'YV  Lit+{Tv+!!r_\r\n`})>i -S^==l[i-` Y~ i_~  o^?-!x'^Ltr*VL?S=)  ~7 V``' L `|` C`  ` _ `^!`i!vs)^)-r\r\n~_( ^`zzzL1|`Yv^`!! ~(`t+t!|l t`^ ov-+t~!Y^`   `,_``(!_ `'~ `` 'Y' |- ^^ s|F(`?k\r\n`_=V'?oL*v  `  ~ ?t`'_ ^)- V _|rJc{ L>)_^]v;{`|`> )`x  _  x_s= ' ' `- ``iT)s7i-r\r\nLL]iCinji  ^ ,`'- ``vX_C+l` -Yr>r2#&M-}=]?J={`|~    '' ''~ > `- ~{_`, `+''^!?,`X\r\nj-}vVL+ ^`_  !)v>_L(~r| ^'` vL`xc&@WM//o{Y_MM^'`T  -'' x''x _ C)!(^v` `_(i ` tJ!\r\n>c[/|`' ^ VL|J'+f|^VLL!)Yt^Vi'J-t@##jVVVJ?Vfl  '>   r`xV'J,`|` V>>ii`^- '_ `)^ '\r\n`~^_(!  c_JL(CiJ?xiTv`!s{^ L,`_Y $MKt_]]^~(V  +     g` `L ++ ! ?~ `(     JV>   _\r\n` T}=`{=- 7ut,^u^LL=iir_ i_`_Li' @8_f~[!{uS__ ```  #@& 7'TC_^o t_   *``'`{' >-  \r\n  Y)~:->vrx-YYtcoYJJx''?_)_tj^ viu{c3|/]-n`'' V'i  &]NC J>^_  ` ^!`/{` J' ^V `{?\r\n' tt-v{ lT !|+{-Lii )^L)`*oviYJJ-o{zY{{'L!>`V&&g _ @&Akv  V^)vYx!' `  ^`_ ` +L> \r\n   (lr=-r)J+u| x^i ?`_+`C;ni,vVVt7S|)/lT~|` dM@Mp UAN&E  s ~^i`_  i (_'' >   _ )\r\n   >x>t+__>~`r?`^~(`)  -`'+uLfcc{jj-}-|^(+=->Vs@@b@$&@*-`_ ``` `v` ^ -`(L- _`  {\r\n   V _]>r`~`  ! ``( ~(-lrTx{7{tVVLwgp{yvV|![|^=M@W&BmWW  Ci^``|   {|l^``' _V _ >\r\npp (gM@K`  `  '' t`'- {-t+zz_=iyb&@@M@MNF]?V'~%#@#@@M@&/^agpp ^ ` |'!i!  ''_~ C`\r\nNWagM$P   'v~rs's' !?==|^Sc[=LzA&@@#W@#@E1^=^ &$&A$M@&@$@M@@$`' ` ``_ |||)_```  \r\n&W@@$''LMMj^`si V>>zV=^jF=-^'cT#@@@@B@M##WVTJ&#@M@MgM&$@N@MM# c`   'x' !-''rrr '\r\n&&&A^ @&@$#P```i^?=7Vt^V*V===sy$&@M@M&@WM@^`VW@@M@@@@MgIb}ZW  > ' '   { '_  _ ^,\r\n@Me'  m#M@#A  _f=[k^_?V{JJ{`}8^@WN@@M#MM@n+tq@@W$$$M@@MM@W&^^    `{~  ~ _  C``'{\r\n#M ` {ZA@WW@c?=j=-{ifYV^rYV=)rFV@&Z#M#W$Lvs }M@@M@@@6$MMMM_ ^   ``''^   r` s''L(\r\n} `'' @MM@$@=_bvrt(^^i-}-_jt=-jz('FMM@{zJTs_?@P3@$#M@Bb7^` -`T  ``  ^)iJ_J >L^J;\r\nW  _`nB#@M#T_V+tSc{L >Vrr]+=|*jSi=L* oAr^bi  o]s_w3K@{@~`   '_ `  `^ '  ` ``|)~r\r\n^` r^x@Li=]{)!^>cVxJ>(V~t^J3i^=}!>[zr,7ztt{_ ^#XFwu9#]yj^  '   `l `7'   ~s !t`7^\r\nx ^kT` '{i{! jNT~>^-'-jb-{TTVr|!'*r-xcVt !  `))]W[_g9d&>` `     ``v`t|| ' _ 7tc+\r\n[  J/C`~{Yt!y+)`xJ))))J=L!ri)=V=LJn-i-^f7X7 _!r]@mMQ@@AAv    _` J'i`l't_{`i!_iCJ\r\nW^_Jk=v`|,LwT>_^rr||||VL3__=r=i^ _ Y'xtXj`^_ _-^Z#sMU&j2{   ^      J |'t7v 'i!n)\r\nzL''?^`_?YLr^ sr|TV-+?!'+|[Y]'CY]jY^?i+iuL> ^ --Tsja]kIgL,  `_  ~i` _ '- >`'-jLu\r\n!C `  `w3Y^ `~(-+--3~sJ71l^i^^L>|?{+^``L - ` ^ ^>7cmQdkzC  & '_`'`L' ```(?_' ~ll\r\nr r`+vvr~ xJ__==={f=Ls_L7iVr V?T3`l`-]'t|^_   ' Y`=u}l^ s  ]` -' ' `,|_i`t`t~,Lr\r\n   -+7  !_^+(----'VSVc>zzl?`L=~ioV'x`^)*>T`       x+>77'^ %$` !!^~'`  !x``'{`Y[-\r\n``V{  ` Vrr-)?///?VC~l?>zx|_st{-oJ!xf+>!{=r!         _ _  #$` !  `|  `J,`` `!`!~\r\n  L`+_Jvi7++^='r?+n^T?[c!_,S?{{iF~( !^FL~ 'Y   `      ' -NNMY !  {   >, _,` `i+[\r\nci   ` _`x_rr>_|'r>>`jY( (_kk|`{J)s_^L|V--+ ` ` -   !'>)kkMeT s^|T {>L C''^'!-~r\r\n\r\nSIDEVIEW Y:    Z  0 to 2    Y  -0.99983900113 to 1.0    T  0.0 to 7.0    MIN MAX\r\nl?*~_-----_>cC}lTl{7Tx_--------------------------------------------_+*Tll'*+_---\r\n|    T, ,r',*l      '_ ),                                        .(         `-_ \r\n|      a_ /           )_ \\_                                    ,*             ,(\r\n|    ,C ~C             `.  ,                                  )              )  \r\n|   )  >  \\              \\  \\                                /              /  (\r\n|  /  /    \\              '_ ^                              '             _^  ' \r\n| (  '      '_             `_ )                            '              ' ,'  \r\n|r _'                       `c '_                        ,'             ,' ,    \r\n(  '           _              c `                       ,              ,' ,     \r\n| '            `c              c `_                    ,              ,  .      \r\n|'              `c              _ `                   ,              ,' +       \r\n ----------------`---------------L-`-------------- --.--------------,'-+--------\r\n|                  _              c `_              .              ,' +         \r\n|                   _             `C `             .              ,' +          \r\n|                                      c          .              .  ,           \r\n|                    `C              ,  c        ,              ,  )            \r\n|                      ,              . ?c      )              )  /             \r\n|                       x              t  .    /              <  /              \r\n|                        \\              \\  \\  (              / _*               \r\n|                         '_             '_ ;C             ,' ,'                \r\n|                           x             (%) x           x _x                  \r\n|                            '<         _>' ?x_'C       >'_r'                   \r\n|------------------------------`*<____>r------`*<{jy_yj1+*'---------------------\r\n                                                                                \r\nTOPVIEW Z:  Z  0.0 to 0.25  (top to bottom)  Y  -0.9999 to 0.9999  T  0.0 to 7.0\r\n DOGKz1(7Lx\\:,-'`   `._~>r?;tfVne6H MQpZaV}oTY?+(,!'` `'-_>+|/Cc[]KPRg  8REnVSt7\r\n DOGKX3(7/vi:_-`    `-_~iv/YcS{aZqm &8qI4yzts7r~i'-`  `-'i~r7stjy4Iq8& dqEa{jtYL\r\n DAG5X3cY/vi~_.`   `'-,:|xJT=3y4U9  Wm0EXnFTY?\\(_!.` `'!,:\\l^)Fn3U9mN m%Za{j=Y?x\r\n DAZ5{jcY?r>~_.`   `''!(+lsCf}neR8 $gRI4yz=slx*i'.' `'-_(+rYT2[]GO6D D9U5X3=T?r*\r\n DAZa{jt;?r>!'.`   `._~i|/YcoV5GOd BH9GXnF)Y?\\:_-'` `.!i~vLstj{3PhbN HqE][fCsx*i\r\n DAZa{jt;l|(!'.`   `._~irL7=j{4U9 @D6OK][oT7r*>'.' `'-_(\\|Y)FnXGqd# bAZa[ft;l+(~\r\n mqEaVoCsl|(,-'    '.,:\\vJ)2}yeR8 &bhP3{jts?\\:,-'` `.'i*r7Jo[VawmW  OG5XSc;?r>!_\r\n mqEnVoCs^+:,-'   `'-!(+^;tSkuGOd WmAeV[oTYr*>'.` `'!,(vL^)fy4PhQ  8U4z1cY?ri!'.\r\n mqEnkS)Jx*:_-'   `'-~>|l7(j{50h  gRZK{jtsl\\:,!'` '-'>*|YT2k3U9H  Hqwy}27/v\\:'.'\r\n mqeukS)Lx*~_.`   `.'~|r/)F1ywqH $d9U3}2TY|*>'-` `.!,:v7J=zXGO6W dOZu[fCLv\\:,.``\r\n mqeu[fTLv\\~'.`   `._:*xLtfkueOm #%0EVfcslx:,!'` `-_(+|^)S{KZRg  9IKVSt;x*(,-`  \r\n mReu[fT/v\\!'.`   '-_(+^sco{5Gh @DhP5uF(Y?\\>'-' `'!,:vLJ=z]eAHB Hqeu1FTL|i~'.`  \r\n mRe][27/ri!''`  `'-,>|l;=3z4U8 $89e1noC/r*i!.` `._(+|Ytj{5w%D  OZaV2)Jxi~_.`   \r\n mRP]}27?ri!-'`  `''!ir?72}]PRd #H0a]zt^Lv:_-' `'!i~x7J2}Xeh8  8UKXjts^+:_.`   `\r\n dRP]}FY?|>,-'   `.'!\\vLTSknZA  D%I5{ST/|*>!.` `.'(\\?;)zyawH# dAPy1FYl|>,-'    '\r\n d6Py1F;l|>,-'   `._~*xJCjXKI9 $8hGX}oslv:,-' `'!,*r/Cok3IhD  9InkfC/ri~-'`   '-\r\n d6wy1=;l+(_.`   `-_:+l;c1yw68 #HAKyftY|+>_.` `.'>\\L^tjVGOm  86w{oc;x\\:_.`   `._\r\n d6wz3=s^+(_.`   '-,(r?7=[uEA  DRZ3kF(7x~i!'` '!,:r/T2n4ZRQ dAEu3=7?+(,-`   `'_~\r\n d6wz3(s^*(_.`  `''!>vLT2V5G% $8qUV[=J?\\(_-` `.'>*?^tjuGAH# p04zSCJxi~'.`   '-~i\r\n d6wz3(sx*:'.`  `''!ixJ)fXKUh NdAGyft^|*>'.` `-,:v/C2n1ZRQ  qe]}(Yl+:_.`   `._(+\r\n d04XjcJx\\:''`  `.'~\\^stoywRH W6wKkFTYx:,!' `''>*|^tfya9b& 9GaVST/ri,-'   `.'~*x\r\n d04XjcJv\\~-'`  `._:*lY(3uEAm gpI3[=Jl+(_-` `.,:vlT2n3I6W m6wzj(Jx\\:''`  `''!>vL\r\n d04XocLv\\~-'   `-,(+/7F}aG9 @d9GVj);?~i!.` '-i~r/)jyK0d& 8Gakf)?|>!.`   '-,(+/T\r\n\r\nAUTHOR:\r\n  kai zhu\r\n  kaizhu256@gmail.com\r\n\r\nREQUIREMENTS:\r\n  posix os\r\n  Python 2.6\r\n  Python Imaging Library  http://www.pythonware.com/products/pil\r\n  numpy                   http://www.scipy.org/Download\r\n\r\nINSTALL:\r\n  python setup.py build\r\n  python setup.py install\r\n  python setup.py dev --quicktest\r\n\r\nUSAGE:\r\n  $ python setup.py dev --quicktest\r\n    render color image in shell terminal &\r\n    plot scientific functions as well\r\n\r\n\r\n\r\n  >>> from asciiporn import *\r\n\r\n  >>> print( img2txt(\"filename\") )\r\n    display color image from gif, jpg, bmp, ... to screen.\r\n    only works if u have Python Imaging Library installed\r\n\r\n  >>> help(img2txt.load)\r\n    display img2txt options\r\n\r\n\r\n\r\n  >>> plot(ft = lambda t: cos(t), tmin = 0, tmax = 16)\r\n    plot cos(t) for t = [0, 16]\r\n\r\n  >>> plot(ft = [cos, sin], tmin = 0, tmax = 16)\r\n    plot 2 functions, cos & sin\r\n\r\n  >>> plot( y = [1.5, 2.5, 3.5], t = [0, 1, 2] )\r\n    plot datapoints (y, t) = (1.5, 0), (2.5, 1), (3.5, 2)\r\n\r\n  >>> f = lambda t, z: sin( t*(2*pi + z) ) * (0.5 + z) - z\r\n  >>> plot3d(ftz = ftz, tmin = 0, tmax = 16, zmin = 0, zmax = 1)\r\n    plot f in 3d using specified ranges for t & z\r\n\r\n  >>> help(plot.__call__)\r\n  >>> help(dataZYT.__new__)\r\n    display plot options\r\n\r\n\r\n\r\n  >>> fitpoly2d.test()\r\n    test asciiporn's polynomial fitting routine\r\n    peruse fitpoly.test in asciiporn/main.py for usage\r\n\r\n  >>> fft2d.test()\r\n    test asciiporn's cosine fitting routine\r\n    peruse fft2d.test in asciiporn/main.py for usage\r\n\r\n################################################################################\r\nRECENT CHANGELOG:\r\n20090407\r\n  fixed installation bugs\r\n  added retro-gif feature\r\n20090328\r\n  removed py3to2 requirement\r\n  update documentation\r\n20090103\r\n  rewrote 3d plotter\r\n  fixed more 64bit issues\r\n20081123\r\n  fixed bug where 64bit gets truncated to 32 on 32bit machine\r\n  256 color support\r\n20081119\r\n  fixed bugs in setup.py"}}, {"pk": 169, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gpustats", "license": "BSD", "author": "Wes McKinney", "author_email": "wesmckinn@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "https://github.com/dukestats/gpustats", "version": "0.0.1", "platform": "any", "keywords": null, "summary": "GPU-based statistical functions", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "gpustats is a PyCUDA-based library implementing functionality similar to that\npresent in scipy.stats. It implements a simple framework for specifying new CUDA\nkernels and extending existing ones. Here is a (partial) list of target\nfunctionality:\n\n* Probability density functions (pdfs). These are intended to speed up\n  likelihood calculations in particular in Bayesian inference applications, such\n  as in PyMC\n\n* Random variable generation using CURAND\n\nNotes\n-----\nRequires working PyCUDA installation"}}, {"pk": 170, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pysdif", "license": "UNKNOWN", "author": "UNKNOWN", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/gesellkammer/pysdif", "version": "0.1.0", "platform": "Linux,Mac OS X", "keywords": "scientific computing,music,sound analysis,SDIF,IRCAM", "summary": "SDIF for python", "classifiers": "Development Status :: 2 - Pre-Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Cython\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nTopic :: Multimedia\nTopic :: Multimedia :: Sound/Audio\nTopic :: Multimedia :: Sound/Audio :: Analysis\nTopic :: Multimedia :: Sound/Audio :: Sound Synthesis\nTopic :: Multimedia :: Sound/Audio :: Speech\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "It allows to read and write any kind of SDIF file, to define new\nkinds of frames and matrices and to read and write metadata. \n\nThe matrices read from a sdif file are exposed as numpy arrays.\n\nIt exposes both a low level and a high level interface.\n\nThe low level interface for reading and writing sdif files mirrors the \nsdif library quite transparently so that the example files and \nutilities using it can be directly translated with it. In particular\nit does not create any intermediate objects, even the data of the matrices\nis a numpy array mapped to the c array read from disk, so no allocation takes\nplace. Whereas this makes for very fast code, one has to take care to copy the\ndata if it will be used longer, since by the time a new matrix is read this\ndata is no longer valid. \n\nto read for ex. 1TRC format:\n\nimport pysdif\n\nsdif_file = pysdif.SdifFile('filename.sdif')\nsig1TRC = pysdif.str2signature(\"1TRC\")\nwhile not sdif_file.eof:\n    sdif_file.read_frame_header()\n    if sdif_file.frame_numerical_signature) == sig1TRC:\n        print sdif_file.time\n        for n in range(sdif_file.matrices_in_frame):\n            sdif_file.read_matrix_header()\n            if sdif_file.matrix_numerical_signature == sig1TRC:\n                data = sdif_file.get_matrix_data() \n                # data is now a numpy array but you must copy the data if \n                # you intend to keep it after you have read the matrix.\n                # One you read a new matrix, this data will be no longer valid\n                print data\n    \na more natural way:\n\nfrom pysdif import SdifFile\nsdif_file = SdifFile('filename.sdif')\nfor frame in sdif_file:\n    if frame.signature == \"1TRC\":\n        print frame.time\n        for matrix in frame:\n            if matrix.signature == \"1TRC\":\n                print matrix.get_data()\n                \nthe frames and the matrices resulting from the iteration\nare only guaranteed to be valid as long as no new frames and matrices are read\n\nto write a SdifFile:\n\nf = SdifFile('new_sdif.sdif', 'w')\n# these are optional\n#   add some metadata\nf.add_NVT({\n    'name' : 'my name',\n    'date' : time.asctime(time.localtime())\n})\n# define new frame and matrix types\nf.add_frame_type('1NEW', '1ABC NewMatrix, 1FQ0 New1FQ0')\nf.add_matrix_type('1ABC', 'Column1, Column2')\n# now you can begin adding frames\nframe = f.new_frame('1NEW', time_now)\nframe.add_matrix('1ABC', array([\n    [0,     1.2],\n    [3.5,   8.13],\n    ...\n    ]))\nframe.write()\n\n# say we just want to take the data from an existing\n# sdiffile, modify it and write it back\nin_sdif = SdifFile(\"existing-file.sdif\")\nout_sdif = SdifFile(\"outfile.sdif\", \"w\")\nout_sdif.clone_definitions(in_sdif)\nfor in_frame in in_sdif:\n    if in_frame.signature == \"1NEW\":\n        new_frame = out_sdif.new_frame(\"1NEW\", in_frame.time)\n        in_data = in_frame.get_matrix_data() # we know there is only one matrix\n        # multiply the second column by 0.5\n        in_data[:,1] *= 0.5\n        new_frame.add_matrix('1ABC', in_data)\n        new_frame.write()\n\nthere are also many utility functions under pysdif.sdiftools\n\nsee release notes and changes at http://github.com/gesellkammer/pysdif"}}, {"pk": 171, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "graph", "license": "modified Python", "author": "Robert Dick and Kosta Gaitanis", "author_email": "dickrp@eecs.umich.edu and gaitanis@tele.ucl.ac.be", "project_url": null, "maintainer_email": null, "home_page": "http://robertdick.org/python/mods.html", "version": "0.4", "platform": "UNKNOWN", "keywords": null, "summary": "Directed and undirected graph data structures and algorithms.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python Software Foundation License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "Directed and undirected graph data structures and algorithms.\n\nCopyright 2005, Robert Dick (dickrp@eecs.umich.edu).  Numerous bug fixes\nand improvements from Kosta Gaitanis (gaitanis@tele.ucl.ac.be).  Please see the\nlicense file for legal information."}}, {"pk": 172, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.plugins.neos", "license": "BSD", "author": "William Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "http://coopr-forum.googlecode.com/svn/neos", "version": "1.0", "platform": "any", "keywords": "optimization", "summary": "Coopr NEOS Plugins", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Plugins for NEOS solvers and the NEOS solver manager."}}, {"pk": 173, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pytrap", "license": "This software can be used under one of the following two licenses: (1) The BSD license. (2) Any other license, as long as it is obtained from the original author.", "author": "Alexandre Vallette", "author_email": "vallettea@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/pytrap/", "version": "1.0", "platform": "UNKNOWN", "keywords": "physics,electrostatics,trap", "summary": "Utilities for physicists using the  Electrostatic Ion Beam Trap", "classifiers": "Development Status :: 2 - Pre-Alpha\nIntended Audience :: Education\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Utilities", "description": "====================================\nWelcome to the PyTrap package\n====================================\n\nThis package is destined to physicists using or studying the\n(`Electron Ion Beam Trap <http://pra.aps.org/abstract/PRA/v55/i3/pR1577_1>`_).\nThe main features are:\n   - a fast (analytic) calculation of the **potential inside the trap** depending on the set of potentials\n   - a **stability map** indicating which potentials lead to stable trapping\n   - trajectories simulations.\nMost of the proofs can be found in this `article`_.\n\nExamples are the best way to dive into PyTrap."}}, {"pk": 174, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pywcs", "license": "BSD", "author": "Michael Droettboom", "author_email": "mdroe@stsci.edu", "project_url": null, "maintainer_email": "", "home_page": "http://projects.scipy.org/astropy/astrolib/wiki/WikiStart", "version": "1.10-4.7", "platform": "unix,windows", "keywords": "astronomy", "summary": "Python wrappers to WCSLIB", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: MacOS X\nEnvironment :: Win32 (MS Windows)\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows :: Windows 95/98/2000\nOperating System :: Microsoft :: Windows :: Windows NT/2000\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Astronomy", "description": ""}}, {"pk": 175, "model": "importing.pypicache", "fields": {"maintainer": "Hugo Liu", "name": "MontyLingua", "license": "GPL", "author": "Hugo Liu", "author_email": "hugo@media.mit.edu", "project_url": null, "maintainer_email": "hugo@media.mit.edu", "home_page": "http://web.media.mit.edu/~hugo", "version": "2.1", "platform": "All", "keywords": "part-of-speech tagging; part-of-speech tagger, nlp, parser, natural language processing, natural language processor, pos tagger", "summary": "A Free, Commonsense-Enriched Natural Language Understander for English", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing", "description": "MontyLingua is a free*, commonsense-enriched, end-to-end natural language\r\nunderstander for English. Feed raw English text into MontyLingua, and the output\r\nwill be a semantic interpretation of that text. Perfect for information\r\nretrieval and extraction, request processing, and question answering. From\r\nEnglish sentences, it extracts subject/verb/object tuples, extracts adjectives,\r\nnoun phrases and verb phrases, and extracts people's names, places, events,\r\ndates and times, and other semantic information. MontyLingua makes traditionally\r\ndifficult language processing tasks trivial!\r\n\r\nVersion 2.1 is substantially FASTER, MORE ACCURATE, and MORE RELIABLE than\r\nversion 1.3.1. It has now been tested across Windows, many flavors of UNIX, and\r\nMac OS X, and several flavors of Java, and is in use by several university\r\nresearch projects and under several commercial settings.\r\n\r\nMontyLingua differs from other natural language processing tools because:\r\n\r\n    * it is complete end-to-end.. input raw_text; output semantic interpretation\r\n    * not many dated tools and implementations sewn together; it is one\r\nwell-integrated implementation\r\n    * it does not require \"training\" and other fidgetting, and will work right\r\nout-of-the-box\r\n    * it is enriched with \"common sense\" knowledge about the everyday world,\r\nallowing it to escape many stupid interpretive mistakes. e.g.:\r\n          o \"(NX the/DT mosquito/NN bit/NN NX) (NX the/DT boy/NN NX)\" ==corrected==>\r\n          o \"(NX the/DT mosquito/NN NX) (VX bit/VBD VX) (NX the/DT boy/NN NX)\"\r\n    * it is lightweight and portable across platforms, written in portable\r\nPython and also available as a compiled Java library\r\n    * it is easy to customize by allowing for a user lexicon\r\n\r\nMontyLingua performs the following tasks over text:\r\n\r\n   1. MontyTokenizer - Tokenizes raw English text (sensitive to abbreviations),\r\nand resolve contractions, e.g. \"you're\" ==> \"you are\"\r\n   2. MontyTagger - Part-of-speech tagging based on Brill94, enriched with\r\ncommon sense.\r\n   3. MontyChunker - Lightning fast regular expression chunker\r\n   4. MontyExtractor - Extracts phrases and subject/verb/object triplets from\r\nsentences\r\n   5. MontyLemmatiser - Strips inflectional morphology, i.e. changes verbs to\r\ninfinitive form and nouns to singular form\r\n   6. MontyNLGenerator - Uses MontyLingua's concise predicate-arg representation\r\nto generate naturalistic English sentences and text summaries"}}, {"pk": 176, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "arboris", "license": "LGPL", "author": "S\u00e9bastien BARTH\u00c9LEMY", "author_email": "barthelemy@crans.org", "project_url": null, "maintainer_email": null, "home_page": "http://chronos.isir.upmc.fr/~barthelemy/arboris", "version": "0.1.0pre7", "platform": "UNKNOWN", "keywords": null, "summary": "A rigid body dynamics and contacts simulator written in python.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Physics", "description": "Arboris is a rigid body dynamics and contacts simulator written in python.\n\nArboris includes a generic and easily extensible set of joints \n(singularity-free multi-dof joints, non-honolomic joints, etc.) which are\nused to model open rigid mechanisms with a minimal set of state variables. \n\nThe dynamics of these systems are computed in a form similar to the \nBoltzmann-Hamel equations.\n\nUsing time-stepping and a semi-implicit Euler integration scheme, a first-order\napproximation of the model is also computed. This allows for additional \nconstraints such as contacts and kinematic loops to be solved using a \nGauss-Seidel algorithm.\n\nArboris is mostly useful for robotic applications and human motion studies. \nThe python language makes it particularly suited for fast-paced development\n(prototyping) and education.\n\n\nBackground\n==========\n\nIn 2005, Alain Micaelli, a researcher from CEA LIST, wrote a first version of\nthe simulator in the matlab language. It was an implementation (and often an\nextension) of the algorithms described in [Park2005]_, [Murray1994]_ and\n[Liu2003]_.\nHe was later joined by S\u00e9bastien Barth\u00e9lemy, from ISIR/UPMC, who reorganized\nthe code to take advantage of the early object-oriented features of matlab.\nIt eventually became clear that the language was ill-designed, and that a full\nrewrite was necessary. With the help of Joseph Salini, also from ISIR/UPMC,\nArboris-python was born. The resulting framework is now quite similar to what\nis presented in [Duindam2006]_.\n\nThe matlab version of the simulator is now deprecated.\n\n.. [Murray1994]\n    Richard M. Murray, Zexiang Li and S. Shankar Sastry,\n    \"A  Mathematical Introduction to Robotic Manipulation\",\n    CRC Press, 1994.\n\n.. [Park2005]\n    Jonghoon Park,\n    \"Principle of Dynamical Balance for Multibody Systems\",\n    Multibody System Dynamics, vol. 14, number 3-4, pp. 269-299, 2005.\n\n.. [Liu2003]\n    T. Liu and M. Y. Wang, \n    \"Computation of three dimensional rigid body dynamics of\n    multiple contacts using time-stepping and Gauss-Seidel\n    method\",\n    IEEE Transaction on Automation Science and Engineering, \n    submitted, November 2003.\n\n.. [Duindam2006] \n    V. Duindam, \n    \"Port-Based Modelling and Control for  Efficent Bipedal Walking Robots\",\n    University of Twente, 2006."}}, {"pk": 177, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "CocoPy", "license": "GPL", "author": "Ron Longo", "author_email": "ron.longo@cox.net", "project_url": null, "maintainer_email": null, "home_page": "http://www.ssw.uni-linz.ac.at/coco", "version": "1.1.0rc", "platform": "UNKNOWN", "keywords": null, "summary": "Python implementation of the famous CoCo/R LL(k) compiler generator.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Compilers\nTopic :: Software Development :: Interpreters\nTopic :: Software Development :: Pre-processors\nTopic :: System :: Shells\nTopic :: Text Processing :: General\nTopic :: Text Processing :: Linguistic", "description": "UNKNOWN"}}, {"pk": 178, "model": "importing.pypicache", "fields": {"maintainer": "Dave Brown", "name": "PyNIO", "license": "Free but restricted, see http://www.pyngl.ucar.edu/license.shtml", "author": "Dave Brown", "author_email": "dbrown@ucar.edu", "project_url": null, "maintainer_email": "dbrown@ucar.edu", "home_page": "http://www.pyngl.ucar.edu/Nio.shtml", "version": "1.0", "platform": "MacOSX (Intel and PPC)\r\n32-bit and 64-bit (x86_64) Linux\r\nSGI/IRIX64\r\nSolaris 9", "keywords": "netCDF, GRIB, HDF, scientific data formats", "summary": "PyNIO allows read and/or write access to a variety of scientific data formats.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: MacOS X\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: Free To Use But Restricted\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: IRIX\nOperating System :: POSIX :: Linux\nOperating System :: POSIX :: SunOS/Solaris\nOperating System :: Unix\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Atmospheric Science", "description": "PyNIO is a Python package that allows read and/or write access to a variety of\r\nscientific data formats \r\nusing an interface modelled on netCDF."}}, {"pk": 179, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "Micro-Manager", "license": "LGPL/BSD", "author": "University of California at San Francisco", "author_email": "", "project_url": null, "maintainer_email": "", "home_page": "http://micro-manager.org", "version": "1.3.41", "platform": "", "keywords": "\u03bcManager, Micro-Manager, Micromanager, Microscopy, Microscope, Camera, Filter, Illuminator, Laser, Objective, Stage, ABS, Andor, AOTF, Arduino, ASI, Cobolt, Coherent, Conix, CoolLed, dc1394, Diagnostic-SPOT, FireWire, Hamamatsu, Lambda, Leica, Ludl, Mad-City, Marzhauser, Nikon, Olympus, Pecon, Photometrics, Physik Instrumente, PrecisExcite, Prior, PVCAM, QImaging, Roper, Sensicam, Spectral, Sutter, Thorlabs, TWAIN, Uniblitz, Velleman, Vincent, Yokogawa, Zeiss", "summary": "Microscope hardware control", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: MacOS X\nEnvironment :: Win32 (MS Windows)\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nProgramming Language :: C++\nProgramming Language :: Java\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Human Machine Interfaces", "description": "\u03bcManager is an Open Source software package for imaging and control of automated\r\nmicroscopes on multiple platforms (Windows, Mac and Linux). Together with\r\nImageJ, a popular image processing package, \u03bcManager provides a comprehensive\r\nimaging solution \u2013 comparable to commercially available ones.\r\n\r\nA python wrapper is provided that allows complete access to the\r\nMicro-Manager core hardware control system. A large number of motorized\r\nmicroscopes, cameras, stages, and accessories can be easily controlled from\r\npython scripts or the python command line.\r\n\r\nSee\r\nhttps://valelab.ucsf.edu/~nico/MMwiki/index.php/Using_the_Micro-Manager_python_library\r\nfor instructions on using python with Micro-Manager."}}, {"pk": 180, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "skidmarks", "license": "MIT", "author": "brentp", "author_email": "bpederse@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/brentp/biostuff/", "version": "0.0.3", "platform": "UNKNOWN", "keywords": "bioinformatics sequence randomness test", "summary": "find runs (non-randomness) in sequences", "classifiers": "Topic :: Scientific/Engineering :: Bio-Informatics", "description": "Skid Marks: Check for runs in sequences\n----------------------------------------\n\n  Q: how do you check for runs?\n\n  A: look for skidmarks.\n\nThis module implements some functions to check a sequence for randomness.\nin some cases, it is assumed to be a binary sequence (not only 1's and 0's\nbut containing only 2 distinct values).\nAny feedback, improvements, additions are welcomed.\n\n    >>> from skidmarks import gap_test, wald_wolfowitz, auto_correlation, serial_test\n\n\nWald-Wolfowitz\n---------------\n\nhttp://en.wikipedia.org/wiki/Wald-Wolfowitz_runs_test\n\nhttp://support.sas.com/kb/33/092.html\n\n    >>> r = wald_wolfowitz('1000001')\n    >>> r['n_runs'] # should be 3, because 1, 0, 1\n    3\n\n    >>> r['p'] < 0.05 # not < 0.05 evidence to reject Ho of random sequence\n    False\n\n# this should show significance for non-randomness\n    >>> li = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n    >>> wald_wolfowitz(li)['p'] < 0.05\n    True\n\n\n\nAutocorrelation\n----------------\n\n    >>> result = auto_correlation('00000001111111111100000000')\n    >>> result['p'] < 0.05\n    True\n\n    >>> result['auto_correlation']\n    0.83766233766233755\n\n\nSerial Test\n------------\n\nhttp://books.google.com/books?id=EIbxfCGfzgcC&lpg=PA141&ots=o-8ymmqbs9&pg=PA142#v=onepage&q=&f=false\n\n    >>> serial_test('101010101111000')\n    {'chi': 1.4285714285714286, 'p': 0.69885130769248427}\n\n    >>> serial_test('110000000000000111111111111')\n    {'chi': 18.615384615384617, 'p': 0.00032831021826061683}\n\n\nGap Test\n---------\n\nhttp://books.google.com/books?id=EIbxfCGfzgcC&lpg=PA141&ots=o-8ymmqbs9&pg=PA142#v=onepage&q=&f=false\n\n    >>> gap_test('100020001200000')\n    {'chi': 756406.99909855379, 'item': '1', 'p': 0.0}\n\n    >>> gap_test('101010111101000')\n    {'chi': 11.684911193438811, 'item': '1', 'p': 0.23166089118674466}\n\ngap_test() will default to looking for gaps between the first value in\nthe sequence (in this case '1') and each later occurrence. use the `item`\nkwarg to specify another value.\n\n    >>> gap_test('101010111101000', item='0')\n    {'chi': 11.028667632612191, 'item': '0', 'p': 0.27374903509732523}"}}, {"pk": 181, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Nikweb", "license": "UNKNOWN", "author": "Robert Coup", "author_email": "robert@coup.net.nz", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/mapnik-utils/", "version": "0.1.0", "platform": "UNKNOWN", "keywords": "mapnik,gis,geospatial,webob,django", "summary": "A GeoJSON web service for Mapnik", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Django\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Scientific/Engineering :: GIS\nTopic :: Utilities", "description": "Submit GeoJSON feature data via HTTP request, and receive your Mapnik map rendered with the feature data in the appropriate places."}}, {"pk": 182, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Studio", "license": "GPLv3", "author": "Camptocamp", "author_email": "studio-discuss@googlegroups.com", "project_url": null, "maintainer_email": null, "home_page": "http://camptocamp.github.com/Studio/", "version": "0.5.1", "platform": "UNKNOWN", "keywords": "GIS management mapserver", "summary": "Web-based administration interface for MapServer", "classifiers": "Development Status :: 4 - Beta\nFramework :: Pylons\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering :: GIS", "description": "Studio is an administration tool for `MapServer <http://mapserver.org>`_.  It\nallows to manage MapServer mapfiles, using an easy-to-use web interface.\n\nStudio provides graphical tools, such as sliders and color pickers, for\nediting styles and symbols. It also provides a tool for automatic\nclassification, and allows saving layers as templates for reuse.\n\nStudio is based on modern frameworks and libraries, including, but not limited\nto, `Pylons <http://pylonshq.com>`_, `SQLAlchemy <http://www.sqlalchemy.org>`_,\n`OGRGDAL <http://gdal.org>`_, `OpenLayers <http://www.openlayers.org>`_, and\n`GeoExt <http://www.geoext.org>`_.\n\nStudio is covered by the GPLv3 open-source license.\n\nSee the Studio documentation at http://camptocamp.github.com/Studio/."}}, {"pk": 183, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyFFTW3", "license": "GPL v3", "author": "Jochen Schroeder", "author_email": "cycomanic@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "www.launchpad.net/pyfftw", "version": "0.2.1", "platform": "any", "keywords": null, "summary": "PyFFTW: Python bindings to the FFTW3 C-library", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "PyFFTW provieds Python bindings to the FFTW3  \"Fastest Fourier Transform in \n        the West.\" C-library(http://www.fftw.org/) for computing discrete Fourier \n        transforms. It uses numpy and ctypes and includes a somewhat pythonic interface\n        to the FFTW routines, but leaves the concept of creating plans and executing \n        these plans intact."}}, {"pk": 184, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyPSO", "license": "GPL", "author": "Damian Swistowski", "author_email": "dswistowski@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "0.9.3", "platform": "Many", "keywords": "Particle Swarm Optimalization PSO", "summary": "Implementation of Particle Swarm Optimalizator in python.       Toolkit with bunch of usefull tools.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: X11 Applications\nEnvironment :: X11 Applications :: GTK\nIntended Audience :: Education\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: Polish\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence", "description": "Implementation of Particle Swarm Optimalizator in python. Toolkit with bunch of usefull tools."}}, {"pk": 185, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PyTango", "license": "LGPL", "author": "Tiago Coutinho", "author_email": "tcoutinho@cells.es", "project_url": null, "maintainer_email": "", "home_page": "http://packages.python.org/PyTango", "version": "7.1.2", "platform": "Linux,Windows XP/2000/NT,Windows 95/98/ME", "keywords": "Tango,CORBA,binding", "summary": "A python binding for the Tango control system", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Other Environment\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "This module implements the Python Tango Device API mapping"}}, {"pk": 186, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Aptus", "license": "MIT", "author": "Ned Batchelder", "author_email": "ned@nedbatchelder.com", "project_url": null, "maintainer_email": null, "home_page": "http://nedbatchelder.com/code/aptus", "version": "2.0", "platform": "UNKNOWN", "keywords": null, "summary": "Aptus: A Mandelbrot set explorer and renderer.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: MacOS X\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications :: GTK\nLicense :: OSI Approved :: MIT License\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Artistic Software\nTopic :: Scientific/Engineering :: Mathematics", "description": "Aptus is a Mandelbrot set explorer and renderer with a wxPython GUI and\na computation extension in C for speed."}}, {"pk": 187, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "copads", "license": "GNU Lesser General Public License version 3", "author": "Maurice HT Ling", "author_email": "mauriceling@acm.org", "project_url": null, "maintainer_email": "", "home_page": "http://copads.sourceforge.net", "version": "0.3", "platform": "UNKNOWN", "keywords": "", "summary": "Collection of Python Algorithms and Data Structures", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Collection of Python Algorithms and Data Structures"}}, {"pk": 188, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "sempy", "license": "GPL", "author": "Stian Jensen", "author_email": "stianjnsn@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.sempy.org", "version": "0.0.18", "platform": "UNKNOWN", "keywords": null, "summary": "A Python implementation of the spectral element method", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Fortran\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics", "description": "Sempy\n**********\n\n*Note: This software is in a pre-alpha state.*\n\nThe main documentation for this package is located at \n`www.sempy.org <http://www.sempy.org>`_ , but this page offers a \nminimal set of information to get started using Sempy.\n\n\nAbout\n======\n\nSempy is a numerical software package designed to solve partial differential \nequations arising from the analysis of fluid flow and heat transfer.\nIt is written in Python and carries the intuitive syntax of this language. \nFurthermore, computational meshes can be imported from the Gmsh mesh generator, \nmaking Sempy flexible towards handling complex geometries. \n\n\n\nGetting started\n----------------\n\nThe quickest way to get started using the Sempy package is to install it \nwith  \n`easy_install <http://peak.telecommunity.com/DevCenter/EasyInstall/>`_\nThis can be achieved by e.g. typing::  \n\n   $ easy_install sempy\n\non the command line. This requires an internet connection to work. Another \npossibility is to download the latest version as a \n`zip <https://bitbucket.org/stianjnsn/sempy/get/tip.zip>`_ or\n`tar.gz <https://bitbucket.org/stianjnsn/sempy/get/tip.tar.gz>`_\nfile and then install it with::\n\n   $ python setup.py install\n\nIt might be necessary to use super user privileges on the above \ncommands. For instance::\n\n   $ sudo easy_install sempy\n\nAslo, it might be necessary to run:: \n\n  $ sudo easy_install --upgrade sempy\n  \non a regular basis to obtain updated versions. \n\nAn example script\n------------------\n\nSolve the Poisson problem with a simple script::\n   \n      import sempy\n     \n      X = sempy.Space( filename = 'square', n = 4, dim = 2 )\n      A = sempy.operators.Laplacian( X ).matrix\n    \n      f = sempy.Function( X, basis_coeff = 1.0 )\n      b = sempy.operators.Mass( X ).action_local( f.basis_coeff )\n      u = sempy.Function( X, basis_coeff = 0.0 )\n    \n      [v, flag] = sempy.linsolvers.Krylov().solve( A, b, u.glob() )\n      u.basis_coeff = X.mapping_q( v )\n      u.plot_wire()"}}, {"pk": 189, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "SpaceFuncs", "license": "new BSD", "author": "('Dmitrey Kroshko',)", "author_email": "dmitrey-at-openopt-dot-org", "project_url": null, "maintainer_email": null, "home_page": "http://openopt.org", "version": "0.33", "platform": "UNKNOWN", "keywords": null, "summary": "A python module for 2D, 3D, ND space objects modelling and optimization", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": ""}}, {"pk": 190, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.bootstrap", "license": "BSD", "author": "Constantine Evans", "author_email": "cevans@evanslabs.org", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/cevans/bootstrap", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Bootstrap Error-Estimation Scikit", "classifiers": "Development Status :: 1 - Planning\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": "Bootstrapping Error-Estimation Scikit for Numpy/Scipy."}}, {"pk": 191, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "goby", "license": "GNU General Public License (GPL)", "author": "Campagne Lab", "author_email": "icb@med.cornell.edu", "project_url": null, "maintainer_email": null, "home_page": "http://goby.campagnelab.org/", "version": "1.9.4", "platform": "UNKNOWN", "keywords": null, "summary": "Python API for reading binary data files created with the Goby next-gen data management framework.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "This directory contains the Python API for reading binary data files\ncreated using the Goby next-gen data management framework.\n\nNormally, this directory comes as part of the complete Goby package,\navailable from:\n\n  http://goby.campagnelab.org/\n\nThe complete package includes the Java source code.  If you downloaded\nthis package from PyPI or some other Python-specific source, you may\nhave received only the Python part of the code.\n\nDevelopment Warning\n===================\n\nThe Goby Python libraries are not as mature as the Java\nimplementation.  It may be more buggy and is not intended to provide\nthe complete set of features that are found in the Java version.\n\nInstallation\n============\n\n1) Make sure you have Python 2.5 or newer.  If in doubt, run:\n\n     $ python -V\n\n2) Download and install the prerequisite python packages:\n\na) Protocol Buffers\n\n   Available from http://code.google.com/p/protobuf/ or PyPI\n\nb) pyjavaproperties - Python replacement for java.util.Properties\n\n   Available from http://pypi.python.org/pypi/pyjavaproperties\n\n3) Install the Goby package:\n\n     $ python setup.py install\n\n   This step may require superuser privileges.\n\nUsage\n=====\n\nExample scripts are provided to demonstrate how to access the content\nof Goby files in Python.\n\n- Here is how to scan a Goby alignment file:\n\n  GobyAlignmentStats.py basename\n\n(The files basename.entries and basename.header must exit.)\n\n- The next command will print the content of an alignment file as text:\n\nGobyAlignmentToText.py basename\n\n- The next command will convert a compact reads file to fasta format:\n\nGobyCompactToFasta.py file.compact-reads\n\n- The next command will print statistics about the content of a\n  compact reads file: \n\nGobyReadsStats.py file.compact-reads\n\nDocumentation\n=============\n\nThe complete documentation for Goby is available online at:\n\n  http://goby.campagnelab.org/"}}, {"pk": 192, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.subprocess", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.subprocess", "version": "3.2.2", "platform": "any", "keywords": "utility", "summary": "PyUtilib utilites for managing subprocesses.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==========================\npyutilib.subprocess README\n==========================\n\nThis Python package includes utilies to execute subprocesses in a robust manner.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 193, "model": "importing.pypicache", "fields": {"maintainer": "Erik Max Francis", "name": "PyChurch", "license": "GPL", "author": "Erik Max Francis", "author_email": "software@alcyone.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.alcyone.com/software/church/", "version": "1.0a", "platform": "any", "keywords": "lambda calculus, lambda calculi", "summary": "A simple but full-featured module for exploring lambda calculus", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This module allows simple experimentation with the lambda\r\n    calculus, first developed by Church.  It understands the different\r\n    types of lambda expressions, can extract lists of variables (both\r\n    free and bound) and subterms, and can simplify complicated by\r\n    expression by means of application."}}, {"pk": 194, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.component.doc", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.component.doc", "version": "1.0.1", "platform": "any", "keywords": "utility", "summary": "Documentation for the PyUtilib Component Architecture.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==============================\npyutilib.component.core README\n==============================\n\nThis package supports documentation for the PyUtilib\nComponent Architecture.  See `The PyUtilib Component Architecture\n<https://software.sandia.gov/svn/public/pyutilib/pyutilib.component.doc/trunk/doc/component/pca.pdf>`_\nfor a detailed description of PyUtilib components and examples of\ntheir use.\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * PyUtilib is managed with the Acro Project. A separate checkins mailing\n    list is managed for PyUtilib, but otherwise the main Acro mailing lists\n    are used to manage the development of this software:\n\n    - acro-developers@software.sandia.gov\n    - acro-users@software.sandia.gov\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 195, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "TraitsBackendQt", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/traits_gui", "version": "3.6.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "PyQt backend for Traits and TraitsGUI (Pyface).", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The TraitsBackendQt project contains an implementation of TraitsGUI using PyQt.\nIt provides Qt-based support for visualization and editing of Traits-based\nobjects.\n\nPrerequisites\n-------------\nYou must have the following libraries installed before building or installing\nTraitsBackendQt:\n\n* `PyQt <http://pypi.python.org/pypi/PyQt/3.15>`_\n* `setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 196, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "python-gdsii", "license": "LGPL-3+", "author": "Eugeniy Meshcheryakov", "author_email": "eugen@debian.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.gitorious.org/python-gdsii", "version": "0.2", "platform": "any", "keywords": null, "summary": "GDSII manipulation libaray", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Electronic Design Automation (EDA)\nTopic :: Software Development :: Libraries :: Python Modules", "description": "python-gdsii is a library that can be used to read, create, modify and save\nGDSII files. It supports both low-level record I/O and high level interface to\nGDSII libraries (databases), structures, and elements.\n\nThis package also includes scripts that can be used to convert binary GDS file\nto a text format."}}, {"pk": 197, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "thredds", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/related/thredds.html", "version": "0.1.5", "platform": "UNKNOWN", "keywords": "thredds data", "summary": "THREDDS catalog generator.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This is a THREDDS catalog generator implemented as a WSGI application.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/thredds#egg=thredds-dev>`_."}}, {"pk": 198, "model": "importing.pypicache", "fields": {"maintainer": "Indico Team", "name": "cds-indico", "license": "http://www.gnu.org/licenses/gpl-2.0.txt", "author": "Indico Team", "author_email": "indico-team@cern.ch", "project_url": null, "maintainer_email": "indico-team@cern.ch", "home_page": "http://indico-software.org", "version": "0.97-rc1", "platform": "any", "keywords": "conference meetings lectures paper HEP", "summary": "Indico is a full-featured conference lifecycle management and meeting/lecture scheduling tool", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: ZODB\nIntended Audience :: Education\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Physics", "description": "Indico allows you to schedule conferences, from single talks to complex meetings\r\nwith sessions and contributions. It also includes an advanced user delegation\r\nmechanism, allows paper reviewing, archival of conference information and\r\nelectronic proceedings"}}, {"pk": 199, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MSGNReader", "license": "GNU GPL", "author": "Mario Cruz", "author_email": "duartecruz@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.projectfailure.org/msgnreader", "version": "0.5.0", "platform": "UNKNOWN", "keywords": null, "summary": "MSG Native File Reader", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering :: Atmospheric Science", "description": "Extracts data from Meteosat Second Generation (MSG) Level 1.5 Native Format files and outputs text files or images."}}, {"pk": 200, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "LayoutEditor", "license": "different licenses, basic version under GPL", "author": "Jurgen Thies", "author_email": "juergen.thies@juspertor.com", "project_url": null, "maintainer_email": "", "home_page": "www.layouteditor.net", "version": "20100217", "platform": "linux, mac, windows", "keywords": "EDA, GDSII, OASIS", "summary": "LayoutEditor for IC/MEMS design", "classifiers": "Development Status :: 6 - Mature\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: Science/Research\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Electronic Design Automation (EDA)", "description": "The LayoutEditor is a program to design and edit layout for IC/MEMS fabrication.\r\nThe python modul enables not only scripting in the very popular scripting\r\nlanguage python, but also allows anyone to adjust, extend and embed the\r\nLayoutEditor in a very flexible way. The LayoutEditor main window and a new\r\n'juspertor library manager' is written in python itself and can be modified to\r\nyour demands"}}, {"pk": 201, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pyaler", "license": "GPLv2", "author": "Guyzmo, Bearstech", "author_email": "bpratz@bearstech.com", "project_url": null, "maintainer_email": "", "home_page": "http://www.pyaler.org/", "version": "0.3", "platform": "linux, BSD, OSX", "keywords": "arduino http restful api", "summary": "A restfull application to control your arduino devices", "classifiers": "Framework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Education\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nNatural Language :: French\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nTopic :: Home Automation\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Internet :: WWW/HTTP :: WSGI :: Application\nTopic :: Internet :: WWW/HTTP :: WSGI :: Server\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Software Development :: Libraries :: Python Modules", "description": "pyaler is a WSGI application to control your arduino devices via an RESTfull api.\r\n\r\nInstallation\r\n------------\r\n\r\nWith easy_install::\r\n\r\n  $ easy_install -U pyaler\r\n\r\nWith pip::\r\n\r\n  $ pip install pyaler\r\n\r\nUsage\r\n------\r\n\r\n::\r\n\r\n  $ pyaler conf.yaml\r\n\r\n\r\n\r\n\r\nSee http://packages.python.org/pyaler/ for the full documentation\r\n\r\nNews\r\n====\r\n\r\n0.1\r\n---\r\n\r\nInitial version"}}, {"pk": 202, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.sac", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team & C. J. Ammon", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.6", "platform": "OS Independent", "keywords": "ObsPy,seismology,SAC,waveform,seismograms", "summary": "Read & Write Seismograms, Format SAC.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "obspy.sac - Read & Write Seismograms, Format SAC\n    \n    Python methods for reading and writing seismograms to SAC.\n\n    For more information visit http://www.obspy.org."}}, {"pk": 203, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "StarCluster", "license": "LGPL3", "author": "Justin Riley", "author_email": "justin.t.riley@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://web.mit.edu/starcluster", "version": "0.91.2", "platform": "UNKNOWN", "keywords": "", "summary": "StarCluster is a utility for creating and managing computing clusters hosted on Amazon's Elastic Compute Cloud (EC2).", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: System :: Clustering\nTopic :: System :: Distributed Computing", "description": "StarCluster\r\n===========\r\n| Homepage: http://web.mit.edu/starcluster\r\n| Author: Justin Riley (justin.t.riley@gmail.com)\r\n| Team: Software Tools for Academics and Researchers (http://web.mit.edu/star)\r\n\r\nDescription:\r\n------------\r\nStarCluster is a utility for creating and managing computing clusters hosted on \r\nAmazon's Elastic Compute Cloud (EC2). StarCluster utilizes Amazon's EC2 web service \r\nto create and destroy clusters of Linux virtual machines on demand.\r\n\r\nTo get started, the user creates a simple configuration file with their AWS account \r\ndetails and a few cluster preferences (e.g. number of machines, machine type, ssh \r\nkeypairs, etc). After creating the configuration file and running StarCluster's \r\n\"start\" command, a cluster of Linux machines configured with the Sun Grid Engine \r\nqueuing system, an NFS-shared /home directory, and OpenMPI with password-less ssh is \r\ncreated and ready to go out-of-the-box. Running StarCluster's \"stop\" command will \r\nshutdown the cluster and stop paying for service. This allows the user to only pay \r\nfor what they use.\r\n\r\nStarCluster can also utilize Amazon's Elastic Block Storage (EBS) volumes to provide \r\npersistent data storage for a cluster. EBS volumes allow you to store large amounts \r\nof data in the Amazon cloud and are also easy to back-up and replicate in the cloud. \r\nStarCluster will mount and NFS-share any volumes specified in the config. StarCluster's \r\n\"createvolume\" command provides the ability to automatically create, format, and \r\npartition new EBS volumes for use with StarCluster.\r\n\r\nStarCluster provides a Ubuntu-based Amazon Machine Image (AMI) in 32bit and 64bit \r\narchitectures. The AMI contains an optimized NumPy/SciPy/Atlas/Blas/Lapack \r\ninstallation compiled for the larger Amazon EC2 instance types. The AMI also comes\r\nwith Sun Grid Engine (SGE) and OpenMPI compiled with SGE support. The public AMI \r\ncan easily be customized by launching a single instance of the public AMI,\r\ninstalling additional software on the instance, and then using StarCluster's \r\n\"createimage\" command to completely automate the process of creating a new AMI from \r\nan EC2 instance.\r\n\r\nDependencies:\r\n-------------\r\n* Amazon AWS Account\r\n* Python 2.4+\r\n* Boto 1.9b\r\n* Paramiko 1.7.6\r\n\r\nGetting Started:\r\n----------------\r\n\r\nTo install StarCluster using easy_install::\r\n\r\n    $ sudo easy_install StarCluster\r\n\r\nTo install StarCluster manually::\r\n\r\n    $ (Download StarCluster from http://web.mit.edu/starcluster)\r\n    $ tar xvzf starcluster-X.X.X.tar.gz  (where x.x.x is a version number)\r\n    $ cd starcluster-X.X.X\r\n    $ sudo python setup.py install\r\n\r\nAfter the software has been installed, the next step is to setup the configuration file: ::\r\n\r\n    $ starcluster help\r\n    \r\nThis will give you a template to use to create a configuration file containing your AWS credentials, \r\ncluster settings, etc.  The next step is to customize this file using your favorite text-editor: ::\r\n\r\n    $ vi ~/.starcluster/config  \r\n\r\nThis file is commented with example \"cluster templates\". A cluster template defines a set of configuration\r\nsettings used to start a cluster. The example config provides a 'smallcluster' template that is\r\nready to go out-of-the-box. Simply fill in your AWS credentials and keypair info and you're ready to go.\r\n\r\nNext we start a cluster named \"mycluster\" using the default cluster template 'smallcluster' in the example config: \r\n::\r\n\r\n    $ starcluster start mycluster \r\n\r\nThe *default_template* setting in the [global] section of the config specifies the default cluster template and\r\nis automatically set to 'smallcluster' in the example config.\r\n\r\nAfter the *start* command completes you should now have a working cluster. You can login to the master node as \r\nroot by running: ::\r\n\r\n    $ starcluster sshmaster mycluster\r\n\r\nOnce you've finished using the cluster and wish to stop paying for it: ::\r\n\r\n    $ starcluster stop mycluster \r\n\r\nHave a look at the rest of StarCluster's commands: ::\r\n\r\n    $ starcluster --help\r\n\r\nLearn more...\r\n-------------\r\nWatch an ~8min screencast @ http://web.mit.edu/stardev/cluster\r\n\r\nTo learn more have a look at the rest of the documentation:\r\nhttp://web.mit.edu/stardev/cluster/docs\r\n\r\nThe docs explain the configuration file in detail, how to create/use EBS volumes with StarCluster, and\r\nhow to use the Sun Grid Engine queueing system to submit jobs on the cluster.\r\n\r\n\r\nLicensing:\r\n----------\r\n| StarCluster is licensed under the LGPL\r\n| see COPYING.LESSER (LGPL) and COPYING (GPL) for LICENSE details"}}, {"pk": 204, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.responses.wms", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/responses.html#wms", "version": "0.4.6", "platform": "UNKNOWN", "keywords": "wms opendap dods dap data science climate oceanography meteorology", "summary": "WMS response for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This response enables Pydap to serve data as a WMS server."}}, {"pk": 205, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "matter", "license": "BSD", "author": "J. Brandon Keith", "author_email": "jbrkeith@gmail.edu", "project_url": null, "maintainer_email": null, "home_page": "http://dev.danse.us/trac/inelastic/wiki/crystal", "version": "0.8-r960-20110308", "platform": "UNKNOWN", "keywords": "matter material crystal structure symmetry", "summary": "matter classes and parsers for structure formats", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 206, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ordf", "license": "AGPL", "author": "Open Knowledge Foundation", "author_email": "okfn-help@lists.okfn.org", "project_url": null, "maintainer_email": null, "home_page": "http://ordf.org/", "version": "0.36", "platform": "UNKNOWN", "keywords": "rdf rdflib provenance messaging", "summary": "Open Knowledge Foundation RDF", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nFramework :: Pylons\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Affero General Public License v3\nOperating System :: POSIX\nProgramming Language :: Python :: 2.6\nTopic :: Internet\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Open Knowledge Foundation RDF Library"}}, {"pk": 207, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "python-igraph", "license": "GNU General Public License (GPL)", "author": "Tamas Nepusz", "author_email": "tamas@cs.rhul.ac.uk", "project_url": null, "maintainer_email": "", "home_page": "UNKNOWN", "version": "0.5.4", "platform": "ALL", "keywords": "graph,network,mathematics,math,graph theory,discrete mathematics", "summary": "High performance graph data structures and algorithms", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Python interface to the igraph high performance graph\r\nlibrary, primarily aimed at complex network research and analysis.\r\n\r\nGraph plotting functionality is provided by the Cairo library, so make\r\nsure you install the Python bindings of Cairo if you want to generate\r\npublication-quality graph plots.\r\n\r\nSee the `Cairo homepage <http://cairographics.org/pycairo>`_ for details.\r\n\r\nFrom release 0.5, the C core of the igraph library is **not** included\r\nin the Python distribution - you must compile and install the C core\r\nseparately. Windows installers already contain a compiled igraph DLL,\r\nso they should work out of the box. Linux users should refer to the\r\n`igraph homepage <http://igraph.sourceforge.net>`_ for\r\ncompilation instructions (but check your distribution first, maybe\r\nthere are pre-compiled packages available). OS X Snow Leopard users may\r\nbenefit from the meta-package in the Python Package Index."}}, {"pk": 208, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "collective.classification", "license": "GPL", "author": "Yiorgis Gozadinos", "author_email": "ggozad@jarn.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.org/ggozad/collective.classification", "version": "0.1b2", "platform": "Any", "keywords": "term-extract,semantic,classification,Parts-Of-Speech,tagging,plone", "summary": "Content classification/clustering through language processing", "classifiers": "Environment :: Web Environment\nFramework :: Plone\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Filters\nTopic :: Text Processing :: General\nTopic :: Text Processing :: Indexing", "description": "Introduction\n============\n\n*collective.classification* aims to provide a set of tools for automatic\ndocument classification. Currently it makes use of the\n`Natural Language Toolkit`_ and features a trainable document classifier based\non Part Of Speech (POS) tagging, heavily influenced by `topia.termextract`_.\nThis product is mostly intended to be used for experimentation and\ndevelopment. Currently english and dutch are supported.\n\n  .. _`Natural Language Toolkit`: http://www.nltk.org\n  .. _`topia.termextract`: http://pypi.python.org/pypi/topia.termextract/\n\nWhat is this all about?\n=======================\n\nIt's mostly about having fun! The package is in a very early experimental\nstage and awaits eagerly contributions. You will get a good understanding of\nwhat works or not by looking at the tests. You might also be able to do some\nuseful things with it:\n\n    1) Term extraction can be performed to provide quick insight on what a\n    document is about.\n    2) On a large site with a lot of content and tags (or subjects in the\n    plone lingo) it might be difficult to assign tags to new content. In this\n    case, a trained classifier could provide useful suggestions to an editor\n    responsible for tagging content.\n    3) Similar documents can be found based on term similarity.\n    4) Clustering can help you organize unclassified content into groups.\n\nHow it works?\n=============\n\nAt the moment there exist the following type of utilities:\n\n  * *POS taggers*, utilities for classifying words in a document\n    as `Parts Of Speech`_. Two are provided at the moment, a Penn TreeBank\n    tagger and a trigram tagger. Both can be trained with some other language\n    than english which is what we do here.\n  * *Term extractors*, utilities responsible for extracting the important\n    terms from some document. The extractor we use here, assumes that in a\n    document only nouns matter and uses a POS tagger to find those mostly used\n    in a document. For details please look at the code and the tests.\n  * *Content classifiers*, utilities that can tag content in predefined\n    categories. Here, a `naive Bayes`_ classifier is used. Basically, the\n    classifier looks at already tagged content, performs term extraction and\n    trains itself using the terms and tags as an input. Then, for new content,\n    the classifier will provide suggestions for tags according to the\n    extracted terms of the content.\n  * Utilities that find *similar content* based on the extracted terms.\n  * *Clusterers*, utilities that without prior knowledge of content\n    classification can group content into groups according to feature\n    similarity. At the moment NLTK's `k-means`_ clusterer is used.\n\n\n  .. _`Parts Of Speech`: http://en.wikipedia.org/wiki/Part-of-speech_tagging\n  .. _`naive Bayes`: http://en.wikipedia.org/wiki/Naive_Bayes_classifier\n  .. _`k-means`: http://en.wikipedia.org/wiki/K-means_clustering\n\nInstallation & Setup\n====================\n\nBefore running buildout, make sure you have yaml and its python bindings\ninstalled (use macports on osx, or your package installer on linux). If nltk\nexists for your OS you might as well install that, otherwise it will be\nfetched when you run buildout.\n\nTo get started you will simply need to add the package to your \"eggs\" section\nand run buildout, restart your Plone instance and install the\n\"collective.classification\" package using the quick-installer or via the\n\"Add-on Products\" section in \"Site Setup\".\n\n**WARNING: Upon first time installation linguistic data will be fetched from\nNLTK's repository and stored locally on your filesystem. It's not big (about 400kb) but you need the plone user to have access to its \"home\". Running the\ntests will also fetch more data from nltk bringing the total to about 225Mb, so not for the faint at disk space.**\n\nHow to use it?\n==============\n  * For a parsed document you can call the term view to display the identified\n    terms (just append *@@terms* to the url of the content to call the view).\n  * In order to use the classifier and get suggested tags for some content,\n    you can call *@@suggest-categories* on the content. This comes down to\n    appending @@suggest-categories to the url in your browser. A form will\n    come up with suggestions, choose the ones that seem appropriate and apply.\n    You will need to have the right to edit the document in order to call the\n    view.\n  * You can find similar content for some content based on its terms by\n    calling the *@@similar-items* view. \n  * For clustering you can just call the *@@clusterize* view from anywhere.\n    The result is not deterministic but hopefully helpful;). You need manager\n    rights for this so as to not allow your users to DOS your site!\n\n\nIntegration test\n================\n\nHere, we'll test the classifier using a sample of the Brown corpus. The Brown\ncorpus has a list of POS-tagged english articles which are also conveniently\ncategorized. The test consists of training the classifier using 20 documents\nfrom each of the categories 'news','editorial' and 'hobbies'. Then we'll ask\nthe classifier to classify 5 more documents from each category and see what\nhappens.\n\nWe can now start adding documents, starting with the first 20 documents in the\nBrown corpus categorized as 'news'.\n\n    >>> from nltk.corpus import brown\n    >>> for articleid in brown.fileids(categories='news')[:20]:\n    ...     text = \" \".join(brown.words(articleid))\n    ...     id = self.folder.invokeFactory('Document',articleid,\n    ...                                    title=articleid,\n    ...                                    text=text,\n    ...                                    subject='news')\n\nContinuing with 20 documents categorized as 'editorial':\n\n    >>> for articleid in brown.fileids(categories='editorial')[:20]:\n    ...     text = \" \".join(brown.words(articleid))\n    ...     id = self.folder.invokeFactory('Document',articleid,\n    ...                                    title=articleid,\n    ...                                    text=text,\n    ...                                    subject='editorial')\n\nAnd finally 20 documents categorized as 'hobbies':\n\n    >>> for articleid in brown.fileids(categories='hobbies')[:20]:\n    ...     text = \" \".join(brown.words(articleid))\n    ...     id = self.folder.invokeFactory('Document',articleid,\n    ...                                    title=articleid,\n    ...                                    text=text,\n    ...                                    subject='hobbies')\n\nAll these documents should have been parsed and indexed:\n\n    >>> catalog = self.folder.portal_catalog\n    >>> sr = catalog.searchResults(noun_terms='state')\n    >>> len(sr) > 5\n    True\n\nLet's see what terms we get for the first 'editorial' content:\n\n    >>> browser = self.getBrowser()\n    >>> browser.open(self.folder.absolute_url()+'/cb01/@@terms')\n    >>> browser.contents\n    '...state...year...budget...war...danger...nuclear war...united states...'\n\nNuclear war and United States? Scary stuff... Time to train the classifier:\n\n    >>> from zope.component import getUtility\n    >>> from collective.classification.interfaces import IContentClassifier\n    >>> classifier = getUtility(IContentClassifier)\n    >>> classifier.train()\n    >>> classifier.tags()\n    ['editorial', 'hobbies', 'news']\n\nFor a start, the classifier should be pretty certain when asked about text\nalready classified:\n\n    >>> browser.open(self.folder.absolute_url()+'/ca01/@@suggest-categories')\n    >>> browser.contents\n    '...news 100.0%...editorial 0.0%...hobbies 0.0%...'\n\nSo let's see where this gets us, by asking the classifier to categorize 5 more\ndocuments for which we know the category. We will use the classifier's\nfunctions directly this time instead of adding the documents to plone and\ncalling the *@@suggest-categories* view. 'News' first:\n\n    >>> classificationResult = []\n    >>> for articleid in brown.fileids(categories='news')[20:25]:\n    ...     text = \" \".join(brown.words(articleid))\n    ...     id = self.folder.invokeFactory('Document',articleid,\n    ...                                    text=text)\n    ...     uid = self.folder[id].UID()\n    ...     classificationResult.append(classifier.classify(uid))\n    >>> classificationResult\n    ['news', 'news', 'news', 'news', 'news']\n\nLet's see how we do with 'editorials'\n\n    >>> classificationResult = []\n    >>> for articleid in brown.fileids(categories='editorial')[20:25]:\n    ...     text = \" \".join(brown.words(articleid))\n    ...     id = self.folder.invokeFactory('Document',articleid,\n    ...                                    text=text)\n    ...     uid = self.folder[id].UID()\n    ...     classificationResult.append(classifier.classify(uid))\n    >>> classificationResult\n    ['editorial', 'editorial', 'editorial', 'editorial', 'editorial']\n\nThat's excellent! What about 'hobbies'?\n\n    >>> classificationResult = []\n    >>> for articleid in brown.fileids(categories='hobbies')[20:25]:\n    ...     text = \" \".join(brown.words(articleid))\n    ...     id = self.folder.invokeFactory('Document',articleid,\n    ...                                    text=text)\n    ...     uid = self.folder[id].UID()\n    ...     classificationResult.append(classifier.classify(uid))\n    >>> classificationResult\n    ['hobbies', 'hobbies', 'editorial', 'hobbies', 'hobbies']\n\nNot so bad! Overall: we got 14/15 right...\n\nLet's now pick again the first editorial item and see which documents are\nsimilar to it based on the terms we extracted:\n\n    >>> browser.open(self.folder['cb01'].absolute_url()+'/@@similar-items')\n\nThe most similar item (a Jaccard index of ~0.2) is\ncb15:\n\n    >>> browser.contents\n    '...cb15...0.212121212121...'\n\nLet's see what their common terms are:\n\n    >>> cb01terms = catalog.searchResults(\n    ... UID=self.folder['cb01'].UID())[0].noun_terms[:20]\n    >>> cb15terms = catalog.searchResults(\n    ... UID=self.folder['cb15'].UID())[0].noun_terms[:20]\n    >>> set(cb01terms).intersection(set(cb15terms))\n    set(['development', 'state', 'planning', 'year', 'area'])\n\nwhich is fine, since both documents talk about development and budget\nplanning...\n\nWhat about stats? We can call the *@@stats* view to find out...\n\n    >>> self.setRoles('Manager')\n    >>> browser.open(self.folder.absolute_url()+'/@@classification-stats')\n    >>> browser.contents\n    '...state...True...editorial:hobbies...5.0...'\n\nwhich basically tells us, that if the word 'state' is present the classifier\ngives 5 to 1 for the content to be in the 'editorial' category rather than the\n'hobbies' category\nChangelog\n=========\n\n0.1b2\n-------------------\n\n- Removed the persistent noun storage altogether. Now noun and noun-phrase\n  terms are stored directly in the catalog using plone.indexer.\n  [ggozad, stefan]\n- Using BTrees instead of PersistenDict. Should make writes to ZODB lighter.\n  [ggozad]\n- Noun-phrase grammar and normalization is now a property of the\n  language-dependent tagger.\n  [ggozad]\n- Removed a lot of the control panel functionality. Not need for confusion.\n  [ggozad]\n- Fixed Dutch language support.\n  [ggozad]\n\n0.1b1\n-------------------\n\n- Speed gain by not utilizing the PenTreeBank tagger anymore. [ggozad]\n- Added multi-lingual support, starting with dutch! [ggozad]\n- No need to download all the coprora anymore. [ggozad]\n- A lot of refactoring. Things got moved around and a lot of unnecessary code\n  was removed. [ggozad]\n- We now use a Brill/Trigram/Affix tagger that is pre-trained. This\n  allows collective.classification to ship without all the corpora. The user\n  can still supply a different tagger if necessary. [ggozad]\n- The default nltk PenTreeBank tagger is no longer used. Too slow. [ggozad]\n- npextractor is no longer a local persistent utility. Opted for a global\n  non-persisted object. [ggozad]\n- zope.lifecycle events are now used. [ggozad]\n- Gained compatibility with plone 4. [ggozad]\n\n0.1a3\n-------------------\n\n- Introduced IClassifiable interface. ATContentTypes are now adapted to it,\n  and it should be easier to add other non-AT content types or customize the\n  adapter. [ggozad]\n- Handling of IObjectRemovedEvent event. [ggozad]\n- Added a form to import sample content from the brown corpus, for debugging\n  and testing. [ggozad]\n- Added some statistics information with @@classification-stats.\n  Displays the number of parsed documents, as well as the most useful terms.\n  [ggozad]\n- Added @@terms view, allowing a user to inspect the identified terms for some\n  content. [ggozad]\n- Have to specify corpus categories when training n-gram tagger. Fixes #3\n  [ggozad]\n\n0.1a2\n-------------------\n\n- Made control panel more sane. Fixes #1. [ggozad]\n- NP-extractor has become a local persistent utility. [ggozad]\n- Renamed @@subjectsuggest to @@suggest-categories. Fixes #2. [ggozad]\n- \"memoized\" term extractor. [ggozad]\n- Added friendly types to the control panel. [ggozad]\n- Updated documentation and dependencies to warn about yaml. [ggozad]\n\n0.1a1\n-------------------\n\n- First public release. [ggozad]"}}, {"pk": 209, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.virtualenv", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.virtualenv", "version": "2.4", "platform": "any", "keywords": "utility", "summary": "PyUtilib utility for building custom virtualenv bootstrap scripts.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==========================\npyutilib.virtualenv README\n==========================\n\nThis Python package includes the **vpy_create** script, which is\nused to create **virtualenv** bootstrap scripts that automate the installation of\n**virtualenv** along with other Python packages.\n\n---------------\nGetting Started\n---------------\n\nOverview\n~~~~~~~~\n\nThe **vpy_create** script integrates a Python module into a **virtualenv**\nbootstrap script.  A user defines a **configure()** function in this module to\ncontrol the configuration of the **virtualenv** installation.  For example, the\nfollowing function declares the default installation directory, and that the\nvirtual Python repository contains the **virtualenv** and **nose** Python packages::\n\n  def configure(installer):\n        installer.default_dirname = 'venv'\n        installer.add_repository('virtualenv', pypi='virtualenv')\n        installer.add_repository('nose', pypi='nose')\n        installer.add_repository(\n            'pyutilib.subprocess', \n            root='https://software.sandia.gov/svn/public/pyutilib.subprocess', \n            dev=True)\n        return installer\n\nThe **add_repository** method can specify a PyPI package with the *pypi*\noption.  Alternatively, the root of a subversion repository can be specified\nwith the *root* option.  If the *dev* option is specified, then this\nrepository is checked out and installed in the **<root>/src** directory.\nFurther, this package is installed in *develop* mode.\n\n\nA virtual Python bootstrap script is created by calling\n**vpy_create** and specifying the Python module and script\nname.::\n\n  vpy_create venv.py venv_install\n\nThe bootstrap script, **venv_install**, creates the virtual Python\ninstallation in the specified directory, **venv**:\n\n  venv_install\n\nThe user can also specify the installation directory::\n\n  venv_install venvdir\n\n\nBy default, the bootstrap script installs the latest software release.\nIn PyPI, this is the latest revision.  In subversion, this is the latest\nrevision in either the *tags* or *releases* directory.  The trunk branch of\nthe subversion repository can also be installed using the **--trunk** option::\n\n  venv_install --trunk venv\n\nSimilarly, the bootstrap script recognizes stable branches, which can\nbe installed with the **--stable** option.  Note that if stable branches are\nnot available, then the latest release is installed.\n\n\nInternet Connectivity\n~~~~~~~~~~~~~~~~~~~~~\n\nBy default, the bootstrap script uses an internet connection to download the \nPython packages that are installed.  Note that a proxy server may be needed\nfor the bootstrap script to work correctly.  The user can define the\nHTTP_PROXY environmental variable to specify the name of a proxy server.\nAlternatively, the **--proxy** option can be specified.\n\nThe bootstrap script also provides a mechanism for enabling offline virtualenv\ninstallations.  This requires a two-stage process.  First, the\n**--preinstall** option is used to create a ZIP file that contains the Python\npackages.  For example, the command::\n\n  venv_install --preinstall\n\ncreates a **venv** directory, which includes the file **venv/venv.zip**.\nThe preinstall step must be executed on a machine with internet\nconnectivity.  However, this ZIP file can be used to perform an off-line\ninstallation with the **--offline** option.  For example, the following\ncommand will uses the **venv.zip** file to perform off-line installation\nin the **temp** directory::\n\n  venv_install --offline --zip=venv.zip test\n\nNote that this technique also installs the **setuptools** packages offline.\nThus, the bootstrap script generated by **vpy_create** \nsupports a purely offline setup of virtualenv environments, which is not supported\nby the **virtualenv** bootstrap process.\n\n\nA Configurable Installer\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe **vpy_install** script provided with **pyutilib.virtualenv** is a **virtualenv**\nbootstrap script that can be configured with INI files.  For example, the\nconsider the following INI file::\n\n    ;\n    ; This INI file can be used by vpy_install to create a virtual\n    ; Python installation.\n    ;\n    [installer]\n    description=This is an example.\n    README=\"#\n     # This is a README file created by the bootstrap script.\n     #\"\n\n    [nose]\n    pypi=nose\n\n    [pyutilib.subprocess]\n    root=https://software.sandia.gov/svn/public/pyutilib/pyutilib.subprocess\n    dev=True\n\nThe default installation directory for **vpy_install** is **python**.\nThis INI file will install the **nose** and **pyutilib.subprocess**\npackages, and the **pyutilib.subprocess** package will be installed in\n**python/src/pyutilib.subprocess** as an editable *develop* package.\n\nNote that **vpy_install** does not require a user to install\n**setuptools**.  The **setuptools** package is only required when the\n**--preinstall** option is specified.  Thus, the default behavior of\n**vpy_install** (and other bootstrap scripts) does not require the\ninstallation of any third-party packages.  The **vpy_install** script\ncan be distributed independent of **pyutilib.virtualenv**, and it can\ngenerally be used as a stand-alone script.\n\nThe **vpy_install** script supports an **--update** option that allows the\nuser to update virtual Python installations.  This option does the following\nupdates:\n\n* PyPI packages are upgraded\n* Subversion packages are updated and reinstalled\n\nNote that this option does not search for a newer release of a subversion\npackage.  This limitation reflects the manner in which subversion packages\nare checked out within the virtual Python installation, which may be revised\nin the future.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n \n  * Examples in the pyutilib.virtualenv/example directory\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nThe pyutilib.virtualenv package depends on the following Python packages:\n    - virtualenv"}}, {"pk": 210, "model": "importing.pypicache", "fields": {"maintainer": "Pavol Juhas", "name": "diffpy.pdffit2", "license": "BSD", "author": "Simon J.L. Billinge", "author_email": "sb2896@columbia.edu", "project_url": null, "maintainer_email": "pj2192@columbia.edu", "home_page": "http://www.diffpy.org/", "version": "1.0-r3067-20090410", "platform": "UNKNOWN", "keywords": "PDF structure refinement", "summary": "PDFfit2 - real space structure refinement program.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: C++\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 211, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "glycomesite.policy", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://glycans.jpl.nasa.gov/", "version": "1.0.0", "platform": "UNKNOWN", "keywords": "web zope plone portal glycome glycans cancer detection", "summary": "GLYCANS site policy and component orchestration", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==============\n Introduction\n==============\n\nThis is the \"policy\" product for the public portal of the Alliance of\nGlycobiologists for Detection of Cancer and Cancer Risk, or Glycans.  This\nproduct specifies no custom content types or look-and-feel but instead\nspecifies minimum policy settings and orchestrates all other dependent\ncomponents.  To turn a Plone site into the Glycans site, just install this\ncomponent.\n\n\n===========\n Changelog\n===========\n\n0.0.0 - Unreleased\n------------------\n\n* Initial release"}}, {"pk": 212, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "qitensor", "license": "BSD", "author": "Dan Stahlke", "author_email": "dstahlke@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.stahlke.org/dan/qitensor", "version": "0.5.1", "platform": "UNKNOWN", "keywords": "quantum,tensor,numpy,sage", "summary": "Quantum Hilbert Space Tensors in Python and Sage", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics", "description": "This module is essentially a wrapper for numpy that uses semantics useful for\nfinite dimensional quantum mechanics of many particles.  In particular, this\nshould be useful for the study of quantum information and quantum computing.\nEach array is associated with a tensor-product Hilbert space.  The underlying\nspaces can be bra spaces or ket spaces and are indexed using any finite\nsequence (typically a range of integers starting from zero, but any sequence is\nallowed).  When arrays are multiplied, a tensor contraction is performed among\nthe bra spaces of the left array and the ket spaces of the right array.\nVarious linear algebra methods are available which are aware of the Hilbert\nspace tensor product structure.\n\n* Component Hilbert spaces have string labels (e.g. ``qubit('a') * qubit('b')``\n  gives ``|a,b>``).\n* Component spaces are finite dimensional and are indexed either by integers or\n  by any sequence (e.g. elements of a group).\n* In Sage, it is possible to create arrays over the Symbolic Ring.\n* Multiplication of arrays automatically contracts over the intersection of the\n  bra space of the left factor and the ket space of the right factor.\n* Linear algebra routines such as SVD are provided which are aware of the\n  Hilbert space labels."}}, {"pk": 213, "model": "importing.pypicache", "fields": {"maintainer": "Ray Buvel", "name": "ratfun", "license": "GPL", "author": "Ray Buvel", "author_email": "rlbuvel@gmail.com", "project_url": null, "maintainer_email": "rlbuvel@gmail.com", "home_page": "http://calcrpnpy.sourceforge.net/ratfun.html", "version": "2.6", "platform": "Platform Independent", "keywords": "polynomial rational function", "summary": "Polynomial and Rational Function module", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Mathematics", "description": "The ratfun module provides classes for defining polynomial and rational function\r\n(ratio of two polynomials) objects. These objects can be used in arithmetic\r\nexpressions and evaluated at a particular point."}}, {"pk": 214, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.samplerate", "license": "GPL", "author": "David Cournapeau", "author_email": "david@ar.media.kyoto-u.ac.jp", "project_url": null, "maintainer_email": null, "home_page": "http://www.ar.media.kyoto-u.ac.jp/members/david/softwares/samplerate", "version": "0.3.3", "platform": "UNKNOWN", "keywords": null, "summary": "A python module for high quality audio resampling", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Multimedia :: Sound/Audio\nTopic :: Scientific/Engineering", "description": "Samplerate is a small python package to do high quality audio resampling for\ndata in numpy arrays; IOW, it is a matlab resample replacement.\n\nSamplerate is a wrapper around the Secret Rabbit Code from Erik de Castro Lopo\n(http://www.mega-nerd.com/SRC/), which has high quality converters based on the\nwork of J.O Smith from CCRMA (see\nhttp://ccrma.stanford.edu/~jos/resample/optfir.pdf)"}}, {"pk": 215, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "oodt", "license": "Apache 2.0", "author": "Sean Kelly", "author_email": "kelly@apache.org", "project_url": null, "maintainer_email": "", "home_page": "http://oodt.apache.org/", "version": "0.2", "platform": "UNKNOWN", "keywords": "data grid discovery query optimization object middleware archive catalog index", "summary": "Agile OODT", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: No Input/Output (Daemon)\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Apache Software License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Front-Ends\nTopic :: Internet :: WWW/HTTP\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Internet :: WWW/HTTP :: HTTP Servers\nTopic :: Internet :: Z39.50\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "****\noodt\n****\n\nAgile OODT is a new version of `Object Oriented Data Technology`_.  It\nimproves upon the previous version by being easier to develop, maintain, and\nextend; simpler to integrate by; and faster to use.\n\n.. This is licensed software; see the files NOTICE.txt and docs/LICENSE.txt.\n\n.. For installation instructions, see docs/INSTALL.txt.\n\n.. References:\n.. _`Object Oriented Data Technology`: http://incubator.apache.org/projects/oodt.html\n\n.. meta::\n    :keywords: OODT, data, object, OO, discovery, metadata,\n        transfer, transformation, query, search, retrieval\n    :description lang=en: Agile OODT, the nimble version of\n        Object Oriented Data Technology\n\n\n\nInstallation\n============\n\nWhat follows are the installation instructions for Agile OODT.\n\n\nQuick Instructions\n------------------\n\nAs a user with administrative privileges, run either::\n\n    pip oodt\n\nor::\n\n    easy_install oodt\n\ndepending on what's available on your system.  You're done!\n\n\nFull Instructions\n-----------------\n\nAgile OODT requires the Python_ programming language.  We recommend version 2.4\nor later.  As of this writing, 2.7 is the latest stable version.  If Python is\nnot yet installed on your system, you can find binary and and source\ndistributions from the Python website.\n\nTo test if a correct version of Python is available on your system, run::\n\n    python -V\n    \nYou should see output similar to::\n\n    Python 2.7\n    \nindicating the version of Python installed.  You may then proceed to install\nAgile OODT.\n\nBy far the easiest, recommended, and encouraged way to install Agile OODT is\neither with Pip_ or EasyInstall_.  If your Python installation has either of\nthese installers available to it, then one command is all you need to run in\norder to download, build, install, and generate command-line tools all in one\ngo for all users on your system.  For Pip users, it's::\n\n    pip oodt\n\nAnd for EasyInstall users, it's::\n\n    easy_install oodt\n    \nBe sure to run that command as an administrative user.  For example, on Mac OS\nX and other Unix systems, you might need to run either of::\n\n    sudo pip oodt\n    sudo easy_install oodt\n\n\nInstalling From Source\n~~~~~~~~~~~~~~~~~~~~~~\n\nIf neither Pip nor EasyInstall are available, you can still make a proper\ninstallation of Agile OODT by building it from its source code.  Just follow\nthese instructions:\n\n1.  Download the Agile OODT source distribution and extract the source\n    archive.  The source distribution is packaged as a gzip'd tar archive.\n2.  Change the current working directory to the newly extracted directory.\n3.  As an administrative user, run: ``python setup.py install``\n\n\nFor More Information\n--------------------\n\nVisit any of the following links for additional information, to ask questions,\nreport bugs, and so forth:\n\nOODT Home Page\n    http://oodt.apache.org/\nMailing List for OODT Development\n    mailto:dev@oodt.apache.org\nPackage Page (Cheese Shop)\n    http://pypi.python.org/pypi/oodt/\nIssue Tracker (submit bug reports here)\n    https://issues.apache.org/jira/browse/OODT\n\n\n.. References:\n.. _EasyInstall: http://packages.python.org/distribute/easy_install.html\n.. _Pip: http://pip.openplans.org/\n.. _Python: http://python.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes to this software.\n\n0.2 - Current\n-------------\n\nThis is the current release of Agile OODT, representing its migration from the\nApache Incubator to a full-fledged top-level Apache project.\n\n\n0.1-incubating - Initial Apache Release\n---------------------------------------\n\nThis release marks the induction of Agile OODT into the Apache Software\nFoundation's Incubator_.\n\n\n.. References:\n.. _Incubator: http://incubator.apache.org/"}}, {"pk": 216, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "DendroPy", "license": "BSD", "author": "Jeet Sukumaran and Mark T. Holder", "author_email": "jeet@ku.edu and mtholder@ku.edu", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/DendroPy/", "version": "3.7.1", "platform": "UNKNOWN", "keywords": "phylogenetics phylogeny phylogenies phylogeography evolution evolutionary biology systematics coalescent population genetics phyloinformatics bioinformatics", "summary": "A Python library for phylogenetics and phylogenetic computing: reading, writing, simulation, processing and manipulation of phylogenetic trees (phylogenies) and characters.", "classifiers": "Environment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "Introduction\n============\n\nDendroPy is a Python library for phylogenetic computing.\nIt provides classes and functions for the simulation, processing, and manipulation of phylogenetic trees and character matrices, and supports the reading and writing of phylogenetic data in a range of formats, such as NEXUS, NEWICK, NeXML, Phylip, FASTA, etc.\nApplication scripts for performing some useful phylogenetic operations, such as data conversion and tree posterior distribution summarization, are also distributed and installed as part of the libary.\nDendroPy can thus function as a stand-alone library for phylogenetics, a component of more complex multi-library phyloinformatic pipelines, or as a scripting \"glue\" that assembles and drives such pipelines.\n\nThe primary home page for DendroPy, with detailed tutorials and documentation, is at:\n\n    http://packages.python.org/DendroPy/\n\nRequirements and Installation\n=============================\n\nDendroPy runs under any version of Python 2 from 2.4 upwards (i.e., Python 2.4, 2.5, 2.6, 2.7, etc.). At present, it does not run under Python 3.\n\nIf you have `setuptools <http://pypi.python.org/pypi/setuptools>`_ installed, you can install the latest public release of DendroPy directly from the `Python Package Index <http://pypi.python.org/pypi/DendroPy/>`_ by running::\n\n    $ sudo easy_install -U dendropy\n\nAlternatively, if you have `pip <http://pypi.python.org/pypi/pip>`_ installed, you can run::\n\n    $ sudo pip install dendropy\n\nIf you `download the source code archive <http://pypi.python.org/packages/source/D/DendroPy/DendroPy-3.7.1.tar.gz>`_ from the `Python Package Index <http://pypi.python.org/pypi/DendroPy/>`_, you can unarchive it and install it from the local source by running::\n\n    $ tar -xvzf DendroPy-3.7.1.tar.gz\n    $ cd DendroPy-3.7.1\n    $ sudo python setup.py install\n\nDocumentation\n=============\n\nA detailed example-rich \"cookbook\"-style tutorial on using DendroPy can be found here:\n\n    http://packages.python.org/DendroPy/tutorial/index.html\n\nWhile the API reference can be found here:\n\n    http://packages.python.org/DendroPy/library/index.html\n\nSource Code Repository\n======================\n\nThe DendroPy source code is version-controlled using `Git <http://git-scm.com/>`_, and the `DendroPy Git repository <http://github.com/jeetsukumaran/DendroPy>`_ can be cloned by running::\n\n    $ git clone git://github.com/jeetsukumaran/DendroPy.git\n\nChange History\n==============\n\nThe major changes (new features and bug fixes) in the development history of DendroPy can be found here:\n\n    http://packages.python.org/DendroPy/changes.html\n\nMore Information\n=================\nMore information, including tutorials, library API references, citation, license, etc. can be found on the `DendroPy documentation website <http://packages.python.org/DendroPy/>`_:\n\n    http://packages.python.org/DendroPy/\n\n\nCurrent Release\n===============\n\nThe current release of DendroPy is version 3.7.1 (revision: fc59ea40e33c905a42dff673552c109fea24b33a, 2010-10-20 17:39:37)."}}, {"pk": 217, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.handlers.sql", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/handlers.html#sql", "version": "0.1.0", "platform": "UNKNOWN", "keywords": "sql database opendap dods dap data science climate oceanography meteorology", "summary": "A SQL handler for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This handler enables Pydap to serve data from any DB API 2\ncompatible database."}}, {"pk": 218, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "whoosh-igo", "license": "Apache License, Version 2.0", "author": "Hideaki Takahashi", "author_email": "mymelo@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "https://launchpad.net/igotokenizer/", "version": "0.4", "platform": "UNKNOWN", "keywords": "japanese,tokenizer", "summary": "tokenizers for Whoosh designed for Japanese language", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: Apache Software License\nNatural Language :: Japanese\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX :: Linux\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Linguistic", "description": "================================\n Japanese Tokenizers for Whoosh\n================================\n\nAbout\n=====\n\nTokenizers for Whoosh full text search library designed for Japanese language.\nThis package conteins two Tokenizers.\n\n* IgoTokenizer\n\n + requires igo-python(http://pypi.python.org/pypi/igo-python/) and its dictionary.\n\n* TinySegmenterTokenizer\n\n + requires TinySegmenter in Python(https://code.google.com/p/mhagiwara/source/browse/trunk/nltk/jpbook/tinysegmenter.py)\n\n* MeCabTokenizer\n\n * requires MeCab python binding(http://mecab.sourceforge.net/bindings.html)\n\n\nHow To Use\n==========\n\nIgoTokenizer::\n\n import igo.Tagger\n import WhooshJapaneseTokenizer\n\n tk = WhooshJapaneseTokenizer.IgoTokenizer(igo.Tagger.Tagger('ipadic'))\n scm = Schema(title=TEXT(stored=True, analyzer=tk), path=ID(unique=True,stored=True), content=TEXT(analyzer=tk))\n\n\nTinySegmenterTokenizer::\n\n import WhooshJapaneseTokenizer\n import tinysegmenter\n\n tk = WhooshJapaneseTokenizer.TinySegmenterTokenizer(tinysegmenter.TinySegmenter())\n scm = Schema(title=TEXT(stored=True, analyzer=tk), path=ID(unique=True,stored=True), content=TEXT(analyzer=tk))\n\n\n\nChangelog for Japanese Tokenizers for Whoosh\n============================================\n\n2011-02-19 -- 0.1\n    * first release.\n\n2011-02-21 -- 0.2\n    * add TinySegmenterTokenizer\n    * change module name\n\n2011-02-24 -- 0.3\n    * add FeatureFilter\n\n2011-02-27 -- 0.4\n    * add MeCabTokenizer\n    * add a mode for don't pickle igo tagger to minimize index."}}, {"pk": 219, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "AeroCalc", "license": "BSD", "author": "Kevin Horton", "author_email": "kevin01@kilohotel.com", "project_url": null, "maintainer_email": "", "home_page": "http://www.kilohotel.com/python/aerocalc", "version": "0.11", "platform": "UNKNOWN", "keywords": "", "summary": "Aeronautical Engineering Calculations", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Atmospheric Science", "description": "AeroCalc is a pure python package that performs various aeronautical \r\nengineering calculations.  Currently it provides airspeed conversions, \r\nstatic source error correction calculations, standard atmosphere \r\ncalculations and unit conversions."}}, {"pk": 220, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cGPolyEncode", "license": "UNKNOWN", "author": "Robert Coup", "author_email": "robert.coup@koordinates.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/py-gpolyencode/", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "gis,geospatial,google-maps,gmaps,mapping", "summary": "Google Maps Polyline encoding (C++ extension)", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Utilities", "description": "Encode line & polygon coordinates for use in Google Maps."}}, {"pk": 221, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "descartes", "license": "BSD", "author": "Sean Gillies", "author_email": "sean.gillies@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/sgillies/descartes/", "version": "1.0", "platform": "UNKNOWN", "keywords": "matplotlib gis geojson geometry", "summary": "Use geometric objects as matplotlib paths and patches", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "Descartes\n=========\n\nUse Shapely_ or GeoJSON-like geometric objects as matplotlib paths and patches\n\n.. image:: http://farm4.static.flickr.com/3662/4555372019_9bbed1f956_o_d.png\n   :width: 800\n   :height: 320\n\nRequires: matplotlib, numpy, and optionally Shapely 1.2.\n\nExample::\n\n  from matplotlib import pyplot\n  from shapely.geometry import LineString\n  from descartes import PolygonPatch\n  \n  BLUE = '#6699cc'\n  GRAY = '#999999'\n  \n  def plot_line(ax, ob):\n      x, y = ob.xy\n      ax.plot(x, y, color=GRAY, linewidth=3, solid_capstyle='round', zorder=1)\n  \n  line = LineString([(0, 0), (1, 1), (0, 2), (2, 2), (3, 1), (1, 0)])\n  \n  fig = pyplot.figure(1, figsize=(10, 4), dpi=180)\n  \n  # 1\n  ax = fig.add_subplot(121)\n  \n  plot_line(ax, line)\n  \n  dilated = line.buffer(0.5)\n  patch1 = PolygonPatch(dilated, fc=BLUE, ec=BLUE, alpha=0.5, zorder=2)\n  ax.add_patch(patch1)\n  \n  #2\n  ax = fig.add_subplot(122)\n  \n  patch2a = PolygonPatch(dilated, fc=GRAY, ec=GRAY, alpha=0.5, zorder=1)\n  ax.add_patch(patch2a)\n  \n  eroded = dilated.buffer(-0.3)\n  \n  # GeoJSON-like data works as well\n  \n  polygon = eroded.__geo_interface__\n  # >>> geo['type']\n  # 'Polygon'\n  # >>> geo['coordinates'][0][:2]\n  # ((0.50502525316941682, 0.78786796564403572), (0.5247963548222736, 0.8096820147509064))\n  patch2b = PolygonPatch(polygon, fc=BLUE, ec=BLUE, alpha=0.5, zorder=2)\n  ax.add_patch(patch2b)\n  \n  pyplot.show()\n\n\nSee also: examples/patches.py.\n\nDescartes is not associated with the identically named and apparently defunct\nproject at http://descartes.sourceforge.net/.\n\n.. _Shapely: http://gispython.org/lab/wiki/Shapely"}}, {"pk": 222, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pymc", "license": "Academic Free License", "author": "Christopher Fonnesbeck, Anand Patil and David Huard", "author_email": "fonnesbeck@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "pymc.googlecode.com", "version": "2.1beta", "platform": "UNKNOWN", "keywords": null, "summary": "Markov Chain Monte Carlo sampling toolkit.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Academic Free License (AFL)\nOperating System :: OS Independent\nProgramming Language :: Fortran\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "Bayesian estimation, particularly using Markov chain Monte Carlo (MCMC),\n            is an increasingly relevant approach to statistical estimation. However,\n            few statistical software packages implement MCMC samplers, and they are\n            non-trivial to code by hand. ``pymc`` is a python package that implements the\n            Metropolis-Hastings algorithm as a python class, and is extremely\n            flexible and applicable to a large suite of problems. ``pymc`` includes\n            methods for summarizing output, plotting, goodness-of-fit and convergence\n            diagnostics.\n\n            ``pymc`` only requires ``NumPy``. All other dependencies such as ``matplotlib``,\n            ``SciPy``, ``pytables``, ``sqlite`` or ``mysql`` are optional."}}, {"pk": 223, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Ctrax", "license": "UNKNOWN", "author": "Kristin Branson", "author_email": "bransonk@janelia.hhmi.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.dickinson.caltech.edu/Ctrax", "version": "0.1.6", "platform": "Windows,Linux", "keywords": null, "summary": "Ctrax: The Caltech Multiple Fly Tracker", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Image Recognition\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Medical Science Apps.", "description": "Ctrax: The Caltech Multiple Fly Tracker\n\n(c) 2007-2010 The Caltech Ethomics Project\nhttp://www.dickinson.caltech.edu/ctrax\nbranson@caltech.edu\n\nCtrax is an open-source, freely available, machine vision program for\nestimating the positions and orientations of many walking flies,\nmaintaining their individual identities over long periods of time. It\nwas designed to allow high-throughput, quantitative analysis of\nbehavior in freely moving flies. Our primary goal in this project is\nto provide quantitative behavior analysis tools to the neuroethology\ncommunity, thus we've endeavored to make the system adaptable to other\nlab's setups. We have assessed the quality of the tracking results for\nour setup, and found that it can maintain fly identities indefinitely\nwith minimal supervision, and on average for 1.5 fly-hours\nautomatically."}}, {"pk": 224, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "magic_square", "license": "MIT License", "author": "Alec Mihailovs", "author_email": "alec@mihailovs.com", "project_url": null, "maintainer_email": null, "home_page": "http://mihailovs.com/Alec/", "version": "0.2", "platform": "UNKNOWN", "keywords": null, "summary": "Simple operations with magic squares.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Education\nTopic :: Games/Entertainment\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Simple operations with magic squares\n      \n      **Prerequisites:**\n          - NumPy_\n\n      **Functions:**\n          - `ismagic(A)` -- test whether *A* is a magic square.\n          - `magic(N)` -- create an *N* by *N* magic square.\n          - `magic_constant(A)` -- calculate the magic constant of *A*.\n\n      .. _NumPy: http://www.scipy.org/Download"}}, {"pk": 225, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.th", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.th", "version": "4.6", "platform": "any", "keywords": "utility", "summary": "PyUtilib test harness package.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==================\npyutilib.th README\n==================\n\nThis Python package includes utilities for testing Python software.  The \nmain component of this package is an extension of **unittest** to \nsupport new testing capabilities (e.g. tests that perform comparison with baseline data, and dynamic registration of test methods).\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 226, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Nodes", "license": "UNKNOWN", "author": "Alexander Sedov aka Electronic from Lomy.RU", "author_email": "Elec.Lomy.RU@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "1.2", "platform": "UNKNOWN", "keywords": null, "summary": "Neuralnets-based Artificial Intelligence implementation", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Nodes is yet another Pythonic AI library with NN-similar concept.\nCalculations are splitted into \"nodes\" - small objects with programmers-defined\nactions. Nodes are connected into digraph-like network. Every Node has as much\ninput and output arcs as you want (actually, as its shape declares, but it is\nuser-defined too). For information, see README.\nEditor, Twisted-matrix integration and full documentation may be available\nin future versions.\nIt is highly recommended to use Python Syncronized Compiler (python-psyco)\nto accelerate speed."}}, {"pk": 227, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.bvp1lg", "license": "Noncommercial, see LICENSE.txt", "author": "Pauli Virtanen", "author_email": "pav@iki.fi", "project_url": null, "maintainer_email": null, "home_page": "http://www.iki.fi/pav/software/bvp", "version": "0.2.5", "platform": "UNKNOWN", "keywords": null, "summary": "Boundary value problem (legacy) solvers for ODEs", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: Free for non-commercial use\nTopic :: Scientific/Engineering", "description": "Python-wrapped legacy solvers for boundary value problems for ODEs.\n\nThese are implemented by wrapping the COLNEW and MUS Fortran\ncodes from netlib.org."}}, {"pk": 228, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "units", "license": "Python Software Foundation License", "author": "Aran Donohue", "author_email": "aran@arandonohue.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.arandonohue.com/hg/units", "version": "0.04", "platform": "all", "keywords": null, "summary": "Python support for quantities with units", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: Python Software Foundation License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "Provides support for quantities and units, which strictly disallow\ninvalid operations between incompatible quantities. For example, we cannot add \n2 metres to 5 seconds, because this doesn't make sense.\n\nWhy?\n\nFrom Wikipedia:\n\nThe Mars Climate Orbiter was intended to enter orbit at an altitude of\n140-150 km (460,000-500,000 ft.) above Mars. However, a navigation error\ncaused the spacecraft to reach as low as 57 km (190,000 ft.). The spacecraft\nwas destroyed by atmospheric stresses and friction at this low altitude. The\nnavigation error arose because a NASA subcontractor (Lockheed Martin) used\nImperial units (pound-seconds) instead of the metric system.\n\nInstallation\n============\n\nThis module is distributed via PyPI. So, you can do::\n\n pip install units\n\nor::\n\n easy_install units\n \nor, you can download a bundle yourself at http://pypi.python.org/pypi/units/\n\nIf you want the latest::\n\n pip install -e hg+http://www.arandonohue.com/hg/units#egg=units\n \n \nHow to Use\n==========\n\nMake Quantities\n---------------\n\nUnits are objects that you use to make quantities::\n\n  >>> from units import unit\n  >>> metre = unit('m')\n  >>> print(metre(7) + metre(11))\n  18 m\n \nYou can mix and match these quantities in some ways::\n\n  >>> from units import unit\n  >>> metre = unit('m')\n  >>> second = unit('s')\n  >>> print(metre(10) / second(2))\n  5 m / s\n  >>> print(metre(10) ** 3)\n  1000 m * m * m\n \nBut if you make a mistake, you get a safety net::\n\n  >>> from units import unit\n  >>> unit('m')(5) + unit('s')(5)\n  Traceback (most recent call last):\n  ...\n  IncompatibleUnitsError\n\nMake Your Own Units\n-------------------\nBefore you start making your own units, you should check out the units that \nyou get for free::\n\n  >>> import units.predefined\n  >>> units.predefined.define_units()\n \nIt includes all the official SI units, some units for measuring time such as \ndays and weeks, units for volumes like cups, gallons and litres, imperial \nunits and more.\n\nYou've already seen how to make your own simple units. You call\nthe unit function and give it a string::\n  \n  >>> from units import unit\n  >>> blog = unit('blog')\n  >>> print(blog(3))\n  3 blog\n\nThese units are automatically incompatible with other units.\n\nYou can combine units with multiplication and division to make new units::\n\n  >>> from units import unit\n  >>> blogs_per_network = unit('blog') / unit('network')\n  >>> print(blogs_per_network(2.34))\n  2.34 blog / network\n\nThere's a built-in shortcut for making new units that are scalar multiples\nof other units::\n\n  >>> from units import unit, scaled_unit\n  >>> sickle = scaled_unit('sickle', 'knut', 29)\n  >>> galleon = scaled_unit('galleon', 'sickle', 17)\n  >>> knut = unit('knut')\n  >>> galleon(3.0) + sickle(1.0) - knut(25.0) == knut(1483)\n  True\n  \nThere's also a shortcut for giving names to slightly more complicated units::\n\n  >>> from units import unit, named_unit\n  >>> from units.predefined import define_units\n  >>> define_units()\n  >>> twp = named_unit('tweetpack', ['tweet', 'meme'], ['day'], 5)\n  >>> # A tweetpack is 5 tweetmemes per day\n  >>> print(twp(2))\n  2 tweetpack\n  >>> tweet, meme, day = [unit(x) for x in ['tweet', 'meme', 'day']]\n  >>> print(twp(5) - (tweet(5) * meme(4) / day(2)))\n  3.0 tweetpack\n\nIf two units are compatible, you can convert between them easily::\n\n  >>> from units import unit\n  >>> from units.predefined import define_units\n  >>> define_units()\n  >>> furlongs_per_fortnight = unit('fur') / unit('fortnight')\n  >>> kph = unit('km') / unit('h')\n  >>> print(furlongs_per_fortnight(kph(100)))\n  167024.576473 fur / fortnight\n  \nYou can also use lower-level constructors to make your own units and\nquantities. The ways shown above are easier, though.\n\nWarnings\n--------\n\nThis module doesn't solve problems with numerical accuracy or \nfloating point conversions::\n\n  >>> from units import unit\n  >>> unit('m')(5) / unit('m')(7)\n  0\n  \nMore dangerously, certain internal operations have implicit arithmetic\nthat can surprise you::\n\n  >>> from units import unit, scaled_unit\n  >>> sickle = scaled_unit('sickle', 'knut', 29)\n  >>> galleon = scaled_unit('galleon', 'sickle', 17)\n  >>> knut = unit('knut')\n  >>> galleon(3) + sickle(1) - knut(25) == galleon(3)\n  True\n\n\nUsing Modified Python\n---------------------\n\nIn units-enhanced Python, you can do::\n\n  print(2cm / 0.5 s)\n  -> 4.0 cm / s\n\nUnits-enhanced Python is a version of PyPy with built-in support\nfor units. You can find it in the unitPython directory. Essentially,\napply the supplied patches to r66797 of PyPy. If you're on a suitable\nUNIX, the included unitPython/unitPython.sh does this for you.\n\n@requires: U{Python<http://python.org/>} >= 2.5\n@since: 2009-Aug-10\n@status: under development"}}, {"pk": 229, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pymilia", "license": "GPLv3", "author": "Sergio Pascual", "author_email": "sergiopr@astrax.fis.ucm.es", "project_url": null, "maintainer_email": null, "home_page": "https://guaix.fis.ucm.es/projects/milia/wiki", "version": "0.3.0", "platform": "UNKNOWN", "keywords": null, "summary": "Cosmological distances and ages", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Other Environment\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy", "description": "This is PyMilia, a set of Python bindings for milia.\n        \n         Milia is library that provides distances and ages in cosmology.\n\n         Pymilia requires a functional milia installation, and \n         boost (http://www.boost.org/), a C++ library that provides \n         the wrapping library.\n\n         This package is distributed under GPL , either version 3 of the License, or\n         (at your option) any later version. See the file COPYING for details."}}, {"pk": 230, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "googlemaps", "license": "Lesser Affero General Public License v3", "author": "John Kleint", "author_email": "py-googlemaps-general@lists.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://sourceforge.net/projects/py-googlemaps/", "version": "1.0.2", "platform": "UNKNOWN", "keywords": "google maps local search ajax api geocode geocoding directions navigation json", "summary": "Easy geocoding, reverse geocoding, driving directions, and local search in Python via Google.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Affero General Public License v3\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: GIS", "description": "An easy-to-use Python wrapper for the Google Maps and Local Search APIs.\n\n    **Geocoding**: convert a postal address to latitude and longitude\n    \n    >>> from googlemaps import GoogleMaps\n    >>> gmaps = GoogleMaps(api_key)\n    >>> address = 'Constitution Ave NW & 10th St NW, Washington, DC'\n    >>> lat, lng = gmaps.address_to_latlng(address)\n    >>> print lat, lng\n    38.8921021 -77.0260358\n    \n    **Reverse Geocoding**: find the nearest address to (lat, lng)\n        \n    >>> destination = gmaps.latlng_to_address(38.887563, -77.019929)\n    >>> print destination\n    Independence and 6th SW, Washington, DC 20024, USA\n    \n    **Local Search**: find places matching a query near a given location\n    \n    >>> local = gmaps.local_search('cafe near ' + destination)\n    >>> print local['responseData']['results'][0]['titleNoFormatting']\n    Vie De France Bakery & Cafe\n    \n    **Directions**: turn-by-turn directions, distance, time, etc. from \n    point A to point B\n    \n    >>> directions = gmaps.directions(address, destination)\n    >>> print directions['Directions']['Distance']['meters']\n    1029\n    >>> print directions['Directions']['Duration']['seconds']\n    106\n    >>> for step in directions['Directions']['Routes'][0]['Steps']:\n    ...     print step['descriptionHtml']\n    Head <b>east</b> on <b>Constitution Ave NW</b> toward <b>9th St NW</b>\n    Take the 2nd <b>right</b> onto <b>7th St NW</b>\n    Turn <b>left</b> at <b>Independence Ave SW</b>\n    \n    This software is in no way associated with or endorsed by Google Inc.\n    Use of the Google Maps API is governed by its Terms of Service:\n    http://code.google.com/apis/maps/terms.html.  Note in particular that\n    you will need your own Google Maps API key to use this service,\n    and that there are rate limits to the number of requests you can\n    make."}}, {"pk": 231, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.responses.ddx", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/responses/ddx.html", "version": "0.1.2", "platform": "UNKNOWN", "keywords": "xml ddx dap opendap dods data", "summary": "Experimental DDX response for pydap server", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "An experimental implementation of the DDX response, based on the behavior of the official OPeNDAP server.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/responses/ddx#egg=dap.responses.ddx-dev>`_."}}, {"pk": 232, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "thermopy", "license": "UNKNOWN", "author": "Guillem Borrell i Nogueras", "author_email": "guillem@torroja.dmt.upm.es", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/thermopy", "version": "0.3", "platform": "UNKNOWN", "keywords": null, "summary": "Some utilities for Thermodynamics and Thermochemistry", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nNatural Language :: Spanish\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 233, "model": "importing.pypicache", "fields": {"maintainer": "Ray Buvel", "name": "clnum", "license": "GPL", "author": "Ray Buvel", "author_email": "rlbuvel@gmail.com", "project_url": null, "maintainer_email": "rlbuvel@gmail.com", "home_page": "http://calcrpnpy.sourceforge.net/clnum.html", "version": "1.6", "platform": "", "keywords": "math functions rational fraction arbitrary precision float complex", "summary": "Rational and arbitrary precision floating point numbers", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: C++\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Mathematics", "description": "Adds rational numbers and arbitrary precision floating point numbers in real and\r\ncomplex form to Python.  Also provides arbitrary precision floating point\r\nreplacements for the functions in the math and cmath standard library modules."}}, {"pk": 234, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "wavemol.core", "license": "BSD", "author": "Stefano Borini", "author_email": "stefano.borini+wavemol@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://wavemol.org", "version": "0.1.0", "platform": "UNKNOWN", "keywords": "computational theoretical chemistry utilities wavemol", "summary": "Core functionality for wavemol", "classifiers": "License :: OSI Approved :: BSD License\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "This package is part of the wavemol set of tools for computational chemists.\nIt contains core functionality useful as a basis for the other modules."}}, {"pk": 235, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "GridDataFormats", "license": "GPLv3", "author": "Oliver Beckstein", "author_email": "orbeckst@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "https://github.com/orbeckst/GridDataFormats", "version": "0.2.2", "platform": "any", "keywords": "science array density", "summary": "Reading and writing of data on regular grids in Python", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "The *gridDataFormats* package provides classes to unify reading and\r\nwriting n-dimensional datasets. One can read grid data from files,\r\nmake them available as a :class:`Grid` object, and allows one to\r\nwrite out the data again.\r\n\r\nThe Grid class\r\n--------------\r\n\r\nA :class:`Grid` consists of a rectangular, regular, N-dimensional\r\narray of data. It contains\r\n(1) The position of the array cell edges.\r\n(2) The array data itself.\r\n\r\nThis is equivalent to knowing\r\n(1) The origin of the coordinate system (i.e. which data cell\r\n    corresponds to (0,0,...,0)\r\n(2) The spacing of the grid in each dimension.\r\n(3) The data on a grid.\r\n\r\n:class:`Grid` objects have some convenient properties:\r\n\r\n* The data is represented as a :class:`numpy.array` and thus shares\r\n  all the advantages coming with this sophisticated and powerful\r\n  library.\r\n\r\n* They can be manipulated arithmetically, e.g. one can simply add or\r\n  subtract two of them and get another one, or multiply by a\r\n  constant. Note that all operations are defined point-wise (see the\r\n  :mod:`numpy` documentation for details) and that only grids defined\r\n  on the same cell edges can be combined.\r\n\r\n* A :class:`Grid` object can also be created from within python code\r\n  e.g. from the output of the :func:`numpy.histogramdd` function.\r\n\r\n* The representation of the data is abstracted from the format that\r\n  the files are saved in. This makes it straightforward to add\r\n  additional readers for new formats.\r\n\r\n* The data can be written out again in formats that are understood by\r\n  other programs such as VMD_ or PyMOL_.\r\n\r\n.. _VMD: http://www.ks.uiuc.edu/Research/vmd/\r\n.. _PyMOL: http://www.pymol.org/\r\n\r\n\r\nSupported file formats\r\n----------------------\r\n\r\nThe package can be easily extended. The OpenDX format is widely\r\nunderstood by many molecular viewers and is sufficient for many\r\napplications that were encountered so far. Hence, at the moment only a\r\nsmall number of file formats is directly supported.\r\n\r\n==========  =========  =====  =====  =========================================\r\nformat      extension  read   write  remarks\r\n==========  =========  =====  =====  =========================================\r\nOpenDX_     dx         x      x      subset of OpenDX implemented\r\ngOpenMol    plt        x            \r\npickle      pickle     x      x      standard Python pickle of the Grid class\r\n==========  =========  =====  =====  ========================================="}}, {"pk": 236, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nebgbhist", "license": "MIT", "author": "Paul Joseph Davis", "author_email": "davisp@neb.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/davisp/nebgbhist", "version": "0.0.5", "platform": "any", "keywords": "bioinformatics Genbank annotation history", "summary": "Annotation histories from Genbank files.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "nebgbhist\n=========\n\nTools for building annotation histories from multiple Genbank files.\n\nExample\n=======\n\n::\n\n    $ mkdir gbhist\n    $ neb-rev-fetch -d gbhist NC_008512\n    $ neb-gbhist -d gbhist | neb-diff-apply NC_008512.git\n    $ git --git-dir=NC_008512.git gc --aggressive\n    $ neb-validate-history -p NC_008512.git -g gbhist/2009-04-29-04-04.gbk\n\nPlaying with files\n==================\n\nIf you clone the pack repository after building you can poke around at the\ncontents on the file system. For larger genomes with lots of edits this may run\nafoul of directory entry limits until I rewrite the object storage. For the\nCarsonella (NC_008512) example I use there isn't an issue.\n\n::\n\n    $ git clone NC_008512.git\n    $ cd NC_008512\n    $ ls -1\n    accession  dblink     keywords   objects/   seq/       version\n    comment    definition locus      ref/       source\n\nFiles in the root directory represent keywords defined in the Genbank file. The\nref and seq subdirectories contain information about references and the sequence\nhashes. The objects directory lists the features in the history. The files\nobjects/known and objects/alive are dictionaries of hashes that point toward\nthe current version of a feature at a given location. Active features are\nanything that is not deleted or replaced with a new version.\n\nI recommend that you work with nebpack.Pack objects if you want to actually do\nanything with the objects."}}, {"pk": 237, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coinor.pulp", "license": "Copyright (c) 2010, Stuart Mitchell\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n\n    - Redistributions of source code must retain the above copyright notice, \n      this list of conditions and the following disclaimer.\n\n    - Redistributions in binary form must reproduce the above copyright notice,\n      this list of conditions and the following disclaimer in the documentation \n      and/or other materials provided with the distribution.\n\n      \nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND \nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED \nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE \nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE \nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL \nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR \nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER \nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, \nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE \nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "author": "Stuart Mitchell", "author_email": "s.mitchell@auckland.ac.nz", "project_url": null, "maintainer_email": null, "home_page": "http://www.coin-or.org/PuLP/", "version": "1.0.4", "platform": "UNKNOWN", "keywords": null, "summary": "This is a package that wraps pulp and imports it into the namespace\npackage coinor.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "====\ncoinor.pulp\n====\n\nThis is a package that wraps pulp and imports it into the namespace package\ncoinor.\n\nFor all other documentation please see the documentation in the pulp project."}}, {"pk": 238, "model": "importing.pypicache", "fields": {"maintainer": "Minh-Tri Pham, Viet-Dung D. Hoang", "name": "pycv", "license": "GNU Public License version 3", "author": "Minh-Tri Pham, Viet-Dung D. Hoang, and Tat-Jen Cham", "author_email": "mtpham@ntu.edu.sg", "project_url": null, "maintainer_email": "mtpham@ntu.edu.sg", "home_page": "http://www.ntu.edu.sg/home5/pham0004/pycv/", "version": "0.2.2", "platform": "Windows,Linux,Unix", "keywords": "", "summary": "PyCV - A Computer Vision Package for Python Incorporating Fast Training of Face Detection", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "PyCV is a package of C++ and Python modules implementing various algorithms\r\nthat are useful in computer vision, and augments the capabilities of OpenCV.\r\nIn particular, PyCV provides implementations for:\r\n\r\n- Fast training and selection of Haar-like features for a weak classifier\r\n  [Pham2007b]_.  This is currently the world's fastest method for training a face\r\n  detector. It runs in just a few hours, while most existing methods run in\r\n  days or weeks.\r\n- Asymmetric Online Boosting [Pham2007a]_: a variant of AdaBoost that learns\r\n  incrementally using an asymmetric goal as the learning criterion.\r\n\r\nAdditionally, PyCV contains many useful modules for computer vision and\r\nmachine learning, specially boosting techniques, Haar-like features, and face\r\ndetection.\r\n\r\nThe package is primarily developed by Minh-Tri Pham, as part of his PhD\r\nresearch on face detection. This research is being carried out in the Centre\r\nfor Multimedia & Network Technology (CeMNet), School of Computer Engineering,\r\nNanyang Technological University, Singapore.\r\n\r\nCopyright 2007 Nanyang Technological University, Singapore.\r\n\r\n:Founding Contributors:\r\n  Minh-Tri Pham <mtpham@ntu.edu.sg> -- Primary author\r\n\r\n  Viet-Dung D. Hoang <hoan0008@ntu.edu.sg> -- Contributing author\r\n\r\n  Tat-Jen Cham <astjcham@ntu.edu.sg> -- Supervising faculty\r\n\r\n\r\nReferences\r\n----------\r\n\r\n.. [Pham2007a] Minh-Tri Pham and Tat-Jen Cham. Online Learning Asymmetric\r\n   Boosted Classifiers for Object Detection. In Proc. IEEE Computer Society\r\n   Conference on Computer Vision and Pattern Recognition (CVPR'07),\r\n   Minneapolis, MN, 2007.\r\n\r\n.. [Pham2007b] Minh-Tri Pham and Tat-Jen Cham. Fast Training and Selection of\r\n   Haar features using Statistics in Boosting-based Face Detection. In Proc.\r\n   11th IEEE International Conference on Computer Vision (ICCV'07), Rio de\r\n   Janeiro, Brazil, 2007."}}, {"pk": 239, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "petsc", "license": "PETSc", "author": "Lisandro Dalcin", "author_email": "dalcinl@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.mcs.anl.gov/petsc/", "version": "3.1.post8", "platform": "POSIX", "keywords": "PETSc,MPI", "summary": "PETSc: Portable, Extensible Toolkit for Scientific Computation", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: Public Domain\nOperating System :: POSIX\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Fortran\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "The Portable, Extensible Toolkit for Scientific Computation (PETSc),\nis a suite of data structures and routines for the scalable (parallel)\nsolution of scientific applications modeled by partial differential\nequations. It employs the Message Passing Interface (MPI) standard for\nall message-passing communication."}}, {"pk": 240, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pupynere", "license": "MIT", "author": "Roberto De Almeida", "author_email": "roberto@dealmeida.net", "project_url": null, "maintainer_email": null, "home_page": "http://dealmeida.net/projects/pupynere", "version": "1.0.13", "platform": "UNKNOWN", "keywords": "netcdf data array math", "summary": "NetCDF file reader and writer.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pupynere is a Python module for reading and writing NetCDF files,\nusing the same API as Scientific.IO.NetCDF and pynetcdf. It depends only\non Numpy, so you don't need to have the NetCDF library installed.\n\nChangelog:\n\n1.0.13\n  Fixed bug when reading character variables without mmap.\n\n1.0.12\n  No idea, sorry. :-/  \n\n1.0.11\n  Fixed bug with 64 bit architectures.\n\n1.0.10\n  Fixed bug when packing integer attributes in 64-bit systems.\n\n1.0.9\n  Should work with Python 2.3.\n  Accepts file objects instead of only filenames.\n\n1.0.8\n  Allow writing version 2 files (Large Files).\n\n1.0.7\n  Removed reads from asserts to allow PYTHONOPTIMIZE.\n\n1.0.6\n  Allows zero-length record variables.\n\n1.0.5\n  Added the option to open files without using mmap, since mmap can't\n  handle huge files on Windows.\n\n1.0.4\n  Fixed packing of dimensions when writing a file. The order was being\n  read from a dictionary (essentially unordered), instead of from the list\n  with the proper order.\n\n1.0.3\n  Fixed bug so that it can write scalar variables.\n\n1.0.2\n  Fixed broken 1.0.1, ``var.shape`` was returning the current number\n  of records in the first dimension, breaking the detection of record\n  variables.\n\n1.0.1\n  Changed the code to read the variable shape from the underlying\n  data object.\n\n1.0.0\n  Initial stable release. Handles record arrays properly (using a single\n  mmap for all record variables) and writes files."}}, {"pk": 241, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "hedge", "license": "GPLv3", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/hedge", "version": "0.91", "platform": "UNKNOWN", "keywords": null, "summary": "Hybrid Easy Discontinuous Galerkin Environment", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization", "description": "hedge is an unstructured, high-order, parallel\n            Discontinuous Galerkin solver for partial differential\n            equations.   \n            \n            Features:\n\n            * Supports simplicial unstructured meshes in two and\n              three dimensions (i.e. triangles and tetrahedra)\n            * Approximates using orthogonal polynomials of any degree\n              (and therefore to any order of accuracy) you specify at\n              runtime\n            * Solves PDEs in parallel using MPI \n            * Easy to use\n            * Powerful Parallel Visualization"}}, {"pk": 242, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "rootplot", "license": "UNKNOWN", "author": "Jeff Klukas", "author_email": "klukas@wisc.edu", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/rootplot/", "version": "2.2.1", "platform": "UNKNOWN", "keywords": null, "summary": "Tools for quick and beautiful plotting with ROOT", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Utilities", "description": "Includes command-line scripts and an API for easily producing complex canvases from ROOT histograms along with tools for producing histograms from TTrees and quickly displaying the contents of a ROOT file and a library for producing matplotlib figures from ROOT input."}}, {"pk": 243, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gc3pie", "license": "LGPL", "author": "Grid Computing Competence Centre, University of Zurich", "author_email": "gc3utils-dev@gc3.lists.uzh.ch", "project_url": null, "maintainer_email": null, "home_page": "http://gc3pie.googlecode.com/", "version": "1.0rc6", "platform": "UNKNOWN", "keywords": "grid arc globus sge gridengine ssh gamess rosetta batch job", "summary": "A Python library and simple command-line frontend for computational job submission to multiple resources.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: DFSG approved\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: System :: Distributed Computing", "description": "========================================================================\n    GC3Pie\n========================================================================\n\n.. This file follows reStructuredText markup syntax; see\n   http://docutils.sf.net/rst.html for more information\n\n\nGC3Pie is a suite of Python classes (and command-line tools built\nupon them) to aid in submitting and controlling batch jobs to clusters\nand grid resources seamlessly.  GC3Pie aims at providing the\nbuilding blocks by which Python scripts that combine several\napplications in a dynamic workflow can be quickly developed.\n\nThe GC3Pie suite is comprised of three main components: \n\n * GC3Libs: A python package for controlling the life-cycle of a Grid or batch computational job\n * GC3Utils: Command-line tools exposing the main functionality provided by GC3Libs\n * GC3Apps: Driver scripts to run large job campaigns \n\n\nGC3Libs\n=======\n\nGC3Libs provides services for submitting computational jobs to Grids\nand batch systems and controlling their execution, persisting job\ninformation, and retrieving the final output.  \n\nGC3Libs takes an _application-oriented approach to batch computing.  A\ngeneric ``Application`` class provides the basic operations for\ncontrolling remote computations, but different ``Application``\nsubclasses can expose adapted interfaces, focusing on the most\nrelevant aspects of the application being represented. Specific\ninterfaces are already provided for the GAMESS_ and Rosetta_ suites;\nnew ones can be easily created by subclassing the generic\n``Application`` class.\n\n\nGC3Utils\n========\n\nMost of the time users have lots of different accounts on several\ndiverse resources. The idea underlying GC3Utils is that a user can\nsubmit and control a computational job from one single place with a few\nsimple commands.\n\nCommands are provided to submit a job (``gsub``), check its running\nstatus (``gstat``), get a snapshot of the output files (``gget``,\n``gtail``), or cancel it (``gkill``).\n\n\nGC3Apps\n=======\n\nThere is a need in some scientific communities, to run large job\ncampaigns to analyze a vast number of data files with the same\napplication.  The single-job level of control implemented by GC3Utils\nin this case is not enough: you would have to implement \"glue scripts\"\nto control hundreds or thousand scripts at once.  GC3Pie has provisons\nfor this, in the form of re-usable Python classes that implement a\nsingle point of control for job families.\n\nThe GC3Apps scripts are driver scripts that run job campaigns using\nthe supported applications on a large set of input data.  They can be\nused in production as-is, or adapted to suit your data processing needs.\n\n\nInstallation instructions and further reading\n=============================================\n\nFor up-to-date information, please visit the GC3Pie home page at:\nhttp://gc3pie.googlecode.com/\n\nInstallation instructions are in the ``INSTALL.txt`` file (in this\nsame directory), or can be read online at: \nhttp://code.google.com/p/gc3pie/wiki/InstallGC3Pie\n\n\n.. References\n\n.. _GC3Pie: http://gc3pie.googlecode.com/\n.. _GAMESS: http://www.msg.chem.iastate.edu/gamess/\n.. _Rosetta: http://www.rosettacommons.org/\n\n\n.. (for Emacs only)\n..\n  Local variables:\n  mode: rst\n  End:"}}, {"pk": 244, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "tilelite", "license": "BSD", "author": "Dane Springmeyer", "author_email": "dbsgeo@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/springmeyer/tilelite/", "version": "0.1.5", "platform": "UNKNOWN", "keywords": "mapnik,gis,geospatial,openstreetmap,tiles,cache", "summary": "Lightweight WSGI tile-server, written in Python, using Mapnik rendering and designed to serve tiles in the OSM/Google scheme.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Django\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Scientific/Engineering :: GIS\nTopic :: Utilities", "description": "UNKNOWN"}}, {"pk": 245, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "geolocator", "license": "http://www.fsf.org/licensing/licenses/lgpl.txt", "author": "Petri Savolainen", "author_email": "petri.savolainen@iki.fi", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/geolocator", "version": "0.1.1", "platform": "any", "keywords": "", "summary": "geolocator library: locate places and calculate distances between them", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "The geolocator library provides a common interface to location-related data\r\nfrom various sources and provides means to calculate distances between places.\r\nCurrently the MaxMind country & city geoip data sources are supported. There is\r\nalso some preliminary support for using GNS (GEOnet Names Server )data. For \r\ndistance calculation, the Haversine function is used.\r\n\r\nThe library can be useful for example to implement location-based features in\r\ndifferent www frameworks; for an example of that, see the GeoLocation Zope /\r\nCMF / Plone package from which this library was spun off. Please note, however,\r\nthat there is nothing www-specific in the library, nor does it have any\r\nexternal dependencies.\r\n\r\nIf you use this library, please send me email; I would like to add links to\r\nthe package home page to point to other software using this library."}}, {"pk": 246, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gmpy", "license": "UNKNOWN", "author": "Alex Martelli", "author_email": "aleaxit@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/gmpy/", "version": "1.11rc1", "platform": "UNKNOWN", "keywords": null, "summary": "MPIR/GMP interface to Python 2.4+ and 3.x", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: C\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 247, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "hachoir-regex", "license": "GNU GPL v2", "author": "Victor Stinner", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/haypo/hachoir/wiki/hachoir-regex", "version": "1.0.5", "platform": "UNKNOWN", "keywords": null, "summary": "Manipulation of regular expressions (regex)", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Education\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Interpreters\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing\nTopic :: Utilities", "description": "Hachoir regex\n=============\n\nhachoir-regex is a Python library for regular expression (regex or regexp)\nmanupulation. You can use a|b (or) and a+b (and) operators. Expressions are\noptimized during the construction: merge ranges, simplify repetitions, etc.\nIt also contains a class for pattern matching allowing to search multiple\nstrings and regex at the same time.\n\nWebsite: http://bitbucket.org/haypo/hachoir/wiki/hachoir-regex\n\nChangelog\n=========\n\nVersion 1.0.5 (2010-01-28)\n\n * Create a MANIFEST.in to include extra files: regex.rst, test_doc.py, etc.\n * Create an INSTALL file\n\nVersion 1.0.4 (2010-01-13)\n\n * Support \\b (match a word)\n * Fix parser: support backslash in a range, eg. parse(r\"[a\\]x]\")\n\nVersion 1.0.3 (2008-04-01)\n\n * Raise SyntaxError on unsupported escape character\n * Two dot atoms are always equals\n\nVersion 1.0.2 (2007-07-12)\n\n * Refix PatternMatching without any pattern\n\nVersion 1.0.1 (2007-06-28)\n\n * Fix PatternMatching without any pattern\n\nVersion 1.0 (2007-06-28)\n\n * First public version\n\nRegex examples\n==============\n\nRegex are optimized during their creation:\n\n   >>> from hachoir_regex import parse, createRange, createString\n   >>> createString(\"bike\") + createString(\"motor\")\n   <RegexString 'bikemotor'>\n   >>> parse('(foo|fooo|foot|football)')\n   <RegexAnd 'foo(|[ot]|tball)'>\n\nCreate character range:\n\n   >>> regex = createString(\"1\") | createString(\"3\")\n   >>> regex\n   <RegexRange '[13]'>\n   >>> regex |= createRange(\"2\", \"4\")\n   >>> regex\n   <RegexRange '[1-4]'>\n\nAs you can see, you can use classic \"a|b\" (or) and \"a+b\" (and)\nPython operators. Example of regular expressions using repetition:\n\n   >>> parse(\"(a{2,}){3,4}\")\n   <RegexRepeat 'a{6,}'>\n   >>> parse(\"(a*|b)*\")\n   <RegexRepeat '[ab]*'>\n   >>> parse(\"(a*|b|){4,5}\")\n   <RegexRepeat '(a+|b){0,5}'>\n\nCompute minimum/maximum matched pattern:\n\n   >>> r=parse('(cat|horse)')\n   >>> r.minLength(), r.maxLength()\n   (3, 5)\n   >>> r=parse('(a{2,}|b+)')\n   >>> r.minLength(), r.maxLength()\n   (1, None)\n\nPattern maching\n===============\n\nUse PatternMaching if you would like to find many strings or regex in a string.\nUse addString() and addRegex() to add your patterns.\n\n    >>> from hachoir_regex import PatternMatching\n    >>> p = PatternMatching()\n    >>> p.addString(\"a\")\n    >>> p.addString(\"b\")\n    >>> p.addRegex(\"[cd]\")\n\nAnd then use search() to find all patterns:\n\n    >>> for start, end, item in p.search(\"a b c d\"):\n    ...    print \"%s..%s: %s\" % (start, end, item)\n    ...\n    0..1: a\n    2..3: b\n    4..5: [cd]\n    6..7: [cd]\n\nYou can also attach an objet to a pattern with 'user' (user data) argument:\n\n    >>> p = PatternMatching()\n    >>> p.addString(\"un\", 1)\n    >>> p.addString(\"deux\", 2)\n    >>> for start, end, item in p.search(\"un deux\"):\n    ...    print \"%r at %s: user=%r\" % (item, start, item.user)\n    ...\n    <StringPattern 'un'> at 0: user=1\n    <StringPattern 'deux'> at 3: user=2\n\n\nInstallation\n============\n\nWith distutils:\n\n   sudo ./setup.py install\n\nOr using setuptools:\n\n   sudo ./setup.py --setuptools install"}}, {"pk": 248, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "diffpy.pdfgui", "license": "BSD", "author": "Pavol Juhas", "author_email": "pj2192@columbia.edu", "project_url": null, "maintainer_email": "", "home_page": "http://www.diffpy.org/", "version": "1.0-r5261-20100512", "platform": "UNKNOWN", "keywords": "PDF structure refinement GUI", "summary": "GUI for PDF simulation and structure refinement.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: MacOS X\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications\nIntended Audience :: Science/Research\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 249, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "neuronpy", "license": "MIT License", "author": "Thomas McTavish", "author_email": "Thomas.McTavish@yale.edu", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/tommctavish/neuronpy/", "version": "0.1.2", "platform": "any", "keywords": "neuron neural simulation simulator raster", "summary": "Python interfaces and utilities for interacting with the NEURON simulator and analyzing neural data.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: Web Environment\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "NeuronPy\n~~~~~~~~\n\nA library of Python interfaces and utilities for the\nNEURON simulator and analysis of neural data."}}, {"pk": 250, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Polygon", "license": "LGPL for Polygon, other for gpc", "author": "Joerg Raedler", "author_email": "jr@j-raedler.de", "project_url": null, "maintainer_email": null, "home_page": "http://www.j-raedler.de/projects/polygon", "version": "3.0.3", "platform": "UNKNOWN", "keywords": null, "summary": "Polygon is a python package that handles polygonal shapes in 2D", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nLicense :: Other/Proprietary License\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.0\nProgramming Language :: Python :: 3.1\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization", "description": "THIS VERSION WORKS WITH PYTHON-3.x ONLY!\n\nPolygon is a python package that handles polygonal shapes in 2D. It contains \nPython bindings for gpc, the excellent General Polygon Clipping Library by \nAlan Murta and some extensions written in C and pure Python. With Polygon you \nmay handle complex polygonal shapes in Python in a very intuitive way. Polygons \nare simple Python objects, clipping operations are bound to standard operators \nlike +, -, \\|, & and ^. TriStrips can be constructed from Polygons with a \nsingle statement. Functions to compute the area, center point, convex hull,\npoint containment and much more are included. This package was already used to\nprocess shapes with more than one million points!\n\nThe gpc homepage is located at http://www.cs.man.ac.uk/~toby/alan/software/ .\n\nThe wrapping and extension code is free software, but the core gpc library is\nfree for non-commercial usage only. The author says:\n\n    GPC is free for non-commercial use only. We invite non-commercial users \n    to make a voluntary donation towards the upkeep of GPC.\n    \n    If you wish to use GPC in support of a commercial product, you must obtain \n    an official GPC Commercial Use Licence from The University of Manchester.\n\nPlease respect this statement and contact the author (see gpc homepage) if you\nwish to use this software in commercial projects!"}}, {"pk": 251, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pywordnet", "license": "Artistic License", "author": "Oliver Steele", "author_email": "steele@osteele.com", "project_url": null, "maintainer_email": null, "home_page": "http://pywordnet.sourceforge.net", "version": "2.0.1", "platform": "Platform independent", "keywords": null, "summary": "An interface to the WordNet database.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Artistic License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: Libraries :: Python Modules", "description": "PyWordNet presents a concise interface to WordNet, that allows the user to type\r\nexpressions such as N['dog'], hyponyms(N['dog'][0]), and closure(ADJ['red'],\r\nSYNONYM) to query the database."}}, {"pk": 252, "model": "importing.pypicache", "fields": {"maintainer": "Jacob Page", "name": "interval", "license": "LGPL", "author": "Jacob Page", "author_email": "jacob.h.page@gmail.com", "project_url": null, "maintainer_email": "jacob.h.page@gmail.com", "home_page": "http://members.cox.net/apoco/interval/", "version": "1.0.0", "platform": "", "keywords": "", "summary": "Python interval and interval set implementation", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "An Interval represents a continuous range of values.  An IntervalSet is like the\r\nbuilt-in set class, only it can also contain sets of Interval objects."}}, {"pk": 253, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.plugins.compress", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/plugins/compress.html", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "zip bzip2 dap opendap dods data", "summary": "Compression plugin for pydap server", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This metaplugin handles compressed files, uncompressing them on the fly\nand forwarding the request to the proper handler.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/plugins/compress#egg=dap.plugins.compress-dev>`_."}}, {"pk": 254, "model": "importing.pypicache", "fields": {"maintainer": "nobody, no longer developed", "name": "batchlib", "license": "", "author": "albert hofkamp", "author_email": "a.t.hofkamp@tue.nl", "project_url": null, "maintainer_email": "", "home_page": "http://seweb.se.wtb.tue.nl/~hat", "version": "1.3", "platform": "", "keywords": "", "summary": "Run computations in parallel in a LAN", "classifiers": "Development Status :: 7 - Inactive\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: Dutch\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: System :: Clustering", "description": "You need to run many independent computations/jobs and you have a LAN of idle\r\nmachines."}}, {"pk": 255, "model": "importing.pypicache", "fields": {"maintainer": "nobody, no longer developed", "name": "exec_proxy", "license": "", "author": "albert hofkamp", "author_email": "a.t.hofkamp@tue.nl", "project_url": null, "maintainer_email": "", "home_page": "http://seweb.se.wtb.tue.nl/~hat", "version": "0.4.0", "platform": "", "keywords": "", "summary": "Run arbitrary commands/scripts remotely using SSH", "classifiers": "Development Status :: 7 - Inactive\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: MIT License\nNatural Language :: Dutch\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: System :: Systems Administration", "description": "You are at machine A, and want to execute a script automagically at machine B"}}, {"pk": 256, "model": "importing.pypicache", "fields": {"maintainer": "Patrick Sunter", "name": "CREDO", "license": "LGPLv2.1", "author": "Patrick Sunter", "author_email": "patdevelop@gmail.com", "project_url": null, "maintainer_email": "patdevelop@gmail.com", "home_page": "https://www.mcc.monash.edu.au/trac/AuScopeEngineering/wiki/CREDO", "version": "0.1.2", "platform": "", "keywords": "modelling, workflow, benchmarking, profiling, analysis", "summary": "Package for benchmarking, profiling and analysis scientific modelling codes", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics", "description": "CREDO is a Python toolkit for system testing, benchmarking and analysis of Modelling tools based on the StGermain framework, such as Underworld.\r\n\r\nCREDO\u2019s core design goals are to:\r\n\r\n* Support the effective development, inquiry and maintenance of a suite of benchmarks that test the scientific features, numerical accuracy, and computational performance of StGermain-based codes.\r\n* Significantly enhance the ease and effectiveness of performing scientific analysis of the results of StGermain modelling applications."}}, {"pk": 257, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "collective.geo.mapwidget", "license": "GPL", "author": "Giorgio Borelli", "author_email": "giorgio@giorgioborelli.it", "project_url": null, "maintainer_email": null, "home_page": "https://svn.plone.org/svn/collective/collective.geo.mapwidget", "version": "0.1.3", "platform": "UNKNOWN", "keywords": "Zope Plone GIS KML Google Maps Bing Yahoo OpenLayers", "summary": "collective.geo mapwidget", "classifiers": "Framework :: Plone\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering :: GIS", "description": "collective.geo.mapwidget\n========================\n\n.. contents:: Summary\n   :local:\n\n\nIntroduction\n------------\n\ncollective.geo.mapwidget provides some handy page macros and adapters to easily manage\nmultiple maps on one page.\n\n\nRequirements\n------------\n* Plone >= 4.0\n* plone.app.z3cform\n* collective.z3cform.colorpicker\n* collective.geo.openlayers\n* collective.geo.settings\n\nInstallation\n------------\nYou can install collective.geo.mapwidget as part of a specific project's buildout, by having a buildout configuration such as: ::\n\n        [buildout]\n        ...\n        eggs = \n            collective.geo.mapwidget\n        ...\n        [instance]\n        ...\n        zcml = \n            collective.geo.mapwidget\n\nInstall this product from the Plone control panel.\n\n\nContributors\n------------\n\n* Gerhard Weis - gweis\n* Giorgio Borelli - gborelli\n* Silvio Tomatis - silviot\n* David Breitkreutz - rockdj\n\nChangelog\n=========\n\n0.1.3 (2011-02-20)\n------------------\n\n- changed Google maps javascript url\n\n\n0.1.2 (2010-12-28)\n------------------\n\n- fixed UnicodeDecodeError in maplayers [gborelli]\n- fixed set_coordinates js [gborelli]\n- Added dutch translations [robgietema]\n\n\n0.1.1 (2010-11-13)\n------------------\n\n- added geocoding to controlpanel\n- added cgmap.portal_url in collective.geo javascript\n- Removed unused googleapi configuration from controlpanel\n- Changed numZoomLevels in default mapwidget \n- Updated Google map layers to Googlemaps v3\n- fixed italian translation\n\n\n0.1 (2010-10-31)\n----------------\n\n* Initial release moved from collective.geo.settings"}}, {"pk": 258, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "zgeo.plone.kml", "license": "GPL", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/projects/PrimaGIS/wiki/zgeo.plone.kml", "version": "0.2", "platform": "UNKNOWN", "keywords": "plone geo gis kml google earth", "summary": "KML for Plone content", "classifiers": "Development Status :: 3 - Alpha\nFramework :: Plone\nFramework :: Zope2\nFramework :: Zope3\nIntended Audience :: Developers\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Provides KML views of georeferenced objects, allowing Plone containers and collections to be visualized in Google Earth."}}, {"pk": 259, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pyepr", "license": "GPL3", "author": "Antonio Valentino", "author_email": "antonio.valentino@tiscali.it", "project_url": null, "maintainer_email": "", "home_page": "http://avalentino.github.com/pyepr", "version": "0.3", "platform": "any", "keywords": "", "summary": "Python ENVISAT Product Reader API", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Other Environment\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Cython\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries", "description": "PyEPR provides Python_ bindings for the ENVISAT\r\nProduct Reader C API (`EPR API`_) for reading satellite data from ENVISAT_\r\nESA_ (European Space Agency) mission.\r\n\r\nPyEPR, as well as the `EPR API`_ for C, supports ENVISAT_ MERIS, AATSR\r\nLevel 1B and Level 2 and also ASAR data products. It provides access to\r\nthe data either on a geophysical (decoded, ready-to-use pixel samples)\r\nor on a raw data layer. The raw data access makes it possible to read\r\nany data field contained in a product file.\r\n\r\nThe complete HTML documentation is available here_ while the source browser and the issue tracker can be found on the `project page`_.\r\n\r\n.. _Python: http://www.python.org\r\n.. _`EPR API`: https://github.com/bcdev/epr-api\r\n.. _ENVISAT: http://envisat.esa.int\r\n.. _ESA: http://earth.esa.int\r\n.. _here: file:///home/antonio/projects/pyepr-doc/html/index.html\r\n.. _`project page`: file:///home/antonio/projects/pyepr-doc/html/index.html"}}, {"pk": 260, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyfasta", "license": "MIT", "author": "brentp", "author_email": "bpederse@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/brentp/pyfasta/", "version": "0.4.1", "platform": "UNKNOWN", "keywords": "bioinformatics blast fasta", "summary": "fast, memory-efficient, pythonic (and command-line) access to fasta sequence files", "classifiers": "Topic :: Scientific/Engineering :: Bio-Informatics", "description": "==================================================\npyfasta: pythonic access to fasta sequence files.\n==================================================\n\n\n:Author: Brent Pedersen (brentp)\n:Email: bpederse@gmail.com\n:License: MIT\n\n.. contents ::\n\nImplementation\n==============\n\nRequires Python >= 2.5. Stores a flattened version of the fasta file without \nspaces or headers and uses either a mmap of numpy binary format or fseek/fread so the\n*sequence data is never read into memory*. Saves a pickle (.gdx) of the start, stop \n(for fseek/mmap) locations of each header in the fasta file for internal use.\n\nUsage\n=====\n::\n  \n    >>> from pyfasta import Fasta\n\n    >>> f = Fasta('tests/data/three_chrs.fasta')\n    >>> sorted(f.keys())\n    ['chr1', 'chr2', 'chr3']\n\n    >>> f['chr1']\n    NpyFastaRecord(0..80)\n\n\nSlicing\n-------\n::\n\n    >>> f['chr1'][:10]\n    'ACTGACTGAC'\n\n    # get the 1st basepair in every codon (it's python yo)\n    >>> f['chr1'][::3]\n    'AGTCAGTCAGTCAGTCAGTCAGTCAGT'\n\n    # can query by a 'feature' dictionary\n    >>> f.sequence({'chr': 'chr1', 'start': 2, 'stop': 9})\n    'CTGACTGA'\n\n    # same as:\n    >>> f['chr1'][1:9]\n    'CTGACTGA'\n\n    # with reverse complement (automatic for - strand)\n    >>> f.sequence({'chr': 'chr1', 'start': 2, 'stop': 9, 'strand': '-'})\n    'TCAGTCAG'\n\nKey Function\n------------\nSometimes your fasta will have a long header like: \"AT1G51370.2 | Symbols:  | F-box family protein | chr1:19045615-19046748 FORWARD\" when you only want to key off: \"AT1G51370.2\". In this case, specify the key_fn argument to the constructor:\n\n::\n\n    >>> fkey = Fasta('tests/data/key.fasta', key_fn=lambda key: key.split()[0])\n    >>> sorted(fkey.keys())\n    ['a', 'b', 'c']\n\nNumpy\n=====\n\nThe default is to use a memmaped numpy array as the backend. In which case it's possible to\nget back an array directly...\n::\n\n    >>> f['chr1'].tostring = False\n    >>> f['chr1'][:10] # doctest: +NORMALIZE_WHITESPACE\n    memmap(['A', 'C', 'T', 'G', 'A', 'C', 'T', 'G', 'A', 'C'], dtype='|S1')\n\n    >>> import numpy as np\n    >>> a = np.array(f['chr2'])\n    >>> a.shape[0] == len(f['chr2'])\n    True\n\n    >>> a[10:14] # doctest: +NORMALIZE_WHITESPACE\n    array(['A', 'A', 'A', 'A'], dtype='|S1')\n\nmask a sub-sequence\n::\n\n    >>> a[11:13] = np.array('N', dtype='S1')\n    >>> a[10:14].tostring()\n    'ANNA'\n\n\nBackends (Record class)\n=======================\nIt's also possible to specify another record class as the underlying work-horse\nfor slicing and reading. Currently, there's just the default: \n\n  * NpyFastaRecord which uses numpy memmap\n  * FastaRecord, which uses using fseek/fread\n  * MemoryRecord which reads everything into memory and must reparse the original\n    fasta every time.\n  * TCRecord which is identical to NpyFastaRecord except that it saves the index\n    in a TokyoCabinet hash database, for cases when there are enough records that\n    loading the entire index from a pickle into memory is unwise. (NOTE: that the\n    sequence is not loaded into memory in either case).\n\nIt's possible to specify the class used with the `record_class` kwarg to the `Fasta`\nconstructor:\n::\n\n    >>> from pyfasta import FastaRecord # default is NpyFastaRecord\n    >>> f = Fasta('tests/data/three_chrs.fasta', record_class=FastaRecord)\n    >>> f['chr1']\n    FastaRecord('tests/data/three_chrs.fasta.flat', 0..80)\n\nother than the repr, it should behave exactly like the Npy record class backend\n\nit's possible to create your own using a sub-class of FastaRecord. see the source \nin pyfasta/records.py for details.\n\nFlattening\n==========\nIn order to efficiently access the sequence content, pyfasta saves a separate, flattened file with all newlines and headers removed from the sequence. In the case of large fasta files, one may not wish to save 2 copies of a 5GG+ file. In that case, it's possible to flatten the file \"inplace\", keeping all the headers, and retaining the validity of the fasta file -- with the only change being that the new-lines are removed from each sequence. This can be specified via `flatten_inplace` = True\n::\n    \n    >>> import os\n    >>> os.unlink('tests/data/three_chrs.fasta.gdx') # cleanup non-inplace idx\n    >>> f = Fasta('tests/data/three_chrs.fasta', flatten_inplace=True)\n    >>> f['chr1']  # note the difference in the output from above.\n    NpyFastaRecord(6..86)\n\n    # sequence from is same as when requested from non-flat file above.\n    >>> f['chr1'][1:9]\n    'CTGACTGA'\n\n    # the flattened file is kept as a place holder without the sequence data.\n    >>> open('tests/data/three_chrs.fasta.flat').read()\n    '@flattened@'\n\n\nCommand Line Interface\n======================\nthere's also a command line interface to manipulate / view fasta files.\nthe `pyfasta` executable is installed via setuptools, running it will show\nhelp text.\n\nsplit a fasta file into 6 new files of relatively even size:\n\n  $ pyfasta **split** -n 6 original.fasta\n\nsplit the fasta file into one new file per header with \"%(seqid)s\" being filled into each filename.:\n  \n  $ pyfasta **split** --header \"%(seqid)s.fasta\" original.fasta\n\ncreate 1 new fasta file with the sequence split into 10K-mers:\n\n  $ pyfasta **split** -n 1 -k 10000 original.fasta\n\n2 new fasta files with the sequence split into 10K-mers with 2K overlap:\n\n  $ pyfasta **split** -n 2 -k 10000 -o 2000 original.fasta\n\n\nshow some info about the file (and show gc content):\n\n  $ pyfasta **info** --gc test/data/three_chrs.fasta\n\n\n**extract** sequence from the file. use the header flag to make\na new fasta file. the args are a list of sequences to extract.\n\n  $ pyfasta **extract** --header --fasta test/data/three_chrs.fasta seqa seqb seqc\n\n**extract** sequence from a file using a file containing the headers *not* wanted in the new file:\n\n  $ pyfasta extract --header --fasta input.fasta --exclude --file seqids_to_exclude.txt\n\n**extract** sequence from a fasta file with complex keys where we only want to lookup based on the part before the space.\n\n  $ pyfasta extract --header --fasta input.with.keys.fasta --space --file seqids.txt\n\n**flatten** a file inplace, for faster later use by pyfasta, and without creating another copy. (`Flattening`_)\n\n  $ pyfasta flatten input.fasta \n\ncleanup \n=======\n(though for real use these will remain for faster access)\n::\n\n    >>> os.unlink('tests/data/three_chrs.fasta.gdx')\n    >>> os.unlink('tests/data/three_chrs.fasta.flat')\n\nTesting\n=======\nthere is currently > 99% test coverage for the 2 modules and all included \nrecord classes. to run the tests:\n::\n\n  $ python setup.py nosetests\n\nChanges\n=======\n0.4.0\n-----\n* add key_fn kwarg to constuctor\n\n0.3.9\n-----\n* only require 'r' (not r+) for memory map.\n\n0.3.8\n-----\n* clean up logic for mixing inplace/non-inplace flattened files.\n  if the inplace is available, it is always used. \n\n0.3.6/7\n-------\n* dont re-flatten the file every time!\n* allow spaces before and after the header in the orginal fasta.\n\n0.3.5\n-----\n\n* update docs in README.txt for new CLI stuff.\n* allow flattening inplace.\n* get rid of memmap (results in faster parsing).\n\n0.3.4\n-----\n\n* restore python2.5 compatiblity.\n* CLI: add ability to exclude sequence from extract\n* CLI: allow spliting based on header.\n\n0.3.3\n-----\n\n* include this file in the tar ball (thanks wen h.)\n\n0.3.2\n-----\n\n* separate out backends into records.py\n\n* use nosetests (python setup.py nosetests)\n\n* add a TCRecord backend for next-gen sequencing availabe if tc is (easy-)installed.\n\n* improve test coverage."}}, {"pk": 261, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "spyse", "license": "LGPL", "author": "Andr\u00e9 Meyer", "author_email": "meyer@acm.org", "project_url": null, "maintainer_email": "", "home_page": "http://spyse.sf.net", "version": "0.1", "platform": "", "keywords": "software agents, multi-agent system, fipa, semantic web, distributed intelligence", "summary": "spyse is a development framework and platform for building multi-agent systems using the Python programming language", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Web Environment\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Healthcare Industry\nIntended Audience :: Information Technology\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nIntended Audience :: Telecommunications Industry\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Games/Entertainment :: Simulation\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Sociology\nTopic :: Software Development :: Libraries :: Application Frameworks\nTopic :: Software Development :: Libraries :: Python Modules", "description": "spyse is a development framework and platform for building multi-agent systems\r\nusing the Python programming language. A multi-agent system (MAS) combines\r\nconcepts from distributed computing and artificial intelligence. Agents are\r\nautonomously reasoning software entities that can collaborate (or compete) in\r\norder to achieve a (common) goal. By cooperating they create emergent behaviour\r\nin the system (distributed artificial intelligence). The architecture of a MAS\r\nis specified in the FIPA standard.\r\n\r\nSpyse provides multiple means for reasoning (BDI logics, CLIPS expert shell,\r\netc.) and communicating locally and remotely.\r\n\r\nEach agent has its own thread of control. Agents within and among instances of\r\nthe platform communicate by exchanging messages based on ontologies. Spyse makes\r\nuse of the Web Ontology Language (OWL) defined for the Semantic Web.\r\n\r\nFurthermore, spyse is coupled to the Zope web application server in order to\r\nprovide for access to the MAS via a dynamic Web interface."}}, {"pk": 262, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.responses.xls", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/responses.html#xls", "version": "0.1.2", "platform": "UNKNOWN", "keywords": "xls opendap dods dap data science climate oceanography meteorology", "summary": "XLS response for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This response enables Pydap to serve data as XLS files."}}, {"pk": 263, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "railgun", "license": "MIT License", "author": "Takafumi Arakaki", "author_email": "aka.tkf@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/tkf/railgun/src", "version": "0.1.5", "platform": "UNKNOWN", "keywords": "numerical simulation,research,ctypes,numpy,c", "summary": "ctypes utilities for faster and easier simulation programming in C and Python", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "RailGun: Accelerate your simulation programing with \"C on Rails\"\n================================================================\n\nOverview\n--------\n\nRailGun is ctypes utilities for faster and easier simulation\nprogramming in C and Python. It requires constraint to C library\nloaded from Python and gives you automatically generated Python class\nwhich calls C functions safely.\n\n\nInstallation\n------------\n::\n\n    easy_install railgun  # using setuptools\n    pip install railgun   # using pip\n\n\nUsage\n-----\n\nPlease read\n`document <http://tkf.bitbucket.org/railgun-doc/index.html>`_ and\n`samples <https://bitbucket.org/tkf/railgun/src/tip/samples/>`_.\n\n\nRequirement\n-----------\n- Numpy\n- (matplotlib for sample code)"}}, {"pk": 264, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.R", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.R", "version": "3.0.4", "platform": "any", "keywords": "utility", "summary": "PyUtilib utilities that use R", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "=================\npyutilib.R README\n=================\n\nThis Python package includes utilities that use R.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 265, "model": "importing.pypicache", "fields": {"maintainer": "Paul F. Kunz and others", "name": "HippoDraw", "license": "GPL", "author": "Paul F, Kunz", "author_email": "Paul_Kunz@slac.stanford.edu", "project_url": null, "maintainer_email": "hippodraw@glast.stanford.edu", "home_page": "http://www.slac.stanford.edu/grp/ek/hippodraw/", "version": "1.16.5", "platform": "Linux, Windows, Mac OS X, and flavors of UNIX", "keywords": "Visualization, plotting, fitting, histograms", "summary": "Interactive data visualizaton python extenstion module", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: MacOS X\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows :: Windows 95/98/2000\nOperating System :: Microsoft :: Windows :: Windows NT/2000\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Visualization", "description": "HippoDraw is a highly interactive data visualization package which can be use as\r\na Python extension module.  Plot types include 1D and 2D histograms, scatter\r\nplots, XY plots, strip chart, etc.   Data can be read from ASCII, FITS, and ROOT\r\nfiles.   Data can also be generated by Python.   Plots can be manipulated by\r\nPython script or via intutive GUI.   Python can access the contents of the\r\nplots.   Fitting to functions using C++ minimizers is allowed and functions can\r\nbe written in Python.   Can be used in conjunction with Numeric or numarray\r\nextension modules."}}, {"pk": 266, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "qm", "license": "modified Python", "author": "Robert Dick", "author_email": "dickrp@eecs.umich.edu", "project_url": null, "maintainer_email": null, "home_page": "http://robertdick.org/python/mods.html", "version": "0.2", "platform": "UNKNOWN", "keywords": null, "summary": "Quine-McCluskey two-level logic minimization method.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python Software Foundation License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "Quine-McCluskey two-level logic minimization method.\n\nCopyright 2008, Robert Dick <dickrp@eecs.umich.edu> with improvements\nfrom Pat Maupin <pmaupin@gmail.com>.\n\nRoutines to compute the optimal sum of products implementation from sets of\ndon't-care terms, minterms, and maxterms.\n\nCommand-line usage example:\n  qm.py -o1,2,5 -d0,7\n\nLibrary usage example:\n  import qm\n  print qm.qm(ones=[1, 2, 5], dc=[0, 7])\n\nPlease see the license file for legal information."}}, {"pk": 267, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "WorldMill", "license": "BSD", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/projects/PCL/wiki/WorldMill", "version": "0.1", "platform": "UNKNOWN", "keywords": "gis vector feature data", "summary": "Access and transform geospatial feature data", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "WorldMill\n=========\n\nWorldMill provides a smoother and more productive Python interface to the open\nsource GIS community's most trusted geodata access library; doing for libgdal_\nwhat lxml does for libxml2. WorldMill integrates readily with other Python GIS\npackages such as pyproj_, Rtree_, and Shapely_.\n\n\nDependencies\n------------\n\nWorldMill requires libgdal 1.3.2+.\n\n\nBuilding\n--------\n\nFrom the distribution root::\n\n  $ ./cypsrc\n  $ python setup.py build_ext --inplace\n  $ PYTHONPATH=src python tests.py\n\nIf you have ogr.py installed, you can compare to WorldMill::\n\n  $ PYTHONPATH=src python benchmark.py\n\n\nUsage\n-----\n\nSee `docs/reading-data.txt`_ for examples.\n\n.. _libgdal: http://www.gdal.org\n.. _pyproj: http://pypi.python.org/pypi/pyproj/\n.. _Rtree: http://pypi.python.org/pypi/Rtree/\n.. _Shapely: http://pypi.python.org/pypi/Shapely/\n.. _docs/reading-data.txt: http://trac.gispython.org/projects/PCL/browser/WorldMill/trunk/docs/reading-data.txt"}}, {"pk": 268, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyMetis", "license": "wrapper: MIT/code: Free for research and non-commercial use", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/pymetis", "version": "2011.1", "platform": "UNKNOWN", "keywords": null, "summary": "A Graph Partitioning Package", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: Free for non-commercial use\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics :: 3D Modeling\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries", "description": "PyMetis is a Python wrapper for the\n          `Metis <http://glaros.dtc.umn.edu/gkhome/views/metis>`_ graph\n          partititioning software by George Karypis, Vipin Kumar and others. It\n          includes version 5.0pre2 of Metis and wraps it using the \n          `Boost Python <http://www.boost.org/libs/python/doc/>`_ wrapper generator\n          library. So far, it only wraps the most basic graph partitioning\n          functionality (which is enough for my current use), but extending it\n          in case you need more should be quite straightforward. Using PyMetis\n          to partition your meshes is really easy--essentially all you need to\n          pass into PyMetis is an adjacency list for the graph and the number\n          of parts you would like."}}, {"pk": 269, "model": "importing.pypicache", "fields": {"maintainer": "Pierre GERARD-MARCHANT", "name": "scikits.timeseries", "license": "BSD", "author": "Pierre GERARD-MARCHANT & Matt KNOX", "author_email": "pierregmcode_AT_gmail_DOT_com", "project_url": null, "maintainer_email": "pierregmcode_AT_gmail_DOT_com", "home_page": "http://pytseries.sourceforge.net", "version": "0.91.3", "platform": "Windows,Linux,Solaris,Mac OS-X,Unix", "keywords": "", "summary": "Time series manipulation", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "The scikits.timeseries module provides classes and functions for manipulating,\r\nreporting, and plotting time series of various frequencies. The focus is on\r\nconvenient data access and manipulation while leveraging the existing\r\nmathematical functionality in Numpy and SciPy."}}, {"pk": 270, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.optimization", "license": "new BSD", "author": "Matthieu Brucher", "author_email": "matthieu.brucher@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://projects.scipy.org/scipy/scikits", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "A python module for numerical optimization", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": ""}}, {"pk": 271, "model": "importing.pypicache", "fields": {"maintainer": "Brett G. Olivier", "name": "PySCeS", "license": "", "author": "Brett G. Olivier, Johann M. Rohwer, Jan-Hendrik S. Hofmeyr", "author_email": "bgoli@users.sourceforge.net", "project_url": null, "maintainer_email": "bgoli@users.sourceforge.net", "home_page": "http://pysces.sourceforge.net", "version": "0.7.0", "platform": "", "keywords": "computational systems biology, modelling, simulation", "summary": "The Python Simulator for Cellular Systems - simulation and analysis tools for modelling biological systems", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Fortran\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Chemistry", "description": "PySCeS is developed by the Triple-J Group for Molecular Cell Physiology\r\nin order to try model and understand the complex processes and systems\r\nwhich make up the living cell. \r\n\r\nPySCeS features, amongst other things:\r\n - A text based model description language.\r\n - A structural analysis module.\r\n - Integrators for time simulation\r\n - Non-linear solvers for steady-state analysis\r\n - A module for performing Metabolic Control Analysis\r\n - A bifurcation module for systems which exhibit multiple steady states\r\n - A variety of extra utilites for parameter scans, data output and plotting.\r\n - A dynamic module loading framework.\r\n - SBML import and export capability."}}, {"pk": 272, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "corr", "license": "GPL", "author": "Jason Manley", "author_email": "jason_manley at hotmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/corr", "version": "0.6.5", "platform": "UNKNOWN", "keywords": null, "summary": "Interfaces to CASPER correlators", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Provides interfaces to CASPER hardware and functions to configure packetised correlators."}}, {"pk": 273, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "electruth", "license": "GPLv3+", "author": "Niels Serup", "author_email": "ns@metanohi.org", "project_url": null, "maintainer_email": null, "home_page": "http://metanohi.org/projects/electruth/", "version": "0.2.0", "platform": "UNKNOWN", "keywords": null, "summary": "A collection of boolean logic tools", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: DFSG approved\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python :: 3.1\nTopic :: Education\nTopic :: Scientific/Engineering :: Electronic Design Automation (EDA)\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "=========\nelectruth\n=========\n\nelectruth is a collection of boolean logic tools. It can be used as\nboth a command-line tool and a Python library. It understands boolean\nalgebra (to some extent) and can be used to simplify boolean\nexpressions using the Quine-McClusky method. This can be useful if you\nhave a truth table in need of basic shortening. electruth can also be\nused to compare boolean expressions, which can be very useful if you\nneed to compare a truth table with a schematic you created based on\nthat truth table. electruth can also be used to transform complex\nboolean expressions into simpler ones consisting only of ANDS, ORS and\nNOTS.\n\n\nLicense\n=======\n\nelectruth is free software under the terms of the GNU General Public\nLicense version 3 (or any later version). The author of electruth is\nNiels Serup, contactable at ns@metanohi.org. This is version 0.2.0 of\nthe program, the first version to support Python 3.1+ (if you need\nsupport for Python 2.6+, you should download v0.1.1).\n\nThe libraries used by electruth are GPL-compatible.\n\n\nInstallation\n============\n\nWay #1\n------\nJust run this (requires that you have python-setuptools installed)::\n\n  $ sudo easy_install3 electruth\n\nWay #2\n------\nGet the newest version of electruth at\nhttp://metanohi.org/projects/electruth/ or at\nhttp://pypi.python.org/pypi/electruth\n\nExtract the downloaded file and run this in a terminal::\n\n  # python3 setup.py install\n\nDependencies\n============\n\nPython 3.1+ is a requirement.\n\n``qvikconfig``\n + Web address: http://pypi.python.org/pypi/qvikconfig/\n + License: GPLv3+\n + Installing: ``$ sudo easy_install qvikconfig``\n + Author: Niels Serup\n\nNote that ``qvikconfig`` is included with electruth, so you don't really\nhave to install it.\n\nOptional extras\n---------------\nIf present, electruth will also use these Python modules:\n\n``termcolor``\n + Web address: http://pypi.python.org/pypi/termcolor/\n + License: GPLv3+\n + Installing: ``$ sudo easy_install termcolor``\n + Author: Konstantin Lepa <konstantin lepa at gmail com>\n\nNote that ``termcolor`` is included with electruth, so you don't\nreally have to install it.\n \n``setproctitle``\n + Web address: http://pypi.python.org/pypi/setproctitle/\n + License: New BSD License\n + Installing: ``$ sudo easy_install setproctitle``\n + Author: Daniele Varrazzo <daniele varrazzo at gmail com>\n\n\nUse\n===\n\nInstalling electruth installs a command-line utility named\n``electruth``. This program has many settings, and it's recommended to\nrun ``electruth --help`` to get an overview of them.\n\nThe program creates boolean expressions from whatever input you give\nit. If you give it more than one input, it will compare the two inputs\n(unless if you tell it not to do that). Many inputs are supported:\n\n* Basic boolean expressions (e.g. ``A and (B or C)`` or ``A * (B +\n  C)`` (the same))\n* Truthtables, using tab-separated (.tsv) or comma-separated (.csv)\n  values in a file, the first row specifying the names of the inputs\n  and outputs with a ``<`` prefix for inputs and a ``>`` prefix for\n  outputs.\n* Netlists (.net), e.g. those generated from ``gnetlist`` from the gEDA\n  project (gEDA schematics from ``gschem`` can also be loaded, but\n  they will be converted to netlists (saved in temporary files) at\n  first).\n\nSome settings can also be set in a config file. Config files use a\n``property = value`` syntax (e.g. ``auto compare = false``) separated\nby newlines.\n\n\nTo see the help for electruth, run::\n\n  pydoc3 electruth\n\nAnd especially::\n\n  pydoc3 electruth.booleanexpression\n  pydoc3 electruth.netlist\n  pydoc3 electruth.truthtable\n\n\nDevelopment\n===========\n\nelectruth is written in Python and uses Git for code management. To\nget the latest branch, download it from gitorious.org like this::\n\n  $ git clone git://gitorious.org/electruth/electruth.git\n\n\nLogo\n====\n\nelectruth's current logo has been put into the public domain.\n\n\nThis document\n=============\nCopyright (C) 2010, 2011  Niels Serup\n\nCopying and distribution of this file, with or without modification,\nare permitted in any medium without royalty provided the copyright\nnotice and this notice are preserved.  This file is offered as-is,\nwithout any warranty."}}, {"pk": 274, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "playdoh", "license": "UNKNOWN", "author": "Cyrille Rossant, Bertrand Fontaine, Dan F. M. Goodman", "author_email": "Cyrille.Rossant at ens.fr", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/playdoh/", "version": "0.3", "platform": "UNKNOWN", "keywords": null, "summary": "Open-source library for distributing computations over multiple cores and machines", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "Playdoh is a pure Python library for distributing computations across the free computing units \n(CPUs and GPUs) available in a small network of multicore computers. Playdoh supports independent \n(embarassingly) parallel problems as well as loosely coupled tasks such as global optimizations, \nMonte Carlo simulations and numerical integration of partial differential equations. It is designed \nto be lightweight and easy to use and should be of interest to scientists wanting to turn their lab \ncomputers into a small cluster at no cost."}}, {"pk": 275, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyUGraph", "license": "UNKNOWN", "author": "Doug Hellmann", "author_email": "doug.hellmann@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.doughellmann.com/projects/PyUGraph/", "version": "1.0", "platform": "('Any',)", "keywords": "('graph', 'visualization')", "summary": "Graph class suitable for use with uGraph graphing tool.", "classifiers": "Development Status :: 6 - Mature\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Visualization", "description": "This module defines classes and functions for manipulating\n  representations of graph objects which support the features of the\n  uGraph graphing system.\n\n  http://www.informatik.uni-bremen.de/uDrawGraph/en/index.html"}}, {"pk": 276, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyDDE", "license": "GPL", "author": "Benjamin J. Cairns", "author_email": "ben.cairns@ceu.ox.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://users.ox.ac.uk/~clme1073/python/PyDDE/", "version": "0.2.2", "platform": "Any", "keywords": "delay differential equation solver dde switches solv95 ddesolve pydde", "summary": "PyDDE is a solver for delay differential equations written in Python and C.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "PyDDE is an open source numerical solver for systems of delay differential equations (DDEs), implemented as a Python package and written in both Python and C.  It is built around the numerical routines of the R package ddesolve, which is itself based on Simon Wood's Solv95, a DDE solver for Microsoft Windows systems written in C.\n        \n        PyDDE can solve a wide range of ODE and DDE models with discontinuities that may have state-dependent effects but state-independent timings.  Simulation is handled by an adaptively-stepping embedded RK2(3) scheme with cubic Hermite interpolation for calculation of delay terms.  Some of the advantages of PyDDE are that it is fast, efficient and allows rapid prototyping of scriptable models in a free, platform-independent environment."}}, {"pk": 277, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.sucasa", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/coopr/coopr.sucasa", "version": "2.0.4", "platform": "any", "keywords": "optimization", "summary": "Coopr framework for integrating symbolic data into MIP solvers", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "===================\ncoopr.sucasa README\n===================\n\nThis Python package defines scripts for customizing integer programming\nsolvesr.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * coopr-forum@googlegroups.com\n    - The main list for help and announcements\n  * coopr-developers@googlegroups.com\n    - Where developers of Coopr discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 278, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "QuantLib-Python", "license": "Copyright (c) 2002, 2003 Ferdinando Ametrano\nCopyright (c) 2001, 2002, 2003 Nicolas Di C\u00e9sar\u00e9\nCopyright (c) 2001, 2002, 2003 Sadruddin Rejeb\nCopyright (c) 2000, 2001, 2002, 2003 RiskMap srl\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n    Redistributions of source code must retain the above copyright notice,\n    this list of conditions and the following disclaimer.\n\n    Redistributions in binary form must reproduce the above copyright notice,\n    this list of conditions and the following disclaimer in the documentation\n    and/or other materials provided with the distribution.\n\n    Neither the names of the copyright holders nor the names of the QuantLib\n    Group and its contributors may be used to endorse or promote products\n    derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "author": "QuantLib Team", "author_email": "quantlib-users@lists.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://quantlib.org", "version": "0.3.3", "platform": "UNKNOWN", "keywords": null, "summary": "Python bindings for the QuantLib library", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "QuantLib (http://quantlib.org/) is a C++ library for financial quantitative\nanalysts and developers, aimed at providing a comprehensive software framework\nfor quantitative finance."}}, {"pk": 279, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "osgb", "license": "BSD", "author": "Paul-Michael Agapow", "author_email": "agapow@bbsrc.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://www.agapow.net/software/osgb", "version": "0.2dev", "platform": "UNKNOWN", "keywords": "geospatial OSGB UK", "summary": "Inter-conversion of OSGB references and lon-lats", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering :: GIS", "description": "Many geospatial locations within the UK are given with the (accurate but peculiar to the UK) Ordnance Survey system. This module presents functions for converting between these and the most widely spread longitude-latitude system."}}, {"pk": 280, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "asciiporn3k", "license": "UNKNOWN", "author": "kai zhu", "author_email": "kaizhu256@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/asciiporn3k", "version": "2009.11.16.py3k.cpp", "platform": "UNKNOWN", "keywords": null, "summary": "asciiporn3k", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 3.1\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics\nTopic :: Multimedia :: Graphics :: Graphics Conversion\nTopic :: Scientific/Engineering :: Image Recognition\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 281, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cloudflu", "license": "Apache License, Version 2.0", "author": "Alexey Petrov", "author_email": "alexey.petrov.nnov@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://sourceforge.net/projects/cloudflu", "version": "0.23-alfa", "platform": "linux", "keywords": null, "summary": "Delivers \"Cloud Computing\" commodities for OpenFOAM(R) users", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Apache Software License\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "Sends user data in a cloud cluster, runs the appointed solver and feteches the output results back to the user"}}, {"pk": 282, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "CosmoloPy", "license": "MIT", "author": "Roban Hultman Kramer", "author_email": "robanhk@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://roban.github.com/CosmoloPy/", "version": "0.1.100", "platform": "UNKNOWN", "keywords": "astronomy cosmology cosmological distance density galaxyluminosity magnitude reionization Press-Schechter Schecter", "summary": "a cosmology package for Python.", "classifiers": "License :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Astronomy", "description": "CosmoloPy is a package of cosmology routines built on NumPy/SciPy.\n\nCapabilities include\n--------------------\n\n`cosmolopy.density`\n  Calculate various cosmological densities.\n\n`cosmolopy.distance`\n  Calculate various cosmological distance measures.\n\n`cosmolopy.luminosityfunction`\n  Routines related to galaxy luminosity functions (Schecter functions).\n\n`cosmolopy.magnitudes`\n  Simple routines for conversion in and out of the AB magnitude system.\n\n`cosmolopy.parameters`\n  Provides some pre-defined sets of cosmological parameters (e.g. from WMAP).\n\n`cosmolopy.perturbation`\n  Routines related to perturbation theory and the power spectrum.\n\n`cosmolopy.reionization`\n  Routines related to the reionization of the IGM."}}, {"pk": 283, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyPedal", "license": "GNU LGPL", "author": "John B. Cole, PhD", "author_email": "john.cole@ars.usda.gov", "project_url": null, "maintainer_email": null, "home_page": "http://pypedal.sourceforge.net/", "version": "2.0.1", "platform": "UNKNOWN", "keywords": "Python pedigree genetic analysis diversity", "summary": "Tools for pedigree analysis", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Education\nIntended Audience :: Science/Research\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics", "description": "PyPedal provides an API that may be used to maniuplate pedigrees in a number of ways.  Key metrics include coefficients of inbreeding and relationship; effective founder and ancestor numbers; and expected inbreeding from a given mating.  If you have Graphviz and pydot installed, PyPedal can be used to produce a graph from your pedigree."}}, {"pk": 284, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ast2src", "license": "gpl", "author": "kai zhu", "author_email": "kaizhu256@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/ast2src", "version": "2010.01.21.ast2src", "platform": "UNKNOWN", "keywords": null, "summary": "DESCRIPTION: ast2src - reverse compile ast tree back to legal python source code", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "DESCRIPTION: ast2src - reverse compile ast tree back to legal python source code\n\n  REQUIRES: LINUX OS AND PYTHON3.1\n\n  QUICK TEST: $ python3.1 setup.py build dev --quicktest\n\n  SUMMARY:\n  ast2src is a pure python module.\n  ast2src is a python ast tree hack.\n  \nRECENT CHANGELOG:\n  20100121 - added ast2src\n  20091231 - added <<<< and >>>> sugar\n  20091224 - added pseudomethod interactive console - revamped pseudomethod import hook\n  20091224 - modularized package - fix install issues - added sdist check\n  20091209 - improved documentation\n  20091205 - moved source code to c++\n  20091116 - package integrated\n\nDEMO USAGE:\n\n  PseudoSugar - adding hook <ast2src.PseudoSugar object at 0xb7ba856c> to sys.meta_path\n>>> from ast2src import *\n\n>>> ## let's use ast2src's source code as example\n>>> import ast2src, ast\n>>> source_code1 = open(ast2src.__file__).read()\n>>> print( '\\n' + re.sub('\\n+', '\\n', source_code1[:1024]) + '...' )\n\n## import ast2src; reload(ast2src); from ast2src import *\nimport os, sys\nif os.name != 'posix': sys.stderr.write('\\nast2src requires linux os\\n\\n'); exit()\nif sys.version_info[:2] != (3, 1): sys.stderr.write('\\nast2src requires python3.1\\n\\n'); exit()\nif 1: ###### INIT\n  import ast2src as _MODULE\n  if '_SETUP' not in globals(): _SETUP = sys.modules.get('ast2src.setup', None)\n  def closure(*args, **kwds): return lambda fnc: fnc(*args, **kwds)\n  def identity(aa): return aa\n  def _import(ss, globals = globals()):\n    for aa in ss.split(' '): globals[aa] = __import__(aa)\n    return identity\n  class Namespace(object):\n    def __init__(self, **kwds): vars(self).update(kwds)\n  @_import('ast builtins collections re ' #### pseudosugar compiler\n           'imp importlib importlib.abc importlib.util ' #### import hook\n           'locale') ## PYTHON BUG\n  class PseudoSugar(ast.NodeVisitor, importlib.abc.Finder, importlib.abc.PyLoader):\n    ## convenience function\n    @staticmethod\n    def exec(ss, globa...\n\n>>> ## compile source to ast\n>>> ast_tree1 = compile(source_code1, '', 'exec', ast.PyCF_ONLY_AST)\n>>> print( Ast2Src.debugnode(ast_tree1)[:1024], '...' )\n<class '_ast.Module'>\tbody [<_ast.Import object at 0x9c6ea2c>, <_ast.If object at 0x9c6e7cc>, <_ast.If object at 0x9ab2b0c>, <_ast.If object at 0x9ab2fec>]\n <class '_ast.Import'>\tcol_offset 0\tlineno 2\tnames [<_ast.alias object at 0x9c6e2ec>, <_ast.alias object at 0x9c6e9ac>]\n  <class '_ast.alias'>\tasname None\tname 'os'\n  <class '_ast.alias'>\tasname None\tname 'sys'\n <class '_ast.If'>\tbody [<_ast.Expr object at 0x9ccc92c>, <_ast.Expr object at 0x9ab2acc>]\tcol_offset 0\tlineno 3\torelse []\ttest <_ast.Compare object at 0x9c6eccc>\n  <class '_ast.Compare'>\tcol_offset 3\tcomparators [<_ast.Str object at 0x9ccc9ec>]\tleft <_ast.Attribute object at 0x9c948cc>\tlineno 3\tops [<_ast.NotEq object at 0xb7b3682c>]\n   <class '_ast.Attribute'>\tattr 'name'\tcol_offset 3\tctx <_ast.Load object at 0xb7bb2ccc>\tlineno 3\tvalue <_ast.Name object at 0x9ccc46c>\n    <class '_ast.Name'>\tcol_offset 3\tctx <_ast.Load object at 0xb7bb2ccc>\tid 'os'\tlineno 3\n     <class '_ast.Load'>\t\n    <class '_ast.Load'>\t\n   <class '_ast.NotEq'>\t\n   <class '_ast. ...\n\n>>> ## reverse compile ast back to source\n>>> source_code2 = Ast2Src.unparse(ast_tree1)\n>>> print( '\\n' + re.sub('\\n+', '\\n', source_code1[:1024]) + '...' )\n\n## import ast2src; reload(ast2src); from ast2src import *\nimport os, sys\nif os.name != 'posix': sys.stderr.write('\\nast2src requires linux os\\n\\n'); exit()\nif sys.version_info[:2] != (3, 1): sys.stderr.write('\\nast2src requires python3.1\\n\\n'); exit()\nif 1: ###### INIT\n  import ast2src as _MODULE\n  if '_SETUP' not in globals(): _SETUP = sys.modules.get('ast2src.setup', None)\n  def closure(*args, **kwds): return lambda fnc: fnc(*args, **kwds)\n  def identity(aa): return aa\n  def _import(ss, globals = globals()):\n    for aa in ss.split(' '): globals[aa] = __import__(aa)\n    return identity\n  class Namespace(object):\n    def __init__(self, **kwds): vars(self).update(kwds)\n  @_import('ast builtins collections re ' #### pseudosugar compiler\n           'imp importlib importlib.abc importlib.util ' #### import hook\n           'locale') ## PYTHON BUG\n  class PseudoSugar(ast.NodeVisitor, importlib.abc.Finder, importlib.abc.PyLoader):\n    ## convenience function\n    @staticmethod\n    def exec(ss, globa...\n\n>>> ## recompile reverse-compiled source\n>>> ast_tree2 = compile(source_code2, '', 'exec', ast.PyCF_ONLY_AST)\n>>> print( Ast2Src.debugnode(ast_tree2)[:1024], '...' )\n<class '_ast.Module'>\tbody [<_ast.Import object at 0x9ad7ecc>, <_ast.If object at 0x9b3316c>, <_ast.If object at 0x9b3abcc>, <_ast.If object at 0x9b3ae6c>]\n <class '_ast.Import'>\tcol_offset 0\tlineno 2\tnames [<_ast.alias object at 0x9c2966c>, <_ast.alias object at 0x9c022ec>]\n  <class '_ast.alias'>\tasname None\tname 'os'\n  <class '_ast.alias'>\tasname None\tname 'sys'\n <class '_ast.If'>\tbody [<_ast.Expr object at 0x9b3aaac>, <_ast.Expr object at 0x9b3ab6c>]\tcol_offset 0\tlineno 3\torelse []\ttest <_ast.Compare object at 0x9b332ac>\n  <class '_ast.Compare'>\tcol_offset 4\tcomparators [<_ast.Str object at 0x9b3a80c>]\tleft <_ast.Attribute object at 0x9b3490c>\tlineno 3\tops [<_ast.NotEq object at 0xb7b3682c>]\n   <class '_ast.Attribute'>\tattr 'name'\tcol_offset 4\tctx <_ast.Load object at 0xb7bb2ccc>\tlineno 3\tvalue <_ast.Name object at 0x9b3a10c>\n    <class '_ast.Name'>\tcol_offset 4\tctx <_ast.Load object at 0xb7bb2ccc>\tid 'os'\tlineno 3\n     <class '_ast.Load'>\t\n    <class '_ast.Load'>\t\n   <class '_ast.NotEq'>\t\n   <class '_ast. ..."}}, {"pk": 285, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "spice", "license": "UNKNOWN", "author": "Matt Born", "author_email": "mattborn@ssl.berkeley.edu", "project_url": null, "maintainer_email": null, "home_page": "http://efw.ssl.berkeley.edu/packages/spice", "version": "0.12", "platform": "UNKNOWN", "keywords": null, "summary": "This package provides a limited interface to the NASA NAIF SPICE library.", "classifiers": "Development Status :: 2 - Pre-Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Apache Software License\nTopic :: Scientific/Engineering :: Astronomy", "description": "UNKNOWN"}}, {"pk": 286, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.mseed", "license": "GNU General Public License (GPL)", "author": "The ObsPy Development Team & Chad Trabant", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.8", "platform": "OS Independent", "keywords": "ObsPy,seismology,MSEED,MiniSEED,waveform,seismograms", "summary": "Read & write seismograms, Format MiniSeed", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "obspy.mseed - Read & write seismograms, Format MiniSeed\n    \n    This module contains Python wrappers for libmseed - The MiniSeed\n    library of Chad Trabant. Libmseed is written in C and interfaced via\n    Python ctypes.\n\n    For more information visit http://www.obspy.org."}}, {"pk": 287, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "py_ica", "license": "", "author": "Uwe Schmitt", "author_email": "uschmitt@mineway.de", "project_url": null, "maintainer_email": "uschmitt@mineway.de", "home_page": "http://www.procoders.net/?p=111", "version": "1.1", "platform": "Windows, Linux 32 Bit, Linux 64 Bit", "keywords": "ICA multivariate signalanalysis cocktailparty bss source separation", "summary": "Python Module for performing Extended Infomax ICA", "classifiers": "Intended Audience :: Financial and Insurance Industry\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nOperating System :: Microsoft :: Windows\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "*I fixed some errors and built two Linux versions.*\r\n\r\nAbout ICA:\r\n\r\nIndependent Componnent Analysis (ICA) is a modern and effective method for\r\nperforming blind Source separation (also known as Cocktail Party Problem).\r\nFields of application are artifact reduction in multivariate data (eg EEG or\r\nMEG), finding hidden factors in financial data or noise reduction in images.\r\nFurther ICA can be used to simplify and improve the solution of the inverse\r\nsource problem in EEG and MEG analysis.\r\n\r\nAs I found no Python module for performing ICA, I wrapped the existing extended\r\ninfomax implementation from EEGLAB."}}, {"pk": 288, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "zgeo.plone.atom", "license": "GPL", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/projects/PrimaGIS/wiki/zgeo.plone.atom", "version": "0.2", "platform": "UNKNOWN", "keywords": "plone geo gis georss atom", "summary": "Plone specific Atom syndication with GeoRSS", "classifiers": "Development Status :: 3 - Alpha\nFramework :: Plone\nFramework :: Zope2\nFramework :: Zope3\nIntended Audience :: Developers\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 289, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pymorphous", "license": "", "author": "Charles Dietrich", "author_email": "charles.m.dietrich at gmail", "project_url": null, "maintainer_email": "", "home_page": "http://www.pymorphous.org/", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "spatial_computing,amorphous_computing,simulator,robotics", "summary": "Spatial computing library and simulator for Python", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "About: http://pymorphous.googlecode.com/\r\n\r\nInstallation: http://code.google.com/p/pymorphous/wiki/Installation\r\n\r\nQuickStart: http://code.google.com/p/pymorphous/wiki/QuickStart"}}, {"pk": 290, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "upoints", "license": "GNU General Public License Version 3", "author": "James Rowe", "author_email": "jnrowe@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://www.jnrowe.ukfsn.org/projects/upoints.html", "version": "0.11.0", "platform": "UNKNOWN", "keywords": "navigation xearth trigpointing cities baken weather geonames openstreetmap nmea gpx", "summary": "upoints - Modules for working with points on Earth", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: Other Environment\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database\nTopic :: Education\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Filters", "description": "``upoints`` is a collection of `GPL v3`_ licensed modules for working with\r\npoints on Earth, or other near spherical objects.  It allows you to calculate\r\nthe distance and bearings between points, mangle xearth_/xplanet_ data files,\r\nwork with online UK trigpoint databases, NOAA_'s weather station database and\r\nother such location databases.\r\n\r\nThe git repository is hosted at GitHub_.\r\n\r\n.. _GPL v3: http://www.gnu.org/licenses/\r\n.. _xearth: http://www.cs.colorado.edu/~tuna/xearth/\r\n.. _xplanet: http://xplanet.sourceforge.net/\r\n.. _NOAA: http://weather.noaa.gov/\r\n.. _GitHub: https://github.com/JNRowe/upoints/"}}, {"pk": 291, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "h5py", "license": "UNKNOWN", "author": "Andrew Collette", "author_email": "\"h5py\" at the domain \"alfven.org\"", "project_url": null, "maintainer_email": null, "home_page": "http://h5py.alfven.org", "version": "1.3.0", "platform": "UNKNOWN", "keywords": null, "summary": "Read and write HDF5 files from Python", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Database\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "The h5py package provides both a high- and low-level interface to the HDF5\nlibrary from Python. The low-level interface is intended to be a complete\nwrapping of the HDF5 API, while the high-level component supports  access to\nHDF5 files, datasets and groups using established Python and NumPy concepts.\n\nA strong emphasis on automatic conversion between Python (Numpy) datatypes and\ndata structures and their HDF5 equivalents vastly simplifies the process of\nreading and writing data from Python.\n\nSupports HDF5 versions 1.6.5 through 1.8.4.  On Windows, HDF5 is included in\nthe installer."}}, {"pk": 292, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "la", "license": "Simplified BSD", "author": "Keith Goodman", "author_email": "larry-discuss@lists.launchpad.net", "project_url": null, "maintainer_email": "", "home_page": "http://larry.sourceforge.net", "version": "0.4.0", "platform": "OS Independent", "keywords": "", "summary": "Label the rows, columns, any dimension, of your NumPy arrays.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Cython\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "Who's larry?\r\n============\r\n        \r\nThe main class of the la package is a labeled array, larry. A larry consists of\r\ndata and labels. The data is stored as a NumPy array and the labels as a list of\r\nlists (one list per dimension).\r\n        \r\nHere's larry in schematic form::\r\n        \r\n                     date1    date2    date3\r\n            'AAPL'   209.19   207.87   210.11\r\n        y = 'IBM'    129.03   130.39   130.55\r\n            'DELL'    14.82    15.11    14.94\r\n        \r\nThe larry above is stored internally as a `Numpy <http://www.numpy.org>`_ array\r\nand a list of lists::\r\n        \r\n        y.label = [['AAPL', 'IBM', 'DELL'], [date1, date2, date3]]\r\n        y.x = np.array([[209.19, 207.87, 210.11],\r\n                        [129.03, 130.39, 130.55],\r\n                        [ 14.82,  15.11,  14.94]])\r\n        \r\nA larry can have any number of dimensions except zero. Here, for example, is one\r\nway to create a one-dimensional larry:\r\n        \r\n::\r\n        \r\n    >>> import la\r\n    >>> y = la.larry([1, 2, 3])\r\n        \r\nIn the statement above the list is converted to a Numpy array and the labels\r\ndefault to ``range(n)``, where *n* in this case is 3.\r\n        \r\nlarry has built-in methods such as **movingsum, ranking, merge, shuffle, zscore,\r\ndemean, lag** as well as typical Numpy methods like **sum, max, std, sign,\r\nclip**. NaNs are treated as missing data.\r\n        \r\nAlignment by label is automatic when you add (or subtract, multiply, divide) two\r\nlarrys.\r\n        \r\nYou can archive larrys in HDF5 format using **save** and **load** or using a\r\ndictionary-like interface:\r\n        \r\n::\r\n        \r\n    >>> io = la.IO('/tmp/dataset.hdf5')\r\n    >>> io['y'] = y   # <--- save\r\n    >>> z = io['y']   # <--- load\r\n    >>> del io['y']   # <--- delete from archive\r\n        \r\nFor the most part larry acts like a Numpy array. And, whenever you want, you\r\nhave direct access to the Numpy array that holds your data. For example if you\r\nhave a function, *myfunc*, that works on Numpy arrays and doesn't change the\r\nshape or ordering of the array, then you can use it on a larry, *y*, like this:\r\n        \r\n::\r\n        \r\n    y.x = myfunc(y.x)\r\n        \r\nlarry adds the convenience of labels, provides many built-in methods, and let's\r\nyou use your existing array functions.\r\n        \r\n===============   ========================================================\r\n docs              http://berkeleyanalytics.com/la\r\n code              http://github.com/kwgoodman/la\r\n issues            http://github.com/kwgoodman/la/issues \r\n list              http://groups.google.com/group/labeled-array\r\n===============   ========================================================"}}, {"pk": 293, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pyproj", "license": "OSI Approved", "author": "Jeff Whitaker", "author_email": "jeffrey.s.whitaker@noaa.gov", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/pyproj/", "version": "1.8.9", "platform": "any", "keywords": "python,map projections,GIS,mapping,maps", "summary": "Python interface to PROJ.4 library", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nOperating System :: OS Independent\nTopic :: Scientific/Engineering :: GIS\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Performs cartographic transformations and geodetic computations.\r\n\r\nThe Proj class can convert from geographic (longitude,latitude) to native map\r\nprojection (x,y) coordinates and vice versa, or from one map projection\r\ncoordinate system directly to another.\r\n\r\nThe Geod class can perform forward and inverse geodetic, or Great Circle,\r\ncomputations. The forward computation involves determining latitude, longitude\r\nand back azimuth of a terminus point given the latitude and longitude of an\r\ninitial point, plus azimuth and distance. The inverse computation involves\r\ndetermining the forward and back azimuths and distance given the latitudes and\r\nlongitudes of an initial and terminus point.\r\n\r\nInput coordinates can be given as python arrays, lists/tuples, scalars or\r\nnumpy/Numeric/numarray arrays. Optimized for objects that support the Python\r\nbuffer protocol (regular python and numpy array objects).\r\n\r\nThis project has a `Subversion repository\r\n<http://code.google.com/p/pyproj/source>`_ where you may access the most\r\nup-to-date source.\r\n\r\n`Changelog\r\n<http://pyproj.googlecode.com/svn/trunk/Changelog>`_"}}, {"pk": 294, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "OpenBayes", "license": "modified Python", "author": "Kosta Gaitanis, Elliot Cohen", "author_email": "gaitanis@tele.ucl.ac.be, elliot.cohen@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.openbayes.org", "version": "0.1.0", "platform": "UNKNOWN", "keywords": null, "summary": "An OpenSource Python implementation of bayesian networks inspired by BNT.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: Free for non-commercial use\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "OpenBayes is a library that allows users to easily create a bayesian network and perform inference on it.\nIt is mainly inspired from the Bayes Net Toolbox (BNT) which is available for MatLAB, \nbut uses python as a base language which provides many benefits : fast execution, portability \nand ease to use and maintain. Any inference engine can be implemented by inheriting a base\nclass. In the same way, new distributions can be added to the package by simply defining the \ndata contained in the distribution and some basic probabilistic operations. \n\nThe project is mature enough to be used for static bayesian networks and we are currently \ndevelopping the dynamical aspect."}}, {"pk": 295, "model": "importing.pypicache", "fields": {"maintainer": "Roland Memisevic", "name": "Monte", "license": "Python software foundation license.", "author": "Roland Memisevic", "author_email": "roland@cs.toronto.edu", "project_url": null, "maintainer_email": "roland@cs.toronto.edu", "home_page": "http://montepython.sourceforge.net", "version": "0.0.11", "platform": "", "keywords": "machine learning, neural networks, conditional random fields", "summary": "Monte - machine learning in pure Python.", "classifiers": "Topic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Visualization", "description": "Monte (python) is a framework for rapidly building learning machines, such as\r\nneural networks, conditional random fields, logistic regression, and others.\r\nMonte consists of almost 100% pure Python code (with a little bit of optional\r\ninline-C for efficiency) and is therefore extremely easy to use and to extend."}}, {"pk": 296, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PyIMSL", "license": "", "author": "Rogue Wave Software", "author_email": "info@vni.com", "project_url": null, "maintainer_email": "", "home_page": "http://www.roguewave.com/products/imsl-numerical-libraries/pyimsl-studio.aspx", "version": "1.6", "platform": "", "keywords": "", "summary": "Python wrappers for the IMSL C Numerical Library for math and statistics", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": ""}}, {"pk": 297, "model": "importing.pypicache", "fields": {"maintainer": "Benny Malengier & The Gramps Team", "name": "Gramps", "license": "", "author": "Don Allingham", "author_email": "dallingham@users.sourceforge.net", "project_url": null, "maintainer_email": "bmcage@users.sourceforge.net", "home_page": "http://sourceforge.net/projects/gramps/", "version": "3.2.5", "platform": "", "keywords": "Genealogy Pedigree Ancestry Birth Marriage Death Family Family-tree GEDCOM", "summary": "Research, organize and share your family genealogy.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: MacOS X\nEnvironment :: Plugins\nEnvironment :: Web Environment\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications :: GTK\nFramework :: Django\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: Bulgarian\nNatural Language :: Catalan\nNatural Language :: Chinese (Simplified)\nNatural Language :: Croatian\nNatural Language :: Czech\nNatural Language :: Danish\nNatural Language :: Dutch\nNatural Language :: English\nNatural Language :: Esperanto\nNatural Language :: Finnish\nNatural Language :: French\nNatural Language :: German\nNatural Language :: Hebrew\nNatural Language :: Hungarian\nNatural Language :: Italian\nNatural Language :: Norwegian\nNatural Language :: Polish\nNatural Language :: Portuguese (Brazilian)\nNatural Language :: Russian\nNatural Language :: Slovak\nNatural Language :: Slovenian\nNatural Language :: Spanish\nNatural Language :: Swedish\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: Other OS\nOperating System :: POSIX :: BSD\nOperating System :: POSIX :: Linux\nOperating System :: POSIX :: SunOS/Solaris\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nTopic :: Database\nTopic :: Desktop Environment :: Gnome\nTopic :: Education\nTopic :: Multimedia\nTopic :: Other/Nonlisted Topic\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Sociology :: Genealogy", "description": "Gramps is a free genealogy program. That is both intuitive for hobbyists and feature-complete for professional genealogists. It is a community project, created, developed and governed by genealogists."}}, {"pk": 298, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ndg-saml", "license": "http://www.apache.org/licenses/LICENSE-2.0", "author": "Philip Kershaw", "author_email": "Philip.Kershaw@stfc.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://proj.badc.rl.ac.uk/ndg/wiki/Security/SAML2.0", "version": "0.5.5", "platform": "UNKNOWN", "keywords": null, "summary": "SAML 2.0 implementation for the NERC DataGrid based on the Java OpenSAML library", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: Apache Software License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Security\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Distributed Computing\nTopic :: System :: Systems Administration :: Authentication/Directory", "description": "SAML 2.0 implementation for use with the NERC DataGrid / Earth System Grid\n        Project Attribute and Authorisation Query interfaces.  The implementation is\n        based on the Java OpenSAML libraries.  An implementation is provided with\n        ElementTree but it can easily be extended to use other Python XML parsers.\n        \n        0.5.5 - allow passing a client certificate chain in client HTTPS requests\n        \n        0.5.4 - fix for ndg.saml.saml2.binding.soap.server.wsgi.queryinterface.SOAPQueryInterfaceMiddleware:\n        bug in issuerFormat property setter - setting issuerName value\n        \n        0.5.3 - fix for ndg.soap.utils.etree.prettyPrint for undeclared Nss.\n        \n        0.5.2 - fix for applying clock skew property in queryinterface WSGI middleware,\n        and various minor fixes for classfactory module and m2crytpo utilities.\n        \n        0.5.1 - fix for date time parsing where no seconds fraction is present, fixed\n        error message for InResponseTo ID check for Subject Query.\n        \n        0.5 - adds WSGI middleware and clients for SAML SOAP binding and assertion\n        query/request profile.\n        \n        It is not a complete implementation of SAML 2.0.  Only those components required\n        for the NERC DataGrid have been provided (Attribute and AuthZ Decision Query/\n        Response).  Where possible, stubs have been provided for other classes."}}, {"pk": 299, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "python-graph", "license": "", "author": "Pedro Matiello", "author_email": "pmatiello@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/python-graph/", "version": "1.8.0", "platform": "", "keywords": "python, graphs, hypergraphs, networks, library, algorithms", "summary": "A library for working with graphs in Python", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "*python-graph* is a library for working with graphs in Python.\r\n\r\nThis software provides \ufeffa suitable data structure for representing graphs and a\r\nwhole set of important algorithms.\r\n\r\nThe code is appropriately documented and API reference is generated\r\nautomatically by epydoc.\r\n\r\nComments, bug reports and suggestions are welcome.\r\n\r\nProvided features and algorithms:\r\n\r\n * Support for directed, undirected, weighted and non-weighted graphs\r\n * Support for hypergraphs\r\n * Canonical operations\r\n * XML import and export\r\n * DOT-Language import and export (for usage with Graphviz)\r\n * Random graph generation\r\n\r\n * Accessibility (transitive closure)\r\n * Breadth-first search\r\n * Critical path algorithm\r\n * Cut-vertex and cut-edge identification\r\n * Cycle detection\r\n * Depth-first search\r\n * Gomory-Hu cut-tree algorithm\r\n * Heuristic search (A* algorithm)\r\n * Identification of connected components\r\n * Maximum-flow / Minimum-cut (Edmonds-Karp algorithm)\r\n * Minimum spanning tree (Prim's algorithm)\r\n * Mutual-accessibility (strongly connected components)\r\n * Pagerank algorithm\r\n * Shortest path search (Dijkstra's algorithm)\r\n * Shortest path search (Bellman-Ford algorithm)\r\n * Topological sorting\r\n * Transitive edge identification"}}, {"pk": 300, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyUniversalLibrary", "license": "BSD", "author": "Andrew Straw", "author_email": "strawman@astraw.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.its.caltech.edu/~astraw/pyul.html", "version": "20061020", "platform": "UNKNOWN", "keywords": null, "summary": "data acquisition library wrapper for Universal Library", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Win32 (MS Windows)\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Manufacturing\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: Microsoft :: Windows\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "UNKNOWN"}}, {"pk": 301, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "weblogo", "license": "UNKNOWN", "author": "Gavin Crooks", "author_email": "gec@threeplusone.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/weblogo/", "version": "3.0", "platform": "UNKNOWN", "keywords": null, "summary": "WebLogo3 : Sequence Logos Redrawn", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "WebLogo (http://code.google.com/p/weblogo/) is a tool for creating sequence \nlogos from biological sequence alignments.  It can be run on the command line,\nas a standalone webserver, as a CGI webapp, or as a python library.\n\nThe main WebLogo webserver is located at http://bespoke.lbl.gov/weblogo/\n\nPlease consult the manual for installation instructions and more information:\n(Also located in the weblogolib/htdocs subdirectory.)\n\n    http://bespoke.lbl.gov/weblogo/manual.html\n\nFor help on the command line interface run\n    ./weblogo --help\n\nTo build a simple logo run\n    ./weblogo  < cap.fa > logo0.eps\n    \nTo run as a standalone webserver at localhost:8080 \n    ./weblogo --server\n\nTo create a logo in python code:\n    >>> from weblogolib import *\n    >>> fin = open('cap.fa')\n    >>> seqs = read_seq_data(fin) \n    >>> data = LogoData.from_seqs(seqs)\n    >>> options = LogoOptions()\n    >>> options.title = \"A Logo Title\"\n    >>> format = LogoFormat(data, options)\n    >>> fout = open('cap.eps', 'w') \n    >>> eps_formatter( data, format, fout)\n\n\n-- Distribution and Modification --\nThis package is distributed under the new BSD Open Source License. \nPlease see the LICENSE.txt file for details on copyright and licensing.\nThe WebLogo source code can be downloaded from \nhttp://code.google.com/p/weblogo/\n\nWebLogo requires Python 2.3, 2.4 or 2.5, the corebio python toolkit for\ncomputational biology (http://code.google.com/p/corebio), and the python\narray package 'numpy' (http://www.scipy.org/Download)"}}, {"pk": 302, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyswisseph", "license": "UNKNOWN", "author": "S.Marquis", "author_email": "stnsls@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pyswisseph.chaosorigin.com/", "version": "1.76.00-1", "platform": "UNKNOWN", "keywords": "Astrology Ephemeris Swisseph", "summary": "Python extension to the Swiss Ephemeris", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Religion\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nTopic :: Religion\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Python extension to AstroDienst's Swiss Ephemeris library.\n\nSwiss Ephemeris homepage: http://www.astro.com/swisseph/\n\nNow Python 3 compatible.\n\nUsage example:\n\n>>> import swisseph as swe\n>>> swe.set_ephe_path('/usr/share/ephe') # set path to ephemeris files\n>>> now = swe.julday(2007,3,3) # get Julian day number\n>>> res = swe.lun_eclipse_when(now) # find next lunar eclipse (from now on)\n>>> ecltime = swe.revjul(res[1][0]) # get date UTC\n>>> ecltime\n(2007, 3, 3, 23.347975596785545)\n>>> jd = swe.julday(2008,3,21)\n>>> swe.calc_ut(jd, swe.AST_OFFSET+13681)[0] # asteroid Monty Python\n0.098474291148756998\n>>> help(swe)\n\nInstallation: ``# python setup.py install``\n\nDebian/Ubuntu packages: http://www.openastro.org/"}}, {"pk": 303, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "DeliciousAPI", "license": "GNU General Public License version 2", "author": "Michael G. Noll", "author_email": "coding[AT]michael-noll[DOT]com", "project_url": null, "maintainer_email": null, "home_page": "http://www.michael-noll.com/wiki/Del.icio.us_Python_API", "version": "1.6.7", "platform": "UNKNOWN", "keywords": "del.icio.us delicious api research social bookmarking python", "summary": "Unofficial Python API for retrieving data from Delicious.com", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering\nTopic :: Sociology\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This module provides the following features plus some more:\n\n    * retrieving a URL's full public bookmarking history including\n        * users who bookmarked the URL including tags used for such bookmarks\n          and the creation time of the bookmark (up to YYYY-MM-DD granularity)\n        * top tags (up to a maximum of 10) including tag count\n        * title as stored on Delicious.com\n        * total number of bookmarks/users for this URL at Delicious.com\n    * retrieving a user's full bookmark collection, including any private bookmarks\n      if you know the corresponding password\n    * retrieving a user's full public tagging vocabulary, i.e. tags and tag counts\n    * retrieving a user's network information (network members and network fans)\n    * HTTP proxy support\n    * updated to support Delicious.com \"version 2\" (mini-relaunch as of August 2008)\n\n    The official Delicious.com API and the JSON/RSS feeds do not provide all\n    the functionality mentioned above, and in such cases this module will query\n    the Delicious.com *website* directly and extract the required information\n    by parsing the HTML code of the resulting Web pages (a kind of poor man's\n    web mining). The module is able to detect IP throttling, which is employed\n    by Delicious.com to temporarily block abusive HTTP request behavior, and\n    will raise a custom Python error to indicate that. Please be a nice netizen\n    and do not stress the Delicious.com service more than necessary.\n\n    It is strongly advised that you read the Delicious.com Terms of Use\n    before using this Python module. In particular, read section 5\n    'Intellectual Property'.\n\n    The code is licensed to you under version 2 of the GNU General Public\n    License.\n\n    More information about this module can be found at\n    http://www.michael-noll.com/wiki/Del.icio.us_Python_API\n\n    Changelog is available at\n    http://code.michael-noll.com/?p=deliciousapi;a=log\n\n    Copyright 2006-2010 Michael G. Noll <http://www.michael-noll.com/>"}}, {"pk": 304, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydaqtools", "license": "BSD", "author": "Joe Grado", "author_email": "gradoj@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.pydaqtools.org/", "version": "0.2.0", "platform": "UNKNOWN", "keywords": "data acquisition nidaqmx nidaq national instruments daq", "summary": "Python Data Acquisition Tools", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Console\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "pydaqtools\n===============================\n\npydaqtools provides an interface for pc-compatible data-acquisition hardware for Python. Control analog/digital output or acquire analog/digital input for immediate analysis with Python for scientific or engineering applications. \n\nDependencies\n===============================\nnumpy\nscipy(optional)\nmatplotlib(optional)\n\nAdditional hardware drivers required:\nnidaqmx(National Instruments)\nnidaqmxbase(National Instruments)\npyAudio\n\nSupport\n===============================\n\nURL: http://www.pydaqtools.org/\nMailing List: pydaqtools-users@lists.sourceforge.net"}}, {"pk": 305, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.pyomo", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/coopr/coopr.pyomo", "version": "2.6.1", "platform": "any", "keywords": "optimization", "summary": "Coopr's Pyomo math programming language", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==================\ncoopr.pyomo README\n==================\n\nThis Python package defines a Pythonic modeling language for math programming.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * coopr-forum@googlegroups.com\n    - The main list for help and announcements\n  * coopr-developers@googlegroups.com\n    - Where developers of Coopr discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 306, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mcview", "license": "GPL", "author": "Andy Buckley", "author_email": "andy@insectnation.org", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "0.4.0", "platform": "UNKNOWN", "keywords": "generator montecarlo simulation data hep physics particle", "summary": "A 3D / graph event viewer for high-energy physics event simulations", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Physics", "description": "mcview uses the Python wrapper for HepMC to load and view HepMC\nevents as 3D final-state representations in (log-)momentum space, and to dump\nthe graph structure to PDF and graphviz formats."}}, {"pk": 307, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "iwand", "license": "GNU GPL", "author": "A. Brazhe", "author_email": "brazhe@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://iwand.sf.net", "version": "0.5.3", "platform": "UNKNOWN", "keywords": null, "summary": "Easy continuous wavelet analysis", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: X11 Applications :: GTK\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "iWand is a tool for wavelet data analysis. \n                Its meant to be simple in use and easy to extend."}}, {"pk": 308, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Rtree", "license": "LGPL", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/lab/wiki/Rtree", "version": "0.6.0", "platform": "UNKNOWN", "keywords": "gis spatial index", "summary": "R-Tree spatial index for Python GIS", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Database\nTopic :: Scientific/Engineering :: GIS", "description": ".. _home:\n\nRtree: Spatial indexing for Python\n------------------------------------------------------------------------------\n\n`R-trees`_ possess excellent query performance, good incremental \ninsert performance, and great flexibility in the spatial indexing algorithms \nworld.  \n\n.. _`R-trees`: http://en.wikipedia.org/wiki/R-tree\n.. _`ctypes`: http://docs.python.org/library/ctypes.html\n\n`Rtree`_ is a Python library that uses `ctypes`_ \nto wrap `libspatialindex`_.\n`Rtree`_ has gone through a number of iterations, and at 0.5.0, it was\ncompletely refactored to use a new internal architecture (ctypes + a C API\nover `libspatialindex`_). This refactoring has resulted in a number of new\nfeatures and much more flexibility. See CHANGES.txt_ for more detail.\n\nRtree 0.6.0+ requires `libspatialindex`_ 1.5.0+ to work.  Rtree 0.5.0 included \na C library that is now the C API for libspatialindex and is part of that \nsource tree.  The code bases  are independent from each other and can now \nevolve separately.  Rtree is now pure Python.\n\n.. _Rtree: http://pypi.python.org/pypi/Rtree/\n.. _CHANGES.txt: http://trac.gispython.org/lab/browser/Rtree/trunk/CHANGES.txt\n\n\nIndex Protocol\n------------------------------------------------------------------------------\n\nIn a nutshell::\n\n  >>> from rtree import Rtree\n  >>> idx = Rtree()\n  >>> minx, miny, maxx, maxy = (0.0, 0.0, 1.0, 1.0)\n  >>> idx.add(0, (minx, miny, maxx, maxy))\n  >>> list(idx.intersection((1.0, 1.0, 2.0, 2.0)))\n  [0L]\n  >>> list(idx.intersection((1.0000001, 1.0000001, 2.0, 2.0)))\n  []\n\nThe following finds the 1 nearest item to the given bounds. If multiple items\nare of equal distance to the bounds, both are returned::\n  \n  >>> idx.add(1, (minx, miny, maxx, maxy))\n  >>> list(idx.nearest((1.0000001, 1.0000001, 2.0, 2.0), 1))\n  [0L, 1L]\n\nThis resembles a subset of the set protocol. *add* indexes a new object by id,\n*intersection* returns an iterator over ids (or objects) where the node\ncontaining the id intersects with the specified bounding box. The\n*intersection* method is exact, with no false positives and no missed data.\nIds can be ints or long ints; index queries return long ints.\n\n\nPickles\n..............................................................................\n\nRtree also supports inserting pickleable objects into the index (called a clustered \nindex in `libspatialindex`_ parlance).  The following inserts the \npickleable object ``42`` into the index with the given id::\n\n  >>> index.add(id=id, bounds=(left, bottom, right, top), obj=42)\n\nYou can then return a list of objects by giving the ``objects=True`` flag\nto intersection::\n\n  >>> [n.object for n in index.intersection((left, bottom, right, top), objects=True)]\n  42\n\n\n3D indexes\n..............................................................................\n\nAs of Rtree version 0.5.0, you can create 3D (actually kD) `R-trees`_. The\nfollowing is a 3D index that is to be stored on disk. Persisted indexes are\nstored on disk using two files -- an index file (.idx) and a data (.dat) file.\nYou can modify the extensions these files use by altering the properties of\nthe index at instantiation time. The following creates a 3D index that is\nstored on disk as the files ``3d_index.data`` and ``3d_index.index``::\n\n  >>> from rtree import index\n  >>> p = index.Property()\n  >>> p.dimension = 3\n  >>> p.dat_extension = 'data'\n  >>> p.idx_extension = 'index'  \n  >>> idx3d = index.Index('3d_index',properties=p)\n  >>> idx3d.insert(1, (0, 0, 60, 60, 23.0, 42.0))\n  >>> idx3d.intersection( (-1, -1, 62, 62, 22, 43))\n  [1L]\n\nInstallation\n------------------------------------------------------------------------------\n\n\\*nix \n..............................................................................\n\nFirst, download and install version 1.5.0 of the `libspatialindex`_ library from:\n\nhttp://trac.gispython.org/spatialindex/wiki/Releases\n\nThe library is a GNU-style build, so it is a matter of::\n\n  $ ./configure; make; make install\n\nYou may need to run the ``ldconfig`` command after installing the library to \nensure that applications can find it at startup time.  \n\nAt this point you can get Rtree 0.6.0 via easy_install::\n\n  $ easy_install Rtree\n\nor by running the local setup.py::\n\n  $ python setup.py install\n\nYou can build and test in place like::\n\n  $ python setup.py test\n\nWindows \n..............................................................................\n\nThe Windows DLLs of both libsidx and `libspatialindex`_ are pre-compiled in \nwindows installers that are available from `PyPI`_.  Installation on Windows \nis as easy as::\n\n  c:\\python2x\\scripts\\easy_install.exe Rtree\n\n\nDocumentation and Usage\n------------------------------------------------------------------------------\n\nHTML documentation for Rtree is available at http://gispython.org/rtree/docs/ \nand they can be generated via `Sphinx`_ from the docs/ directory. \n\nSee `tests/index.txt`_ for more detail on index usage and `tests/properties.txt`_ \nfor index properties that can be set and manipulated.  `tests/test_customStorage.txt`_ \ndemonstrates how to create a custom storage backend using Rtree for your own \ndatabase.  \n\nRefer to `libspatialindex`_ documentation or code for more detail on the meanings and usage \nof index properties.\n\nhttps://mail.zope.org/pipermail/zodb-dev/2010-June/013491.html contains a custom \nstorage backend for `ZODB`_\n\n.. _tests/index.txt: http://trac.gispython.org/lab/browser/Rtree/trunk/tests/index.txt\n.. _tests/properties.txt: http://trac.gispython.org/lab/browser/Rtree/trunk/tests/properties.txt\n.. _tests/test_customStorage.txt: http://trac.gispython.org/lab/browser/Rtree/trunk/tests/test_customStorage.txt\n.. _Sphinx: http://sphinx.pocoo.org/\n.. _ZODB: http://www.zodb.org/\n\nPerformance\n------------------------------------------------------------------------------\n\nSee the `tests/benchmarks.py`_ file for a comparison.\n\n.. _tests/benchmarks.py: http://trac.gispython.org/lab/browser/Rtree/trunk/tests/benchmarks.py\n\nThere are a few simple things that will improve performance.\n\n - Use stream loading. This will substantially (orders of magnitude in many cases) \n   improve performance over Rtree.insert by allowing the data to be pre-sorted \n   \n\n   :: \n\n       >>> def generator_function():\n       ...    for i, obj in enumerate(somedata):\n       ...        yield (i, (obj.xmin, obj.ymin, obj.xmax, obj.ymax), obj)\n       >>> r = Rtree(generator_function())\n\n   After bulk loading the index, you can then insert additional records into \n   the index using `insert()`\n\n - Override Rtree.dumps() to use the highest pickle protocol ::\n\n    >>> import cPickle, rtree\n    >>> class FastRtree(rtree.Rtree):\n    ...     def dumps(self, obj):\n    ...         return cPickle.dumps(obj, -1)\n    >>> r = FastRtree()\n\n\n - In any query, use objects='raw' keyword argument ::\n\n    >>> objs = r.intersection((xmin, ymin, xmax, ymax), objects=\"raw\")\n\n - Adjust `rtree.index.Property` appropriate to your index.\n\n   * Set your leaf_capacity to a higher value than the default 100.  1000+ is \n     fine for the default pagesize of 4096 in many cases.\n\n   * Increase the fill_factor to something near 0.9.  Smaller fill factors \n     mean more splitting, which means more nodes.  This may be bad or good \n     depending on your usage.\n   \n - Don't use more dimensions than you actually need. If you only need 2,\n   only use two. Otherwise, you will waste lots of storage and add that \n   many more floating point comparisons for each query, search, and insert \n   operation of the index.\n \n - Use `.count()` if you only need a count and `.intersection()`\n   if you only need the ids.  Otherwise, lots of data may potentially be copied.\n\nSupport\n------------------------------------------------------------------------------\n\nFor current information about this project, see the wiki_.\n\n.. _wiki: http://trac.gispython.org/lab/wiki/Rtree\n\nIf you have questions, please consider joining our community list:\n\nhttp://lists.gispython.org/mailman/listinfo/community\n\n.. _`libspatialindex`: http://research.att.com/~marioh/spatialindex/index.html  \n.. _`PyPI`: http://pypi.python.org/pypi/Rtree/"}}, {"pk": 309, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyopencv", "license": "New BSD License", "author": "Minh-Tri Pham", "author_email": "pmtri80@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/pyopencv/", "version": "2.1.0.wr1.2.0", "platform": "OS Independent,Windows,Linux,MacOS", "keywords": null, "summary": "PyOpenCV - A Python wrapper for OpenCV 2.x using Boost.Python and NumPy", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Multimedia :: Video\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: Libraries :: Python Modules", "description": "PyOpenCV brings Willow Garage's Open Source Computer Vision Library\n(OpenCV) verion 2.x to Python. The package takes a completely new and\ndifferent approach in wrapping OpenCV from traditional swig-based and\nctypes-based approaches. It is intended to be a successor of\nctypes-opencv and to provide Python bindings for OpenCV 2.x.\nCtypes-based approaches like ctypes-opencv, while being very flexible at\nwrapping functions and structures, are weak at wrapping OpenCV's C++\ninterface. On the other hand, swig-based approaches flatten C++ classes\nand create countless memory management issues. In PyOpenCV, we use\nBoost.Python, a C++ library which enables seamless interoperability\nbetween C++ and Python. PyOpenCV will offer a better solution than both\nctypes-based and swig-based wrappers. Its main features include:\n\n    * A Python interface similar to the new C++ interface of OpenCV 2.x,\n      including features that are available in the existing C interface\n      but not yet in the C++ interface.\n    * Access to C++ data structures in Python.\n    * Elimination of memory management issues. The user never has to\n      worry about memory management.\n    * Ability to convert between OpenCV's Mat and arrays used in\n      wxWidgets, PyGTK, and PIL.\n    * OpenCV extensions: classes DifferentialImage, IntegralImage, and\n      IntegralHistogram.\n\nTo the best of our knowledge, PyOpenCV is the largest wrapper among\nexisting Python wrappers for OpenCV. It exposes to Python 200+ classes\nand 500+ free functions of OpenCV 2.x, including those instantiated from\ntemplates.\n\nIn addition, we use NumPy to provide fast indexing and slicing\nfunctionality to OpenCV's dense data types like Vec-like, Point-like,\nRect-like, Size-like, Scalar, Mat, and MatND, and to offer the user an\noption to work with their multi-dimensional arrays in NumPy. It is\nwell-known that NumPy is one of the best packages (if not the best) for\ndealing with multi-dimensional arrays in Python. OpenCV 2.x provides a\nnew C++ generic programming approach for matrix manipulation (i.e.\nMatExpr). It is a good attempt in C++. However, in Python, a package\nlike NumPy is without a doubt a better solution. By incorporating NumPy\ninto PyOpenCV to replace OpenCV 2.x's MatExpr approach, we seek to bring\nOpenCV and NumPy closer together, and offer a package that inherits the\nbest of both world: fast computer vision functionality (OpenCV) and fast\nmulti-dimensional array computation (NumPy)."}}, {"pk": 310, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gpxtools", "license": "GPL", "author": "Wojciech Lichota", "author_email": "wojciech@lichota.pl", "project_url": null, "maintainer_email": null, "home_page": "http://lichota.pl/blog/topics/gpxtools", "version": "0.2.1", "platform": "UNKNOWN", "keywords": "GPS GPX SRTM", "summary": "Command line tools useful to manipulate GPX files.", "classifiers": "Environment :: Console\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Scientific/Engineering :: GIS\nTopic :: Text Processing :: Markup :: XML", "description": "========\ngpxtools\n========\n\nOverview\n========\n\nCommand line tools useful to manipulate GPX files.\n\n\nTools\n=====\n\ngpx-elevation-fix\n-----------------\n\nFixes elevation (Z-axis) data in GPX file based on *Shuttle Radar Topography \nMission* data. `SRTM`_ data are not available for whole globe. If SRTM data\nfor position taken from GPX file do not exists, user will see download error \nof SRTM TIF file (for example srtm_38_00.TIF for Norway).\n\nMore information about Shuttle Radar Topography Mission:\n\n* `SRTM`_ on CGIAR-CSI\n* `SRTM on Wikipedia`_\n* `SRTM world map`_ \n\ngpx-cleanup\n-----------\n\nRemoves from GPX file unnecessary data (e.g.: speed or course) stored by some GPS devices.\n\n\ngpx-compress\n------------\n\nRemoves unnecessary chars (e.g.: white spaces) to decrease GPX file size.\n\n     \nUsage\n=====\n\n::\n\n    Usage: command-name [options]\n    \n    Options:\n      -h, --help                show this help message and exit\n      -i FILE, --intput=FILE    name of GPX input file, if not set stdin will be used\n      -o FILE, --output=FILE    name of GPX output file, if not set stdout will be used\n\nTools can be easily used in pipeline::\n\n    cat input.gpx  | ./bin/gpx-fix-elevation | ./bin/gpx-cleanup | ./bin/gpx-compress > output.gpx\n\n\nInstallation\n============\n\n*gpxtools* requires `GDAL python bindings`_. This packege uses `GDAL library`_.\nYou can build it form source or install from binary package. \nFor more details see `GDAL library`_ homepage.\n\nFor example in Ubuntu (feisty or higher) can be installed from package::\n\n    sudo apt-get install python-gdal\n\n*gpxtools* requires also `lxml`_. To build it you can use `plone.recipe.lxml`_ buildout recipe.\n\nInstallation with *easy_install*\n--------------------------------\n\nRun command::\n\n    $ easy_install gpxtools\n\n\nInstallation with *buildout*\n----------------------------\n\nSave script in `buildout.cfg` file::\n\n    [buildout]\n    develop = .\n    parts = gpxtools-script\n    \n    [gpxtools-script]\n    recipe = zc.recipe.egg\n    eggs = gpxtools\n\nRun commands::\n\n    $ python bootstrap.py\n    $ ./bin/buildout\n    \nCommands will be created in *bin* subdirectory.\n\n\nReferences\n==========\n\n* `gpxtools home page`_\n* `gpxtools at pypi`_\n* `GDAL python bindings`_\n* `GDAL library`_\n* `SRTM`_\n* `lxml`_\n* `plone.recipe.lxml`_\n* `SRTM on Wikipedia`_\n* `SRTM world map`_\n\n\nAuthors & Contact\n=================\n\n* [sargo] - `Wojciech Lichota`_ <``wojciech[at]lichota.pl``>\n* [teo] - Matteo Gottardi <``matgott[at]tin.it``>\n\n.. _gpxtools home page: http://lichota.pl/blog/topics/gpxtools\n.. _gpxtools at pypi: http://pypi.python.org/pypi/gpxtools/\n.. _GDAL python bindings: http://pypi.python.org/pypi/GDAL\n.. _GDAL library: http://gdal.org/\n.. _SRTM: http://srtm.csi.cgiar.org/\n.. _lxml: http://pypi.python.org/pypi/lxml\n.. _plone.recipe.lxml: http://pypi.python.org/pypi/plone.recipe.lxml\n.. _SRTM on Wikipedia: http://en.wikipedia.org/wiki/Shuttle_Radar_Topography_Mission\n.. _SRTM world map: http://srtm.csi.cgiar.org/SRT_IMAGES/worldMap.jpg\n.. _Wojciech Lichota: http://lichota.pl/\n\n\n=========\nChangelog\n=========\n\n2010/02/15 0.2.1:\n=================\n\n- mkdir import fix [samuel.adam]\n\n\n2009/12/10 0.2.0:\n=================\n\n- Support for GPX 1.0 files [teo]\n- Add the <ele> tag if not present [teo]\n- Documentation update [sargo]\n\n\n2009/07/07 0.1.0:\n=================\n\n- Initial release [sargo]"}}, {"pk": 311, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "csa", "license": "GPLv3", "author": "Mikael Djurfeldt", "author_email": "mikael@djurfeldt.com", "project_url": null, "maintainer_email": null, "home_page": "http://software.incf.org/software/csa/", "version": "0.0.1", "platform": "UNKNOWN", "keywords": "computational neuroscience modeling connectivity", "summary": "The Connection-Set Algebra implemented in Python", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering", "description": "The CSA library provides elementary connection-sets and operators for\n        combining them. It also provides an iteration interface to such\n        connection-sets enabling efficient iteration over existing connections\n        with a small memory footprint also for very large networks. The CSA\n        can be used as a component of neuronal network simulators or other\n        tools."}}, {"pk": 312, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "piquant", "license": "UNKNOWN", "author": "Dan Goodman, Romain Brette", "author_email": "dan.goodman at ens.fr", "project_url": null, "maintainer_email": null, "home_page": "http://piquant.sourceforge.net/", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "A Python package extending NumPy and SciPy to allow specification of numbers and arrays with physical units.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Physics", "description": "A Python package extending NumPy and SciPy to allow specification of numbers and arrays with physical units."}}, {"pk": 313, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "sparsesvd", "license": "UNKNOWN", "author": "Radim Rehurek", "author_email": "radimrehurek@seznam.cz", "project_url": null, "maintainer_email": "", "home_page": "http://pypi.python.org/pypi/sparsesvd", "version": "0.1.5", "platform": "any", "keywords": "Singular Value Decomposition,SVD,sparse SVD", "summary": "Python module that wraps SVDLIBC, a library for sparse Singular Value Decomposition.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Text Processing :: Linguistic", "description": "=================================================\r\nsparsesvd -- Sparse Singular Value Decomposition\r\n=================================================\r\n\r\n**sparsesvd** is a Python wrapper around the `SVDLIBC <http://tedlab.mit.edu/~dr/SVDLIBC/>`_ \r\nlibrary by Doug Rohde, which is itself based on Michael Berry's `SVDPACK <http://www.netlib.org/svdpack/>`_.\r\n\r\nsparsesvd uses SciPy's sparse CSC (Compressed Sparse Column) matrix format as input to SVD.\r\nThis is the same format used internally by SVDLIBC, so that no extra data copies need to be\r\nmade by the Python wrapper. \r\n\r\nInstallation\r\n------------\r\n\r\nIn order to install `sparsesvd`, you'll need NumPy and Scipy, two Python packages for scientific computing.\r\nYou can get them from <http://www.scipy.org/Download>.\r\n\r\nThe simple way to install `sparsesvd` is::\r\n\r\n    sudo easy_install -U sparsesvd\r\n\r\nOr, if you have instead downloaded and unzipped the `source tar.gz <http://pypi.python.org/pypi/sparsesvd>`_ package, \r\nyou'll need to run::\r\n\r\n    python setup.py test\r\n    sudo python setup.py install\r\n\r\nThis version has been tested under Python 2.5 and 2.6, but should run on any 2.5 <= Python < 3.0.\r\n\r\nDocumentation\r\n--------------\r\n\r\nThe `sparsesvd` module offers a single function, `sparsesvd`, which accepts two parameters.\r\nOne is a sparse matrix in the `scipy.sparse.csc_matrix` format, the other is the number\r\nof requested factors (an integer).\r\n\r\n>>> import numpy, scipy.sparse\r\n>>> from sparsesvd import sparsesvd\r\n>>> mat = numpy.random.rand(200, 100) # create a random matrix\r\n>>> smat = scipy.sparse.csc_matrix(mat) # convert to sparse CSC format\r\n>>> ut, s, vt = sparsesvd(smat, 100) # do SVD, asking for 100 factors\r\n>>> assert numpy.allclose(mat, numpy.dot(ut.T, numpy.dot(numpy.diag(s), vt)))\r\n\r\n\r\n-------\r\n\r\nOriginal wrapper by Lubos Kardos, package maintained by Radim Rehurek. For an application of sparse SVD to Latent Semantic Analysis, see the `gensim <http://pypi.python.org/pypi/gensim>`_ package."}}, {"pk": 314, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ipdasite.projectmgmt", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/ipdasite.projectmgmt/", "version": "2.0.1", "platform": "UNKNOWN", "keywords": "web zope plone planetary data science project management", "summary": "Web-based project management tools for the International Planetary Data Alliance", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Atmospheric Science\nTopic :: Software Development :: Libraries :: Python Modules", "description": "********************\nipdasite.projectmgmt\n********************\n\nThis package provides project management tools for the International Planetary\nData Alliance (IPDA_).  These tools include:\n\n* IPDA Events, such as conferences or meetings\n* IPDA Documents, web pages with IPDA document identifiers\n* IPDA Files, uploaded files (like PDFs or Word documents) also with IPDA\n  documents identifiers\n* IPDA Projects, collaborative containers for documents and files pursued by\n  the IPDA.\n* Project Folders, containing IPDA Projects\n* Steering Committee, a special display of IPDA members for are part of the\n  IPDA Steering Committee\n\nAlthough intended for the web site of the IPDA, this package may be installed\non any Plone_ 4 site.  It was developed by the Planetary Data System (PDS_).\n\n.. References:\n.. _IPDA: http://planetarydata.org/\n.. _Plone: http://plone.org/\n.. _PDS: http://pds.nasa.gov/\n\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``ipdasite.projectmgmt`` to the list of eggs to install, e.g.::\n\n    [buildout]\n    ...\n    eggs =\n        ...\n        ipdasite.projectmgmt\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n\n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        ipdasite.projectmgmt\n        \n* Re-run buildout, e.g. with::\n  \n    $ ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\n2.0.1 - The Experts are Technical - 2011-11-25\n----------------------------------------------\n\nDan.Crichton@jpl.nasa.gov wants the members of the Technical Experts Group to\nappear under the \"Members\" tab.  Well, the \"Members\" tab was already a\nmisnomer, as it was an instance of a \"Steering Committee Display\" object whose\nsole purpose was to show those registered users who were in the group \"SC\".\nWell, now that object's view also has a section for \"TEG\" members.\n\n\n2.0.0 - Plone 4\n---------------\n\nThis release of the IPDA Project Management brings about Plone 4\ncompatibility.\n\n\n\nCopyright & License\n===================\n\nCopyright 2008-2011 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 315, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "root2matplot", "license": "UNKNOWN", "author": "Jeff Klukas", "author_email": "klukas@wisc.edu", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/root2matplot/", "version": "0.9.3.1", "platform": "UNKNOWN", "keywords": null, "summary": "Tools for use with ROOT; deprecated in favor of rootplot", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: Free for non-commercial use\nNatural Language :: English\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Utilities", "description": "UNKNOWN"}}, {"pk": 316, "model": "importing.pypicache", "fields": {"maintainer": "Guillaume Libersat", "name": "metamodel", "license": "GPLv3", "author": "Pablo Martin", "author_email": "caedes@grupoikusnet.com", "project_url": null, "maintainer_email": "glibersat@sigill.org", "home_page": "http://delcorp.dyne.org/metamodel", "version": "0.1", "platform": "", "keywords": "model, metamodel, mvc", "summary": "Seamless model library for interactive applications", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Multimedia :: Graphics :: Editors\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development\nTopic :: Software Development :: Libraries :: Python Modules", "description": "A model package for python offering automatic serialization and synchronization\r\nusing different backends.\r\n\r\nModels are to be defined based on one unified metamodel, and they get all the\r\nfeatures for free, while keeping the model access natural from the application."}}, {"pk": 317, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "basemap", "license": "OSI Approved", "author": "Jeff Whitaker", "author_email": "jeffrey.s.whitaker@noaa.gov", "project_url": null, "maintainer_email": "", "home_page": "http://matplotlib.sourceforge.net/basemap/doc/html", "version": "1.0.1", "platform": "any", "keywords": "python,plotting,plots,graphs,charts,GIS,mapping,map projections,maps", "summary": "Plot data on map projections with matplotlib", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nOperating System :: OS Independent\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "An add-on toolkit for matplotlib that lets you plot data\r\non map projections with coastlines, lakes, rivers and political boundaries.\r\nSee http://scipy.org/Cookbook/Matplotlib/Maps for an\r\nexample of what it can do."}}, {"pk": 318, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pyDATR", "license": "Python License", "author": "Henrik Weber", "author_email": "hweber@sourceforge.net", "project_url": null, "maintainer_email": "", "home_page": "http://pydatr.sourceforge.net/", "version": "0.2", "platform": "All platforms Python 2.4 runs on", "keywords": "", "summary": "An implementation of the DATR language written in Python.", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Console\nEnvironment :: Other Environment\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python Software Foundation License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Linguistic", "description": "pyDATR is an implementation of the DATR language written in Python.\r\nIt can parse DATR theories and evaluate queries against them. It\r\nalso contains a persistence layer that allows storing theories and\r\nnodes in a relational database. Theories that have been stored through\r\nthis layer can later be partially loaded and will transparently\r\nretrieve nodes from the database as needed, thus reducing memory\r\nconsumption.\r\n\r\nThere's not much there in the way of a user interface as it is intended\r\nto be called from Python scripts."}}, {"pk": 319, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "AREM", "license": "UNKNOWN", "author": "Jake Biesinger; Daniel Newkirk; Alvin Chon; Yong Zhang; Tao (Foo) Liu", "author_email": "jake.biesinger@gmail.com; dnewkirk@uci.edu; achon@uci.edu; zy@jimmy.harvard.edu; taoliu@jimmy.harvard.edu", "project_url": null, "maintainer_email": null, "home_page": "http://cbcl.ics.uci.edu/AREM", "version": "1.0.0", "platform": "UNKNOWN", "keywords": null, "summary": "Aligning Reads by Expectation-Maximization.\nBased on MACS (Model Based Analysis for ChIP-Seq data)", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Artistic License\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "README for AREM 1.0, based on MACS 1.4.0beta\nTime-stamp: <2011-01-20 18:21:42 Jake Biesinger>\n\n* Introduction\n\nHigh-throughput sequencing coupled to chromatin immuno-\nprecipitation (ChIP-Seq) is widely used in characterizing genome-wide\nbinding patterns of transcription factors, cofactors, chromatin modifiers,\nand other DNA binding proteins. A key step in ChIP-Seq data analysis\nis to map short reads from high-throughput sequencing to a reference\ngenome and identify peak regions enriched with short reads. Although\nseveral methods have been proposed for ChIP-Seq analysis, most ex-\nisting methods only consider reads that can be uniquely placed in the\nreference genome, and therefore have low power for detecting peaks lo-\ncated within repeat sequences. Here we introduce a probabilistic ap-\nproach for ChIP-Seq data analysis which utilizes all reads, providing a\ntruly genome-wide view of binding patterns. Reads are modeled using a\nmixture model corresponding to K enriched regions and a null genomic\nbackground. We use maximum likelihood to estimate the locations of the\nenriched regions, and implement an expectation-maximization (E-M) al-\ngorithm, called AREM, to update the alignment probabilities of each\nread to different genomic locations.\n\nFor additional information, see our paper in RECOMB 2011 or visit our website:\nhttp://cbcl.ics.uci.edu/AREM\n\nAREM is based on the popular MACS peak caller, as described below:\n\nWith the improvement of sequencing techniques, chromatin\nimmunoprecipitation followed by high throughput sequencing (ChIP-Seq)\nis getting popular to study genome-wide protein-DNA interactions. To\naddress the lack of powerful ChIP-Seq analysis method, we present a\nnovel algorithm, named Model-based Analysis of ChIP-Seq (MACS), for\nidentifying transcript factor binding sites. MACS captures the\ninfluence of genome complexity to evaluate the significance of\nenriched ChIP regions, and MACS improves the spatial resolution of\nbinding sites through combining the information of both sequencing tag\nposition and orientation. MACS can be easily used for ChIP-Seq data\nalone, or with control sample with the increase of specificity.\n\nThe original MACS package is available at: http://liulab.dfci.harvard.edu/MACS/\n\n* Install\n\nPlease check the file 'INSTALL' in the distribution.\n\n* Usage\n\nUsage: arem <-t tfile> [-n name] [-g genomesize] [options]\n\nExample: arem -t ChIP.bam -c Control.bam -f BAM -g h -n test -w --call-subpeaks\n\n\narem -- Aligning Reads by Expectation-Maximization, based on Model-based Analysis for ChIP-Sequencing (MACS)\n\nOptions:\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit.\n  -t TFILE, --treatment=TFILE\n                        ChIP-seq treatment files. REQUIRED. When ELANDMULTIPET\n                        is selected, you must provide two files separated by\n                        comma, e.g.\n                        s_1_1_eland_multi.txt,s_1_2_eland_multi.txt\n  -c CFILE, --control=CFILE\n                        Control files. When ELANDMULTIPET is selected, you\n                        must provide two files separated by comma, e.g.\n                        s_2_1_eland_multi.txt,s_2_2_eland_multi.txt\n  -n NAME, --name=NAME  Experiment name, which will be used to generate output\n                        file names. DEFAULT: \"NA\"\n  -f FORMAT, --format=FORMAT\n                        Format of tag file, \"AUTO\", \"BED\" or \"ELAND\" or\n                        \"ELANDMULTI\" or \"ELANDMULTIPET\" or \"ELANDEXPORT\" or\n                        \"SAM\" or \"BAM\" or \"BOWTIE\". The default AUTO option\n                        will let MACS decide which format the file is. Please\n                        check the definition in 00README file if you choose EL\n                        AND/ELANDMULTI/ELANDMULTIPET/ELANDEXPORT/SAM/BAM/BOWTI\n                        E. DEFAULT: \"AUTO\"\n  -g GSIZE, --gsize=GSIZE\n                        Effective genome size. It can be 1.0e+9 or 1000000000,\n                        or shortcuts:'hs' for human (2.7e9), 'mm' for mouse\n                        (1.87e9), 'ce' for C. elegans (9e7) and 'dm' for\n                        fruitfly (1.2e8), Default:hs\n  -s TSIZE, --tsize=TSIZE\n                        Tag size. This will overide the auto detected tag\n                        size. DEFAULT: 25\n  --bw=BW               Band width. This value is used while building the\n                        shifting model. If --nomodel is set, 2 time of this\n                        value will be used as a scanwindow width. DEFAULT: 300\n  -p PVALUE, --pvalue=PVALUE\n                        Pvalue cutoff for peak detection. DEFAULT: 1e-5\n  -m MFOLD, --mfold=MFOLD\n                        Select the regions within MFOLD range of high-\n                        confidence enrichment ratio against background to\n                        build model. The regions must be lower than upper\n                        limit, and higher than the lower limit. DEFAULT:10,30\n  -w, --wig             Whether or not to save shifted raw tag count at every\n                        bp into a wiggle file. WARNING: this process is\n                        time/space consuming!!\n  --single-wig          When set, a single wiggle file will be saved for\n                        treatment and input. Default: False\n  --wigextend=WIGEXTEND\n                        If set as an integer, when MACS saves wiggle files, it\n                        will extend tag from its middle point to a wigextend\n                        size fragment. By default it is modeled d. Use this\n                        option if you want to increase the resolution in\n                        wiggle file. It doesn't affect peak calling.\n  --space=SPACE         The resoluation for saving wiggle files, by default,\n                        MACS will save the raw tag count every 10 bps. Usable\n                        only with '--wig' option.\n  --nolambda            If True, MACS will use fixed background lambda as\n                        local lambda for every peak region. Normally, MACS\n                        calculates a dynamic local lambda to reflect the local\n                        bias due to potential chromatin structure.\n  --slocal=SMALLLOCAL   The small nearby region in basepairs to calculate\n                        dynamic lambda. This is used to capture the bias near\n                        the peak summit region. Invalid if there is no control\n                        data. DEFAULT: 1000\n  --llocal=LARGELOCAL   The large nearby region in basepairs to calculate\n                        dynamic lambda. This is used to capture the surround\n                        bias. DEFAULT: 10000\n  --off-auto            Whether turn off the auto pair model process. If not\n                        set, when MACS failed to build paired model, it will\n                        use the nomodel settings, the '--shiftsize' parameter\n                        to shift and extend each tags. DEFAULT: False\n  --nomodel             Whether or not to build the shifting model. If True,\n                        MACS will not build model. by default it means\n                        shifting size = 100, try to set shiftsize to change\n                        it. DEFAULT: False\n  --shiftsize=SHIFTSIZE\n                        The arbitrary shift size in bp. When nomodel is true,\n                        MACS will regard this value as 'modeled' d. DEFAULT:\n                        100\n  --call-subpeaks       If set, MACS will invoke Mali Salmon's PeakSplitter\n                        soft through system call. If PeakSplitter can't be\n                        found, an instruction will be shown for downloading\n                        and installing the PeakSplitter package. DEFAULT:\n                        False\n  --keep-dup            When set, MACS will keep all duplicate tags at the\n                        exact same location -- the same coordination and the\n                        same strand. Otherwise, MACS calculates the maximum\n                        tags at the exact same location based on binomal\n                        distribution, and only keep at most this number of\n                        tags at each location. Default: False\n  --petdist=PETDIST     Best distance between Pair-End Tags. Only available\n                        when format is 'ELANDMULTIPET'. DEFAULT: 200\n  --verbose=VERBOSE     Set verbose level. 0: only show critical message, 1:\n                        show additional warning message, 2: show process\n                        information, 3: show debug messages. DEFAULT:2\n  --diag                Whether or not to produce a diagnosis report. It's up\n                        to 9X time consuming. Please check 00README file for\n                        detail. DEFAULT: False\n  --fe-min=FEMIN        For diagnostics, min fold enrichment to consider.\n                        DEFAULT: 0\n  --fe-max=FEMAX        For diagnostics, max fold enrichment to consider.\n                        DEFAULT: maximum fold enrichment\n  --fe-step=FESTEP      For diagnostics, fold enrichment step.  DEFAULT: 20\n  --no-EM               Do NOT iteratively align multi-reads by E-M. Multi-\n                        read probabilities will be based on quality scores or\n                        uniform (if --no-quals) DEFAULT : FALSE\n  --EM-converge-diff=MIN_CHANGE\n                        The minimum entropy change between iterations before\n                        halting E-M steps. DEFAULT : 1e-05\n  --EM-min-score=MIN_SCORE\n                        Minimum enrichment score. Windows below this threshold\n                        will all look the same to the aligner. DEFAULT : 1.5\n  --EM-max-score=MAX_SCORE\n                        Maximum enrichment score. Windows above this threshold\n                        will all look the same to the aligner, DEFAULT : No\n                        Maximum\n  --EM-show-graphs      generate diagnostic graphs for E-M. (requires\n                        MATPLOTLIB). DEFAULT : FALSE\n  --quality-scale=QUAL_SCALE\n                        Initial alignment probabilities are determined by read\n                        quality and mismatches. Each possible alignment is\n                        assigned a probability from the product over all bases\n                        of either 1-p(ReadError_base) when there is no\n                        mismatch, or p(ReadError_base) when the called base\n                        disagrees with the reference.  You may also select a\n                        uniform initialization. Read quality scale is the must\n                        be one of ['auto', 'sanger+33', 'illumina+64'].\n                        DEFAULT : auto\n  --random-multi        Convert all multi reads to unique reads by selecting\n                        one alignment at random for each read. DEFAULT : False\n  --no-multi            Throw away all reads that have more than one alignment\n  --no-greedy-caller    Use AREM default peak caller instead of the greedy\n                        caller. This normally results in wider, less enriched\n                        peaks, especially with multi-reads. DEFAULT : False\n  --no-map-quals        Do not use mapping probabilities as priors in each\n                        update step; just use relative enrichment. DEFAULT :\n                        False\n  --prior-snp=PRIOR_PROB_SNP\n                        Prior probability that a SNP occurs at any base in the\n                        genome. DEFAULT : 0.001\n  --write-read-probs    Write out all final reads, including their alignment\n                        probabilities as a BED file. DEFAULT : FALSE\n\n** Parameters:\n\n*** -t/--treatment FILENAME\n\nThis is the only REQUIRED parameter for MACS. If the format is\nELANDMULTIPET, user must provide two treatment files separated by\ncomma, e.g. s_1_1_eland_multi.txt,s_1_2_eland_multi.txt\n\n*** -c/--control\n\nThe control or mock data file in either BED format or any ELAND output\nformat specified by --format option. Please follow the same direction\nas for -t/--treatment.\n\n*** -f/--format FORMAT\n\nFormat of tag file, can be \"ELAND\", \"BED\", \"ELANDMULTI\",\n\"ELANDEXPORT\", \"ELANDMULTIPET\" (for pair-end tags), \"SAM\", \"BAM\" or\n\"BOWTIE\". Default is \"AUTO\" which will allow MACS to decide the format\nautomatically. Please use \"AUTO\" only when you combine different\nformats of files.\n\nThe BED format is defined in \"http://genome.ucsc.edu/FAQ/FAQformat#format1\".\n\nIf the format is ELAND, the file must be ELAND result output file,\neach line MUST represents only ONE tag, with fields of:\n\n 1. Sequence name (derived from file name and line number if format is not Fasta)\n 2. Sequence\n 3. Type of match: \n NM - no match found.\n QC - no matching done: QC failure (too many Ns basically).\n RM - no matching done: repeat masked (may be seen if repeatFile.txt was specified).\n U0 - Best match found was a unique exact match.\n U1 - Best match found was a unique 1-error match. \n U2 - Best match found was a unique 2-error match. \n R0 - Multiple exact matches found.\n R1 - Multiple 1-error matches found, no exact matches.\n R2 - Multiple 2-error matches found, no exact or 1-error matches.\n 4. Number of exact matches found.\n 5. Number of 1-error matches found.\n 6. Number of 2-error matches found.\n Rest of fields are only seen if a unique best match was found (i.e. the match code in field 3 begins with \"U\").\n 7. Genome file in which match was found.\n 8. Position of match (bases in file are numbered starting at 1).\n 9. Direction of match (F=forward strand, R=reverse).\n 10. How N characters in read were interpreted: (\".\"=not applicable, \"D\"=deletion, \"I\"=insertion).\n Rest of fields are only seen in the case of a unique inexact match (i.e. the match code was U1 or U2).\n 11. Position and type of first substitution error (e.g. 12A: base 12 was A, not whatever is was in read).\n 12. Position and type of first substitution error, as above. \n\nIf the format is ELANDMULTI, the file must be ELAND output file from\nmultiple-match mode, each line MUST represents only ONE tag, with\nfields of:\n\n 1. Sequence name \n 2. Sequence \n 3. Either NM, QC, RM (as described above) or the following: \n 4. x:y:z where x, y, and z are the number of exact, single-error, and 2-error matches found\n 5. Blank, if no matches found or if too many matches found, or the following:\n    BAC_plus_vector.fa:163022R1,170128F2,E_coli.fa:3909847R1 This says\n    there are two matches to BAC_plus_vector.fa: one in the reverse\n    direction starting at position 160322 with one error, one in the\n    forward direction starting at position 170128 with two\n    errors. There is also a single-error match to E_coli.fa.\n\nIf the data is from Pair-End sequencing. You can sepecify the format\nas ELANDMULTIPET ( stands for ELAND Multiple-match Pair-End Tags),\nthen the --treat (and --control if needed) parameter must be two file\nnames separated by comma. Each file must be in ELAND multiple-match\nformat described above. e.g.\n\nmacs14 --format ELANDMULTIPET -t s_1_1_eland_multi.txt,s_2_1_eland_multi.txt ...\n\nIf you use ELANDMULTIPET, you may need to modify --petdist parameter.\n\nIf the format is BAM/SAM, please check the definition in\n(http://samtools.sourceforge.net/samtools.shtml)\n\nIf the format is BOWTIE, you need to provide the ASCII bowtie output\nfile with the suffix '.map'. Please note that, you need to make sure\nthat in the bowtie output, you only keep one location for one\nread. Check the bowtie manual for detail if you want at\n(http://bowtie-bio.sourceforge.net/manual.shtml)\n\nHere is the definition for Bowtie output in ASCII characters I copied\nfrom the above webpage:\n\n   1.  Name of read that aligned\n\n   2. Orientation of read in the alignment, - for reverse complement,\n   + otherwise\n\n   3. Name of reference sequence where alignment occurs, or ordinal ID\n   if no name was provided\n\n   4. 0-based offset into the forward reference strand where leftmost\n   character of the alignment occurs\n\n   5. Read sequence (reverse-complemented if orientation is -)\n\n   6. ASCII-encoded read qualities (reversed if orientation is -). The\n   encoded quality values are on the Phred scale and the encoding is\n   ASCII-offset by 33 (ASCII char !).\n\n   7. Number of other instances where the same read aligns against the\n   same reference characters as were aligned against in this\n   alignment. This is not the number of other places the read aligns\n   with the same number of mismatches. The number in this column is\n   generally not a good proxy for that number (e.g., the number in\n   this column may be '0' while the number of other alignments with\n   the same number of mismatches might be large). This column was\n   previously described as \"Reserved\".\n\n   8. Comma-separated list of mismatch descriptors. If there are no\n   mismatches in the alignment, this field is empty. A single\n   descriptor has the format offset:reference-base>read-base. The\n   offset is expressed as a 0-based offset from the high-quality (5')\n   end of the read.\n\nNotes:\n\n1) For BED format, the 6th column of strand information is required by\nMACS. And please pay attention that the coordinates in BED format is\nzero-based and half-open\n(http://genome.ucsc.edu/FAQ/FAQtracks#tracks1).\n\n2) For plain ELAND format, only matches with match type U0, U1 or U2 is\naccepted by MACS, i.e. only the unique match for a sequence with less\nthan 3 errors is involed in calculation. If multiple hits of a single\ntag are included in your raw ELAND file, please remove the redundancy\nto keep the best hit for that sequencing tag.\n\n3) For the experiment with several replicates, it is recommended to\nconcatenate several ChIP-seq treatment files into a single file. To do\nthis, under Unix/Mac or Cygwin (for windows OS), type:\n\n$ cat replicate1.bed replicate2.bed replicate3.bed > all_replicates.bed\n\n4) ELAND export format support sometimes may not work on your\ndatasets, because people may mislabel the 11th and 12th column. MACS\nuses 11th column as the sequence name which should be the chromosome\nnames.\n\n** --petdist=PETDIST     \n\nBest distance between Pair-End Tags. Only available when format is\n'ELANDMULTIPE'. Default is 200bps. When MACS reads mapped positions\nfor 5' tag and 3' tag, it will decide the best pairing for them using\nthis best distance parameter. A simple scoring system is used as following,\n\nscore = abs(abs(p5-p3)-200)+e5+e5\n\nWhere p5 is one of the position of 5' tag, and e5 is the\nmismatch/error for this mapped position of 5' tag. p3 and e3 are for\n3' tag. Then the lowest scored paring is regarded as the best\npairing. The 5' tag position of the pair is kept in model building and\npeak calling.\n\n*** -n/--name\n\nThe name string of the experiment. MACS will use this string NAME to\ncreate output files like 'NAME_peaks.xls', 'NAME_negative_peaks.xls',\n'NAME_peaks.bed' ,'NAME_model.r' and so on. So please avoid any\nconfliction between these filenames and your existing files.\n\n*** -g/--gsize\n\nPLEASE assign this parameter to fit your needs!\n\nIt's the mappable genome size or effective genome size which is\ndefined as the genome size which can be sequenced. Because of the\nrepetitive features on the chromsomes, the actual mappable genome size\nwill be smaller than the original size, about 90% or 70% of the genome\nsize. The default hs -- 2.7e9 is recommended for UCSC human hg18\nassembly. Here are all precompiled parameters for effective genome size:\n\n-g hs   =  -g 2.7e9\n-g mm   =  -g 1.87e9\n-g ce   =  -g 9e7\n-g dm   =  -g 1.2e8\n\n*** -s/--tsize\n\nThe size of sequencing tags. If you don't specify it, MACS will try to\nuse the first 10 sequences from your input treatment file to determine\nthe tag size. Specifying it will override the automatic determined tag\nsize.\n\n*** --bw\n\nThe band width which is used to scan the genome for model\nbuilding. You can set this parameter as the sonication fragment size\nexpected from wet experiment. The previous side effect on the peak\ndetection process has been removed. So this parameter only affects the\nmodel building.\n\n*** -p/--pvalue\n\nThe pvalue cutoff. Default is 1e-5.\n\n*** -m/--mfold\n\nThis parameter is used to select the regions within MFOLD range of\nhigh-confidence enrichment ratio against background to build\nmodel. The regions must be lower than upper limit, and higher than the\nlower limit of fold enrichment. DEFAULT:10,30 means using all regions\nnot too low (>10) and not too high (<30) to build paired-peaks\nmodel. If MACS can not find more than 100 regions to build model, it\nwill use the --shiftsize parameter to continue the peak detection.\n\nCheck related *--off-auto* and *--shiftsize* for detail.\n\n*** --verbose\n\nIf you don't want to see any message during the running of MACS, set\nit to 0. But the CRITICAL messages will never be hidden. If you want\nto see rich information like how many peaks are called for every\nchromosome, you can set it to 3 or larger than 3.\n\n** -w/--wig\n\nIf this flag is on, MACS will store the fragment pileup in\nwiggle format for every chromosomes. The gzipped wiggle files will be\nstored in subdirectories named EXPERIMENT_NAME+'_MACS_wiggle/treat'\nfor treatment data and EXPERIMENT_NAME+'_MACS_wiggle/control' for\ncontrol data.\n\n** --wigextend=WIGEXTEND\n\nIf set as an integer, when MACS saves wiggle files, it will extend tag\nfrom its middle point to a specific size. By default it is modeled\nd. Use this option if you want to modify the resolution in wiggle\nfile. It doesn't affect peak calling.\n\n** --space=SPACE         \n\nBy default, the resoluation for saving wiggle files is 10 bps,i.e.,\nMACS will save the raw tag count every 10 bps. You can change it along\nwith '--wig' option.\n\n** --nolambda\n\nWith this flag on, MACS will use the background lambda as local lambda.\n\n** --slocal, --llocal\n\nThese two parameters control which two levels of regions will be\nchecked around the peak regions to calculate the maximum lambda as\nlocal lambda. By default, MACS considers 1000bp for small local\nregion(--slocal), and 10000bps for large local region(--llocal)\nwhich captures the bias from a long range effect like an open\nchromatin domain. You can tweak these according to your\nproject. Remember that if the region is set too small, a sharp spike\nin the input data may kill the significant peak.\n\n** --off-auto\n\nWhether turn off the auto paired-peak model process. If not set, when\nMACS failed to build paired model, it will use the nomodel settings,\nthe '--shiftsize' parameter to shift and extend each tags. If set,\nMACS will be terminated if paried-peak model is failed.\n\n** --nomodel\n\nWhile on, MACS will bypass building the shifting model.\n\n** --shiftsize\n\nWhile '--nomodel' is set, MACS uses this parameter to shift tags to\ntheir midpoint. For example, if the size of binding region for your\ntranscription factor is 200 bp, and you want to bypass the model\nbuilding by MACS, this parameter can be set as 100. This option is\nonly valid when --nomodel is set or when MACS fails to build\npaired-peak model.\n\n**  --call-subpeaks       \n\nIf set, MACS will invoke Mali Salmon's PeakSplitter software through\nsystem call. If PeakSplitter can't be found, an instruction will be\nshown for downloading and installing the PeakSplitter package. The\nPeakSplitter can refine the MACS peaks and split the wide peaks into\nsmaller subpeaks. For more information, please check the following URL:\n\nhttp://www.ebi.ac.uk/bertone/software/PeakSplitter_Cpp_usage.txt\n\n** --diag\n\nA diagnosis report can be generated through this option. This report\ncan help you get an assumption about the sequencing saturation. This\nfuntion is only in beta stage.\n\n** --fe-min, --fe-max & --fe-step\n\nFor diagnostics, FEMIN and FEMAX are the minimum and maximum fold\nenrichment to consider, and FESTEP is the interval of fold\nenrichment. For example, \"--fe-min 0 --fe-max 40 --fe-step 10\" will\nlet MACS choose the following fold enrichment ranges to consider:\n[0,10), [10,20), [20,30) and [30,40).\n\n** --single-wig\n\nIf this flag is on, MACS will store the fragment pileup in wiggle\nformat for the whole genome instead of for every chromosomes. The\ngzipped wiggle files will be stored in subdirectories named\nEXPERIMENT_NAME+'_MACS_wiggle'+'_MACS_wiggle/treat/'\n+EXPERIMENT_NAME+'treat_afterfiting_all.wig.gz'\nfor treatment data and EXPERIMENT_NAME+'_MACS_wiggle'+'_MACS_wiggle/control/'\n+EXPERIMENT_NAME+'control_afterfiting_all.wig.gz' for control data.\n\n* Output files\n\n 1. NAME_peaks.xls is a tabular file which contains information about\n called peaks. You can open it in excel and sort/filter using excel\n functions. Information include: chromosome name, start position of\n peak, end position of peak, length of peak region, peak summit\n position related to the start position of peak region, number of tags\n in peak region, -10*log10(pvalue) for the peak region (e.g. pvalue\n =1e-10, then this value should be 100), fold enrichment for this\n region against random Poisson distribution with local lambda, FDR in\n percentage. Coordinates in XLS is 1-based which is different with BED\n format.\n\n 2. NAME_peaks.bed is BED format file which contains the peak\n locations. You can load it to UCSC genome browser or Affymetrix IGB\n software.\n\n 3. NAME_summits.bed is in BED format, which contains the peak summits\n locations for every peaks. The 5th column in this file is the summit\n height of fragment pileup. If you want to find the motifs at the\n binding sites, this file is recommended.\n\n 4. NAME_negative_peaks.xls is a tabular file which contains\n information about negative peaks. Negative peaks are called by\n swapping the ChIP-seq and control channel.\n\n 5. NAME_model.r is an R script which you can use to produce a PDF\n image about the model based on your data. Load it to R by:\n\n$ R --vanilla < NAME_model.r\n\nThen a pdf file NAME_model.pdf will be generated in your current\ndirectory. Note, R is required to draw this figure.\n\n 6. NAME_treat/control_afterfiting.wig.gz files in NAME_MACS_wiggle\n directory are wiggle format files which can be imported to UCSC\n genome browser/GMOD/Affy IGB.\n\n 7. NAME_diag.xls is the diagnosis report. First column is for various\n fold_enrichment ranges; the second column is number of peaks for that fc\n range; after 3rd columns are the percentage of peaks covered after\n sampling 90%, 80%, 70% ... and 20% of the total tags.\n\n 8. NAME_peaks.subpeaks.bed is a text file which IS NOT in BED\n format. This file is generated by PeakSplitter\n (<http://www.ebi.ac.uk/bertone/software/PeakSplitter_Cpp_usage.txt>)\n when --call-subpeaks option is set.\n\n* FAQs"}}, {"pk": 320, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "simuPOP", "license": "UNKNOWN", "author": "Bo Peng", "author_email": "bpeng@mdanderson.org", "project_url": null, "maintainer_email": null, "home_page": "http://simupop.sourceforge.net", "version": "1.0.0", "platform": "all", "keywords": null, "summary": "Forward-time population genetics simulation environment", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "simuPOP is a forward-time population genetics simulation environment.\nThe core of simuPOP is a scripting language (Python) that provides \na large number of objects and functions to manipulate populations, \nand a mechanism to evolve populations forward in time. Using this \nR/Splus-like environment, users can create, manipulate and evolve \npopulations interactively, or write a script and run it as a batch \nfile. Owing to its flexible and extensible design, simuPOP can simulate\nlarge and complex evolutionary processes with ease. At a more \nuser-friendly level, simuPOP provides an increasing number of built-in\nscripts that perform simulations ranging from implementation of basic \npopulation genetics models to generating datasets under complex \nevolutionary scenarios."}}, {"pk": 321, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cynote", "license": "GNU General Public License version 3", "author": "Maurice HT Ling", "author_email": "mauriceling@acm.org", "project_url": null, "maintainer_email": null, "home_page": "http://cynote.sourceforge.net", "version": "1.1", "platform": "UNKNOWN", "keywords": null, "summary": "Cyber Laboratory Notebook", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "Laboratory notebook using version control system for       backups and independent date-time stamping (which may be a form of       notarization), in order to ensure record accountability and auditing."}}, {"pk": 322, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.handlers.csv", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/handlers.html#csv", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "csv database opendap dods dap data science climate oceanography meteorology", "summary": "A CSV handler for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This handler enables Pydap to serve data from CSV files."}}, {"pk": 323, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.enum", "license": "BSD/PSF/GPL", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.enum", "version": "1.0.6", "platform": "any", "keywords": "utility", "summary": "A variant of the 'enum' package that supports pickling.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nLicense :: OSI Approved :: GNU General Public License (GPL)\nLicense :: OSI Approved :: Python Software Foundation License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "====================\npyutilib.enum README\n====================\n\nThis Python package is a variant of the PyPI 'enum' package.  This package\nhas been modified to support pickling of enum objects, which required\na weakening of the comparison semantics.  Also, this class supports\nhelper functions that allow enumeration objects to be retrieved given\nthe enumeration constant value.\n\n\n-------\nLicense\n-------\n\nSee the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 324, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyaudiere", "license": "GPL", "author": "Christopher Brown", "author_email": "c-b /at/ asu.edu", "project_url": null, "maintainer_email": null, "home_page": "http://www.pyaudiere.org", "version": "0.2", "platform": "Win32,Linux", "keywords": "sound audio wavplay", "summary": "PyAudiere! A high-level audio interface for Python.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Multimedia :: Sound/Audio\nTopic :: Scientific/Engineering", "description": "PyAudiere is a very flexible and easy to use audio library.\n        Available methods allow you to read soundfiles of various formats\n        into memory and play them, or stream them if they are large. You\n        can pass sound buffers as NumPy arrays of float32's to play\n        (non-blocking). You can also create pure tones, square waves, or\n        'on-line' white or pink noise. All of these functions can\n        be utilized concurrently. Sweet!"}}, {"pk": 325, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.responses.kml", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/responses.html#kml", "version": "0.4.5", "platform": "UNKNOWN", "keywords": "kml opendap dods dap data science climate oceanography meteorology", "summary": "KML response for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This response enables the visualization of the data using\nGoogle Earth."}}, {"pk": 326, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.responses.wms", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/responses/wms", "version": "0.3.5", "platform": "UNKNOWN", "keywords": "wms dap opendap dods data", "summary": "WMS response for pydap server", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "pydap--WMS bridge.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/responses/wms#egg=dap.responses.wms-dev>`_."}}, {"pk": 327, "model": "importing.pypicache", "fields": {"maintainer": "Mary Haley", "name": "PyNGL", "license": "Free but restricted, see http://www.pyngl.ucar.edu/license.shtml", "author": "Fred Clare and Mary Haley", "author_email": "fred@ucar.edu and haley@ucar.edu", "project_url": null, "maintainer_email": "haley@ucar.edu", "home_page": "http://www.pyngl.ucar.edu/", "version": "1.0", "platform": "MacOSX (Intel and PPC)\r\n32-bit and 64-bit (x86_64) Linux\r\nSGI/IRIX64\r\nSolaris 9", "keywords": "Graphics, scientific visualization, plotting", "summary": "PyNGL is a module used to visualize scientific data.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: MacOS X\nEnvironment :: X11 Applications\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: Free To Use But Restricted\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: AIX\nOperating System :: POSIX :: BSD\nOperating System :: POSIX :: IRIX\nOperating System :: POSIX :: Linux\nOperating System :: POSIX :: SunOS/Solaris\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Atmospheric Science\nTopic :: Scientific/Engineering :: Visualization", "description": "PyNGL (pronounced \"pingle\") is a Python language module used to visualize\r\nscientific data, with an emphasis on high quality 2D visualizations."}}, {"pk": 328, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "uncertainties", "license": "This software can be used under one of the following two licenses: (1) The BSD license. (2) Any other license, as long as it is obtained from the original author.", "author": "Eric O. LEBIGOT (EOL)", "author_email": "eric.lebigot@normalesup.org", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/uncertainties/", "version": "1.7.1", "platform": "UNKNOWN", "keywords": "error propagation,uncertainties,uncertainty calculations,standard deviation,derivatives,partial derivatives,differentiation", "summary": "Transparent calculations with uncertainties on the quantities involved (aka \"error propagation\") ; fast calculation of derivatives", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "Overview\n========\n\n``uncertainties`` allows calculations such as (2 \u00b1 0.1)*2 = 4\n\u00b1 0.2 to be performed transparently.  Much more complex mathematical\nexpressions involving numbers with uncertainties can also be evaluated\ndirectly.\n\n**Detailed information** about this package can be found on its `main\nwebsite`_.\n\nBasic examples\n==============\n\n::\n\n    >>> from uncertainties import ufloat\n    \n    >>> x = ufloat((2, 0.25))\n    >>> x\n    2.0+/-0.25\n    \n    >>> square = x**2  # Transparent calculations\n    >>> square\n    4.0+/-1.0\n    >>> square.nominal_value\n    4.0\n    >>> square.std_dev()  # Standard deviation\n    1.0\n\n    >>> square - x*x\n    0.0  # Exactly 0: correlations taken into account\n\n    >>> from uncertainties.umath import *  # sin(), etc.\n    >>> sin(1+x**2)\n    -0.95892427466313845+/-0.2836621854632263\n    \n    >>> print (2*x+1000).derivatives[x]  # Automatic calculation of derivatives\n    2.0\n    \n    >>> from uncertainties import unumpy  # Array manipulation\n    >>> random_vars = unumpy.uarray(([1, 2], [0.1, 0.2]))\n    >>> print random_vars\n    [1.0+/-0.1 2.0+/-0.2]\n    >>> random_vars.mean()\n    1.5+/-0.1118033988749895\n    >>> print unumpy.cos(random_vars)\n    [0.540302305868+/-0.0841470984808 -0.416146836547+/-0.181859485365]\n\nMain features\n=============\n\n- **Transparent calculations** with uncertainties: no or little\n  modification of existing code is needed.  Similarly, the Python_ (or\n  IPython_) shell can be used as **a powerful calculator** that\n  handles quantities with uncertainties (``print`` statements are\n  optional, which is convenient).\n\n- **Correlations** between expressions are correctly taken into\n  account.  Thus, ``x-x`` is exactly zero, for instance (most\n  implementations found on the web yield a non-zero uncertainty for\n  ``x-x``, which is incorrect).\n\n- **Almost all mathematical operations** are supported, including most\n  functions from the standard math_ module (sin,...).  Comparison\n  operators (``>``, ``==``, etc.) are supported too.\n\n- This module also gives access to the **derivatives** of any \n  mathematical expression (they are used by error\n  propagation theory, and are thus automatically calculated by this\n  module).\n\n- Many **fast operations on arrays and matrices** of numbers with\n  uncertainties are supported.\n\nInstallation or upgrade\n=======================\n\nInstallation instructions are available on the `main web site\n<http://packages.python.org/uncertainties/#installation-and-download>`_\nfor this package.\n\nContact\n=======\n\nPlease send **feature requests, bug reports, or feedback** to\n`Eric O. LEBIGOT (EOL)`_.\n\nPlease **support this program** and its future development by donating\n$5 or more through PayPal_.\n\n\nVersion history\n===============\n\nMain changes:\n\n- 1.7.1: New semantics: ``ufloat('12.3(78)')`` now represents 12.3\u00b17.8          instead of 12.3\u00b178.\n- 1.7: ``ufloat()`` now raises ValueError instead of a generic Exception,        when given an incorrect        string representation, like ``float()`` does.\n- 1.6: Testing whether an object is a number with uncertainty should now        be done with ``isinstance(\u2026, UFloat)``.        AffineScalarFunc is not imported by ``from uncertainties import *``        anymore, but its new alias ``UFloat`` is.\n- 1.5.5: The first possible license is now BSD instead of GPLv2, which          makes it easier to include this package in other projects.\n- 1.5.4.2: Added ``umath.modf()`` and ``umath.frexp()``.\n- 1.5.4: ``ufloat`` does not accept a single number (nominal value) anymore.        This removes some potential confusion about        ``ufloat(1.1)`` (zero uncertainty) being different from        ``ufloat(\"1.1\")`` (uncertainty of 1 on the last digit).\n- 1.5.2: ``float_u``, ``array_u`` and ``matrix_u`` renamed ``ufloat``,        ``uarray`` and ``umatrix``, for ease of typing.\n- 1.5:  Added functions ``nominal_value`` and ``std_dev``, and        modules ``unumpy`` (additional support for NumPy_ arrays and        matrices) and ``unumpy.ulinalg`` (generalization of some        functions from ``numpy.linalg``).        Memory footprint of arrays of numbers with uncertainties        divided by 3.        Function ``array_u`` is 5 times faster.        Main function ``num_with_uncert`` renamed        ``float_u``, for consistency with ``unumpy.array_u`` and        ``unumpy.matrix_u``, with the added benefit of a shorter name.\n- 1.4.5: Added support for the standard ``pickle`` module.\n- 1.4.2: Added support for the standard ``copy`` module.\n- 1.4: Added utilities for manipulating NumPy_ arrays of numbers with       uncertainties (``array_u``, ``nominal_values`` and ``std_devs``).\n- 1.3: Numbers with uncertainties are now constructed with   ``num_with_uncert()``, which replaces ``NumberWithUncert()``.  This   simplifies the class hierarchy by removing the ``NumberWithUncert`` class.\n- 1.2.5: Numbers with uncertainties can now be entered as          ``NumberWithUncert(\"1.23+/-0.45\")`` too.\n- 1.2.3: ``log(x, base)`` is now supported by ``umath.log()``, in addition          to ``log(x)``.\n- 1.2.2: Values with uncertainties are now output like 3+/-1, in order          to avoid confusing 3+-1 with 3+(-1).\n- 1.2: A new function, ``wrap()``, is exposed, which allows non-Python        functions (e.g. Fortran or C used through a module such as SciPy) to        handle numbers with uncertainties.\n- 1.1: Mathematical functions (such as cosine, etc.) are in a new        uncertainties.umath module;        they do not override functions from the ``math`` module anymore.\n- 1.0.12: Main class (``Number_with_uncert``) renamed ``NumberWithUncert``           so as to follow `PEP 8`_.\n- 1.0.11: ``origin_value`` renamed more appropriately as           ``nominal_value``.\n- 1.0.9: ``correlations()`` renamed more appropriately as          ``covariance_matrix()``.\n\n.. _Python: http://docs.python.org/tutorial/interpreter.html\n.. _IPython: http://ipython.scipy.org/\n.. _NumPy: http://numpy.scipy.org/\n.. _math: http://docs.python.org/library/math.html\n.. _PEP 8: http://www.python.org/dev/peps/pep-0008/\n.. _error propagation theory: http://en.wikipedia.org/wiki/Propagation_of_uncertainty\n.. _setuptools: http://pypi.python.org/pypi/setuptools\n.. _Eric O. LEBIGOT (EOL): mailto:eric.lebigot@normalesup.org\n.. _PayPal: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=4TK7KNDTEDT4S\n.. _main website: http://packages.python.org/uncertainties/"}}, {"pk": 329, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "fisher", "license": "BSD", "author": "haibao tang, brent pedersen", "author_email": "bpederse@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/brentp/fishers_exact_test", "version": "0.1.4", "platform": "UNKNOWN", "keywords": "statistics cython", "summary": "Fast Fisher's Exact Test", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "Fisher's Exact Test\n===================\n\nSimple, fast implementation of `Fisher's exact test <http://en.wikipedia.org/wiki/Fisher's_exact_test>`_. . For example, for the following table:\n\n============  =====================  =========================\no              Having the property    Not having the property\n============  =====================  =========================\nSelected      12                     5\nNot selected  29                     2\n============  =====================  =========================\n\nPerhaps we are interested in whether there is any difference of property in selected vs. non-selected groups, then we can do the Fisher's exact test.\n\n\nInstallation\n============\nwithin this folder ::\n\n    easy_install .\n\nfrom pypi ::\n\n    easy_install fisher\n\nor from github (contributions welcomed) ::\n    \n    git clone git://github.com/brentp/fishers_exact_test.git\n\n\nUsage\n=====\n``fisher.pvalue()`` accepts 4 values corresponding to the 2-by-2 contingency table, returns an object with attributes for left_tail, right_tail, and two_tail p-values\n::\n\n    >>> from fisher import pvalue\n    >>> mat = [[12, 5], [29, 2]]\n    >>> p = pvalue(12, 5, 29, 2)\n    >>> p.left_tail, p.right_tail, p.two_tail\n    (0.044554737835078267, 0.99452520602190897, 0.08026855207410688)\n\nBenchmark\n=========\nA simple benchmark that calls the Fisher's exact test 1000 times (in ``scripts/rfisher.py``)::\n\n    calling python fisher...\n    iterations/sec: 3000.62526381\n    calling rpy fisher...\n    iterations/sec: 289.225902364\n    calling R directly...\n    iterations/sec: 244.36542276\n\nSo the cython fisher is up to 10 times faster than rpy or R version."}}, {"pk": 330, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "csc-utils", "license": "http://www.gnu.org/copyleft/gpl.html", "author": "MIT Media Lab, Software Agents group", "author_email": "conceptnet@media.mit.edu", "project_url": null, "maintainer_email": null, "home_page": "http://csc.media.mit.edu/", "version": "0.6", "platform": "any", "keywords": null, "summary": "A set of utility functions for Python that the Commonsense Computing project uses in multiple projects.", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Text Processing :: Linguistic", "description": "Includes:\n\n* A `foreach` with progress reporting (also Status.reporter)\n* A generator for the \"sampling sequence\" (binary van der Corput sequence),\n  useful for incremental resolution on graphs.\n* A dictionary that stores its items as pickles in a directory. Features\n  lazy loading and lazy evaluation.\n\nPlus a few more odds and ends."}}, {"pk": 331, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "garlicsim_wx", "license": "Proprietary", "author": "Ram Rachum", "author_email": "cool-rr@cool-rr.com", "project_url": null, "maintainer_email": null, "home_page": "http://garlicsim.org", "version": "0.6.2", "platform": "UNKNOWN", "keywords": null, "summary": "GUI for garlicsim, a Pythonic framework for computer simulations", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering", "description": "A wxPython-based GUI for garlicsim.\n\nThe final goal of this project is to become a fully-fledged application for\nworking with simulations, friendly enough that it may be used by\nnon-programmers."}}, {"pk": 332, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pylabrad", "license": "http://www.gnu.org/licenses/gpl-2.0.html", "author": "Matthew Neeley", "author_email": "maffoo@users.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://sourceforge.net/projects/pylabrad/", "version": "0.92.1", "platform": "ANY", "keywords": null, "summary": "LabRAD interface for python", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: Web Environment\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "LabRAD is a system for quickly and easily building distributed\ninstrument control and data analysis applications.  pylabrad\nprovides a python interface to LabRAD."}}, {"pk": 333, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ScipySim", "license": "GPLv3", "author": "Brian Thorne, Allan McInnes", "author_email": "hardbyte@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/scipy-sim/", "version": "0.1.5", "platform": "UNKNOWN", "keywords": "simulation,scipy,discrete events", "summary": "Simulation in Python.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering", "description": "===============\nScipy Simulator\n===============\n\nScipy Simulator provides a **concurrent** way of modelling and simulating \nheterogeneous systems in Python using scipy. You might find it most useful \nfor tasks involving *embedded systems* or *signal processing*. \n\nScipysim models are created in pure Python code, by instantiating various\nactors representing different components of a systems, and connecting \nthe actors to each other through channels. Here's a simple example of what\na model looks like::\n\n    #!/usr/bin/env python\n\n    from scipysim.actors.signal import Ramp\n    from scipysim.actors.display import Plotter\n    from scipysim.actors import Channel, Model\n\n    class RampPlot( Model ):\n        def __init__( self ):\n\t        super( RampPlot, self ).__init__()\n\t        connection = Channel()\n\t        src = Ramp( connection )\n\t        dst = Plotter( connection )\n    \t    self.components = [src, dst]\n\n    RampPlot().run()\n\nYou can find a number of other examples of models in the 'models' directory.\n\nThe scipysim project is inspired by the UC Berkeley Ptolemy project, but \nwe are taking a slightly different approach to implementing the \nsimulation engine. Our approach is based on implementing the simulator \nas a Kahn network of actors that communicate via tagged-signals. Each of \nthese actors run in their own thread, and communicate via dedicated \nChannels - which are based on the thread safe FIFO queue implementation \nin the Python standard library. These base level actors can be composed \ntogether to create models, which are also actors in their own right - \nrunning in their own thread with all communication occurring through \ninput and output channels.\n\nScipysim is still very much under active development, and contains a \nnumber of experimental or prototype components. The structure of the \nsimulator is in a state of flux, so there are no guarantees that models\ndeveloped to work with a particular release will still work with the next release.\n\nTesting Scipy Simulator\n=======================\n\nScipy Simulator comes with a large collection of unit tests.\nAll the tests can be run as a suite using nosetests::\n\n\tnosetests\n\t\nA helper script called test_scipysim.py has been placed in the scipysim \nmodule to launch nosetests::\n\n\t./scipysim/test_scipysim.py\n\nIf you downloaded from the repository the tests can be run with setuptools::\n\n\tpython setup.py test\n\nThe tests can also be found in the module hierarchy and run individually::\n\n\tpython ./scipysim/actors/io/test_io.py\n\n\nInstalling Scipy Simulator\n==========================\n\nYou can install scipysim to your main site-packages folder with::\n\n\tsudo python setup.py install\n\t\non Linux or Mac OS X; and::\n\t\n\tpython setup.py install\n\t\non Windows. To install in a more sandboxed \"development\" environment\nsubstitute develop for install, e.g.::\n\n\tsudo python setup.py develop\n\nThis installs an egg at the current directory and links to the package \nin your site-packages folder.\n \nCreating Binary Installers\n==========================\n\nFirstly to clean the obsolete .pyc or .pyo files use::\n\n\tpython setup.py clean --all\n\nGenerate a built distribution like so::\n\n\tpython setup.py bdist\n\t\nOn Windows, to make a nice pretty GUI installer::\n\n\tpython setup.py bdist --format wininst\n\nSimilarly a source distribution can be created with::\n\n\tpython setup.py sdist\n\nContributors\n============\n\nThis project was initiated in the Department of Electrical & Computer \nEngineering at the University of Canterbury (http://www.elec.canterbury.ac.nz/) by:\n\n* Brian Thorne (brian dot thorne at canterbury dot ac dot nz)\n\n* Allan McInnes (allan dot mcinnes at canterbury dot ac dot nz)\n\n\nProject Site\n============\nThe main development occurs on Google Code at http://scipy-sim.googlecode.com\n\n\nContribute to scipysim\n======================\n\nFirst get the source code with mercurial:\n\n\thg clone https://scipy-sim.googlecode.com/hg/ scipy-sim\n\t\nAnd send us a patch by creating a new issue http://code.google.com/p/scipy-sim/issues/entry"}}, {"pk": 334, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "guiqwt", "license": "CECILL", "author": "Pierre Raybaut", "author_email": "pierre.raybaut@cea.fr", "project_url": null, "maintainer_email": "", "home_page": "http://guiqwt.googlecode.com/", "version": "2.0.8.1", "platform": "UNKNOWN", "keywords": "", "summary": "efficient 2D data-plotting library", "classifiers": "Development Status :: 5 - Production/Stable\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering", "description": "Based on PyQwt (plotting widgets for PyQt4 graphical user interfaces) and on the scientific modules NumPy and SciPy, guiqwt is a Python library providing efficient 2D data-plotting features (curve/image visualization and related tools) for interactive computing and signal/image processing application development."}}, {"pk": 335, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ipdasite.theme", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/ipdasite.theme/", "version": "2.0.0", "platform": "UNKNOWN", "keywords": "web zope plone planetary data science theme style", "summary": "International Planetary Data Alliance Site Theme", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Atmospheric Science\nTopic :: Software Development :: Libraries :: Python Modules", "description": "**************\nipdasite.theme\n**************\n\nThis package provides the look and feel for the the International Planetary\nData Alliance (IPDA_) web site.\n\nAlthough intended for the web site of the IPDA, this package may be installed\non any Plone_ 4 site.  It was developed by the Planetary Data System (PDS_).\n\n.. References:\n.. _IPDA: http://planetarydata.org/\n.. _Plone: http://plone.org/\n.. _PDS: http://pds.nasa.gov/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``ipdasite.theme`` to the list of eggs to install, e.g.::\n\n    [buildout]\n    ...\n    eggs =\n        ...\n        ipdasite.theme\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n\n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        ipdasite.theme\n        \n* Re-run buildout, e.g. with::\n  \n    $ ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\n2.0.0 - Plone 4\n---------------\n\nThis release of the IPDA Site Policy brings about Plone 4 compatibility.\n\n\nCopyright & License\n===================\n\nCopyright 2008-2011 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 336, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "visionegg", "license": "LGPL", "author": "Andrew Straw", "author_email": "astraw@users.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://www.visionegg.org/", "version": "1.2.1", "platform": "UNKNOWN", "keywords": null, "summary": "2D/3D visual stimulus generation", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: MacOS X\nEnvironment :: Other Environment\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: IRIX\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Multimedia :: Graphics :: 3D Rendering\nTopic :: Multimedia :: Graphics :: Presentation\nTopic :: Multimedia :: Video :: Display\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Scientific/Engineering :: Medical Science Apps.\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries", "description": "The Vision Egg is a programming library (with demo applications)\nthat uses standard, inexpensive computer graphics cards to produce\nvisual stimuli for vision research experiments.\n\nFor more information, visit the website at www.visionegg.org\n\nAny feedback, questions, or comments, should go to the mailing list at\nvisionegg@freelists.org\n\nThe Vision Egg is Copyright (c) by its authors and is distributed\nunder the GNU Lesser General Public License (LGPL).  This software\ncomes with absolutely no warranties, either expressed or implied."}}, {"pk": 337, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "axographio", "license": "BSD License", "author": "Kendrick Shaw", "author_email": "kms15@case.edu", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/axographio/", "version": "0.1.1b1", "platform": "UNKNOWN", "keywords": "physiology,electrophysiology,axograph", "summary": "A python library for reading and writing AxoGraph data files", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "axographio is a library that makes it easy to read and write binary data files\nin the AxoGraph file format.  \n\nAxoGraph X is a commercial software package used for data acquisition and\nanalysis that is widely used in electrophysiological research (see\nhttp://axographx.com for more details).  While it can read and write files in\ntext format, its binary format is much smaller and faster to load and save;\nthus many users preferentially use this format.  The company distributes the\ndetails of the file format along with sample C++ code for reading and writing\nto these files with AxoGraph X.\n\nPython is a powerful and easy to use general purpose programming language (see\nhttp://python.org for more details).  There are many useful python libraries\navailable for scientific data analysis and data visualization such as scipy,\nmatplotlib and MayaVI.  \n\nThis library provides a simple interface for loading AxoGraph data files into\na python program or interactive session.  If you want to analyze data you\nrecorded in AxoGraph using python based tools, this library provides the glue\ncode you'll need.  \n\nInstallation\n============\n\nPreinstallation Requirements\n----------------------------\n\n* A working Python installation\n* The setuptools package\n* The NumPy package\n* The Cython package\n\nNote that NumPy takes a bit of work to build, so it may be easiest to install\nit from your linux distribution's repository, or use as pre-built package\nsuch as the Scipy Superpack (http://macinscience.org/?page_id=6) for the mac. \nDepending on your OS, you may be able to get away with simply typing:\n\n::\n\n sudo easy_install numpy\n sudo easy_install Cython\n\n\nInstallation\n------------\n\nOnce all the preinstallation requirements have been met, you can download and\ninstall axographio using easy_install by typing the following command in a\nterminal window:\n\n::\n\n easy_install axographio\n\n\nUpgrading\n---------\n\nIf you have an older version of the package installed, you can update it to \nthe newest version using easy_install with the \"-U\" flag:\n\n::\n \n easy_install -U axographio\n\nUsage\n=====\n\nLoading a data file is as easy as calling `read`:\n\n>>> import axographio\n>>>\n>>> f = axographio.read(\"AxoGraph X File.axgx\") \n\nAt this point the variable f will contain a file_contents object with the\ncolumn names and data from the file.  For example, you could now plot the first\ntwo columns using matplotlib:\n\n>>> import matplotlib.pyplot as plt\n>>> \n>>> plt.plot(f.data[0], f.data[1]) \n>>> plt.xlabel(f.names[0]) \n>>> plt.ylabel(f.names[1])\n>>> plt.show() \n\n(The plt.show() command may be optional depending on your OS.)\n\nOf course, you probably have grander plans than just plotting the data.  The\ncolumn data supports the standard sequence interfaces (i.e. indexing,\niteration, etc.) and can be converted to a scipy or numpy array using the\nasarray functions in these packages, e.g.:\n\n>>> import scipy as sp\n>>>\n>>> times = sp.asarray(f.data[0])\n\nWriting files is also relatively easy.  You simply create a new file_contents\nobject (or use one you loaded earlier), and then call write.  For example, the\nfollowing code creates a file in the current directory called \"my60Hz.axgx\" \nwith two channels with 60 Hz sine waves\n\n>>> import axographio \n>>> import numpy as np\n>>>\n>>> times = np.arange(0,10,0.0001) \n>>> column1 = np.sin(2*np.pi * 60 * times) \n>>> column2 = np.cos(2*np.pi * 60 * times) \n>>> f = axographio.file_contents(\n...    ['time (s)', 'my recording (V)', 'your recording (V)'], \n...    [times, column1, column2])\n>>> f.write(\"my60Hz.axgx\")\n\n\nQuestions and Support\n=====================\n\nPlease post any questions, problems, comments, or suggestions on the axographio\ngroup on google groups (http://groups.google.com/group/axographio)\n\n\nNews\n====\n\n0.1.1\n-----\n    Fixed a rounding error that could create one extra data point in the time \n    column. \n\n0.1.0\n-----\n    First release\n\n\nAcknowledgments\n===============\n\nThis initial version of this project was written in the\nChiel Laboratory at Case Western Reserve University, with support from NIH\ngrant NS047073, an Ohio Innovation Incentive Award Fellowship, and the\nCase Western Reserve MSTP (NIH T32 GM007250).  This project builds on a \nnumber of other open source projects, including Python, C++ AxoGraph file\ninput/output code from AxoGraph Scientific (placed in the public domain; a\nmodified version is included with the project source code), Cython, and many\nothers.  Thanks also to Dr. Hillel Chiel for providing testing and helpful \nsuggestions."}}, {"pk": 338, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "leaf", "license": "MIT", "author": "Roman Koblov", "author_email": "pingu.g@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "https://github.com/penpen/Leaf", "version": "0.4", "platform": "UNKNOWN", "keywords": "html,parsing,web scrapping", "summary": "Simple Python library for HTML parsing", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis", "description": "Leaf\n====\nWhat is this?\n-------------\nThis is a simple wrapper around lxml, which adds some nice features,\nwhich make work with lxml better. This library covers all my needs in\nhtml parsing.\n\nDependencies\n------------\n`lxml <http://lxml.de/>`_ obviously :3\n\nFeatures\n--------\n * Nice jquery-like css selectors\n * Simple access to element attributes\n * Easy way for convert html to other format (bbcode, markdown, etc)\n * Few nice functions for work with text\n * And, of course this saves all original features of lxml\n\nDescription\n-----------\nMain function of module (as I mind) is leaf.parse, this function takes string with \nhtml as an argument, and returns leaf.Parser object, which wraps lxml object.\nWith this object you can do anything you want, like this::\n\n\tdocument = leaf.parse(sample)\n\tlinks = document('div#menu a') # get links in div with id menu through css selectors\n\nOr you can do this::\n\n\tlink = document.get('div#menu a') # get first link or return None\n\nAnd you can get attributes from these results like this::\n\n\tprint link.onclick\n\nAnyway, you can use standard lxml methods like object.xpath, and they returns results \nwrapped into leaf.Parser.\nSo, my favorite feature is parsing html into bbcode (markdown, etc)::\n\n\t# Lets define simple formatter, which pass text \n\t# and wraps links into [url][/url] (like bbcode)\n\tdef omgcode_formatter(element, childrens):\n\t\t# Replace <br> tag with line break\n\t    if element.tag == 'br':\n\t        return '\\n'\n\t\t# Wrap links into [url][/url]\n\t    if element.tag == 'a':\n\t        return u\"[url=link}]{text}[/url]\".format(link=element.href, text=childrens)\n\t\t# Return childrens only for other elements.\n\t    if childrens:\n\t        return childrens\n\nThis function will be recursively called with element and childrens (this is string with \nchildrens parsing result).\nSo, lets call this parser in some leaf.Parser object::\n\n\tdocument.parse(omgcode_formatter)\n\nMore detailed examples availible in the tests.\n\nFinally, this library has some nice functions for work with text:\n\n*to_unicode* -- Convert string to unicode string\n\n*strip_accents* -- Strip accents from a string\n\n*strip_symbols* -- Strip ugly unicode symbols from a string\n\n*strip_spaces* -- Strip excess spaces from a string\n\n*strip_linebreaks* -- Strip excess line breaks from a string"}}, {"pk": 339, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "opendws", "license": "GNU General Public License version 2", "author": "Maurice HT Ling", "author_email": "mauriceling@acm.org", "project_url": null, "maintainer_email": null, "home_page": "http://opendws.sourceforge.net", "version": "0.0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Open data warehousing suite", "classifiers": "Development Status :: 1 - Planning\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Database Engines/Servers\nTopic :: Scientific/Engineering", "description": "Assemble and create a platform- and DBMS-independent suite of architected software for data warehousing and analysis"}}, {"pk": 340, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pebl", "license": "MIT", "author": "Abhik Shah", "author_email": "abhikshah@gmail.comm", "project_url": null, "maintainer_email": null, "home_page": "http://pebl-project.googlecode.com", "version": "1.0.2", "platform": "UNKNOWN", "keywords": null, "summary": "Python Environment for Bayesian Learning", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "Pebl is a python library and command line application for learning the\nstructure of a Bayesian network given prior knowledge and observations.  Pebl\nincludes the following features:\n\n * Can learn with observational and interventional data\n * Handles missing values and hidden variables using exact and heuristic\n   methods \n * Provides several learning algorithms; makes creating new ones simple\n * Supports hard and soft structural priors\n * Has facilities for transparent parallel execution\n * Calculates edge marginals and consensus networks\n * Presents results in a variety of formats"}}, {"pk": 341, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MLPY", "license": "GPLv3", "author": "mlpy Developers - FBK-MPBA", "author_email": "albanese@fbk.eu", "project_url": null, "maintainer_email": null, "home_page": "https://mlpy.fbk.eu", "version": "2.2.0", "platform": "UNKNOWN", "keywords": null, "summary": "mlpy - Machine Learning Py - high-performance Python package for predictive modeling", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: BSD\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence", "description": "UNKNOWN"}}, {"pk": 342, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pygooglechart", "license": "UNKNOWN", "author": "Gerald Kaszuba", "author_email": "gerald@geraldkaszuba.com", "project_url": null, "maintainer_email": null, "home_page": "http://pygooglechart.slowchop.com/", "version": "0.3.0", "platform": "UNKNOWN", "keywords": null, "summary": "A complete Python wrapper for the Google Chart API", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 343, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "simplui", "license": "BSD", "author": "Tristam MacDonald", "author_email": "swiftcoder@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://simplui.googlecode.com/", "version": "1.0.4", "platform": "all", "keywords": null, "summary": "Light-weight GUI toolkit for pyglet", "classifiers": "Intended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: User Interfaces", "description": "UNKNOWN"}}, {"pk": 344, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coinor.coopr", "license": "BSD", "author": "William Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://projects.coin-or.org/CoinBazaar/wiki/Projects/coinor.coopr", "version": "2.4", "platform": "any", "keywords": "optimization", "summary": "COIN-OR project for Coopr", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "===================\ncoinor.coopr README\n===================\n\nThis is a package that wraps Coopr and imports it into the namespace package coinor.\n\nFor all other documentation please see the documentation in the Coopr project."}}, {"pk": 345, "model": "importing.pypicache", "fields": {"maintainer": "Alexei Gilchrist and Paul Cochrane", "name": "PyScript", "license": "Gnu Public License", "author": "Alexei Gilchrist and Paul Cochrane", "author_email": "aalexei@users.sourceforge.net, paultcochrane@users.sourceforge.net", "project_url": null, "maintainer_email": "aalexei@users.sourceforge.net, paultcochrane@users.sourceforge.net", "home_page": "http://pyscript.sourceforge.net", "version": "0.6.0", "platform": "OS Independent", "keywords": "presentation scientific/engineering graphics drawing", "summary": "Postscript Graphics with Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization", "description": "PyScript is a python module for producing high quality postscript graphics.\r\nRather than use a GUI to draw a picture, the picture is programmed using python\r\nand the PyScript objects.\r\n\r\nSome of the key features are:\r\n    * All scripting is done in python, which is a high level, easy to learn,\r\nwell-developed scripting language.\r\n    * All the objects can be translated, scaled, rotated, ... in fact any affine\r\ntransformation.\r\n    * Plain text is automatically kerned.\r\n    * You can place arbitrary LaTeX expressions on your figures.\r\n    * You can create your own figure objects, and develop a library of figure\r\nprimitives.\r\n    * Output is publication quality."}}, {"pk": 346, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "py_graph", "license": "MIT License", "author": "Zach Frazier", "author_email": "zfrazier@washington.edu", "project_url": null, "maintainer_email": null, "home_page": "http://compbio.washington.edu/~zach/py_graph/", "version": "0.4", "platform": "UNKNOWN", "keywords": null, "summary": "A graph and graph algorithm package.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "A graph and graph algorithm package with support for directed and undirected graphs.  There are several algorithms provided, including shortest paths, minimum spanning trees, strongly connected components, depth/breadth first search, and more.  A clean API makes writing new algorithms easy."}}, {"pk": 347, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyvisfile", "license": "MIT", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/pyvisfile", "version": "2010.1", "platform": "UNKNOWN", "keywords": null, "summary": "Large-scale Visualization Data Storage", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics :: 3D Modeling\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries", "description": "Pyvisfile allows you to write a variety of visualization file formats,\n            including\n\n            * `Kitware's <http://www.kitware.com>`_ \n              `XML-style <http://www.vtk.org/VTK/help/documentation.html>`_\n              `Vtk <http://vtk.org>`_ data files.\n\n            * Silo visualization files, as\n              introduced by LLNL's \n              `MeshTV <https://wci.llnl.gov/codes/meshtv/>`_ and\n              more recently used by the \n              `VisIt <https://wci.llnl.gov/codes/visit/>`_ \n              large-scale visualization program. \n\n            pyvisfiles supports many mesh geometries, such such as unstructured\n            and rectangular structured meshes, particle meshes, as well as\n            scalar and vector variables on them. In addition, pyvisfile allows the\n            semi-automatic writing of parallelization-segmented visualization files\n            in both Silo and Vtk formats. For Silo files, pyvisfile also\n            supports the writing of expressions as visualization variables.\n\n            pyvisfile can write Vtk files without any extra software installed.\n\n            To use pyvisfile to create Silo files, you need `libsilo\n            <https://wci.llnl.gov/codes/silo/>`_ as well as `Boost.Python\n            <http://www.boost.org>`_ and `PyUblas\n            <http://mathema.tician.de/software/pyublas>`_.  To build\n            pyvisfile's Silo support, please refer to the `PyUblas\n            documentation <http://tiker.net/doc/pyublas>`_ for build\n            instructions first. Check the\n            `VisIt source page <https://wci.llnl.gov/codes/visit/source.html>`_\n            for the latest Silo source code."}}, {"pk": 348, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "basicCAS", "license": "UNKNOWN", "author": "Alex Gittens", "author_email": "rubberduckie@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://tangentspace.net/cz", "version": "1.0", "platform": "UNKNOWN", "keywords": "", "summary": "basic CAS parsing faculties", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: Other Environment\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: Public Domain\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "A mathematica style parser, and associated utilities. Goal is eventual full \r\ncompatibility with Mathematica's text mode parser, but that is far off. Usable \r\nalready."}}, {"pk": 349, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "python-opencl", "license": "UNKNOWN", "author": "In Tlapatlac", "author_email": "tlapatlac@next-touch.com", "project_url": null, "maintainer_email": null, "home_page": "http://python-opencl.next-touch.com", "version": "0.2", "platform": "UNKNOWN", "keywords": null, "summary": "OpenCL wrapper module", "classifiers": "Development Status :: 2 - Pre-Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Distributed Computing\nTopic :: System :: Hardware", "description": "UNKNOWN"}}, {"pk": 350, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "bayesnet", "license": "modified Python", "author": "Kosta Gaitanis", "author_email": "gaitanis@tele.ucl.ac.be", "project_url": null, "maintainer_email": null, "home_page": "http://ziyang.ece.northwestern.edu/~dickrp/python/mods.html", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Bayesian network implementation.  Influenced by Cecil Huang's and Adnan", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python Software Foundation License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "Bayesian network implementation.  Influenced by Cecil Huang's and Adnan\nDarwiche's \"Inference in Belief Networks: A Procedural Guide,\" International\nJournal of Approximate Reasoning, 1994.\n\nCopyright 2005, Kosta Gaitanis (gaitanis@tele.ucl.ac.be).  Please see the\nlicense file for legal information."}}, {"pk": 351, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pdsvex.theme", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://agility.jpl.nasa.gov/products/pdsvex-theme", "version": "1.0.1", "platform": "UNKNOWN", "keywords": "web theme zope plone jpl nasa caltech pds esa venus express vex planetary data", "summary": "Theme that augments the JPL theme to provide the logo for Venus Express", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This is the theme product for PDS Venus Express Data's HTTP interface.  It\nlets visitors using a browser view the control panel and browse VEX profiles\nin a comforting environment.\n\nThis product depends on ``jpl.theme`` and, if you're using your buildout\nproperly, it'll be used automatically.\n\nChangelog\n*********\n\n1.0.1 - 2009.7.16 - Cosmetic Update\n===================================\n\nThis release is a purely cosmetic update that makes the documentation somewhat\nmore readable by not displaying certain unnecessary elements.\n\n\n1.0.0 - FCS\n===========\n\nThis was the first customer ship of the PDS VEX Theme.\n\n\n0.0.0 - Unreleased\n==================\n\n* Initial release"}}, {"pk": 352, "model": "importing.pypicache", "fields": {"maintainer": "Robert Wallhead", "name": "SeShell", "license": "", "author": "Robert Wallhead", "author_email": "rwallhead@gmail.com", "project_url": null, "maintainer_email": "rwallhead@gmail.com", "home_page": "http://github.com/thisismyrobot/SeShell", "version": "0.4", "platform": "", "keywords": "Serial, Console, Shell", "summary": "Serial to Shell converter", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX :: Linux\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: GIS\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator", "description": "Maps serial commands to shell (console) commands."}}, {"pk": 353, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "consensus", "license": "PSF", "author": "Brian Beck, Michael Rotondo", "author_email": "exogen@gmail.com, mrotondo@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://exogen.case.edu/projects/consensus/", "version": "0.1.1", "platform": "all", "keywords": "collaborative filtering filter suggest recommendations", "summary": "Make suggestions and find similar users using collaborative filtering", "classifiers": "Development Status :: 3 - Alpha\nOperating System :: OS Independent\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries", "description": "Models for making suggestions and predicting the user ratings of items using \r\ncollaborative filtering."}}, {"pk": 354, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nebseq", "license": "MIT", "author": "Paul Joseph Davis", "author_email": "davisp@neb.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/davisp/nebseq", "version": "0.0.2", "platform": "any", "keywords": "bioinformatics sequence reverse-complement translation", "summary": "Basic Biological Sequence Manipulations", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Import as usual\n---------------\n\n    >>> import nebseq\n\nReverse complements\n-------------------\n\nThe only note here is that `revcomp` does not check the input\nsequence to see if it looks like DNA or RNA. \n\n    >>> nebseq.revcomp('ACGT')\n    'ACGT'\n    >>> nebseq.revcomp('TTACC')\n    'GGTAA'\n\nAnd if we give it garbage it just gives us garbage back.\n    \n    >>> nebseq.revcomp('ZQ')\n    'QZ'\n\nTranslation\n-----------\n\nThe translation function should allow for full support of sequence\ntranslation. This includes things like trimming the first couple\nbases and using alternate translation tables. There is also\nsupport for the more esoteric post translational modifications\nthat can be found in some Genbank files as well as translating\npartial peptides (for things like fuzzy coordinates).\n\nBasic translation:\n\n    >>> nebseq.translate('TTGGCCAAGGAACGA', table=11)\n    'MAKER'\n\nShowing the effects of a partial peptide translation. By default\nthe first codon should be a start codon according to the selected\ntranslation table, if not then its converted to an 'X'\n\n    >>> nebseq.translate('GCCAAG')\n    'XK'\n    >>> nebseq.translate('GCCAAG', partial=True)\n    'AK'\n\nOr we can remove the first couple of bases for fuzzy coordinates.\n\n    >>> nebseq.translate('TTGCCAAG', start=2, partial=True)\n    'AK'\n\nModifications are specified as an (index, amino_acid) two-tuple. Notice\nthat modification indexes are specified as one-based indexes into the\namino acid sequence.\n\n    >>> nebseq.translate('ATGAAGGAA', modifications=[(2, 'U')])\n    'MUE'\n\nExtraction\n----------\n\nSequence extraction is for when you want to slice out part of a larger\nsequence. This is useful if you use the `nebgb` module and its\ndefinition of locations parsed from strings like `join(1..5,9..100)`.\n\n    >>> location = {'type': 'span', 'from': 4, 'to': 10}\n    >>> nebseq.extract('ACCGTACCATAGTT', location)\n    ('GTACCAT', (False, False))\n    >>> location = {\n    ...     \"type\": \"complement\",\n    ...     \"segment\": {\n    ...         \"type\": \"join\",\n    ...         \"segments\": [\n    ...             {\"type\": \"span\", \"from\": 3, \"to\": 8},\n    ...             {\"type\": \"span\", \"from\": 10, \"to\": 14}\n    ...         ]\n    ...     }\n    ... }\n    >>> nebseq.extract('ACCGTATTTCGGGGACAT', location)\n    ('CCCCGAATACG', (False, False))"}}, {"pk": 355, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "crcmod", "license": "MIT", "author": "Ray Buvel", "author_email": "rlbuvel@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://crcmod.sourceforge.net/", "version": "1.7", "platform": "UNKNOWN", "keywords": null, "summary": "CRC Generator", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nTopic :: Communications\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Utilities", "description": "===========================\ncrcmod for Calculating CRCs\n===========================\n\nThe software in this package is a Python module for generating objects that\ncompute the Cyclic Redundancy Check (CRC).  There is no attempt in this package\nto explain how the CRC works.  There are a number of resources on the web that\ngive a good explanation of the algorithms.  Just do a Google search for \"crc\ncalculation\" and browse till you find what you need.  Another resource can be\nfound in chapter 20 of the book \"Numerical Recipes in C\" by Press et. al.\n\nThis package allows the use of any 8, 16, 24, 32, or 64 bit CRC.  You can\ngenerate a Python function for the selected polynomial or an instance of the\nCrc class which provides the same interface as the ``md5`` and ``sha`` modules\nfrom the Python standard library.  A ``Crc`` class instance can also generate\nC/C++ source code that can be used in another application.\n\n----------\nGuidelines\n----------\n\nDocumentation is available from the doc strings.  It is up to you to decide\nwhat polynomials to use in your application.  If someone has not specified the\npolynomials to use, you will need to do some research to find one suitable for\nyour application.  Examples are available in the unit test script ``test.py``.\nYou may also use the ``predefined`` module to select one of the standard\npolynomials.\n\nIf you need to generate code for another language, I suggest you subclass the\n``Crc`` class and replace the method ``generateCode``.  Use ``generateCode`` as\na model for the new version.\n\n------------\nDependencies\n------------\n\nPython Version\n^^^^^^^^^^^^^^\n\nThe package has separate code to support the 2.x and 3.x Python series.\n\nFor the 2.x versions of Python, these versions have been tested:\n\n* 2.4\n* 2.5\n* 2.6\n* 2.7\n\nIt may still work on earlier versions of Python 2.x, but these have not been\nrecently tested.\n\nFor the 3.x versions of Python, these versions have been tested:\n\n* 3.1\n\nBuilding C extension\n^^^^^^^^^^^^^^^^^^^^\n\nTo build the C extension, the appropriate compiler tools for your platform must\nbe installed. Refer to the Python documentation for building C extensions for\ndetails.\n\n------------\nInstallation\n------------\n\nThe crcmod package is installed using ``distutils``.\nRun the following command::\n\n    python setup.py install\n\nIf the extension module builds, it will be installed.  Otherwise, the\ninstallation will include the pure Python version.  This will run significantly\nslower than the extension module but will allow the package to be used.\n\nFor Windows users who want to use the mingw32 compiler, run this command::\n\n    python setup.py build --compiler=mingw32 install\n\nFor Python 3.x, the install process is the same but you need to use the 3.x\ninterpreter.\n\n------------\nUnit Testing\n------------\n\nThe ``crcmod`` package has a module ``crcmod.test``, which contains unit\ntests for both ``crcmod`` and ``crcmod.predefined``.\n\nWhen you first install ``crcmod``, you should run the unit tests to make sure\neverything is installed properly.  The test script performs a number of tests\nincluding a comparison to the direct method which uses a class implementing\npolynomials over the integers mod 2.\n\nTo run the unit tests on Python >=2.5::\n\n    python -m crcmod.test\n\nAlternatively, in the ``test`` directory run::\n\n    python test_crcmod.py\n\n---------------\nCode Generation\n---------------\n\nThe crcmod package is capable of generating C functions that can be compiled\nwith a C or C++ compiler.  In the test directory, there is an examples.py\nscript that demonstrates how to use the code generator.  The result of this is\nwritten out to the file ``examples.c``.  The generated code was checked to make\nsure it compiles with the GCC compiler.\n\n-------\nLicense\n-------\n\nThe ``crcmod`` package is released under the MIT license. See the ``LICENSE``\nfile for details.\n\n------------\nContributors\n------------\n\nCraig McQueen"}}, {"pk": 356, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyUblas", "license": "BSD", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/pyublas", "version": "2011.1", "platform": "UNKNOWN", "keywords": null, "summary": "Seamless Numpy-UBlas interoperability", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX\nProgramming Language :: C++\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nTopic :: Office/Business\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Utilities", "description": "PyUblas provides a seamless glue layer between\n            `Numpy <http://www.numpy.org>`_ and\n            `Boost.Ublas <http://www.boost.org/doc/libs/1_35_0/libs/numeric/ublas/doc/index.htm>`_\n            for use with\n            `Boost.Python <http://www.boost.org/doc/libs/1_35_0/libs/python/doc/index.html>`_.\n\n            What does that mean? When writing \n            `hybrid scientific code <http://mathema.tician.de/node/455>`_, \n            one of the main problems is that abstractions that\n            exist in the high-level language go away or become unwieldy in the\n            low-level language. Sometimes libraries exist in both languages for\n            these abstractions, but they refuse to talk to each other. PyUblas is\n            a bridge between two such libraries, for some of the main\n            abstractions used in scientific codes, namely vectors and matrices.\n\n            Documentation\n            =============\n\n            See the \n            `PyUblas Documentation <http://tiker.net/doc/pyublas>`_\n            page.\n\n            PyUblasExt\n            ==========\n\n            PyUblasExt is a companion to PyUblas and exposes a variety of useful\n            additions to PyUblas, such as an \"operator\" class, matrix-free linear\n            system solvers and eigensolvers. Interested? Head over to the\n            `PyUblasExt <http://mathema.tician.de/software/pyublas/pyublasext>`_ \n            page."}}, {"pk": 357, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "StatePy", "license": "BSD", "author": "Joseph Lisee", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/jlisee/statepy", "version": "0.1.0", "platform": "UNKNOWN", "keywords": null, "summary": "A hierarchical finite state machine library", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Libraries", "description": "UNKNOWN"}}, {"pk": 358, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "winrandom-ctypes", "license": "BSD", "author": "Gregory Taylor", "author_email": "gtaylor@duointeractive.com", "project_url": null, "maintainer_email": "", "home_page": "http://github.com/duointeractive/winrandom-ctypes", "version": "1.0", "platform": "Windows", "keywords": "random windows winrandom", "summary": "Winrandom equivalent using ctypes.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "An implementation of the winrandom module (http://pypi.python.org/pypi/winrandom/) using ctypes instead of a\r\ncompiled extension module."}}, {"pk": 359, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "ncbi", "license": "", "author": "Josh Cherry", "author_email": "jcherry@ncbi.nlm.nih.gov", "project_url": null, "maintainer_email": "", "home_page": "", "version": "0308", "platform": "", "keywords": "", "summary": "Python wrapper for the NCBI C++ Toolkit", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: Public Domain\nNatural Language :: English\nOperating System :: POSIX :: Linux\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "The `NCBI C++ Toolkit\r\n<http://www.ncbi.nlm.nih.gov/books/bv.fcgi?call=bv.View..ShowTOC&rid=toolkit.TOC&depth=2>`_\r\nprovides a wide variety of functionality for analysis, retrieval, and\r\nmanipulation of DNA and protein sequences and related data, along with much\r\ngeneral-purpose functionality.  This includes (de)serialization and manipulation\r\nof instances of NCBI data model types (usually defined by ASN.1 specifications).\r\n\r\nThe C++ Toolkit is the result of the efforts of many people at the National\r\nCenter for Biotechnology Information over several years.  This module makes most\r\nof its functionality available from Python."}}, {"pk": 360, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "colormath", "license": "GPLv3", "author": "Gregory Taylor", "author_email": "gtaylor@l11solutions.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/python-colormath/", "version": "1.0.8", "platform": "Platform Independent", "keywords": "color math conversions", "summary": "Color math and conversion library.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Implements a large number of different color operations such as\ncolor space conversions, Delta E, and density to spectral."}}, {"pk": 361, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "python-graph-core", "license": "", "author": "Pedro Matiello", "author_email": "pmatiello@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/python-graph/", "version": "1.8.0", "platform": "", "keywords": "python, graphs, hypergraphs, networks, library, algorithms", "summary": "A library for working with graphs in Python", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": ""}}, {"pk": 362, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pfits", "license": "GPL", "author": "Aaron Parsons", "author_email": "aparsons@astron.berkeley.edu", "project_url": null, "maintainer_email": null, "home_page": "http://setiathome.berkeley.edu/~aparsons/aipy/aipy.cgi/PFits", "version": "0.0.2", "platform": "UNKNOWN", "keywords": null, "summary": "A Python FITS interface built using CFITSIO", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Scientific/Engineering :: Astronomy", "description": "This package uses the CFITSIO library to interface to FITS files from Python.  Particular attention has been paid to supporting ASCII and BINARY tables with fixed and variable-length entries.  Data I/O is handled through numpy arrays."}}, {"pk": 363, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ETSProjectTools", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/ets_project_tools.php", "version": "0.6.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Tools for working with projects that have many dependencies.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "ETSProjectTools provides commands to make it easier for developers\nto work on projects that have a large number of dependencies, such as\nthe ETS project itself.  These commands are all predicated on a concept we\ncall a \"checkout\", which is the coherent set of projects and versions that\nare required to satisfy all documented dependencies for the user-requested\nproject(s).\n\nETSProjectTools provides its tools through the 'ets' command, which has many\nsub-commands.\n\nThe first set of sub-commands make it easy to create and interact with\n\"checkouts\" and their contained projects' original source control repositories\n(currently only Subversion is supported).  This is done by providing commands\nlike \"co\" (checkout), \"up\" (update), \"st\" (status), and \"rev\" (revert).  The\nsyntax and semantics of these commands are similar to most source control\nsystems.  You can specify which repositories the 'ets' command knows about by\nediting the \".ets.cfg\" file in your home directory.\n\nThe second set of 'ets' sub-commands make it easy to build, develop, or install\nthese projects into a Python environment.  This set includes the 'build',\n'develop', and 'install' commands.  These all basically invoke the 'python\nsetup.py' command of the same name on all projects within the \"checkout\".\n\nThe last set of 'ets' sub-commands are used to explore the dependencies of\nprojects and enhance performance of the tool itself by generating a cache of\nprojects within a repository, called a map, so that each client doesn't have\nto crawl a repository on its own.  These sub-commands are: depends, graph,\npkgurl, and map.\n\n\nPrerequisites\n-------------\nYou must install the following libraries before building or installing\nETSProjectTools:\n\n * `Subversion <http://subversion.tigris.org/>`_ 1.4. Version 1.5 can be used,\n   but requires a `patch to setuptools\n   <https://svn.enthought.com/enthought/wiki/PatchSetuptools_for_SVN15>`_ if\n   using setuptools 0.6c8 or earlier.\n * `setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 364, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "py3to2", "license": "BSD", "author": "kai zhu", "author_email": "kaizhu256@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pypi.python.org/pypi/py3to2", "version": "2009.01.03", "platform": "UNKNOWN", "keywords": "", "summary": "run python3.0 & 2to3 generated scripts w/ 2.6 extension support", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.0\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Assemblers\nTopic :: Software Development :: Bug Tracking\nTopic :: Software Development :: Build Tools\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Compilers\nTopic :: Software Development :: Debuggers\nTopic :: Software Development :: Disassemblers\nTopic :: Software Development :: Interpreters\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Application Frameworks\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Software Development :: Pre-processors\nTopic :: Software Development :: Testing\nTopic :: System :: Emulators\nTopic :: System :: Shells\nTopic :: Text Processing\nTopic :: Text Processing :: Filters\nTopic :: Utilities", "description": "this project is being superseded by asciiporn at http://code.google.com/p/asciiporn/\r\n\r\nAUTHOR\r\n  kai zhu\r\n  kaizhu256@gmail.com\r\n\r\nREQUIREMENTS\r\n  - posix/unix os (Windows currently unsupported)\r\n  - w/ python2.6 & python3.0 installed\r\n\r\nINSTALL\r\n  $ python2.6 setup.py build\r\n  $ python2.6 setup.py install\r\n  $ python2.6 setup.py dev --quicktest\r\n  $ python2.6 setup.py dev --py2to3test ## takes awhile to finish\r\n\r\n  the above will build & install 3 files:\r\n  - extended python2.6 interpreter: bin/py3to2\r\n  - initialization script:          lib/python2.6/site-packages/py3to2_init.py\r\n  - python3.0 bytecode compiler:    lib/python2.6/site-packages/py3to2.py\r\n\r\n################################################################################\r\nABSTRACT\r\n\r\npy3to2 is a python2.6 interpreter w/ extended python3.0 opcodes, allowing it to\r\nnatively run python3.0 & 2to3 generated scripts. it should b\r\nmostly backwards-compatible w/ cpython2.6 & its extensions.\r\n\r\nthe intended purpose is to allow developers to migrate python2.6 scripts to\r\npython3.0 while retaining backwards compatibility w/ existing extension modules.\r\npy3to2 coexists w/ ur existing python2.6 installation (it consists of 3 files)\r\n\r\nfor a real-world py3to2 app (python3.0 script using 2.6 extension modules),\r\ncheckout asciiporn: http://pypi.python.org/pypi/asciiporn\r\n\r\nMECHANISM\r\n\r\npy3to2 has 3 components:\r\n- py3to2\r\n  python interpreter. can evaluate python2.6 bytecode containing additional\r\n  python3.0 opcode instructions\r\n\r\n- py3to2_init.py\r\n  initialization script.  sets up import hook for recognizing python3.0 scripts\r\n\r\n- py3to2.py\r\n  bytecode compiler. the compile process takes 2 steps:\r\n  - a persistent python3.0 process is created for compiling scripts into\r\n    python3.0 code\r\n  - py3to2.py then converts the code from python3.0 to python2.6 format\r\n\r\nMANIFEST\r\n\r\n./patch/ - patched files\r\n./py3to2.diff - summary of patches (maybe out-of-date)\r\n\r\n################################################################################\r\nMAGIC\r\n  simply add the MAGIC LINE:\r\n\r\n    from __future__ import py3k_syntax\r\n\r\n  to make py3to2 aware that a script is using python3.0 syntax\r\n\r\nPSEUDOMETHOD\r\n  py3to2 supports \"..\" syntax notation for pseudomethods\r\n  goto: http://pypi.python.org/pypi/pseudomethod\r\n  for more details about this feature\r\n\r\n2TO3\r\n  py3to2 includes convenience functions for automatically generating &\r\n  testing scripts using 2to3:\r\n  - class py2to3:\r\n    - __call__ - overwrites file w/ one generated by 2to3\r\n    - overwrite_and_load_module - overwrites file & then attempt to import it\r\n    - test_stdlib - given a directory containing a copy of python2.6's\r\n                    standard library, it will overwrite them using 2to3 & then\r\n                    attempts to load each file\r\n\r\nAPI: try help(py3to2)  ^_-\r\n\r\n  py3to2 module:\r\n  - class codetree - mutable codeobj & disassembler/assembler/debugger\r\n  - class compiler - compiling tools\r\n  - python3.0 wrappers:\r\n    - py3k_compile() - compile python3.0 src\r\n    - py3k_eval() - eval py3thon3.0 src\r\n    - py3k_exec() - exec python3.0 src\r\n\r\nUSAGE\r\n  start up the py3to2 interpreter by typing \"py3to2\" in ur shell:\r\n    $ py3to2\r\n\r\n    Python 2.6.py3to2 (r26:66714, Nov 18 2008, 00:56:43)\r\n    [GCC 3.4.6 20060404 (Red Hat 3.4.6-10)] on linux2\r\n    Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n    >>>\r\n\r\n  try out this simple python3.0 script:\r\n    ################################################################\r\n    ## PEP3132  Extended Iterable Unpacking\r\n    ## copy this to file test_pep3132.py\r\n\r\n    from __future__ import py3k_syntax\r\n\r\n    a,*b = 1,2,3\r\n    assert a == 1 and b == [2,3]\r\n    print(a,b)\r\n    ################################################################\r\n    >>>\r\n    >>> import test_pep3132\r\n    created...\r\n    py3k server starting...\r\n    ...py3k server started w/...\r\n\r\n    1 [2, 3]\r\n\r\n  here's another python3.0 script using scipy (python2.6) extension module:\r\n    ################################################################\r\n    ## u must have scipy installed for this script to work\r\n    ## copy this to file test_pep3132_scipy.py\r\n\r\n    from __future__ import py3k_syntax\r\n\r\n    import scipy\r\n    a,*b = scipy.array([1,2,3])\r\n    assert a == 1 and b == [2,3]\r\n    print(a,b)\r\n    ################################################################\r\n    >>>\r\n    >>> import test_pep3132_scipy\r\n    1 [2, 3]\r\n\r\n  another simple, but more thorough test script, test_py3k,\r\n  is included w/ this distribution:\r\n    >>>\r\n    >>> import test_py3k\r\n    testing PEP3102  Keyword-Only Arguments\r\n    testing PEP3104  Access to Names in Outer Scopes\r\n    testing PEP3105  Make print a function\r\n    testing PEP3107  Function Annotations\r\n    testing PEP3112  Bytes literals in Python 3000\r\n    testing PEP3113  Removal of Tuple Parameter Unpacking\r\n    testing PEP3114  Renaming iterator.next() to .__next__()\r\n    testing PEP3115  Metaclasses in Python 3000\r\n    testing PEP3120  Using UTF-8 as the default source encoding\r\n    testing PEP3127  Integer Literal Support and Syntax\r\n    testing PEP3129  Class Decorators\r\n    testing PEP3131  Supporting Non-ASCII Identifiers\r\n    testing PEP3132  Extended Iterable Unpacking\r\n    testing PEP3135  New Super\r\n    testing pseudomethod example 0\r\n    testing pseudomethod example 1\r\n    testing pseudomethod example 2\r\n    testing pseudomethod example 3\r\n    testing numpy example\r\n\r\nFEATURES\r\n  PEP3102  Keyword-Only Arguments\r\n  PEP3104  Access to Names in Outer Scopes\r\n  PEP3105  Make print a function\r\n  PEP3107  Function Annotations\r\n  PEP3111  Simple input built-in in Python 3000\r\n  PEP3112  Bytes literals in Python 3000\r\n  PEP3113  Removal of Tuple Parameter Unpacking\r\n  PEP3114  Renaming iterator.next() to .__next__()\r\n  PEP3115  Metaclasses in Python 3000\r\n  PEP3120  Using UTF-8 as the default source encoding\r\n  PEP3127  Integer Literal Support and Syntax\r\n  PEP3129  Class Decorators\r\n  PEP3131  Supporting Non-ASCII Identifiers\r\n  PEP3132  Extended Iterable Unpacking\r\n  PEP3135  New Super\r\n\r\nUNICODE SUPPORT\r\n  py3to2 will only load ascii & utf8-encoded scripts\r\n  (utf8 is the default encoding in python3.0).\r\n\r\n  although they're illegal in python3.0, for backwards-compatibility sake,\r\n  py3to2 supports unicode literals for explicit <unicode> obj creation:\r\n\r\n    u\"\\u1234\" is an explicit <unicode> obj (note unicode literal in front)\r\n     \"\\u1234\" is NOT a <unicode> obj when converted back to python2.6\r\n\r\n  note also the following r equivalent under python2.6:\r\n\r\n    u\"\\u1234\"  <==>  \"\\u1234\".decode(\"raw_unicode_escape\")\r\n\r\n  so u MUST do either u\"...\" or \"...\".decode(\"raw_unicode_escape\")\r\n  to create explicit <unicode> obj in py3to2.\r\n\r\nLIMITATIONS (FEATURES NOT FULLY SUPPORTED)\r\n  except for the aforementioned unicode issue, from a migration standpoint,\r\n  py3to2 is mostly feature complete in terms of python3.0's language syntax,\r\n\r\n  language issue aside, python3.0 scripts will still behave differently b/c of\r\n  internal differences between python2.6 & python3.0:\r\n  - exception handling.  py3to2 implements python3.0 syntax for raising &\r\n    catching exceptions.  but the underlying behavior is still python2.6\r\n  - builtin functions / types.  a few of these have become different beasts\r\n    under python3.0\r\n\r\n################################################################################\r\nPYTHON2.6 COMPATIBILITY TEST\r\n  $ python setup.py dev --maketest\r\n  ...\r\n  test_sys\r\n  test test_sys failed -- Traceback (most recent call last):\r\n    File \".../Python-2.6/Lib/test/test_sys.py\", line 487, in test_objecttypes\r\n      check(get_cell().func_code, size(h + '4i8Pi2P'))\r\n    File \".../Python-2.6/Lib/test/test_sys.py\", line 423, in check_sizeof\r\n      self.assertEqual(result, size, msg)\r\n  AssertionError: wrong size for <type 'code'>: got 128, expected 120\r\n  ...\r\n  325 tests OK.\r\n  1 test failed:\r\n      test_sys\r\n  35 tests skipped:\r\n      test_aepack test_al test_applesingle test_bsddb185 test_bsddb3\r\n      test_cd test_cl test_codecmaps_cn test_codecmaps_hk\r\n      test_codecmaps_jp test_codecmaps_kr test_codecmaps_tw test_curses\r\n      test_gdbm test_gl test_imgfile test_kqueue test_linuxaudiodev\r\n      test_macos test_macostools test_normalization test_ossaudiodev\r\n      test_pep277 test_py3kwarn test_scriptpackages test_socketserver\r\n      test_startfile test_sunaudiodev test_tcl test_timeout\r\n      test_urllib2net test_urllibnet test_winreg test_winsound\r\n      test_zipfile64\r\n  2 skips unexpected on linux2:\r\n      test_tcl test_gdbm\r\n\r\n2TO3 COMPATIBILITY TEST\r\n  $ python setup.py dev --py2to3test\r\n  ...\r\n  tested 200 2to3 generated scripts from 2.6.1.py3to2 (r261:67515, Jan  4 2009,\r\n01:28:21)\r\n  [GCC 4.2.3 20071123 (prerelease) (Debian 4.2.2-4)] standard library\r\n\r\n  0 skipped:\r\n\r\n\r\n  28 couldn't import required modules:\r\n  BaseHTTPServer CGIHTTPServer cgi cookielib copy DocXMLRPCServer\r\ndummy_threading HTMLParser httplib _LWPCookieJar macurl2path mimetools mimetypes\r\n_MozillaCookieJar os pdb pickle pydoc re robotparser sgmllib SimpleHTTPServer\r\nSimpleXMLRPCServer _strptime tempfile threading urllib2 urllib\r\n\r\n  6 were non-utf8 compliant scripts:\r\n  base64 getopt heapq shlex smtpd tarfile\r\n\r\n  8 failed import due to other reasons:\r\n  anydbm dbhash doctest imputil sets trace UserList UserString\r\n\r\n  159 passed import:\r\n  _abcoll abc aifc ast asynchat asyncore atexit audiodev Bastion bdb binhex\r\nbisect calendar cgitb chunk cmd codecs codeop code collections colorsys commands\r\ncompileall ConfigParser contextlib Cookie copy_reg cProfile csv decimal difflib\r\ndircache dis dumbdbm dummy_thread filecmp fileinput fnmatch formatter fpformat\r\nfractions ftplib functools __future__ genericpath getpass gettext glob gzip\r\nhashlib hmac htmlentitydefs htmllib ihooks imaplib imghdr inspect io keyword\r\nlinecache locale macpath mailbox mailcap markupbase md5 mhlib MimeWriter mimify\r\nmodulefinder multifile mutex netrc new nntplib ntpath nturl2path numbers opcode\r\noptparse os2emxpath __phello__.foo pickletools pipes pkgutil platform plistlib\r\npopen2 poplib posixfile posixpath pprint profile pstats pty pyclbr py_compile\r\npydoc_topics Queue quopri random repr rexec rfc822 rlcompleter runpy sched sha\r\nshelve shutil site smtplib sndhdr socket SocketServer sre_compile sre_constants\r\nsre_parse sre ssl stat statvfs StringIO stringold stringprep string struct\r\nsubprocess sunaudio sunau symbol symtable tabnanny telnetlib textwrap this\r\n_threading_local timeit toaiff tokenize token traceback tty types unittest\r\nurlparse UserDict user uuid uu warnings wave weakref webbrowser whichdb xdrlib\r\nxmllib xmlrpclib zipfile\r\n\r\n################################################################################\r\nRECENT CHANGES:\r\n20090103 updated to python 2.6.1\r\n20081129 - major revision\r\n  PyCodeObject now has kwonlyargcount attr\r\n  - breaks one regression test but greatly simplifies patch & prevents many\r\n    future bugs\r\n  - fixes pydoc bug\r\n  PyFunctionObject now has __kwdefaults__ & __annotations__ attr\r\n  ceval.c re-patched in light of above changes (much simpler)\r\n20081128\r\n  more documentation\r\n  added 2to3 convenience functions\r\n  added unicode utf-8 support\r\n20081123\r\n  moved pseudomethod syntax handling to py3k server\r\n  added more checks during setup\r\n  added more documentation\r\n  backported patch r67299 fixing an issue w/ super()\r\n  cleaned up py3to2.compiler class\r\n20081120\r\n  fixed package importing bug - py3to2 failed to import foo.bar\r\n20081119\r\n  created self-installing distutils distribution\r\n20081019\r\n  ported to python-2.6\r\n  consolidate & simplify patches to 1 file: ceval.c\r\n  created extension module builtins_py3k\r\n  revamped import hook again\r\n  removed unicode support & restrict source code to ascii-only\r\n20080727\r\n  revampled import hook\r\n20080911\r\n  consolidate patches to 2 files: bltinmodule.c & ceval.c\r\n20080828\r\n  add kwonlyargcount 'attr' to codeobj\r\n  add __annotations__ & __kwdefaults__ attr to funcobj\r\n  add __pseudomethod__ feature to baseobj\r\n20080819\r\n  pure python import hook - removed magic comment & use magic path instead\r\n  revamped str & bytes handling\r\n  revamped py3k .pyc file handling\r\n20080802\r\n  pep3135  New Super\r\n20080717\r\n  pep3107  Function Annotations\r\n  pep3120  Using UTF-8 as the default source encoding\r\n  pep3131  Supporting Non-ASCII Identifiers\r\n20080713\r\n  import / reload works transparently on py3k scripts using a magic comment\r\n  added pep3102  Keyword-Only Arguments\r\n20080709 added a py3k preparser\r\n20080702\r\n  rewrote py3k server's pipe io.  implemented partial bytearray & bytes class.\r\n  wrote a few simple tests\r\n20080630\r\n  __build_class__ function to bltmodule.c.  tested class decorators to b \r\nworking.\r\n################################################################################"}}, {"pk": 365, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MathBench", "license": "BSD", "author": "Thibauld Nion", "author_email": "tibonihoo @at@  yahoo .dot. fr", "project_url": null, "maintainer_email": null, "home_page": "http://mathbench.sourceforge.net", "version": "1.1.0", "platform": "All", "keywords": "editor shell documentation math script IDE", "summary": "Not a whole lab, just a small bench...", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Editors :: Integrated Development Environments (IDE)", "description": "Helps in developping small Python scripts as quickly as it should be.\n\nMathBench is extensible by plugins that can provide facilities to easily access some external libraries (for instance pylab) and also provide documentation and code samples through MathBench's integrated documentation system (aka \"LibraryDesk\").\n\nWarning: Mathbench depends heavily on wxPython(>=2.8) which must be installed before installing Mathbench."}}, {"pk": 366, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyVISA", "license": "GNU General Public License", "author": "Torsten Bronger, Gregor Thalhammer", "author_email": "pyvisa-devel@lists.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://pyvisa.sourceforge.net", "version": "1.3", "platform": "Linux,Windows", "keywords": "VISA GPIB USB serial RS232 measurement acquisition", "summary": "Python VISA bindings for GPIB, RS232, and USB instruments", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Software Development :: Libraries :: Python Modules", "description": "A Python package for support of the Virtual Instrument Software Architecture\n(VISA), in order to control measurement devices and test equipment via GPIB,\nRS232, or USB.  Homepage: http://pyvisa.sourceforge.net"}}, {"pk": 367, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cvexp", "license": "UNKNOWN", "author": "David Baird", "author_email": "dhbaird@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.aclevername.com/projects/cvexp", "version": "0.1", "platform": "UNKNOWN", "keywords": "controlled vocabulary linear programming optimization", "summary": "Expression Tree Builder and Translator based on a Controlled Vocabulary", "classifiers": "Development Status :: 2 - Pre-Alpha\nIntended Audience :: Developers\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "CVExp is short for \"controlled vocabulary expressions.\"  CVExp is a\nPython module that allows abstract syntax trees (\"expressions\") to be\nconstructed just as easily as writing normal Python code.  The names\nof functions in the abstract syntax trees are based on a controlled\nvocabulary, using URIs as names just like the W3C RDF does.\n\nThe intent of CVExp is that it should make it easier for developers\nto integrate 3rd party libraries into Python without having to specify\nentirely new APIs.  Libraries and languages of particular concern are\ncomputer algebra systems, linear programming and optimization (such as\nlp_solve, GLPK, and CVXOPT), and Prolog.\n\nHere is an example usage to solve a mixed-integer linear programming\nproblem using GLPK as the backend.  In order for this to work, you\nobviously must install prerequisite Python packages (i.e.  python-glpk or\nwhatever) because these are not included with CVExp::\n\n    from cvexp.builders import var\n    from cvexp.builders import integer\n    from cvexp.builders import minimize\n    from cvexp.translate_glpk import solve\n\n    # You could also use lp_solve by doing this:\n    # from cvexp.translate_lpsolve55 import solve\n    # ...or you could use CVXOPT like this:\n    # from cvexp.translate_cvxopt import solve\n\n    X = var('X') # the 'X' name is optional\n    Y = var('Y') # ...and so is 'Y'\n\n    # Purely linear programming:\n    sol = solve((\n                 Y + 0.1 == X,\n                 Y >= 9.8 - X,\n                 minimize(Y),\n               ), out_filename='problem.out') # out_filename is optional\n    print 'X =', sol[X] # >>> 4.95\n    print 'Y =', sol[Y] # >>> 4.85\n\n    # Mixed integer-linear programming:\n    sol = solve((\n                 Y + 0.1 == X,\n                 Y >= 9.8 - X,\n                 integer(Y),\n                 minimize(Y),\n               ), out_filename='problem.out') # out_filename is optional\n    print 'X =', sol[X] # >>> 5.1\n    print 'Y =', sol[Y] # >>> 5\n\nIf using CVXOPT, quadratic programming problems can also be solved.\nFor example::\n\n    from cvexp.builders import var\n    from cvexp.builders import integer\n    from cvexp.builders import minimize\n    from cvexp.translate_cvxopt import solve\n\n    X = var()\n    Y = var()\n\n    sol = solve((\n                minimize((X - 5) ** 2 + (Y - 3) ** 2),\n               ))\n    print 'X =', sol[X] # >>> 5.0\n    print 'Y =', sol[Y] # >>> 3.0"}}, {"pk": 368, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "multichain_mcmc", "license": "BSD", "author": "John Salvatier", "author_email": "jsalvati@u.washington.edu", "project_url": null, "maintainer_email": null, "home_page": "pypi.python.org/pypi/multichain_mcmc", "version": "0.3", "platform": "UNKNOWN", "keywords": null, "summary": "Multichain MCMC framework and algorithms", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics", "description": "A simple framework based on PyMC for multichain MCMC algorithms. \n                    \n                    Contains working implementations of:\n                        * DREAM/DREAM_ZS sampler : multichain_mcmc.dream.DreamSampler\n                        * Adaptive Metropolis Adjusted Langevin Algorithm (AMALA) sampler : multichain_mcmc.amala.AmalaSampler\n                        \n                    See the sampler classes for details. AMALA sampler requires PyMC branch with gradient information support to function.\n                        http://github.com/pymc-devs/pymc/tree/gradientBranch"}}, {"pk": 369, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "aipy", "license": "GPL", "author": "Aaron Parsons", "author_email": "aparsons@astron.berkeley.edu", "project_url": null, "maintainer_email": null, "home_page": "http://setiathome.berkeley.edu/~aparsons/aipy/aipy.cgi", "version": "1.0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Astronomical Interferometry in PYthon", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Scientific/Engineering :: Astronomy", "description": "This package collects together tools for radio astronomical interferometry. In addition to pure-python phasing, calibration, imaging, and deconvolution code, this package includes interfaces to MIRIAD (a Fortran interferometry package) and HEALPix (a package for representing spherical data sets), and some math/fitting routines from SciPy."}}, {"pk": 370, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nebfa", "license": "MIT", "author": "Paul Joseph Davis", "author_email": "davisp@neb.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/davisp/nebgb", "version": "0.0.2", "platform": "any", "keywords": "bioinformatics fasta parser", "summary": "Fasta file parser.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "nebfa - Fasta File Parser\n=========================\n\nUsage:\n\n    >>> import nebfa\n    >>> rec = nebfa.parse(open(\"./test/data/basic.fa\")).next()\n    >>> rec.id\n    ('gi', '0120123123')\n    >>> rec.desc\n    'Some stuff'\n    >>> rec.sequence\n    'ACGT'\n    >>> rec.hash\n    '2108994E17F6CCA9FF2352ADA92B6511DB076034'\n    \n    # Alternatively, parse_file avoids the need for a call to open.\n    >>> for rec in nebfa.parse_file(\"./test/data/multi.fa\"):\n    ...     print rec.id\n    ('gi', '0120123123')\n    ('ref', 'YP_234234.2')\n\nRecords also have a meta attribute that has two keys for identifiers and\ndescriptions. You will need to consult that member when you have Ctl-A separated\ndeflines. If you have a better syntax suggestion please send a note along."}}, {"pk": 371, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "EnthoughtBase", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/enthought_base.php", "version": "3.1.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Core packages for the Enthought Tool Suite.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The EnthoughtBase project includes a few core packages that are used by many\nother projects in the Enthought Tool Suite:\n\n- **enthought.etsconfig**: Supports configuring settings that need to be shared\n  across multiple projects or programs on the same system. Most significant of\n  these is the GUI toolkit to be used. You can also configure locations for\n  writing application data and user data, and the name of the company\n  responsible for the software (which is used in the application and user data\n  paths on some systems).\n- **enthought.logger**: Provides convenience functions for creating logging\n  handlers.\n- **enthought.util**: Provides miscellaneous utility functions.\n\nPrerequisites\n-------------\nIf you want to build EnthoughtBase from source, you must first install\n`setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 372, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "genbank-download", "license": "BSD License", "author": "Simon Greenhill", "author_email": "simon@simon.net.nz", "project_url": null, "maintainer_email": null, "home_page": "http://simon.net.nz/code/genbank-download/", "version": "0.5", "platform": "UNKNOWN", "keywords": "genbank genetics mitchondria bioinformatics fasta", "summary": "a small script to download nucleotide sequences from genbank using an accession number.", "classifiers": "Intended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "Download nucleotide sequences from genbank using an accession number\n\n(c) Simon Greenhill, 2009\n\nUsage:\n\npython genbankdownload.py [options] ACCESSION-NUMBER\n\ne.g.\npython genbankdownload.py J01415.1\npython genbankdownload.py J01415.1 > mysequence.xml\npython genbankdownload.py -m fasta J01415.1 > mysequence.fasta"}}, {"pk": 373, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "zgeo.spatialindex", "license": "BSD", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/projects/PrimaGIS/wiki/zgeo.spatialindex", "version": "0.3", "platform": "UNKNOWN", "keywords": "gis geo spatial index", "summary": "Spatial index for Zope", "classifiers": "Development Status :: 3 - Alpha\nFramework :: Plone\nFramework :: Zope3\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "A R-Tree spatial index for geographically annotated objects that plugs into the Zope catalog and enables fast spatial bounding box searches.\n      \nVersion 0.3 is incompatible with version 0.2.\n\nChanges\n=======\n\n0.3: 18 February 2008\n---------------------\n- Implements an Rtree-based index that plugs into the Zope catalog.\n- ISpatialIndex adapter has been removed."}}, {"pk": 374, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "webstemmer", "license": "MIT/X", "author": "Yusuke Shinyama", "author_email": "yusuke at cs dot nyu dot edu", "project_url": null, "maintainer_email": "", "home_page": "http://www.unixuser.org/~euske/python/webstemmer/index.html", "version": "0.7.1", "platform": "UNKNOWN", "keywords": "", "summary": "Web crawler and HTML layout analyzer", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Text Processing :: Markup :: HTML", "description": "Webstemmer is a web crawler and HTML layout analyzer that automatically extracts\r\nmain text of a news site without having banners, ads and/or navigation links\r\nmixed up."}}, {"pk": 375, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "edrnsite.misccontent", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/edrnsite-misccontent", "version": "0.0.2", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers content", "summary": "EDRN Miscellaneous Content Types", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "********************\nedrnsite.misccontent\n********************\n\nThis product, ``edrnsite.misccontent``, provides miscellaneous content types\nfor Plone_ (version 3 or later) in support of the Early Detection Research\nNetwork's public portal.  Although intended for the EDRN_ public portal, it\ncan be installed in any Plone-compatible site.\n\nIt was developed by the Informatics Center (IC_), operated by JPL_.\n\n.. References:\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _IC: http://cancer.jpl.nasa.gov/\n.. _JPL: http://www.jpl.nasa.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``edrnsite.misccontent`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        edrnsite.misccontent\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        edrnsite.misccontent\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.\n\n\n0.0.2 - The Eleventh Hour\n-------------------------\n\nAfter viewing the new look-and-feel for EDRN across a variety of applications,\nmanagement suddenly realizes they don't like it.  This release attempts to\nsatisfy them.  See https://oodt.jpl.nasa.gov/jira/browse/CA-599 for more.\n\n0.0.1 - Unknown release\n-----------------------\n\nIt's a myyyyssteeeerrry!\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 376, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "imposm", "license": "Apache Software License 2.0", "author": "Oliver Tonnhofer", "author_email": "olt@omniscale.de", "project_url": null, "maintainer_email": null, "home_page": "http://imposm.org/", "version": "2.1.0", "platform": "UNKNOWN", "keywords": null, "summary": "OpenStreetMap importer for PostGIS.", "classifiers": "Development Status :: 4 - Beta\nLicense :: OSI Approved :: Apache Software License\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: GIS", "description": ".. # -*- restructuredtext -*-\n\nImposm is an importer for OpenStreetMap data. It reads XML and PBF files and\ncan import the data into PostgreSQL/PostGIS databases.\n\nIt is designed to create databases that are optimized for rendering/WMS\nservices.\n\nIt is developed and supported by `Omniscale <http://omniscale.com>`_, runs on\nLinux or Mac OS X and is released as open source under the `Apache Software\nLicense 2.0 <http://www.apache.org/licenses/LICENSE-2.0.html>`_.\n\nSee http://imposm.org/ for more information."}}, {"pk": 377, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pycuda", "license": "MIT", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/pycuda", "version": "0.94.2", "platform": "UNKNOWN", "keywords": null, "summary": "Python wrapper for Nvidia CUDA", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization", "description": "PyCUDA lets you access `Nvidia <http://nvidia.com>`_'s `CUDA\n            <http://nvidia.com/cuda/>`_ parallel computation API from Python.\n            Several wrappers of the CUDA API already exist-so what's so special\n            about PyCUDA?\n\n            * Object cleanup tied to lifetime of objects. This idiom, often\n              called\n              `RAII <http://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization>`_\n              in C++, makes it much easier to write correct, leak- and\n              crash-free code. PyCUDA knows about dependencies, too, so (for\n              example) it won't detach from a context before all memory\n              allocated in it is also freed.\n\n            * Convenience. Abstractions like pycuda.driver.SourceModule and\n              pycuda.gpuarray.GPUArray make CUDA programming even more\n              convenient than with Nvidia's C-based runtime.\n\n            * Completeness. PyCUDA puts the full power of CUDA's driver API at\n              your disposal, if you wish. It also includes code for\n              interoperability with OpenGL.\n\n            * Automatic Error Checking. All CUDA errors are automatically\n              translated into Python exceptions.\n\n            * Speed. PyCUDA's base layer is written in C++, so all the niceties\n              above are virtually free.\n\n            * Helpful `Documentation <http://documen.tician.de/pycuda>`_ and a\n              `Wiki <http://wiki.tiker.net/PyCuda>`_.\n\n            Relatedly, like-minded computing goodness for `OpenCL <http://khronos.org>`_\n            is provided by PyCUDA's sister project `PyOpenCL <http://pypi.python.org/pypi/pyopencl>`_."}}, {"pk": 378, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "TraitsGUI", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/traits_gui", "version": "3.6.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Traits-capable windowing framework.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The TraitsGUI project contains a toolkit-independent GUI abstraction layer\n(known as Pyface), which is used to support the \"visualization\" features of\nthe Traits package. Thus, you can write code in terms of the Traits API\n(views, items, editors, etc.), and let TraitsGUI and your selected toolkit\nand back-end take care of the details of displaying them.\n\nTo display Traits-based user interfaces, in addition to the TraitsGUI project,\nyou must install one of the following combinations of packages:\n\n- Traits, TraitsBackendWX, and wxPython\n- Traits, TraitsBackendQt, and PyQt\n\nPrerequisites\n-------------\nIf you want to build TraitsGUI from source, you must first install\n`setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 379, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "text-sentence", "license": "UNKNOWN", "author": "Robert Lujo", "author_email": "trebor74hr@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/trebor74hr/text-sentence/", "version": "0.14", "platform": "UNKNOWN", "keywords": null, "summary": "text-sentence is text tokenizer and sentence splitter", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP :: Indexing/Search\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Text Processing\nTopic :: Text Processing :: Indexing\nTopic :: Text Processing :: Linguistic", "description": "Text tokenizer and sentence splitter \n====================================\nLibrary \"text-sentence\" is text tokenizer and sentence splitter. \n\nInput is for main function is text, list of known names and abbreviations. \nResult is list of tokens. Each token has type and other attributes i.e.:\n\n    - is word, \n    - is number, \n    - is roman number, \n    - is sentence end, \n    - is abbreviation, \n    - is name, \n    - is contraction,\n    - is end of chapter \n    - etc. \n    \n**Determining end of sentence** needs special logic and care what is the main\nreason for naming package with \"text-sentence\".\n\nTAGS \n----\n    tokenization, sentence splitter, sentencer, chapter, names, abbreviation\n\nAUTHOR\n======\nRobert Lujo, Zagreb, Croatia, find mail address in LICENCE\n\n\nFEATURES\n========\nTo name the most important:\n - TODO: ...\n\nSystem is based on unicode strings.\n\nCheck `Getting started`_.\n\nINSTALLATION\n============\nInstallation instructions - if you have installed pip package \nhttp://pypi.python.org/pypi/pip::\n\n    pip install text-sentence\n\nIf not, then do it old-fashioned way:\n    - download zip from http://pypi.python.org/pypi/text-sentence/\n    - unzip\n    - open shell\n    - go to distribution directory\n    - python setup.py install\n\nDevelopment version you can see at http://bitbucket.org/trebor74hr/text-sentence.\n\nor Mercurial clone with::\n\n    hg clone https://bitbucket.org/trebor74hr/text-sentence\n\nGETTING STARTED\n===============\nUsage example - start python shell::\n\n    >>> from text_sentence import Tokenizer\n    >>> t = Tokenizer()\n    >>> list(t.tokenize(\"This is first sentence. This is second one!And this is third, is it?\"))\n    [T('this'/sent_start), T('is'), T('first'), T('sentence'), T('.'/sent_end), \n     T('this'/sent_start), T('is'), T('second'), T('one'), T('!'/sent_end), \n     T('and'/sent_start), T('this'), T('is'), T('third'), T(','/inner_sep), \n     T('is'), T('it'), T('?'/sent_end)]\n\nMore samples can be found in tests:\n\n    http://bitbucket.org/trebor74hr/text-sentence/src/tip/text_sentence/test_sentence.txt\n\nFurther\n-------\nSince there is currently no good documentation, the best source of \nfurther information is by reading tests inside of module and\ntests test_sentence. More information in `Running tests`_.\nYou can allways read a source.\n\n\nDOCUMENTATION\n=============\nCurrently there is no documentation. In progress ...\n\n\nSUPPORT\n=======\nSince this project is limited by my free time, support is limited. \n\n\nREPORT BUG OR REQUEST FEATURE\n-----------------------------\nIf you encounter bug, the best is to report it to the bitbucket web page\nhttp://bitbucket.org/trebor74hr/text-sentence.\n\nThe best way to contact me is by mail (find in LICENCE).\n\nTODO list is in readme.txt (dev version).\n\n\nCONTRIBUTION\n============\nSince this project is not currently in the stable API phase, contribution\nshould wait for a while.\n\n\nRUNNING TESTS\n=============\nAll tests are doctests (not unittests). There are two type of tests in the\npackage: \n\n    1. doctests in module i.e. in __init__.py\n    2. doctests in test_sentence.txt \n\nRunning module directly will run 1. and 2. \n\nTo run tests:\n    - goto text_sentence directory\n    - run tests by running module, e.g.::\n\n        > python __init__.py\n        __main__: running doctests\n        test_sentence.txt: running doctests\n\n    - other with::\n\n        > python -m\"text_sentence\"\n\nTODO\n====\nvarious things, see readme.txt in dev version for details.\n\nCHANGES\n=======\n0.14\n----\nulr1 100621: \n    - is_contraction token attribute - e.g. isn't or o\u0161'\n\n0.13\n----\nulr1 100619:\n    - sample in getting started\n\n0.12\n----\nulr1 100619:\n    - test_sentence.txt installation\n    - readme fix main title\n\n0.11\n----\nulr1 100618:\n    - adapted tests\n    - __init__.py and sentence.py\n\n0.10\n----\nulr1 100617:\n    - first installable release"}}, {"pk": 380, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Mayavi", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/mayavi/", "version": "3.4.1", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "The Mayavi scientific data 3-dimensional visualizer.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The Mayavi *project* includes two related *packages* for 3-dimensional\nvisualization:\n\n- **Mayavi2**: A tool for easy and interactive visualization of data.\n- **TVTK**: A Traits-based wrapper for the Visualization Toolkit, a popular\n  open-source visualization library.\n\nThese libraries operate at different levels of abstraction. TVTK manipulates\nvisualization objects, while Mayavi2 lets you operate on your data, and then\nsee the results. Most users either use the Mayavi user interface or program\nto its scripting interface; you probably don't need to interact with TVTK\nunless you want to create a new Mayavi module.\n\nMayavi2\n-------\nMayavi2 seeks to provide easy and interactive visualization of 3-D data.\nIt offers:\n\n- An (optional) rich user interface with dialogs to interact with all data\n  and objects in the visualization.\n- A simple and clean scripting interface in Python, including one-liners,\n  or an object-oriented programming interface.\n- The power of the VTK toolkit, harnessed through these interfaces, without\n  forcing you to learn it.\n\nAdditionally Mayavi2 is a reusable tool that can be embedded in your\napplications in different ways or combined with the Envisage\napplication-building framework to assemble domain-specific tools.\n\n\n\nTVTK\n----\n\nTVTK wraps VTK objects to provide a convenient, Pythonic API, while supporting\nTraits attributes and NumPy/SciPy arrays. TVTK is implemented mostly in pure\nPython, except for a small extension module.\n\nDevelopers typically use TVTK to write Mayavi modules, and then use Mayavi to\ninteract with visualizations or create applications.\n\nPrerequisites\n-------------\nYou must have the following libraries installed before installing the Mayavi\nproject:\n\n* `Numpy <http://pypi.python.org/pypi/numpy/1.1.1>`_ version 1.1.0 or later is\n  preferred. Version 1.0.4 will work, but some tests may fail.\n* `VTK <http://www.vtk.org/>`_ version 5.0 or later.\n* `wxPython <http://www.wxpython.org/>`_ version 2.8 or later.\n* `setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 381, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ygl", "license": "BSD", "author": "Prabhu Ramachandran", "author_email": "prabhu@aero.iitb.ac.in", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/prabhuramachandran/yglpy", "version": "1.0", "platform": "Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "A wrapper for the Ygl plotting library.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: X11 Applications\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries", "description": "Python wrapper for Ygl\n=======================\n\nYgl_, developed by Fred Hucht, emulates a significant subset of SGI's\n`IRIS GL`_ on X11.  IRIS GL was a precursor to OpenGL. Ygl is an easy to\nuse library.  This package provides a ctypes-based, Python wrapper for\nYgl_.  It also provides a convenient and rather simple plotting\ninterface. \n\nIt is perhaps a lot more convenient to use OpenGL via PyOpenGL_,\nhowever, I am providing this wrapper for legacy support for applications\nthat have used Ygl.  I used to provide a SWIG_ based wrapper but a\nctypes based wrapper is a lot easier to build and install.\n \n\n.. _Ygl: <http://WWW.thp.Uni-Duisburg.DE/Ygl/ReadMe.html>\n.. _`IRIS GL`: http://en.wikipedia.org/wiki/IRIS_GL\n.. _PyOpenGL: http://pyopengl.sf.net\n.. _SWIG: http://www.swig.org\n\n\nInstallation\n-------------\n\nYou will require to have Ygl installed.  Under Debian/Ubuntu, this is\neasily done by installing libygl4 like so::\n\n    $ sudo apt-get install libygl4\n\nIf you are not on Debian or Ubuntu you would need to install Ygl from\nthe sources downloadable from the Ygl_ webpage.\n\nTo install the wrapper you should be able to simply do::\n\n   $ easy_install ygl\n\n\nExamples\n---------\n\nThere are a few sample examples in the examples directory of the source\npackage.  These should show you how to use both the ``ygl`` module and the\n``yplot`` module.  A simple example of how to use ``yplot`` is in\n``examples/plot.py``."}}, {"pk": 382, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "dcel", "license": "UNKNOWN", "author": "Angel Yanguas-Gil", "author_email": "angel.yanguas@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://ayanguasgil.net/", "version": "0.1.0", "platform": "UNKNOWN", "keywords": "", "summary": "implementation of a doubly connected edge list", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Console\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "This package implements a doubly connected edge list and a 2D polygonal map with\r\nbasic functionality for saving/reading from file and plotting postscript and eps\r\nfigures of the 2D maps"}}, {"pk": 383, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "CodeTools", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/code_tools.php", "version": "3.2.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Code Analysis and Execution Tools", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The CodeTools project includes packages that simplify meta-programming and\nhelp the programmer separate data from code in Python. This library contains\nclasses that allow defining simple snippets, or \"blocks\", of Python code,\nanalyze variable dependencies in the code block, and use these dependencies to\nconstruct or restrict an execution graph. These (restricted) code blocks can\nthen be executed in any namespace. However, this project also provides a\nTraits-event-enhanced namespace, called a \"context\", which can be used in\nplace of a vanilla namespace to allow actions to be performed whenever\nvariables are assigned or retrieved from the namespace. This project is used\nas the foundation for the BlockCanvas project.\n\nPrerequisites\n-------------\nIf you want to build CodeTools from source, you must first install\n`setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 384, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "EMMSA", "license": "UNKNOWN", "author": "Michael Sarahan", "author_email": "msarahan@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "0.0.4", "platform": "UNKNOWN", "keywords": null, "summary": "Multivariate Statistical Analysis for Electron Microscopy Data", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Other Environment\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 385, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyvib2", "license": "GNU GPL", "author": "Maxim Fedorovsky", "author_email": "Maxim.Fedorovsky@unifr.ch; mutable@yandex.ru", "project_url": null, "maintainer_email": null, "home_page": "http://pyvib2.sourceforge.net", "version": "1.1", "platform": "Any", "keywords": null, "summary": "A program for analyzing vibrational motion and vibrational spectra", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Scientific/Engineering :: Visualization", "description": "PyVib2 is a program for analyzing vibrational motion and vibrational\n        spectra, written in pure Python. The program was developed by\n        Maxim Fedorovsky during his Ph.D. thesis work in Prof. Werner Hug's research\n        group. PyVib2 permits the automatic correlation of vibrational motions of\n        molecules thereby allowing an understanding of Raman, Raman optical\n        activity (ROA), infrared vibrational absorption (IR), and vibrational\n        circular dichroism (VCD) spectra. The versatile representation of\n        vibrational motions, the visualization techniques of Raman/ROA and\n        IR/VCD generation in molecules and the production of publication quality\n        spectra, are features of PyVib2.\n        \n        Output files of Raman/ROA and IR/VCD calculations, produced with the\n        DALTON and Gaussian quantum chemistry packages, can be directly opened.\n        Files in the MOLDEN and XMol XYZ format can be imported and exported.\n        A variety of formats (JPEG, TIFF, PNG, PNM, PS, PDF, Animated GIF, FLI)\n        are available to the user for saving results.\n        \n        All the functionalities are accessible via the pyviblib class library."}}, {"pk": 386, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "cxnet", "license": "GNU General Public License (GPL)", "author": "Arpad Horvath", "author_email": "horvath.arpad.szfvar@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://mail.roik.bmf.hu/cxnet/doc/html", "version": "0.2", "platform": "ALL", "keywords": "graph,network,mathematics,math,graph theory,discrete mathematics,complex networks", "summary": "Complex networks in education", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Education\nLicense :: Free for non-commercial use\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics", "description": "The CXNet package extends IGraph module with some functionality.\r\nI am using in higher education.\r\nMost of the functionality is available with NetworkX module as well.\r\nFunction plotting needs matplotlib (pylab).\r\n\r\nThis package provides two modules cxnet and network_evolution.\r\n\r\nFunctionalities:\r\n\r\n- Creating network from the deb package hierarchy.\r\n\r\n- Investigating and plotting degree distribution.\r\n\r\n- Graph methods:\r\n\r\n * to list the vertices with most degrees,\r\n\r\n * to plot the neighbours of a vertex.\r\n\r\n- A tool to create network evolution models.\r\n\r\nYou can find a documentation on `its homepage <http://mail.roik.bmf.hu/cxnet/doc/html>`_."}}, {"pk": 387, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cclib", "license": "LGPL", "author": "cclib development team", "author_email": "cclib development team", "project_url": null, "maintainer_email": null, "home_page": "http://cclib.sf.net", "version": "1.0.1", "platform": "Any.", "keywords": null, "summary": "cclib: parsers and algorithms for computational chemistry", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Software Development :: Libraries :: Python Modules", "description": "cclib is a Python library that provides parsers for computational\nchemistry log files. It also provides a platform to implement\nalgorithms in a package-independent manner."}}, {"pk": 388, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ephem", "license": "LGPL", "author": "Brandon Craig Rhodes", "author_email": "brandon@rhodesmill.org", "project_url": null, "maintainer_email": null, "home_page": "http://rhodesmill.org/pyephem/", "version": "3.7.3.4", "platform": "UNKNOWN", "keywords": null, "summary": "Scientific-grade astronomy routines", "classifiers": "Development Status :: 6 - Mature\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.0\nTopic :: Scientific/Engineering :: Astronomy", "description": "==============\nPyEphem README\n==============\n\n.. _ephem: http://pypi.python.org/pypi/ephem/\n.. _pyephem: http://pypi.python.org/pypi/pyephem/\n.. _XEphem: http://www.clearskyinstitute.com/xephem/\n.. _Quick Reference: http://rhodesmill.org/pyephem/quick\n.. _Tutorial: http://rhodesmill.org/pyephem/tutorial\n.. _PyEphem web site: http://rhodesmill.org/pyephem/\n\n**This version of PyEphem,\nnamed** `ephem`_ **in the Python Package Index,\nis the version for Python 3.0.\nIf you are still using Python 2.x,\nthen look instead for the package named** `pyephem`_\n**in the Python Package Index.**\n\nPyEphem provides an ``ephem`` Python package\nfor performing high-precision astronomy computations.\nThe underlying numeric routines are coded in C\nand are the same ones that drive the popular `XEphem`_ astronomy application,\nwhose author, Elwood Charles Downey,\ngenerously gave permission for their use in PyEphem.\nThe name *ephem* is short for the word *ephemeris*,\nwhich is the traditional term for a table\ngiving the position of a planet, asteroid, or comet for a series of dates.\n\nThe `PyEphem web site`_ offers documentation\nand also links to the project bug tracker, user support forum,\nand source code repository.\n\nThe design of PyEphem emphasizes convenience and ease of use.\nBoth celestial bodies and the observer's location on Earth\nare represented by Python objects,\nwhile dates and angles automatically print themselves\nin standard astronomical formats::\n\n >>> import ephem\n >>> mars = ephem.Mars()\n >>> mars.compute('2008/1/1')\n >>> print mars.ra, mars.dec\n 5:59:27.35 26:56:27.4\n\nThe documentation includes both a `Quick Reference`_ and a `Tutorial`_,\nwhich are included in text files within the module itself\nas well as being available on the `PyEphem web site`_.\n\nThe features provided by PyEphem include:\n\n* Find where a planet, comet, or asteroid is in the sky.\n\n  * High-precision orbital routines are provdied\n    for the Moon, Sun, planets, and the major planet moons.\n  * The user can supply the orbital elements of a comet, asteroid,\n    or Earth-orbiting satellite, and have its location computed.\n  * The positions of 94 bright stars come built-in,\n    and the user can create further fixed objects as needed\n    for their calculations.\n\n* Determine where in the sky an object appears for a particular observer.\n\n  * The user can supply the longitude, latitude, and altitude\n    of the location from which they will be observing.\n  * For convenience, a small database of longitudes and latitudes\n    for 122 world cities is included.\n  * For specified weather conditions (temperature and pressure),\n    PyEphem will compensate for atmospheric refraction\n    by adjusting the positions of bodies near the horizon.\n\n* Compute when a body will rise, transit overhead, and set\n  from a particular location.\n\n* Parse and use orbital data in either the traditional XEphem file format,\n  or the standard TLE format used for tracking Earth-orbiting satellites.\n\n* Determine the dates of the equinoxes and solstices.\n\n* Compute the dates of the various phases of the Moon.\n\n* Convert from the Greenwich Time (more precisely, Ephemeris Time)\n  which PyEphem uses to the local time of the user.\n\n* Convert positions between the equatorial, ecliptic, and galactic\n  coordinate systems.\n\n* Determine on which page of the Uranometria or the Millennium Star Atlas\n  a particular star should appear.\n\n* Return the Julian Date corresponding to any calendar date."}}, {"pk": 389, "model": "importing.pypicache", "fields": {"maintainer": "Antti Honkela", "name": "tigreBrowser", "license": "AGPL3", "author": "Miika-Petteri Matikainen", "author_email": "mimatika@cc.hut.fi", "project_url": null, "maintainer_email": "antti.honkela@hiit.fi", "home_page": "http://users.ics.tkk.fi/ahonkela/tigre/", "version": "1.0.1", "platform": "UNKNOWN", "keywords": "", "summary": "Gene expression model browser for results from tigre R/Bioconductor package", "classifiers": "Environment :: Web Environment\nLicense :: OSI Approved :: GNU Affero General Public License v3\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Front-Ends\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "============\r\n        tigreBrowser\r\n        ============\r\n        \r\n        Gene expression model browser for results from tigre R package\r\n        (http://www.bioconductor.org/packages/release/bioc/html/tigre.html).\r\n        \r\n        tigreBrowser is licensed under GNU Affero General Public License (AGPL3)\r\n        tigreBrowser includes jQuery 1.4.2. (http://jquery.com/) licensed under MIT/GPL2 license\r\n        tigreBrowser includes jQuery Dynamic Form 1.0.3. (http://code.google.com/p/jquery-dynamic-form/) licensed under GPL3 license\r\n        \r\n        Installation\r\n        ============\r\n        \r\n        tigreBrowser requires Python version >=2.5.\r\n\r\n        If you have pip installed, you can use it to download and install tigreBrowser automatically:\r\n\r\n        ``pip install tigreBrowser``\r\n        \r\n        Starting server\r\n        ===============\r\n        \r\n        The web server included in tigreBrowser must be running in order to use the\r\n        actual result browser.\r\n        \r\n        You will need a database file generated by the tigre R package\r\n        (http://www.bioconductor.org/packages/release/bioc/html/tigre.html). This\r\n        package contains a test database file 'database.sqlite' which can be used to\r\n        test tigreBrowser. The test database was generated using the instructions and\r\n        example data included in tigre package.\r\n        \r\n        Execute tigreServer.py to start the graphical user interface of the server. In\r\n        order to start the result browser, one must first select a database file of\r\n        which results will be shown. This can be accomplished by selecting 'Open\r\n        database file' and choosing a database file. The database file must not have\r\n        write permissions. The server can then be started by clicking 'Start server'.\r\n        When clicked, a label appears below the buttons to show the URL of the result\r\n        browser.\r\n        \r\n        The result browser is now accessible in that URL using a regular web browser.\r\n        Instructions on using the browser are in the next section of this manual. The\r\n        browser is available until the server is stopped with the 'Stop server' button.\r\n        \r\n        tigreServer.py can also be used with a command-line interface. Start the script\r\n        with '--help' option for more details.\r\n        \r\n        \r\n        Using the browser\r\n        =================\r\n        \r\n        Dataset selection\r\n        -----------------\r\n        \r\n        The dataset selection determines which results will be visible in the results\r\n        listing and in which order. The experiment set selection is used to select the\r\n        set of experiments. Only results from these experiments will be shown in the\r\n        listing.\r\n        \r\n        Next in the dataset selection is the selection of transcription factor (TF) or\r\n        target set, depending on whether the result browser is set to Target ranking\r\n        mode or regulator ranking mode (see installation). In target ranking mode, the\r\n        TF selection is available and the results listing contains results for\r\n        different targets with the given TF. In regulator ranking mode, the target set\r\n        is selected and the listing will show results for different regulators.\r\n        \r\n        As the number of results can be high, the results might be divided into multiple\r\n        pages. \"Number of genes per page\" selection can be used to adjust the number of\r\n        showed results. It can be useful to decrease the number of results if the page\r\n        loads slowly due to huge number of images.\r\n        \r\n        Finally, the order in which the results are showed can be altered with the\r\n        \"Sort by\" selection. The results will be sorted descendingly by the given\r\n        criterion.\r\n        \r\n        \r\n        Filtering\r\n        ---------\r\n        \r\n        Results can be filtered by different criteria. One can, for example, show only\r\n        results for genes that have z-score higher than a certain threshold.\r\n        \r\n        It is possible to combine multiple criteria when filtering. \"[+]\" link can be\r\n        used to add another criterion. A criterion can be likewise removed using \"[-]\"\r\n        link (not showed when there is only one criterion). When multiple criteria are\r\n        used, a gene result must meet all the criteria to be showed in the listing.\r\n        \r\n        Filtering is activated using \"Apply filters\" checkbox.\r\n        \r\n        \r\n        Highlighting\r\n        ------------\r\n        \r\n        If genes in the database contain supplementary data, results can be highlighted\r\n        using that data. The available highlighting options are showed with the colors\r\n        associated to those options.\r\n        \r\n        The highlighting works by showing colored boxes below the probe names in the\r\n        result listing for genes which have supplementary data that matches the\r\n        selection.\r\n        \r\n        \r\n        Search\r\n        ------\r\n        \r\n        It is possible to search results for the given genes. The search works by\r\n        typing comma separated list of gene or probe names to the search box. Gene\r\n        aliases can also be used as a search entry.\r\n        \r\n        \r\n        Displaying results\r\n        ------------------\r\n        \r\n        The results for the given selection of dataset, filters, highlights and search\r\n        will be showed when \"Send\" button is clicked. The database will then be queried\r\n        for results which match the given selection. \"Reset\" button can be used to\r\n        clear all selections and textfields.\r\n        \r\n        The results listing contains multiple columns. In the first column a probe\r\n        name is displayed with a GENENAME associated with the probe. Next to the gene\r\n        name, is the gene expression figure if one is defined in the database. The\r\n        following column contains the actual results for genes. Any supplementary data\r\n        is also displayed here. Experiment figures will be displayed alongside the\r\n        result values.\r\n        \r\n        Finally, experiment parameters, if inserted into the database, will be\r\n        displayed as a table next to the figures."}}, {"pk": 390, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "petsc4py", "license": "Public Domain", "author": "Lisandro Dalcin", "author_email": "dalcinl@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://petsc4py.googlecode.com/", "version": "1.1.2", "platform": "POSIX", "keywords": "scientific computing,parallel computing,PETSc,MPI", "summary": "PETSc for Python", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: Public Domain\nOperating System :: POSIX\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Cython\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Python bindings for PETSc libraries."}}, {"pk": 391, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Shelley", "license": "UNKNOWN", "author": "Graham Carlyle", "author_email": "graham@grahamcarlyle.com", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/Shelley/", "version": "0.0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Simple map drawing", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: Apache Software License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "UNKNOWN"}}, {"pk": 392, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyncl.py", "license": "Public Domain", "author": "Jeff Whitaker", "author_email": "Jeffrey.S.Whitaker@noaa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://www.cdc.noaa.gov/people/jeffrey.s.whitaker/python/ncarg", "version": "1.0", "platform": "posix", "keywords": "scientific, graphics, plotting", "summary": "python interfaces to NCAR graphics", "classifiers": "Development Status :: 4 - Beta\nLicense :: Public Domain\nOperating System :: POSIX\nTopic :: Scientific/Engineering :: Visualization", "description": "pyncl.py provides a python interface to the superb 2-D scientific graphics\r\navailable in the NCAR Command Language (http://www.cgd.ucar.edu/nclapps/gsn).\r\nAn interface to the NCAR Graphics library (http://ngwww.ucar.edu/ng) is also\r\navailable."}}, {"pk": 393, "model": "importing.pypicache", "fields": {"maintainer": "Calvin Spealman", "name": "googlecalc", "license": "MIT", "author": "Calvin Spealman, Jamie Becker", "author_email": "", "project_url": null, "maintainer_email": "ironfroggy@gmail.com", "home_page": "", "version": "0.2.2", "platform": "", "keywords": "google", "summary": "An interface to the Google Calculator", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "Provides a simple function to send queries to google and parse Google Calculator\r\nresults into value/unit pairs. Also doubles as a simple command line tool that\r\ncan process such queries as \"googlecalc.py 1 foot + 14 inches in centimeters\"."}}, {"pk": 394, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "L1L2Py", "license": "GNU GPL version 3", "author": "L1L2Py developers - SlipGURU", "author_email": "salvatore.masecchia@disi.unige.it", "project_url": null, "maintainer_email": null, "home_page": "http://slipguru.disi.unige.it/Research/L1L2Py", "version": "1.0.3", "platform": "UNKNOWN", "keywords": "feature selection,regularization,regression,classification,l1-norm,l2-norm", "summary": "L1L2Py is a Python package to perform variable selection by means\nof l1l2 regularization with double optimization.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence", "description": "L1L2Py makes use of NumPy <http://numpy.scipy.org> to provide fast\nN-dimensional array manipulation and is the Python implementation of the\nmethod proposed and applied in [DeMol09]_.\n\nL1L2Py is a project of the SlipGURU - Statistical Learning and Image Processing\nGenoa University Research Group - Via Dodecaneso, 35 - 16146 Genova, ITALY\n<http://slipguru.disi.unige.it>.\n\nL1L2Py is free software. It is licensed under the GNU General Public\nLicense (GPL) version 3 <http://www.gnu.org/licenses/gpl.html>.\n\n\n.. [DeMol09] C. De Mol, S. Mosci, M. Traskine, A. Verri,\n             \"A Regularized Method for Selecting Nested Group of Genes from\n             Microarray Data\"\n             Journal of Computational Biology, vol. 16, pp. 677-690, 2009."}}, {"pk": 395, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "joblib", "license": "BSD", "author": "Gael Varoquaux", "author_email": "gael.varoquaux@normalesup.org", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/joblib/", "version": "0.5.0.dev", "platform": "any", "keywords": null, "summary": "Lightweight pipelining: using Python functions as pipeline jobs.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "Joblib is a set of tools to provide **lightweight pipelining in\nPython**. In particular, joblib offers:\n\n  1. transparent disk-caching of the output values and lazy re-evaluation\n     (memoize pattern)\n\n  2. easy simple parallel computing\n\n  3. logging and tracing of the execution\n\nJoblib is optimized to be **fast** and **robust** in particular on large\ndata and has specific optimizations for `numpy` arrays. It is\n**BSD-licensed**.\n\n\n    ============================== ==============================================\n    **User documentation**:        http://packages.python.org/joblib\n                               \n    **Download packages**:         http://pypi.python.org/pypi/joblib#downloads\n                               \n    **Source code**:               http://github.com/joblib/joblib\n\n    **Report issues**:             http://github.com/joblib/joblib/issues\n    ============================== ==============================================\n\n\nVision\n--------\n\nThe vision is to provide tools to easily achieve better performance and\nreproducibility when working with long running jobs. In addition, Joblib\ncan also be used to provide a light-weight make replacement or caching\nsolution.\n\n *  **Avoid computing twice the same thing**: code is rerun over an\n    over, for instance when prototyping computational-heavy jobs (as in\n    scientific development), but hand-crafted solution to aleviate this\n    issue is error-prone and often leads to unreproducible results\n \n *  **Persist to disk transparently**: persisting in an efficient way\n    arbitrary objects containing large data is hard. In addition,\n    hand-written persistence does not link easily the file on disk to the\n    execution context of the original Python object. As a result, it is\n    challenging to resume a application status or computational job, eg\n    after a crash.\n\nIt strives to address these problems while **leaving your code and your\nflow control as unmodified as possible** (no framework, no new\nparadigms). \n\nMain features\n------------------\n\n1) **Transparent and fast disk-caching of output value:** a memoize or\n   make-like functionality for Python functions that works well for\n   arbitrary Python objects, including very large numpy arrays. Separate\n   persistence and flow-execution logic from domain logic or algorithmic\n   code by writing the operations as a set of steps with well-defined\n   inputs and  outputs: Python functions. Joblib can save their\n   computation to disk and rerun it only if necessary::\n\n      >>> from joblib import Memory\n      >>> mem = Memory(cachedir='/tmp/joblib')\n      >>> import numpy as np\n      >>> a = np.vander(np.arange(3))\n      >>> square = mem.cache(np.square)\n      >>> b = square(a)\n      ________________________________________________________________________________\n      [Memory] Calling square...\n      square(array([[0, 0, 1],\n             [1, 1, 1],\n             [4, 2, 1]]))\n      ___________________________________________________________square - 0.0s, 0.0min\n\n      >>> c = square(a)\n      >>> # The above call did not trigger an evaluation\n\n2) **Embarrassingly parallel helper:** to make is easy to write readable \n   parallel code and debug it quickly:\n\n      >>> from joblib import Parallel, delayed\n      >>> from math import sqrt\n      >>> Parallel(n_jobs=1)(delayed(sqrt)(i**2) for i in range(10))\n      [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n\n\n3) **Logging/tracing:** The different functionalities will\n   progressively acquire better logging mechanism to help track what\n   has been ran, and capture I/O easily. In addition, Joblib will\n   provide a few I/O primitives, to easily define define logging and\n   display streams, and provide a way of compiling a report. \n   We want to be able to quickly inspect what has been run.\n\n.. \n    >>> import shutil ; shutil.rmtree('/tmp/joblib/')"}}, {"pk": 396, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pytst", "license": "UNKNOWN", "author": "Nicolas Lehuen", "author_email": "nicolas@lehuen.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/nlehuen/pytst", "version": "1.18", "platform": "UNKNOWN", "keywords": null, "summary": "An implementation of a Ternary Search Tree (TST) in C++ with Python bindings", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 397, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Numdifftools", "license": "New BSD", "author": "Per A. Brodtkorb", "author_email": "Brodtkorb at frisurf.no", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/numdifftools/", "version": "0.3.4", "platform": "UNKNOWN", "keywords": null, "summary": "Solves automatic numerical differentiation problems in one or more variables.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering :: Mathematics", "description": "NUMDIFFTOOLS\n============\nSuite of tools to solve automatic numerical differentiation\nproblems in one or more variables. All of these methods also\nproduce error estimates on the result.\nA pdf file is also provided to explain the theory behind these tools.\n\nTo test if the toolbox is working paste the following in an interactive\npython session::\n\n   import numdifftools as nd\n   nd.test(coverage=True)\n\nDerivative:\n-----------\nA flexible tool for the computation of derivatives of order 1 through 4\non any scalar function. Finite differences are used in an adaptive manner,\ncoupled with a Romberg extrapolation methodology to provide a maximally\naccurate result. The user can configure many of the options, changing\nthe order of the method or the extrapolation, even allowing the user to\nspecify whether central, forward or backward differences are used.\n\nGradient\n--------\nComputes the gradient vector of a scalar function of one or more variables\nat any location.\n\nJacobian\n--------\nComputes the Jacobian matrix of a vector (or array) valued function of\none or more variables.\n\nHessian\n-------\nComputes the Hessian matrix of all 2nd partial derivatives of a scalar\nfunction of one or more variables.\n\nHessdiag\n--------\nThe diagonal elements of the Hessian matrix are the pure second order\npartial derivatives.\n\nExamples\n--------\nCompute 1'st and 2'nd derivative of exp(x), at x == 1::\n\n    >>> import numpy as np\n    >>> import numdifftools as nd\n    >>> fd = nd.Derivative(np.exp)              # 1'st derivative\n    >>> fdd = nd.Derivative(np.exp,derOrder=2)  # 2'nd derivative\n    >>> fd(1)\n    array([ 2.71828183])\n\nNonlinear least squares::\n\n    >>> xdata = np.reshape(np.arange(0,1,0.1),(-1,1))\n    >>> ydata = 1+2*np.exp(0.75*xdata)\n    >>> fun = lambda c: (c[0]+c[1]*np.exp(c[2]*xdata) - ydata)**2\n    >>> Jfun = Jacobian(fun)\n    >>> Jfun([1,2,0.75]) # should be numerically zero\n    array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n           [  0.00000000e+00,   0.00000000e+00,  -1.30229526e-17],\n           [  0.00000000e+00,  -2.12916532e-17,   6.35877095e-17],\n           [  0.00000000e+00,   0.00000000e+00,   6.95367972e-19],\n           [  0.00000000e+00,   0.00000000e+00,  -2.13524915e-17],\n           [  0.00000000e+00,  -3.08563327e-16,   7.43577440e-16],\n           [  0.00000000e+00,   1.16128292e-15,   1.71041646e-15],\n           [  0.00000000e+00,   0.00000000e+00,  -5.51592310e-16],\n           [  0.00000000e+00,  -4.51138245e-19,   1.90866225e-15],\n           [ -2.40861944e-19,  -1.82530534e-15,  -4.02819694e-15]])\n\nCompute gradient of sum(x**2)::\n\n    >>> fun = lambda x: np.sum(x**2)\n    >>> dfun = Gradient(fun)\n    >>> dfun([1,2,3])\n    array([ 2.,  4.,  6.])\n\n\nSee also\n--------\nscipy.misc.derivative"}}, {"pk": 398, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "finance", "license": "http://www.opensource.org/licenses/PythonSoftFoundation.php", "author": "Niels Henrik Bruun", "author_email": "niels.henrik.bruun@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.bruunisejs.dk/PythonHacks/", "version": "0.11", "platform": "Operating System :: OS Independent", "keywords": null, "summary": "finance - Financial Risk Calculations. Optimized for ease of use through class construction and operator overload", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python Software Foundation License\nProgramming Language :: Python\nTopic :: Education\nTopic :: Office/Business\nTopic :: Office/Business :: Financial\nTopic :: Office/Business :: Financial :: Investment\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Utilities", "description": "##########################\nfinance - long description\n##########################\n\nThe purpose of this project is to deliver ease of use python code for financial\nrisk calculations.\nThis code is not unconsious reproduction of textbook material.\n\nIt's about developing `abstract data types <http://en.wikipedia.org/wiki/Abstract_data_type>`_ as objects to ease financial calculations and code \ndevelopment.\n\nAt this point the code is by no means optimized for speed.\n\nFinancial and mathematical concepts are developed on the PythonHacks homepage.\n\n* `To see more <http://www.bruunisejs.dk/PythonHacks/rstFiles/300%20Thoughts%20on%20finance.html>`_\n\n====================================\nPart 1 - Simple timedependent assets\n====================================\n\nTime is generic like a period such as eg 1 month and non-generic like a specific date.\nIn part both types are implemented with a heavy use of operator overload.\n\nThis means that questions like: How many days are there between a date 2009-12-27\nand 3 months ahead can be calculated like:\n\n>>> from finance import bankdate\n>>> t1 = bankdate('2009-12-27')\n>>> print t1 + '3m'\n2010-03-27\n>>> print t1 + '3m' - t1\n90\n\n* `To see more on bankdate <http://www.bruunisejs.dk/PythonHacks/rstFiles/200%20PythonHacks.html#finance.bankdate>`_\n* `To see more on timeperiods <http://www.bruunisejs.dk/PythonHacks/rstFiles/200%20PythonHacks.html#finance.timeperiod>`_\n\nFurther a vector-like structure handling future payments - a dateflow - is \nimplemented as a class.\n\nThrough method overload it is easy to build even very complex cashflows (= dateflow)\n\n* `To see more on dateflows <http://www.bruunisejs.dk/PythonHacks/rstFiles/200%20PythonHacks.html#finance.dateflow>`_\n\nGenerators of standard dateflows is also a part of the package.\n\n* `To see more on daterange <http://www.bruunisejs.dk/PythonHacks/rstFiles/200%20PythonHacks.html#finance.daterange>`_\n* `To see more on daterangeiter <http://www.bruunisejs.dk/PythonHacks/rstFiles/200%20PythonHacks.html#finance.daterangeiter>`_ \n* `To see more on standarddateflowgenerator <http://www.bruunisejs.dk/PythonHacks/rstFiles/200%20PythonHacks.html#finance.standarddateflowgenerator>`_ \n\nBefore any calculations on a dateflow can be made dates has to be converted into\ntimes. For this the class datetotime is created.\n\n* `To see more on datetotime <http://www.bruunisejs.dk/PythonHacks/rstFiles/200%20PythonHacks.html#finance.datetotime>`_\n\nFinally simpel calculations like present value and different sorts of duration \ncan be made though the class timeflow\n\n* `To see more on timeflow <http://www.bruunisejs.dk/PythonHacks/rstFiles/200%20PythonHacks.html#finance.timeflow>`_\n\n================\nChanges in 0.11:\n================\n\nThanks to Nick Leaton for inspiring comments.\n\n* Date rolling is moved to the bankdate class\n* Time period is added the unit w(eek)\n* Generators will handle date rolling\n* Timeflows are now based on numpy and scipy\n\n######################\nPlanned added contents\n######################\n\nThe planned development so far is:\n\nPlanned added content of version 0.2:\n    DiscountCurves based on benchmark zero bonds                       \n                                                                             \n    * Used as a basis for discountcurve calculations                 \n    * DiscountCurve calculations                                       \n    * Risk calculations based on linearily decomposable discountcurves\n\nPlanned added content of version 0.3:    \n    Currencies, implementing Markowitz etc                             \n\nPlanned added content of version 0.4:\n    Optionality though (binomial) trees\n    \nPlanned added content of version 0.5:\n    Bootstrapping from timeflows to get a base of benchmark zero bonds\n    \nPlanned added content of version 0.6:\n    Concept of portfolios, eg structured products"}}, {"pk": 399, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mapfish", "license": "Modified BSD", "author": "Camptocamp", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": null, "home_page": "http://www.mapfish.org", "version": "2.1", "platform": "UNKNOWN", "keywords": "pylons wsgi framework sqlalchemy geojson shapely GIS", "summary": "The MapFish web-mapping framework.", "classifiers": "Development Status :: 4 - Beta\nFramework :: Pylons\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "MapFish\n      =======\n\n      MapFish is a Pylons-based web framework with GIS orientations.\n\n      MapFish provides:\n\n        * a geometry type which is to be used when mapping PostGIS tables\n          with SQLAlchemy\n\n        * a paster command to generate model and controller mode\n          corresponding to layers (PostGIS tables) defined in a \n          configuration file\n\n        * an implementation of a RESTful protocols for creating, reading,\n          updating, and deleting geographic objects (features)\n\n      MapFish relies on the geojson and shapely packages, see\n      http://gispython.org.\n\n      MapFish projects are Pylons projects, the project developer\n      therefore fully benefits from the power of Pylons and its\n      companion components (SQLAlchemy, Mako, etc.).\n\n      Current status\n      --------------\n\n      MapFish 2.1 described in this page is the current stable version.\n\n      Download and Installation\n      -------------------------\n\n      MapFish can be installed with `Easy Install\n      <http://peak.telecommunity.com/DevCenter/EasyInstall>`_ by typing::\n\n          > easy_install mapfish"}}, {"pk": 400, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "eke.specimens", "license": "Proprietary", "author": "Andrew Hart", "author_email": "andrew.hart@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/eke-specimens", "version": "0.0.3", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers eke knowledge specimen erne", "summary": "ERNE Specimen Management for the EDRN Knowledge Environment", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Internet :: Z39.50\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "*************\neke.specimens\n*************\n\nThis product, ``eke.specimens``, provides display and RDF_ ingest of\nERNE (EDRN Resource Network Exchange) specimens for the Early Detection\nResearch Network (EDRN_) Knowledge Environment (EKE_).  EDRN uses the EKE to\nmake it easy to discover, share, search for, and retrieve all of EDRN's\ncollective knowledge, including cancers and other diseases, biomarkers,\npublications, investigators, participants, studies, protocols, and, as in the\ncase of this product, specimens.\n\nAlthough intended for the EDRN public portal, it can be installed in any\nPlone_ compatible site.\n\nThis software is developed by the `EDRN Informatics Center`_  at JPL_,\noperated by the California Institute of Technology, for NCI_.\n\n.. References:\n.. _EDRN Informatics Center: http://cancer.jpl.nasa.gov/\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _EKE: http://cancer.jpl.nasa.gov/documents/applications/knowledge-environment\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://cancer.gov/\n.. _Plone: http://plone.org/\n.. _RDF: http://w3.org/RDF\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``eke.specimens`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        eke.specimens\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        eke.specimens\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.  Within each\ndescription, you can find more details about cited issue numbers by visiting\nthe issue tracker at https://oodt.jpl.nasa.gov/jira/browse/CA\n\n0.0.3 - NYU\n-----------\n\nThis release tackles the following:\n\n* If an ERNE site is down and the ERNE cache returns an HTTP 500 error, don't\n  abort the entire ingest.  Just skip that site and go forward.  \"Keep calm\n  and carry on.\"\n\n\n0.0.2 - A Mixed Bag\n-------------------\n\nThis release addresses the following issue:\n\n* CA-698 - \"Structural\" objects appear in searches\n\n\n0.0.1 - Goodbye, Peter Lin\n--------------------------\n\nThis time around, the EKE specimen package provides direct display of ERNE\nspecimen data without having to delegate to the ERNE UI web application.\n(There is no corresponding issue in the issue tracker for this new feature; or\nif there is, the issue tracker is down as I write this and can't confirm.)\n\nThis release also addresses the following issues:\n\n* CA-683 - Counts are off on specimen search\n* CA-685 - Specimen Tab search results returns records for the same search\n  summary more than one time (should be grouped together)\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\nCopyright\n=========\n\nCopyright 2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 401, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "transitfeed", "license": "Apache License, Version 2.0", "author": "Tom Brown", "author_email": "tom.brown.code@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/googletransitdatafeed/", "version": "1.2.6", "platform": "OS Independent", "keywords": null, "summary": "Google Transit Feed Specification library and tools", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Other Audience\nLicense :: OSI Approved :: Apache Software License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This module provides a library for reading, writing and validating Google Transit Feed Specification files. It includes some scripts that validate a feed, display it using the Google Maps API and the start of a KML importer and exporter."}}, {"pk": 402, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mapfish.plugin.client", "license": "GPLv3", "author": "Camptocamp", "author_email": "info@camptocamp.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.mapfish.org", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "MapFish JavaScript GeoExt OpenLayers ExtJS", "summary": "Client plugin of the MapFish Framework.", "classifiers": "Development Status :: 3 - Alpha\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: JavaScript\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "MapFish Client Plugin\n      =====================\n\n      The client plugin of the MapFish framework. This plugin provides a Paster\n      template for installing the MapFish JavaScript toolbox and a default\n      JavaScript web-mapping user interface within MapFish applications.\n\n      Current status\n      --------------\n\n      MapFish Client Plugin 0.1.1 described in this page is the current stable\n      version.\n\n      Download and Installation\n      -------------------------\n\n      The plugin can be installed with `Easy Install\n      <http://peak.telecommunity.com/DevCenter/EasyInstall>`_ by typing::\n\n          > easy_install mapfish"}}, {"pk": 403, "model": "importing.pypicache", "fields": {"maintainer": "Carlos Gonzalez", "name": "carnarvon", "license": "GNU General Public License", "author": "Alvaro Navarro", "author_email": "anavarro@gsyc.escet.urjc.es", "project_url": null, "maintainer_email": "karlhangas@gmail.com", "home_page": "http://carnarvon.tigris.org", "version": "0.7.4", "platform": "Linux, Unix, MacOSX", "keywords": "software archaeology mysql cvs subversion gnuplot", "summary": "A Software Archaeology Analysis tool", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: MacOS X\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: SQL\nTopic :: Database\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Documentation\nTopic :: Software Development :: Version Control\nTopic :: Software Development :: Version Control :: CVS", "description": "Carnarvon analyses how old the software system is on a per-line basis and\r\nextracts figures and indexes that make it possible to identify how `old' the\r\nsoftware is, how much it has been maintained and how much effort it may suppose\r\nto maintain it in the future.\t\r\n\r\nA lot of software, mostly open source software, is developed using version\r\ncontrol tools from which it is possible to extract even when a single line of\r\ncode was edited for the last time. To collect all this kind of data and analyze\r\nit statistically could show information in terms of software aging and\r\nindicators of maintainability could be obtained from different perspectives,\r\nsystems area and development area, for example.\r\n\r\nCarnarvon runs on any platform with python 2.3+ interpreter installed. Current\r\nsupported versioning systems are CVS and Subversion."}}, {"pk": 404, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pyreallib", "license": "LGPL", "author": "didier deshommes", "author_email": "dfdeshom@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://www.bitbucket.org/dfdeshom/pyreallib/src/", "version": "1", "platform": "x86, PPC, AMD64", "keywords": "", "summary": "A Pyrex wrapper for the RealLib3 library", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: BSD :: FreeBSD\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nTopic :: Scientific/Engineering :: Mathematics", "description": "RealLib3 is a C++ library that allows computation of real numbers exactly.\r\npyreallib is a Pyrex wrapper for the RealLib3 Library. It compiles on Linux (x86\r\nand AMD64) and PowerPC (OSX 10.3 and higher)."}}, {"pk": 405, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "bioscripts.convert", "license": "BSD", "author": "Paul-Michael Agapow", "author_email": "agapow@bbsrc.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://www.agapow.net/software/bioscripts.convert", "version": "0.3", "platform": "UNKNOWN", "keywords": "bioinformatics conversion", "summary": "Biopython scripts for converting molecular sequences.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing", "description": "Introduction\n============\n\nBiopython scripts for converting molecular sequences.\n\nBioinformatics is bedevilled by a large number of file formats. Biopython\nprovides classes and IO functions that allow interconversion. This module\nprovides scripts that use Biopython internally to simply convert multiple\nfiles on the commandline.\n\n\nInstallation\n============\n\nbioscripts.convert [#homepage]_ can be installed in a number of ways.\nBiopython [#biopython]_ is required. Either of the automated methods using\nsetuptools [#setuptools]_ are preferred, but a manual installation will\nsuffice if need be.\n\nVia setuptools / easy_install\n-----------------------------\n\nFrom the commandline call::\n\n\t% easy_install bioscripts.convert\n\t\nSuperuser privileges may be required. \n\n\nVia setup.py\n------------\n\nDownload a source tarball, unpack it and call setup.py to\ninstall::\n\n\t% tar zxvf bioscripts.convert.tgz\n\t% cd bioscripts.convert\n\t% python setup.py install\n\t\nSuperuser privileges may be required. \n\nManual\n------\n\nDownload and unpack the tarball as above. Ensure Biopython is available. Copy\nthe scripts in bioscripts/convert to a location they can be called from.\n\n\nUsage\n=====\n\nDue to limitations on identifiers in certain formats, sequence names\nmay differ between input and output files. Also, not all formats understood by\nBiopython have been enabled, due to being untested or incomplete.\n\n\nconvbioseq\n----------\n\n::\n\n\tconvbioseq.py [options] FORMAT INFILES ...\n\nwith the options:\n\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit\n  -i FORMAT, --input-format=FORMAT\n                        The format of the input biosequence files. If not\n                        supplied, this will be inferred from the extension of\n                        the files.\n  -e EXTENSION, --output-extension=EXTENSION\n                        The extension of the output biosequence files. If not\n                        supplied, this will be inferred from the output\n                        format.\n\nFORMAT must be one of 'clustal', 'fasta', 'genbank', 'nexus', 'phd', 'phylip',\n'qual', 'stockholm'. The input formats inferred from extensions are clustal\n('.aln'), genbank ('.genbank'), nexus ('.nxs'), nexus ('.nexus'), phylip\n('.phylip'), stockholm ('.sth'), phd ('.phd'), qual ('.qual'), phylip\n('.phy'), clustal ('.clustal'), genbank ('.gb'), tab ('.tab'), fasta\n('.fasta'), stockholm ('.stockholm'). The default extensions for output\nformats are '.aln' (clustal), '.nexus' (nexus), '.phy' (phylip), '.phd' (phd),\n'.qual' (qual), '.gb' (genbank), '.sth' (stockholm), '.fasta' (fasta).\n\nFor example::\n\n\t% convbioseq.py clustal one.fasta two.nxs three.stockholm\n\nwill produce three clustal formatted files 'one.aln', 'two.aln' and\n'three.aln' from files it assumes are Fasta, Nexus and Stockholm formatted\nrespectively.\n\n\t% convbioseq.py -i phylip clustal one.fasta two.nxs\n\nwill produce two Phylip formatted files 'one.phy' and 'two.phy' and from files\nit assumes are Fasta formatted.\n\n\t% convbioseq.py -e foo clustal one.fasta two.nxs\n\t\nwill produce two Clustal formatted files 'one.foo' and 'two.foo' from files\nit assumes are Fasta and Nexus formatted respectively.\t\n\n\nconvalign\n---------\n\n::\n\n\tconvalign.py [options] FORMAT INFILES ...\n\nwith the options:\n\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit\n  -i FORMAT, --input-format=FORMAT\n                        The format of the input alignment files. If not\n                        supplied, this will be inferred from the extension of\n                        the files.\n  -e EXTENSION, --output-extension=EXTENSION\n                        The extension of the output alignment files. If not\n                        supplied, this will be inferred from the output\n                        format.\n\nFORMAT must be one of 'clustal', 'fasta', 'nexus', 'phylip', 'stockholm'. The\ninput formats inferred from extensions are clustal ('.aln'), nexus ('.nxs'),\nnexus ('.nexus'), phylip ('.phylip'), stockholm ('.sth'), phylip ('.phy'),\nclustal ('.clustal'), stockholm ('.stockholm'), fasta ('.fasta'). The default\nextensions for output formats are '.nxs' (nexus), '.phy' (phylip), '.fasta'\n(fasta), '.aln' (clustal), '.sth' (stockholm).\n\n\nDeveloper notes\n===============\n\nThis module is not intended for importing, but the setuptools packaging and\ninfrastructure make for simple distribution of scripts, allowing the checking\nof prerequisites, consistent installation and updating.\n\nThe ``bioscripts`` namespace was chosen as a convenient place to \"keep\" these\nscripts and is open to other developers.\n\n\nReferences\n==========\n\n.. [#homepage] `bioscripts.convert homepage <http://www.agapow/net/software/bioscripts.convert>`__\n\n.. [#biopython] `Biopython homepage <http://www.biopython.org>`__\n\n.. [#setuptools] `Installing setuptools <http://peak.telecommunity.com/DevCenter/setuptools#installing-setuptools>`__\n\n\n\n\nChangelog\n=========\n\n0.2 - 2009/4/14\n---------------\n\n* Initial release\n\n\n0.3.1 - 2009/4/16\n-----------------\n\n* Added alignment converter\n\n* Corrections to documentation"}}, {"pk": 406, "model": "importing.pypicache", "fields": {"maintainer": "Minas Abrahamyan", "name": "PyUnitGUI", "license": "GNU General Public License (GPL), wxWidgets Library Licence", "author": "Minas Abrahamyan", "author_email": "a_minas@web.am", "project_url": null, "maintainer_email": "a_minas@web.am", "home_page": "http://sourceforge.net/projects/pyunitgui/", "version": "0.3", "platform": "Windows, Unix/Linux, wxPython", "keywords": "UnitTest GUI framework Python NUnit JUnit", "summary": "UnitTest GUI framework for Python programs, has NUnit-like look", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications :: GTK\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Information Technology\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Quality Assurance\nTopic :: Software Development :: Testing\nTopic :: Software Development :: User Interfaces\nTopic :: Utilities", "description": "PyUnitGui is UnitTest GUI framework for Python programs. NUnit-like look with \r\ntests tree hierarchy and with console output window too. Writtem in wxPython it \r\naims to be is as portable as Python and wxPython together are."}}, {"pk": 407, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "psifas", "license": "GNU GPLv3+", "author": "Oren Zomer", "author_email": "oren.zomer@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pypsifas.sourceforge.net/", "version": "0.5", "platform": "Any", "keywords": "parsing,binary,serialize,pack,unpack,building,struct,scapy,network,protocol", "summary": "Python library for packing and unpacking complex data structures.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Networking\nTopic :: System :: Networking :: Monitoring", "description": "A python library for parsing and building of data structures with the ability\r\nof solving simple heuristics of interdepent sub-structures. It is based on\r\nthe concept of defining data structures in a declarative manner, where complex\r\nstructures are composed by combining simpler ones."}}, {"pk": 408, "model": "importing.pypicache", "fields": {"maintainer": "V. Armando Sole", "name": "PyMca", "license": "The package follows the dual licensing model of PyQt.\r\n\r\nThis means GPL unless a license is bought.", "author": "V. Armando Sole", "author_email": "sole@esrf.fr", "project_url": null, "maintainer_email": "V. Armando Sole", "home_page": "http://pymca.sourceforge.net/", "version": "4.4.1", "platform": "", "keywords": "", "summary": "X-Ray Fluorescence Analysis Toolkit and Application", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX :: Linux\nOperating System :: POSIX :: SunOS/Solaris\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization", "description": "Stand-alone application and Python tools for interactive and/or batch processing\r\nanalysis of X-Ray Fluorescence Spectra. Graphical user interface (GUI) and batch\r\nprocessing capabilities provided. \r\n\r\nFor its use as a library, it requires PyQt4, PyQwt5 and Numpy. Matplotlib is\r\nrecommended but not mandatory and h5py is needed for HDF5 format support."}}, {"pk": 409, "model": "importing.pypicache", "fields": {"maintainer": "Christian S. Perone", "name": "Pyevolve", "license": "", "author": "Christian S. Perone", "author_email": "christian.perone@gmail.com", "project_url": null, "maintainer_email": "christian.perone@gmail.com", "home_page": "http://pyevolve.sourceforge.net", "version": "0.5", "platform": "Windows, Linux", "keywords": "genetic algorithm framework python evolutionary", "summary": "A complete python genetic algorithm framework", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python Software Foundation License\nNatural Language :: English\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Mathematics", "description": "A complete python genetic algorithm framework"}}, {"pk": 410, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.seisan", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.7", "platform": "OS Independent", "keywords": "ObsPy,seismology,SEISAN,waveform,seismograms", "summary": "SEISAN read support for ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.wav package contains methods in order to read seismogram\nfiles in the SEISAN format.\n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology. \n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 411, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "seishub.core", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "Robert Barsch", "author_email": "barsch@lmu.de", "project_url": null, "maintainer_email": null, "home_page": "http://www.seishub.org", "version": "1.2.1", "platform": "OS Independent", "keywords": "SeisHub,seismology", "summary": "SeisHub - a seismological XML/SQL database hybrid", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "seishub - Web-based technology for storage and processing of\n    multi-component data in seismology.\n\n    For more information visit http://www.seishub.org."}}, {"pk": 412, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nl", "license": "GPL", "author": "Enrique Perez Arnaud", "author_email": "enriquepablo@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://http://enriquepablo.github.com/nlproject/", "version": "0.102", "platform": "UNKNOWN", "keywords": null, "summary": "A python library that provides a production system with an API modelled on the natural language", "classifiers": "Programming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 413, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pseudomethod", "license": "gpl", "author": "kai zhu", "author_email": "kaizhu256@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pypi.python.org/pypi/pseudomethod", "version": "2009.12.30.py3k.cpp", "platform": "UNKNOWN", "keywords": "", "summary": "pseudomethod - adds 'a..b()' syntax feature for dynamically calling ordinary functions as bound methods", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "pseudomethod - adds 'a..b()' syntax feature for dynamically calling ordinary functions as bound methods\n\n  REQUIRES LINUX OS AND PYTHON3.1\n\n  QUICK TEST: $ python3.1 setup.py build dev --quicktest\n\n  DESCRIPTION: pseudomethod - adds 'a..b()' syntax feature for dynamically calling ordinary functions as bound methods\n\nSUMMARY:\npseudomethod is a pure python module.\npseudomethod is a python ast tree hack, adding the following syntax sugars: '..' '...' '....'.\npseudomethod can extend restricted, unsubclassable python types like types.CodeType (python code object type).\npseudomethod can flatten ugly nested function calls by sequentially binding their return values.\n\n  RECENT CHANGELOG:\n  20091231 - added lambda __printop__: sugar\n  20091224 - added pseudomethod interactive console - revamped pseudomethod import hook\n  20091224 - modularized package - fix install issues - added sdist check\n  20091209 - improved documentation\n  20091205 - moved source code to c++\n  20091116 - package integrated\n\n  DEMO USAGE:\n\n\n>>> ## start up the interactive console\n>>> import pseudomethod\n>>> pseudomethod.pseudomethod_console().interact()\n\nPython 3.1.1 (r311:74480, Sep 13 2009, 17:17:12)\n[GCC 4.3.2] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n(pseudomethod_console)\n\n>>> from pseudomethod import *\n\n>>> ## DYNAMICALLY BIND FUNCTION CALLS TO OBJECTS\n>>> ## bind the function call print() to 'hello'\n>>> print('hello')\nhello\n>>> 'hello' ..print()\nhello\n>>> 'hello' ..print('world')\nhello world\n>>> 'hello' ..print('world', '!')\nhello world !\n>>> 'hello' ..print('world', '!', file = sys.stdout)\nhello world !\n\n>>> ## create a string pseudomethod which appends an exclamation or another ending\n>>> def add_end(self, end = '!'): return self + end\n>>> 'hello' ..add_end() ..print()\nhello!\n>>> 'hello'.upper() ..add_end() ..print()\nHELLO!\n>>> 'hello'.upper() ..add_end(' world') ..print()\nHELLO world\n>>> 'hello'.upper() ..add_end(' world').lower() ..print()\nhello world\n>>> 'hello'.upper() ..add_end(' world').lower() ..add_end('!') ..print()\nhello world!\n>>> 'hello'.upper() ..add_end(' world').lower() ..add_end('!') ..add_end(end = '!') ..print()\nhello world!!\n\n\n\n>>> ## OPERATOR PRECEDENCE\n>>> ## 'a..b()' has the same operator precedence as 'a.b()'  which precedes <and or not + - * /> but not <= == ,>\n>>> def add(aa, bb): return aa + bb\n>>> print( 2 * 3 ..add(4) + 5 == 2 * (3 + 4) + 5 )\nTrue\n>>> print( 3 == 1 ..add(2) )\nTrue\n>>> print( 0, 0 ..add(1), 0 )\n0 1 0\n\n\n\n>>> ## EXTEND RESTRICTED TYPES\n>>> ## the python code object type <class 'code'> cannot be subtyped nor will it accept any method binding.\n>>> ## however, we can extend it by dynamically binding ordinary functions.\n>>> ## here's a pseudomethod, which disassembles an instance of the type to a specified output\n>>> import dis, io, sys\n>>> def disassemble(self, file):\n...   backup_stdout = sys.stdout ## backup sys.stdout\n...   try:\n...     sys.stdout = file\n...     dis.dis(self) ## disassemble self\n...     return file\n...   finally:\n...     sys.stdout = backup_stdout ## restore sys.stdout\n\n>>> code_source = 'print( \"hello\" )'; code_object = compile(code_source, '', 'exec'); exec( code_object )\nhello\n>>> code_object ..disassemble(file = io.StringIO()).getvalue() ..print()\n  1           0 LOAD_NAME                0 (print) \n              3 LOAD_CONST               0 ('hello') \n              6 CALL_FUNCTION            1 \n              9 POP_TOP              \n             10 LOAD_CONST               1 (None) \n             13 RETURN_VALUE         \n\n\n\n\n>>> ## '...' AND '....' SYNTAX\n>>> ## sometimes we instead want the 2nd or 3rd argument of a function bound to an object.\n>>> ## '...' and '....' will do this respectively\n>>> '2nd' ...print(0, 0)\n0 2nd 0\n>>> '3rd' ....print(0, 0)\n0 0 3rd\n\n>>> ## '....' is useful for chaining re.sub\n>>> ss = 'file = io.StringIO(); print 1, 2, 3 >> file; print file.getvalue()'; print( ss )\nfile = io.StringIO(); print 1, 2, 3 >> file; print file.getvalue()\n\n>>> print(\n...   re.sub('print (.*?)$', 'print( \\\\1 )',\n...          re.sub('print (.*) >> (.*?);', 'print( \\\\1, file = \\\\2 );', ss)\n...          )\n...   )\nfile = io.StringIO(); print( 1, 2, 3, file = file ); print( file.getvalue() )\n\n>>> ss ....re.sub('print (.*) >> (.*?);', 'print( \\\\1, file = \\\\2 );') \\\n...    ....re.sub('print (.*?)$', 'print( \\\\1 )') \\\n...    ..print()\nfile = io.StringIO(); print( 1, 2, 3, file = file ); print( file.getvalue() )\n\n>>> ## in fact, another primary use of pseudomethod is to flatten ugly, hard-to-read, lisp-like nested function calls\n>>> print( dict( enumerate( zip( 'abc',  sorted( 'abc bca cab'.split(' '), key = lambda x: x[1] ) ) ) ) )\n{0: ('a', 'cab'), 1: ('b', 'abc'), 2: ('c', 'bca')}\n\n>>> 'abc bca cab'.split(' ') ..sorted(key = lambda x: x[1]) ...zip('abc') ..enumerate() ..dict() ..print()\n{0: ('a', 'cab'), 1: ('b', 'abc'), 2: ('c', 'bca')}\n\n\n\n>>> ## IMPORT MODULES WRITTEN WITH PSEUDOMETHOD SYNTAX\n>>> ## in fact, this package was written with pseudomethod syntax\n\n>>> ## enable pseudomethod import hook\n>>> import pseudomethod\n>>> pseudomethod.IMPORTER.add_hook()\npseudomethod_importer - adding hook <pseudomethod.pseudomethod_importer object at 0x870ddec> to sys.meta_path\n<pseudomethod.pseudomethod_importer object at 0x870ddec>\n\n>>> ## create test_module.py\n>>> open('test_module.py', 'w').write('\"hello\" ..print()\\n')\n35\n\n>>> ## during import, add the magic prefix 'pseudomethod.' to the beginning of the module name\n>>> import pseudomethod.test_module\nhello"}}, {"pk": 414, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gdspy", "license": "GNU General Public License (GPL)", "author": "Lucas Heitzmann Gabrielli", "author_email": "heitzmann@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "https://sourceforge.net/projects/gdspy/", "version": "0.2.7", "platform": "OS Independent", "keywords": null, "summary": "A Python GDSII exporter", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "Module for creating GDSII stream files. It also allows the geometry created to be visualized."}}, {"pk": 415, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "wille", "license": "BSD", "author": "TUT / Hypermedia Laboratory", "author_email": "jaakko.salonen@tut.fi", "project_url": null, "maintainer_email": "", "home_page": "https://wiki.tut.fi/Wille/", "version": "2.3", "platform": "UNKNOWN", "keywords": "visualisation framework", "summary": "Wille Visualisation Framework", "classifiers": "Development Status :: 5 - Production/Stable\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering :: Visualization", "description": "Wille is a framework for building data-processing pipeline-based visualisation\r\n        applications."}}, {"pk": 416, "model": "importing.pypicache", "fields": {"maintainer": "Jason Roberts", "name": "GeoEco", "license": "", "author": "", "author_email": "", "project_url": null, "maintainer_email": "jason.roberts@duke.edu", "home_page": "http://code.env.duke.edu/projects/mget", "version": "0.7", "platform": "", "keywords": "", "summary": "Marine Geospatial Ecology Tools", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: GIS", "description": "Marine Geospatial Ecology Tools\r\n-------------------------------\r\n\r\nMarine Geospatial Ecology Tools (MGET), also known as the GeoEco Python \r\npackage, is an open source geoprocessing toolbox designed for coastal and \r\nmarine researchers and GIS analysts who work with spatially-explicit ecological \r\nand oceanographic data in scientific or management workflows. MGET includes \r\nover 180 tools useful for a variety of tasks, such as converting oceanographic \r\ndata to ArcGIS formats, identifying fronts in sea surface temperature images, \r\nfitting and evaluating statistical models such as GAMs and GLMs by integrating \r\nArcGIS with the R statistics program, analyzing coral reef connectivity by \r\nsimulating hydrodynamic larval dispersal, and building grids that summarize \r\nfishing effort, CPUE and other statistics. Currently under development are \r\ntools for identifying rings and eddy cores in sea surface height images, for \r\nanalyzing connectivity networks, for estimating fishing effort when no effort \r\ndata are available, for predicting hard bottom habitat from coarse grain \r\nbathymetry, and much more. \r\n\r\nAlthough \"Marine\" is the first word in the title, many tools are not specific \r\nto marine problems. You may find these tools useful in a variety of situations.\r\n\r\nMGET may be accessed from ArcGIS as a toolbox in the ArcToolbox window and from \r\nprogramming languages as a set of Python modules and COM components. A \"tool\" \r\nin MGET corresponds to a method of a Python class.\r\n\r\nDownload and Installation\r\n-------------------------\r\n\r\nDownload from the `MGET home page <http://code.env.duke.edu/projects/mget>`_\r\n(the files are too large to be hosted by PyPI).\r\n\r\nPlease read the installation instructions `here \r\n<http://code.env.duke.edu/projects/mget/browser/MGET/Tags/GeoEco-\r\n0.7/PythonPackage/dist/TracOnlineDocumentation/Documentation/GettingStarted.html\r\n?format=raw#Installation>`_.\r\n\r\nMinimum requirements:\r\n\r\n* Microsoft Windows XP or later\r\n* Python 2.4 or 2.5\r\n* Python for Windows Extensions (the pywin32 package)\r\n\r\nMost tools also require ArcGIS 9.1 or later. Some tools require other free \r\nsoftware, such as R.\r\n\r\nFor More Information\r\n--------------------\r\n\r\nVisit our home page. Newer releases may be available on the home page."}}, {"pk": 417, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cogent", "license": "GPL", "author": "Gavin Huttley, Rob Knight", "author_email": "gavin.huttley@anu.edu.au, rob@spot.colorado.edu", "project_url": null, "maintainer_email": null, "home_page": "http://sourceforge.net/projects/pycogent", "version": "1.5.0", "platform": "any", "keywords": "biology,genomics,statistics,phylogeny,evolution,bioinformatics", "summary": "COmparative GENomics Toolkit", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Cogent\nA toolkit for statistical analysis of biological sequences.\nVersion 1.5.0."}}, {"pk": 418, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.gse2", "license": "GNU General Public License (GPL)", "author": "The ObsPy Development Team & Stefan Stange", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.7", "platform": "OS Independent", "keywords": "ObsPy,seismology,GSE2,waveform,seismograms", "summary": "Read & write seismograms, Format GSE2.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "obspy.gse2 - Read & write seismograms, Format GSE2\n\n    This module contains Python wrappers for gse_functions - The GSE2 library\n    of Stefan Stange (http://www.orfeus-eu.org/Software/softwarelib.html#gse).\n    Currently CM6 compressed GSE2 files are supported, this should be \n    sufficient for most cases. Gse_functions are written in C and interfaced \n    via Python ctypes.\n\n    For more information visit http://www.obspy.org."}}, {"pk": 419, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pybgpdump", "license": "GPL", "author": "Jon Oberheide", "author_email": "jon@oberheide.org", "project_url": null, "maintainer_email": "", "home_page": "http://jon.oberheide.org/projects/pybgpdump/", "version": "0.1", "platform": "", "keywords": "python, bgp, mrt, libbgpdump, dpkt", "summary": "MRT and BGP parsing in python", "classifiers": "Development Status :: 3 - Alpha\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis", "description": "pybgpdump combines the functionality of libbgpdump and the ease of python to\r\nparse BGP messages from MRT dumps."}}, {"pk": 420, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "hcluster", "license": "New BSD License", "author": "Damian Eads", "author_email": "damian XDOTX eads XATX gmail XDOTX com", "project_url": null, "maintainer_email": null, "home_page": "http://scipy-cluster.googlecode.com", "version": "0.2.0", "platform": "UNKNOWN", "keywords": "dendrogram,linkage,cluster,agglomorative,hierarchical,hierarchy,ward,distance", "summary": "A hierarchical clustering package for Scipy.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Information Analysis", "description": "This library provides Python functions for hierarchical clustering. Its features\ninclude\n\n    * generating hierarchical clusters from distance matrices\n    * computing distance matrices from observation vectors\n    * computing statistics on clusters\n    * cutting linkages to generate flat clusters\n    * and visualizing clusters with dendrograms. \n\nThe interface is very similar to MATLAB's Statistics Toolbox API to make code\neasier to port from MATLAB to Python/Numpy. The core implementation of this\nlibrary is in C for efficiency."}}, {"pk": 421, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "fluid", "license": "MIT", "author": "Guilherme Castelao and Roberto de Almeida", "author_email": "guilherme@castelao.net", "project_url": null, "maintainer_email": null, "home_page": "http://cheeseshop.python.org/pypi/fluid/", "version": "0.1.7", "platform": "any", "keywords": "fluid oceanography meteorology seawater heat flux wind", "summary": "Procedures to study geophysical fluids on Python.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Procedures to study fluids on Python, focused for oceanography, meteorology and related sciences.\n\nFluid is a set of procedures to study fluids, focused for \nocean and atmosphere analysis.\n\nIt's able to estimate/convert basic variables such as mixing ratio, \nsaturation vapor pressure and air viscosity, and estimate heat fluxes \nbetween air-sea interface.\n\nGreat structure modifications are expected in upcoming versions.\n\nUntil version 1.0 I'll try to keep backward compatibility, but I \ncan't guarantee.\n\nI started to develop this package while being funded by SAAC-IAI, CAPES and FAPESP."}}, {"pk": 422, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "edrnsite.search", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/edrnsite-search", "version": "1.0.1", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers eke knowledge search", "summary": "EDRN Public Portal Search", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Internet :: WWW/HTTP :: Indexing/Search\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "***************\nedrnsite.search\n***************\n\nThis product, ``edrnsite.search``, provides customized searching and search\nresults for the EDRN_ Knowledge Environment (EKE_).  EDRN uses the EKE to make\nit easy to discover, share, search for, and retrieve all of EDRN's collective\nknowledge, including cancers and other diseases, biomarkers, specimens,\ninvestigators, participants, studies, protocols, etc.\n\nAlthough intended for the EDRN public portal, it can be installed in any\nPlone_ compatible site.\n\nThis software is developed by the `EDRN Informatics Center`_  at JPL_,\noperated by the California Institute of Technology, for NCI_.\n\n.. References:\n.. _EDRN Informatics Center: http://cancer.jpl.nasa.gov/\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _EKE: http://cancer.jpl.nasa.gov/documents/applications/knowledge-environment\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://cancer.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``edrnsite.search`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        edrnsite.search\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        edrnsite.search\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.\n\n1.0.1 - Specimen Search\n-----------------------\n\nThis time around, the search package works with the new fields in the EKE\nspecimen package and the fact the package no longer delegates to the ERNE UI\nfor specimen display.  (There is no corresponding issue in the issue tracker\nfor this new feature; or if there is, the issue tracker is down as I write\nthis and can't confirm.)\n\n\n1.0.0 - Prime Time\n------------------\n\nThis release addresses a number of issues that make this component (and some\nof its selected counterparts) \"prime time\" for the operational NCI portal.\n\nThis release addresses the following issues:\n\nYou can find the issue tracker at https://oodt.jpl.nasa.gov/jira/browse/CA\n\n\n0.0.2 - Specimen Search - 2010-08-09\n------------------------------------\n\nThis release added free-text search that matched ERNE specimens provided by\nthe ``eke.specimens`` package.\n\n\n0.0.1 - Undocumented Release\n----------------------------\n\nThe changelog failed to be updated for this release.\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 423, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Podis-Web", "license": "http://www.fsf.org/licensing/licenses/agpl-3.0.html", "author": "Romain Soufflet", "author_email": "podis@infos-pratiques.org", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "2.0", "platform": "UNKNOWN", "keywords": "Podis web interface", "summary": "Web interface for Podis", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Web Environment\nIntended Audience :: Information Technology\nLicense :: OSI Approved :: GNU Affero General Public License v3\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "UNKNOWN"}}, {"pk": 424, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cfflib", "license": "BSD License", "author": "Stephan Gerhard", "author_email": "info@connectomics.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.connectomics.org/", "version": "0.9", "platform": "UNKNOWN", "keywords": null, "summary": "Connectome File Format Library", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "The Connectome File Format library supports easy handling of many neuroimaging formats and metadata for research in connectomics"}}, {"pk": 425, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mpmath", "license": "BSD", "author": "Fredrik Johansson", "author_email": "fredrik.johansson@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://mpmath.googlecode.com", "version": "0.17", "platform": "UNKNOWN", "keywords": null, "summary": "Python library for arbitrary-precision floating-point arithmetic", "classifiers": "Topic :: Scientific/Engineering :: Mathematics", "description": "UNKNOWN"}}, {"pk": 426, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "plotlib", "license": "BSD", "author": "J. Brandon Keith", "author_email": "jbrkeith@gmail.edu", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "0.3", "platform": "UNKNOWN", "keywords": "plot vnf", "summary": "library to plot data objects of vnf and danse products", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 427, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pcSVMdemo", "license": "bsd", "author": "Uwe Schmitt", "author_email": "schmitt@num.uni-sb.de", "project_url": null, "maintainer_email": "", "home_page": "http://www.procoders.net/en/Procoders/open_source/pcSVMdemo", "version": "1.0", "platform": "windows, mac os x, linux", "keywords": "artificial intelligence, machine learning, artificial neural networks, classifcation", "summary": "pcSVMdemo demonstrates the operating principles of support vector machines (SMVs)", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Healthcare Industry\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nIntended Audience :: Telecommunications Industry\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Adaptive Technologies\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Image Recognition\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "pcSVMdemo is based on our SVM (support vector machine)  library pcSVM at\r\nhttp://www.procoders.net/en/Procoders/open_source/pcSVM and\r\ndemonstrates the operatring principle of SVMs."}}, {"pk": 428, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pulp-or", "license": "Copyright (c) 2002-2005, Jean-Sebastien Roy (js@jeannot.org)\nModifications Copyright (c) 2007- Stuart Anthony Mitchell (s.mitchell@auckland.ac.nz)\n\nPermission is hereby granted, free of charge, to any person obtaining a\ncopy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be included\nin all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\nOR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.", "author": "J.S. Roy and S.A. Mitchell", "author_email": "s.mitchell@auckland.ac.nz", "project_url": null, "maintainer_email": null, "home_page": "http://pulp-or.googlecode.com/", "version": "1.4.6", "platform": "UNKNOWN", "keywords": "Optimization,Linear Programming,Operations Research", "summary": "PuLP is an LP modeler written in python. PuLP can generate MPS or LP files\nand call GLPK, COIN CLP/CBC, CPLEX, and GUROBI to solve linear\nproblems.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "# Copyright J.S. Roy (js@jeannot.org), 2003-2005\r\n# Copyright Stuart A. Mitchell (stu@stuartmitchell.com)\r\n# See the LICENSE file for copyright information.\r\n\r\nPuLP is an LP modeler written in python. PuLP can generate MPS or LP files\r\nand call GLPK[1], COIN CLP/CBC[2], CPLEX[3], and GUROBI[4] to solve linear\r\nproblems.\r\n\r\nSee the examples directory for examples.\r\n\r\nPuLP requires Python >= 2.5.\r\n\r\nThe examples require at least a solver in your PATH or a shared library file.\r\n\r\nDocumentation is found on https://www.coin-or.org/PuLP/.\r\nA comprehensive wiki can be found at https://www.coin-or.org/PuLP/\n\nUse LpVariable() to create new variables. To create a variable 0 <= x <= 3\n>>> x = LpVariable(\"x\", 0, 3)\n\nTo create a variable 0 <= y <= 1\n>>> y = LpVariable(\"y\", 0, 1)\n\nUse LpProblem() to create new problems. Create \"myProblem\"\n>>> prob = LpProblem(\"myProblem\", LpMinimize)\n\nCombine variables to create expressions and constraints and add them to the\nproblem. \n>>> prob += x + y <= 2\n\nIf you add an expression (not a constraint), it will\nbecome the objective.\n>>> prob += -4*x + y\n\nChoose a solver and solve the problem. ex:\n>>> status = prob.solve(GLPK(msg = 0))\n\nDisplay the status of the solution\n>>> LpStatus[status]\n'Optimal'\n\nYou can get the value of the variables using value(). ex:\n>>> value(x)\n2.0\n\nExported Classes:\n    - LpProblem -- Container class for a Linear programming problem\n    - LpVariable -- Variables that are added to constraints in the LP\n    - LpConstraint -- A constraint of the general form \n      a1x1+a2x2 ...anxn (<=, =, >=) b \n    - LpConstraintVar -- Used to construct a column of the model in column-wise \n      modelling\n\nExported Functions:\n    - value() -- Finds the value of a variable or expression\n    - lpSum() -- given a list of the form [a1*x1, a2x2, ..., anxn] will construct \n      a linear expression to be used as a constraint or variable\n    - lpDot() --given two lists of the form [a1, a2, ..., an] and \n      [ x1, x2, ..., xn] will construct a linear epression to be used \n      as a constraint or variable\r\n\nComments, bug reports, patches and suggestions are welcome.\r\npulp-or-discuss@googlegroups.com\r\n\nReferences:\r\n[1] http://www.gnu.org/software/glpk/glpk.html\r\n[2] http://www.coin-or.org/\r\n[3] http://www.cplex.com/\r\n[4] http://www.gurobi.com/"}}, {"pk": 429, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "curate", "license": "AGPL", "author": "Open Knowledge Foundation", "author_email": "okfn-help@lists.okfn.org", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/curate/", "version": "0.15", "platform": "UNKNOWN", "keywords": "ckan rdf rdflib", "summary": "Curation Utilities for CKAN", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Affero General Public License v3\nOperating System :: POSIX\nProgramming Language :: Python :: 2.6\nTopic :: Internet\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Curation Utilities for CKAN"}}, {"pk": 430, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gpxdata", "license": "UNKNOWN", "author": "Frank P\u00e4hlke", "author_email": "frank@kette-links.de", "project_url": null, "maintainer_email": null, "home_page": "http://www.kette-links.de/technik/", "version": "1.1.0", "platform": "UNKNOWN", "keywords": null, "summary": "Object-Oriented representation of GPX documents and conversion utilities between GPX, KML and OVL", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 431, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "edef", "license": "UNKNOWN", "author": "Hannes Matuschek", "author_email": "hmatuschek@gmx.net", "project_url": null, "maintainer_email": null, "home_page": "http://edef.sourceforge.net", "version": "0.3.1", "platform": "UNKNOWN", "keywords": null, "summary": "A simple discrete event simulation with GUI.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering", "description": "edef - Is a simple discrete event simulation framework. It can\nhandle simple logic circuits but also more complex autoregressive \nprocesses and digital controller circuits. \n\nThere is a GUI application that itegrates a development environment for this\nframwork and a circuit editor."}}, {"pk": 432, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "topographica", "license": "BSD", "author": "Topographica Developers", "author_email": "developers[at]topographica[dot]org", "project_url": null, "maintainer_email": "", "home_page": "http://topographica.org/", "version": "0.9.7", "platform": "Windows,Mac OS X,Linux", "keywords": "", "summary": "A general-purpose neural simulator focusing on topographic maps.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Education\nTopic :: Scientific/Engineering", "description": "`Topographica`_ is a software package for computational modeling of\r\nneural maps. The goal is to help researchers understand brain function\r\nat the level of the topographic maps that make up sensory and motor\r\nsystems.\r\n\r\nPlease see http://topographica.org/ for more information.\r\n\r\n\r\nInstallation\r\n============\r\n\r\nTopographica is already packaged for a number of platforms, including\r\nLinux, Mac, and Windows. Please see http://topographica.org/Downloads\r\nfor links to packages. Below is a brief summary for installation into\r\nan existing Python environment.\r\n\r\nIf you have `easy_install`_ or `pip`_ (or similar), you can use one of\r\nthose to install Topographica and its dependencies automatically\r\n(e.g. ``easy_install topographica`` or ``pip install topographica``).\r\n\r\nAlternatively, you can download and unpack the archive below, and then\r\ninstall Topographica with a command like ``python setup.py install``\r\n(e.g. ``sudo python setup.py install`` for a site-wide installation,\r\nor ``python setup.py install --user`` to install into\r\n``~/.local``). You will need to install at least `NumPy`_ and `PIL`_\r\nbefore running Topographica. We also recommend that you install\r\n`MatPlotLib`_ so you can access all Topographica's plots, as well as\r\n`Gmpy`_ and Weave (available as part of `SciPy`_) for optimum\r\nperformance.\r\n\r\n.. _Topographica:\r\n   http://topographica.org/Home/index.html\r\n.. _NumPy: \r\n   http://pypi.python.org/pypi/numpy\r\n.. _Gmpy: \r\n   http://pypi.python.org/pypi/gmpy\r\n.. _SciPy: \r\n   http://pypi.python.org/pypi/scipy\r\n.. _MatPlotLib: \r\n   http://pypi.python.org/pypi/matplotlib\r\n.. _PIL: \r\n   http://pypi.python.org/pypi/PIL\r\n.. _easy_install:\r\n   http://peak.telecommunity.com/DevCenter/EasyInstall\r\n.. _pip:\r\n   http://pip.openplans.org/"}}, {"pk": 433, "model": "importing.pypicache", "fields": {"maintainer": "Erik Max Francis", "name": "CAGE", "license": "GPL", "author": "Erik Max Francis", "author_email": "software@alcyone.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.alcyone.com/software/cage/", "version": "1.1.2", "platform": "any; Unix for curses frontend", "keywords": "cellular automata, Turing machines, Langton vants, self-organizing systems, finite state machines, finite state automata", "summary": "A generic and fairly complete cellular automata simulation engine.", "classifiers": "Development Status :: 6 - Mature\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Games/Entertainment\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Mathematics", "description": "CAGE is a fairy generic and complete cellular automaton simulation\r\n    engine in Python.  It supports both 1D and 2D automata, a variety\r\n    of prepackaged rules, and the concept of \"agents\" which can move\r\n    about independently on the map for implementing agent behavior.\r\n\r\n    CAGE comes with numerous examples of fully-functional CA systems,\r\n    including Conway's Game of Life, Langton's self-reproducing\r\n    automaton, Langton's \"vants,\" and 1D automata rule explorers.  It\r\n    also comes with simple displayers (including a curses interface\r\n    for 2D automata).  Also included is a unique implementation of a\r\n    finite state machine (ant.py)."}}, {"pk": 434, "model": "importing.pypicache", "fields": {"maintainer": "someonesdad1", "name": "hcpy", "license": "", "author": "someonesdad1", "author_email": "someonesdad1@gmail.com", "project_url": null, "maintainer_email": "someonesdad1@gmail.com", "home_page": "http://code.google.com/p/hcpy/", "version": "5", "platform": "", "keywords": "", "summary": "A console-based RPN calculator", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Healthcare Industry\nIntended Audience :: Information Technology\nIntended Audience :: Manufacturing\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Utilities", "description": ""}}, {"pk": 435, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "de9im", "license": "BSD", "author": "Sean Gillies", "author_email": "sean.gillies@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/sgillies/de9im/", "version": "0.1", "platform": "UNKNOWN", "keywords": "gis computational geometry", "summary": "Dimensionally  Extended 9-Intersections Matrix utilities", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "=======================\nde9im: DE-9IM utilities\n=======================\n\nAs part of my continuing education about the theory and methods underlying\nShapely, GEOS, JTS, and the OGC's Simple Features specs, I've written a small\npackage of utilities for working with DE-9IM matrices and patterns:\nhttp://bitbucket.org/sgillies/de9im/. Shapely provides the standard (these are\nprobably my favorite OGC standards) predicates as geometry class methods::\n\n  >>> from shapely.wkt import loads\n  >>> p = loads('POLYGON ((1.0 0.0, 0.0 -1.0, -1.0 0.0, 0.0 1.0, 1.0 0.0))') \n  >>> q = loads('POLYGON ((3.0 0.0, 2.0 -1.0, 1.0 0.0, 2.0 1.0, 3.0 0.0))')\n  >>> p.disjoint(q)\n  False\n  >>> p.intersects(q)\n  True\n  >>> p.touches(q)\n  True\n\nbut what if you wanted to test whether the features touched at exactly one\npoint only? A \"side hug\", you might say. Instead of computing the intersection\nand checking its geometry type, you can use the de9im package to define a\nDE-9IM matrix pattern and test it against the relation matrix for the two\nfeatures. The `0` in the pattern below requires that the intersection of the\nboundaries of the features be a 0-dimensional figure. In other words: a point::\n\n  >>> from de9im import pattern\n  >>> side_hug = pattern('FF*F0****')\n  >>> im = p.relate(q)\n  >>> print im\n  FF2F01212\n  >>> side_hug.matches(im)\n  True\n\nOne may also use familiarly named patterns::\n\n  >>> from de9im.patterns import touches\n  >>> repr(touches)\n  \"DE-9IM or-pattern: 'FT*******||F**T*****||F***T****'\"\n  >>> touches.matches(im)\n  True"}}, {"pk": 436, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "p3d", "license": "GNU General Public License (GPL)", "author": "Christian Fufezan & Michael Specht", "author_email": "p3d@fufezan.net", "project_url": null, "maintainer_email": "", "home_page": "http://p3d.fufezan.net", "version": "0.4.2", "platform": "any that supports python 3+", "keywords": "", "summary": "protein structure module for structural bioinformatics", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: POSIX :: SunOS/Solaris\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Scientific/Engineering :: Medical Science Apps.\nTopic :: Software Development :: Libraries :: Python Modules", "description": "p3d - python module for structural bioinformatics"}}, {"pk": 437, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "exafmm", "license": "MIT", "author": "Rio Yokota, Andreas Kloeckner", "author_email": "yokota@bu.edu", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "2011.1", "platform": "UNKNOWN", "keywords": null, "summary": "Fast summation in Python", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries\nTopic :: Utilities", "description": "Code-generating FMM etc."}}, {"pk": 438, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "dmath", "license": "MIT", "author": "Brian Beck, Christopher Hesse", "author_email": "exogen@gmail.com, christopher.hesse@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/dmath", "version": "0.9", "platform": "UNKNOWN", "keywords": "decimal math precision trigonometry trigonometric", "summary": "Math routines for Python's Decimal type", "classifiers": "Development Status :: 4 - Beta\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 439, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mixed", "license": "MIT", "author": "Catherine Devlin", "author_email": "catherine.devlin@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac-hg.assembla.com/mixed_python/", "version": "0.2.1", "platform": "UNKNOWN", "keywords": "fraction arithmetic", "summary": "Class for fractions and mixed numbers", "classifiers": "Development Status :: 3 - Alpha\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Class that parses strings representing fractions\nand mixed numbers and handles arithmetic using them properly."}}, {"pk": 440, "model": "importing.pypicache", "fields": {"maintainer": "Tim Whidbey", "name": "gnofract4d", "license": "", "author": "Tim Whidbey", "author_email": "catenary@users.sourceforge.net", "project_url": null, "maintainer_email": "catenary@users.sourceforge.net", "home_page": "http://gnofract4d.sf.net", "version": "3.9", "platform": "", "keywords": "fractal mandelbrot julia", "summary": "A program to create fractal images", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: X11 Applications :: GTK\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: POSIX\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Artistic Software\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Mathematics", "description": "Gnofract 4D is a program which allows you to create varied fractal images such\r\nas the Mandelbrot set and many more. It provides a compiler so you can create\r\nyour own formulas."}}, {"pk": 441, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "readmagick", "license": "GPL", "author": "Luis Pedro Coelho", "author_email": "lpc@mcu.edu", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "1.0.4", "platform": "UNKNOWN", "keywords": null, "summary": "Read and write images using ImageMagick", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: C++\nTopic :: Scientific/Engineering", "description": "ReadMagick\n\nRead and write images using ImageMagick++.\n\nSupports modern image formats such as JPEG2000."}}, {"pk": 442, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "spice_cat", "license": "GPL", "author": "Tim Wegener", "author_email": "twegener@radlogic.com.au", "project_url": null, "maintainer_email": "", "home_page": "http://www.radlogic.com.au/downloads.htm", "version": "0.4", "platform": "", "keywords": "spice eda netlist include lib expand", "summary": "Generate single concatenated spice with expanded inlude/lib statements.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Electronic Design Automation (EDA)", "description": "Evaluate include statements to produce a single Spice netlist file."}}, {"pk": 443, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MDP", "license": "http://mdp-toolkit.sourceforge.net/license.html", "author": "MDP Developers", "author_email": "mdp-toolkit-devel@lists.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://mdp-toolkit.sourceforge.net", "version": "3.1", "platform": "Any", "keywords": null, "summary": "MDP is a Python library of widely used data processing algorithms that can be combined according to a pipeline analogy to build more complex data processing software. The base of available algorithms includes signal processing methods (Principal Component Analysis, Independent Component Analysis, Slow Feature Analysis), manifold learning methods ([Hessian] Locally Linear Embedding), several classifiers, probabilistic methods (Factor Analysis, RBM), data pre-processing methods, and many others.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics", "description": "**The Modular toolkit for Data Processing (MDP)** package is a library\nof widely used data processing algorithms, and the possibility to\ncombine them together to form pipelines for building more complex\ndata processing software.\n\nMDP has been designed to be used as-is and as a framework for\nscientific data processing development.\n\nFrom the user's perspective, MDP consists of a collection of *units*,\nwhich process data. For example, these include algorithms for\nsupervised and unsupervised learning, principal and independent\ncomponents analysis and classification.\n\nThese units can be chained into data processing flows, to create\npipelines as well as more complex feed-forward network\narchitectures. Given a set of input data, MDP takes care of training\nand executing all nodes in the network in the correct order and\npassing intermediate data between the nodes. This allows the user to\nspecify complex algorithms as a series of simpler data processing\nsteps.\n\nThe number of available algorithms is steadily increasing and includes\nsignal processing methods (Principal Component Analysis, Independent\nComponent Analysis, Slow Feature Analysis), manifold learning methods\n([Hessian] Locally Linear Embedding), several classifiers,\nprobabilistic methods (Factor Analysis, RBM), data pre-processing\nmethods, and many others.\n\nParticular care has been taken to make computations efficient in terms\nof speed and memory. To reduce the memory footprint, it is possible to\nperform learning using batches of data. For large data-sets, it is\nalso possible to specify that MDP should use single precision floating\npoint numbers rather than double precision ones. Finally, calculations\ncan be parallelised using the ``parallel`` subpackage, which offers a\nparallel implementation of the basic nodes and flows.\n\nFrom the developer's perspective, MDP is a framework that makes the\nimplementation of new supervised and unsupervised learning algorithms\neasy and straightforward. The basic class, ``Node``, takes care of tedious\ntasks like numerical type and dimensionality checking, leaving the\ndeveloper free to concentrate on the implementation of the learning\nand execution phases. Because of the common interface, the node then\nautomatically integrates with the rest of the library and can be used\nin a network together with other nodes.\n\nA node can have multiple training phases and even an undetermined\nnumber of phases. Multiple training phases mean that the training data\nis presented multiple times to the same node. This allows the\nimplementation of algorithms that need to collect some statistics on\nthe whole input before proceeding with the actual training, and others\nthat need to iterate over a training phase until a convergence\ncriterion is satisfied. It is possible to train each phase using\nchunks of input data if the chunks are given as an iterable. Moreover,\ncrash recovery can be optionally enabled, which will save the state of\nthe flow in case of a failure for later inspection.\n\nMDP is distributed under the open source BSD license. It has been\nwritten in the context of theoretical research in neuroscience, but it\nhas been designed to be helpful in any context where trainable data\nprocessing algorithms are used. Its simplicity on the user's side, the\nvariety of readily available algorithms, and the reusability of the\nimplemented nodes also make it a useful educational tool.\n\nhttp://mdp-toolkit.sourceforge.net"}}, {"pk": 444, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "OWSLib", "license": "BSD", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/projects/PCL/wiki/OwsLib", "version": "0.3.1", "platform": "UNKNOWN", "keywords": "gis ogc ows wfs wms capabilities metadata", "summary": "OGC Web Service utility library", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "OWSLib\n======\n\nPackage for working with OGC map, feature, and coverage services.\n\nOWSLib provides a common API for accessing service metadata and wrappers for\nGetCapabilities, GetMap, and GetFeature requests.\n\nThe OWSLib version 0.3 API is incompatible with version 0.2.1.\n\nDependencies\n------------\n\nOWSLib requires elementtree (standard in 2.5 as xml.etree) or lxml.\n\nUsage\n-----\n\nFind out what a WMS has to offer. Service metadata::\n\n    >>> from owslib.wms import WebMapService\n    >>> wms = WebMapService('http://wms.jpl.nasa.gov/wms.cgi', version='1.1.1')\n    >>> wms.identification.type\n    'OGC:WMS'\n    >>> wms.identification.version\n    '1.1.1'\n    >>> wms.identification.title\n    'JPL Global Imagery Service'\n    >>> wms.identification.abstract\n    'WMS Server maintained by JPL, worldwide satellite imagery.'\n\nAvailable layers::\n\n    >>> list(wms.contents)\n    ['us_landsat_wgs84', 'modis', 'global_mosaic_base', 'huemapped_srtm',\n    'srtm_mag', 'daily_terra', 'us_ned', 'us_elevation', 'global_mosaic',\n    'daily_terra_ndvi', 'daily_aqua_ndvi', 'daily_aqua_721', 'daily_planet',\n    'BMNG', 'srtmplus', 'us_colordem', None, 'daily_aqua', 'worldwind_dem',\n    'daily_terra_721']\n\nDetails of a layer::\n\n    >>> wms['global_mosaic'].title\n    'WMS Global Mosaic, pan sharpened'\n    >>> wms['global_mosaic'].boundingBoxWGS84\n    (-180.0, -60.0, 180.0, 84.0)\n    >>> wms['global_mosaic'].crsOptions\n    ['EPSG:4326', 'AUTO:42003']\n    >>> wms['global_mosaic'].styles\n    {'pseudo_bright': {'title': 'Pseudo-color image (Uses IR and Visual bands,\n    542 mapping), gamma 1.5'}, 'pseudo': {'title': '(default) Pseudo-color\n    image, pan sharpened (Uses IR and Visual bands, 542 mapping), gamma 1.5'},\n    'visual': {'title': 'Real-color image, pan sharpened (Uses the visual\n    bands, 321 mapping), gamma 1.5'}, 'pseudo_low': {'title': 'Pseudo-color\n    image, pan sharpened (Uses IR and Visual bands, 542 mapping)'},\n    'visual_low': {'title': 'Real-color image, pan sharpened (Uses the visual\n    bands, 321 mapping)'}, 'visual_bright': {'title': 'Real-color image (Uses\n    the visual bands, 321 mapping), gamma 1.5'}}\n\nAvailable methods, their URLs, and available formats::\n\n    >>> [op.name for op in wms.operations]\n    ['GetTileService', 'GetCapabilities', 'GetMap']\n    >>> wms.getOperationByName('GetMap').methods\n    {'Get': {'url': 'http://wms.jpl.nasa.gov/wms.cgi?'}}\n    >>> wms.getOperationByName('GetMap').formatOptions\n    ['image/jpeg', 'image/png', 'image/geotiff', 'image/tiff']\n\nThat's everything needed to make a request for imagery::\n\n    >>> img = wms.getmap(   layers=['global_mosaic'],\n    ...                     styles=['visual_bright'],\n    ...                     srs='EPSG:4326',\n    ...                     bbox=(-112, 36, -106, 41),\n    ...                     size=(300, 250),\n    ...                     format='image/jpeg',\n    ...                     transparent=True\n    ...                     )\n    >>> out = open('jpl_mosaic_visb.jpg', 'wb')\n    >>> out.write(img.read())\n    >>> out.close()\n\nA very similar API exists for WebFeatureService. See\ntests/MapServerWFSCapabilities.txt for details.\n\nKnown Issues\n------------\n\nOWSLib works with WMS version 1.1.1 and WFS 1.0.0 Other versions are not\nsupported at this time.\n\nSupport\n-------\n\nOWSLib shares a wiki and email list with the Python Cartographic Library:\n\nhttp://lists.gispython.org/mailman/listinfo/community\n\nhttp://trac.gispython.org/projects/PCL/wiki\n\nUpdated project information can be found at\n\nhttp://trac.gispython.org/projects/PCL/wiki/OwsLib"}}, {"pk": 445, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "swan", "license": "GNU GPL", "author": "Alexey Brazhe", "author_email": "brazhe@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://cell.biophys.msu.ru/static/swan", "version": "0.6.2", "platform": "UNKNOWN", "keywords": null, "summary": "Easy continuous wavelet analysis", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: X11 Applications :: GTK\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "swan is a tool for wavelet data analysis. \n      It's meant to be simple in use and easy to extend."}}, {"pk": 446, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pydisplay", "license": "LGPL", "author": "spacemarmot", "author_email": "spacemarmot@users.sourceforge.com", "project_url": null, "maintainer_email": "", "home_page": "http://pydisplay.sourceforge.net", "version": "0.1", "platform": "", "keywords": "LCD VFD graphics display driver", "summary": "Portable library of display drivers for graphic LCDs, VFDs, and the like", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Software Development :: User Interfaces\nTopic :: System :: Hardware :: Hardware Drivers", "description": ""}}, {"pk": 447, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "topex", "license": "MIT", "author": "Guilherme Castelao", "author_email": "guilherme@castelao.net", "project_url": null, "maintainer_email": null, "home_page": "http://cheeseshop.python.org/pypi/TOPEX", "version": "0.1", "platform": "any", "keywords": "altimetry,TOPEX,JASON-1,oceanography,Sea Surface Height", "summary": "A very simple library to interpret and load TOPEX/JASON altimetry data", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "A very simple library to read the NetCDF altimetry data of TOPEX and JASON-1. The objective here is automatize the procedure to make that dataset ready to use. This include read how many NetCDF files as required, sub-sample by time/period desired and create an accumulated intuitively dictionary of the pertinent data.\n\nIt's not implemented yet but the most interesting feature would be the class TOPEX, which would made very simple and intuitive load, sub-sample and deal with those dataset"}}, {"pk": 448, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pygeocoder", "license": "Lesser General Public License v3", "author": "Xiao Yu", "author_email": "xiao@xiao-yu.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.xster.net/pygeocoder", "version": "1.1.1", "platform": "UNKNOWN", "keywords": "google maps ajax api geocode geocoding address gps json", "summary": "Python interface for Google Geocoding API V3.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==============\npygeocoder 1.1.1\n==============\nXiao Yu\n19/12/2010\n\n*Based on googlemaps 1.0.2 by John Kleint*\n\nREADME\n------\n\nThis is a Python wrapper for Google Geocoding API V3\n\nIt allows you to directly convert an address to coordinates or vice versa. \n\n\nDependencies\n------------\nIts only dependency is the json module, included with Python versions 2.6 and\nlater and available for download as simplejson for earlier versions.\nIt is developed on Python 2.7 but should work on earlier versions.\n\n\nInstallation\n------------\nYou can install this package using pip:\n\n\tsudo pip install pygeocoder\n\t\nor download the source from http://code.xster.net/pygeocoder and install\n\t\n\tpython setup.py install\n\nUsage\n-----\nPlease refer to http://code.xster.net/pygeocoder/wiki for help with usage\n\n\nContact Information\n-------------------\nAuthor: Xiao Yu\nInternet: http://code.xster.net/pygeocoder\n\nFor comments, issues, requests, please contact via bitbucket at the above website\n\n\nChangelog\n---------\nVersion 1.1.1\nReturns GeocoderResult by default. \nResult set accessible by iterator or index.\n\nVersion 1.1\nAdded GeocoderResult in order to ease field retrieval/result parsing.\n\nVersion 1.0\nWorking version an API V3."}}, {"pk": 449, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.segy", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.4", "platform": "OS Independent", "keywords": "ObsPy,seismology,seismogram,SEG Y", "summary": "SEG Y and SU read and write support for ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.segy package contains methods in order to read and write seismogram\nfiles in the SEG Y (rev. 1) and SU (Seismic Unix) format.\n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology.\n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 450, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cfchecker", "license": "UNKNOWN", "author": "Rosalyn Hatcher", "author_email": "r.s.hatcher@reading.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://cf-pcmdi.llnl.gov/conformance/compliance-checker/", "version": "2.0.3", "platform": "UNKNOWN", "keywords": null, "summary": "The NetCDF Climate Forcast Conventions compliance checker", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering :: Atmospheric Science\nTopic :: Software Development :: Libraries", "description": "===================================\n        README  -  CF Checker version 2.0.0\n        ===================================\n        \n        To run the CF file conformance checker you must have the following \n        installed on your system:\n        \n             - Python 2.5\n             - UDUNITS2\n             - CDMS (part of CDAT-5.x)\n        \n        \n        Notes on CDMS install\n        ---------------------\n        \n        The CDMS module is part of the CDAT distribution available from the\n        PCMDI software portal (http://www2-pcmdi.llnl.gov/cdat/).\n        \n        You can either install the entire CDAT distribution or alternatively \n        use the CDAT-lite_ package.\n        \n        .. _CDAT-lite: http://pypi.python.org/pypi/cdat-lite\n        \n        \n        Notes on UDUNITS-2 install\n        --------------------------\n        The UDUNITS-2 package can be obtained from the unidata website\n        (http://www.unidata.ucar.edu/software/udunits)\n        \n        \n        To run the CF checker\n        ---------------------\n        \n        Once you have both UDUNITS-2 and CDMS installed you need to complete the \n        following steps in order to run the CF Checker.\n        \n        1. Make sure that the location of the cdms library is in your PYTHONPATH\n        \n           E.g. export PYTHONPATH=/home/rsh/software/CDAT-5.2-cdms/lib/python2.5/site-packages\n        \n        2. Make sure that the path to the udunits libraries are in the system \n           library path or alternatively set the environment variable LD_LIBRARY_PATH\n        \n           E.g. export LD_LIBRARY_PATH=$PREFIX/lib    \n        \n           where $PREFIX is the --prefix option you passed to the configure script \n           when installing udunits.\n        \n        3. Depending on the platform you are installing on, you may need to edit\n           the name of the udunits2 library in the cfchecks.py script.  If the name\n           of the library is anything other than libudunits2.so then you will need to\n           modify, as appropriate, the line\n        \n           udunits=CDLL(\"libudunits2.so\")\n        \n        4. You may also need to modify the path to the python interpreter at the top \n           of the cfchecks.py script.\n        \n        5. Run the checker by typing:\n              cfchecks.py <netCDF_file.nc>\n        \n        \n        If you have any problems or comments please contact Rosalyn Hatcher\n        (r.s.hatcher@reading.ac.uk)"}}, {"pk": 451, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PyBrain", "license": "BSD", "author": "UNKNOWN", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": "", "home_page": "http://pybrain.org", "version": "0.3", "platform": "UNKNOWN", "keywords": "Neural Networks Machine Learning", "summary": "PyBrain is the swiss army knife for neural networking.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence", "description": "UNKNOWN"}}, {"pk": 452, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "EnrichPy", "license": "MIT", "author": "Roban Hultman Kramer", "author_email": "robanhk@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "0.1.002", "platform": "UNKNOWN", "keywords": null, "summary": "a package of routines related to chemical enrichment", "classifiers": "License :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Astronomy", "description": "UNKNOWN"}}, {"pk": 453, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dlx", "license": "Apache 2.0", "author": "Sebastian Raaphorst", "author_email": "srcoding@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.site.uottawa.ca/~mraap046", "version": "1.0.4", "platform": "UNKNOWN", "keywords": "exact cover algorithm dlx dancing links", "summary": "Implementation of Donald Knuth's Dancing Links algorithm.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: Apache Software License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "This package provides an implementation of Donald Knuth's Dancing\n         Links algorithm for solving exact set cover problems.\n\n         1.0.4: Minor Python 3 bugfix.\n         1.0.3: Attempt to make code compatible with Python 3.\n         1.0.2: Removed extraneous code (had switched from callbacks for solutions to\n                making solve a generator to yield, but had forgotten to remove the\n                solution callback function parameter from the solve method).\n         1.0.1: Critical bugfix (N array was one short: did not account for header).\n         1.0.0: Initial release."}}, {"pk": 454, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "zgeo.kml", "license": "BSD", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/projects/PrimaGIS/wiki/zgeo.kml", "version": "0.4", "platform": "UNKNOWN", "keywords": "gis geography geospatial kml google earth", "summary": "Google Earth KML for Zope", "classifiers": "Development Status :: 3 - Alpha\nFramework :: Plone\nFramework :: Zope3\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Provides KML views of georeferenced objects, allowing Zope containers to be visualized in Google Earth. Version 0.4 is not backwards compatible with 0.3."}}, {"pk": 455, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "speech", "license": "UNKNOWN", "author": "Michael Gundlach", "author_email": "gundlach@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/pyspeech/", "version": "0.5.2", "platform": "UNKNOWN", "keywords": "speech recognition text-to-speech text to speech tts voice recognition", "summary": "A clean interface to Windows speech recognition and text-to-speech capabilities.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Win32 (MS Windows)\nIntended Audience :: Developers\nLicense :: OSI Approved :: Apache Software License\nOperating System :: Microsoft :: Windows\nProgramming Language :: Python\nTopic :: Desktop Environment\nTopic :: Home Automation\nTopic :: Multimedia :: Sound/Audio :: Speech\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: Libraries :: Python Modules", "description": "------------\nspeech.py\n------------\n\n  Allows your Windows python program to:\n    * get the text spoken by the user when prompted (a la raw_input())\n    * execute a callback when certain phrases are heard\n    * execute a callback when any understandable text is heard\n    * have different callbacks for different groups of phrases\n    * convert text to speech.\n\nExample\n=======\n\n  Showing speaking out loud, a simple input, and listening for all\n  recognizable words.\n  ::\n\n    import speech\n    import time\n\n    response = speech.input(\"Say something, please.\")\n    speech.say(\"You said \" + response)\n\n    def callback(phrase, listener):\n        if phrase == \"goodbye\":\n            listener.stoplistening()\n        speech.say(phrase)\n\n    listener = speech.listenforanything(callback)\n    while listener.islistening():\n        time.sleep(.5)\n\nRequirements\n============\n\n  Requires Windows XP or Vista, and Python 2.4 or 2.5.  If you use\n  Windows Vista, you'll need to say \"start listening\" if Speech\n  Recognition is not awake.\n\n  In addition to easy_installing speech.py, you'll need pywin32\n  (`for Python 2.5 <http://tinyurl.com/5ezco9>`__ or\n  `for Python 2.4 <http://tinyurl.com/5uzpox>`__); and if you're on XP,\n  you'll need the Microsoft Speech kit (installer\n  `here <http://tinyurl.com/br8ysh>`__).\n\nResources\n=========\n\n  * Homepage: http://pyspeech.googlecode.com/\n  * Source:\n\n    - Browse at http://code.google.com/p/pyspeech/source/browse/trunk/\n\n    - Get with **svn co http://pyspeech.googlecode.com/svn/trunk/\n      pyspeech-read-only**\n\n  Please let me know if you like or use this module - it would make\n  my day!"}}, {"pk": 456, "model": "importing.pypicache", "fields": {"maintainer": "Pierre GF GERARD-MARCHANT", "name": "scikits.hydroclimpy", "license": "BSD", "author": "Pierre GF GERARD-MARCHANT", "author_email": "pierregmcode_AT_gmail_DOT_com", "project_url": null, "maintainer_email": "pierregmcode_AT_gmail_DOT_com", "home_page": "http://hydroclimpy.sourceforge.net", "version": "0.67.0", "platform": "Windows,Linux,Solaris,Mac OS-X,Unix", "keywords": "", "summary": "Environmental time series manipulation", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "The scikits.hydroclimpy module is a collection of tools for manipulating and \r\nplotting environmental time series of various frequencies. The focus is on\r\nconvenient data access and manipulation while leveraging the existing\r\nmathematical functionality in numpy and scipy."}}, {"pk": 457, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "Dynamism", "license": "", "author": "", "author_email": "", "project_url": null, "maintainer_email": "", "home_page": "http://www.dynamism-project.com", "version": "0.4.9", "platform": "", "keywords": "real-time, robotics, control, distributed, networking", "summary": "Dynamism", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Embedded Systems\nTopic :: Software Development :: Libraries :: Application Frameworks\nTopic :: System :: Networking", "description": "Dynamism is a framework for developing real-time software systems, and is typically used for distributed \r\nrobotics control systems.  Dynamism includes a simple C API, a network-abstracted database for sharing \r\ndata, data logging capabilities, and bindings for high-level languages such as Python."}}, {"pk": 458, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "stats", "license": "MIT", "author": "Steven D'Aprano", "author_email": "steve+python@pearwood.info", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/pycalcstats/", "version": "0.1.2a", "platform": "UNKNOWN", "keywords": "statistics,mathematics,calculator", "summary": "Calculator-style statistical functions", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Other Environment\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 3.1\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Statistical functions\n---------------------\n\nstats is a pure-Python module providing basic statistics functions similar\nto those found on scientific calculators. It has over 40 statistics functions,\nincluding:\n\nUnivariate statistics:\n  * arithmetic, harmonic, geometric and quadratic means\n  * median, mode, midrange, trimean\n  * mean of angular quantities\n  * running and weighted averages\n  * quartiles, hinges and quantiles\n  * variance and standard deviation (sample and population)\n  * average deviation and median average deviation (MAD)\n  * skew and kurtosis\n  * standard error of the mean\n\nMultivariate statistics:\n  * Pearson's correlation coefficient\n  * Q-correlation coefficient\n  * covariance (sample and population)\n  * linear regression\n  * sums Sxx, Syy and Sxy\n\nand others.\n\n\nRequires Python 3.1 or better."}}, {"pk": 459, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pyepics", "license": "Epics Open License", "author": "Matthew Newville", "author_email": "newville@cars.uchicago.edu", "project_url": null, "maintainer_email": "", "home_page": "http://cars9.uchicago.edu/software/python/pyepics3/", "version": "3.1.1", "platform": "UNKNOWN", "keywords": "epics, automation control", "summary": "Epics Channel Access Extensions to Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: Free To Use But Restricted\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nOperating System :: POSIX :: SunOS/Solaris\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.0\nProgramming Language :: Python :: 3.1\nProgramming Language :: Python :: 3.2\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 460, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "bigfloat", "license": "GNU Library or Lesser General Public License (LGPL)", "author": "Mark Dickinson", "author_email": "dickinsm@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/dickinsm/bigfloat", "version": "0.2.1", "platform": "Linux,OS X", "keywords": null, "summary": "Arbitrary precision correctly-rounded floating point arithmetic, via MPFR.", "classifiers": "Development Status :: 3 - Alpha\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "The ``bigfloat`` package is a Python package providing arbitrary-precision\ncorrectly-rounded binary floating-point arithmetic.  It is currently\nimplemented as a ctypes wrapper around the MPFR library (http://www.mpfr.org).\n\nFeatures\n--------\n\n- correct rounding on all operations;  precisely defined semantics\n  compatible with the IEEE 754-2008 standard.\n\n- support for mixed-type operations with Python integers and floats\n\n- support for emulating IEEE 754 arithmetic in any of the IEEE binary\n  interchange formats described in IEEE 754-2008.  Infinities, NaNs,\n  signed zeros, and subnormals are all supported.\n\n- easy control of rounding modes and precisions, via Python's 'with'\n  statement.\n\nA quick tour\n------------\n\nThe ``bigfloat`` module is small and simple to use.  Here's a quick\ntour of some of its features.  See the `full tutorial and reference\ndocumentation <http://packages.python.org/bigfloat/>`_ for more\ndetails.\n\nFor demonstration purposes, start with::\n\n    >>> from bigfloat import *\n\nNote that this import clobbers some builtin Python functions, namely\n``abs``, ``max``, ``min`` and ``pow``.  In normal usage you'll\nprobably only want to import the classes and functions that you\nactually need.\n\nThe main class is the ``BigFloat`` class::\n\n    >>> BigFloat(1)  # can be constructed from an integer, float or string\n    BigFloat.exact('1.0000000000000000', precision=53)\n    >>> BigFloat('3.14159') ** 2 / 6.0  # can combine with ints and floats\n    BigFloat.exact('1.6449312880166664', precision=53)\n    >>> BigFloat('0.1', precision(200)) # high-precision value from string\n    BigFloat.exact('0.1000000000000000000000000000000000000000000000000000\n    0000000002', precision=200)\n\n\nNewly-created ``BigFloat`` instances refer to the current *context* to\ndetermine what precision and rounding modes to use.  This current\ncontext is represented by a ``Context`` instance, and can be retrieved\nby calling ``getcontext``::\n\n    >>> getcontext()\n    Context(precision=53, emax=1073741823, emin=-1073741823,\n            subnormalize=False, rounding='RoundTiesToEven')\n\nThe ``precision(200)`` argument passed to the ``BigFloat`` constructor\nabove is also an example of a ``Context``::\n\n    >>> precision(200)\n    Context(precision=200)\n\nThe context used for a calculation can be set using the ``setcontext``\nfunction, but a better way to make a temporary change to the context\nis to use Python's ``with`` statement::\n\n    >>> with precision(1000):\n    ...     print sqrt(2)\n    ... \n    1.41421356237309504880168872420969807856967187537694807317667973\n    7990732478462107038850387534327641572735013846230912297024924836\n    0558507372126441214970999358314132226659275055927557999505011527\n    8206057147010955997160597027453459686201472851741864088919860955\n    232923048430871432145083976260362799525140798964\n\nHere, ``sqrt`` is one of a number of mathematical functions that the\n``bigfloat`` module exports.  As you can see, these functions operate on\nintegers and floats as well as ``BigFloat`` instances, but always\nreturn a ``BigFloat`` instance.\n\nRounding modes can be controlled similarly.  Here are upper and lower\nbounds for \u03c0, accurate to 53 significant bits.\n\n    >>> with RoundTowardPositive:\n    ...     const_pi()\n    ... \n    BigFloat.exact('3.1415926535897936', precision=53)\n    >>> with RoundTowardNegative:\n    ...     const_pi()\n    ... \n    BigFloat.exact('3.1415926535897931', precision=53)\n\nAnd as you'd expect, ``with`` statements like those above can be\nnested.  ``Context`` objects can also be combined using addition::\n\n    >>> with RoundTowardPositive + precision(24):\n    ...     BigFloat(1) / 3\n    ... \n    BigFloat.exact('0.333333343', precision=24)\n\nVarious ``Context`` objects corresponding to IEEE 754 interchange\nformats are predefined::\n\n    >>> quadruple_precision\n    Context(precision=113, emax=16384, emin=-16493, subnormalize=True)\n    >>> half_precision\n    Context(precision=11, emax=16, emin=-23, subnormalize=True)\n    >>> with half_precision:\n            log(2)\n    ... \n    BigFloat.exact('0.69336', precision=11)\n\n\nLinks\n-----\n\n* `Package documentation <http://packages.python.org/bigfloat/>`_\n* `Project homepage at bitbucket <http://bitbucket.org/dickinsm/bigfloat/>`_"}}, {"pk": 461, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "experimentdb", "license": "BSD", "author": "Dave Bridges", "author_email": "dave.bridges@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://davebridges.github.com", "version": "0.2", "platform": "UNKNOWN", "keywords": "experiment,lims,data,science,data-management", "summary": "A web based application for storage and organization of data regarding experimental data.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Django\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Front-Ends\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "ExperimentDB\n============\n\nThe experimentDB is a web-based application for the storage, organization and communication of experimental data with a focus on molecular biology and biochemical data. This application also stores data regarding reagents, including antibodies, constructs and other biomolecules as well as tracks the distribution of reagents. There is also some preliminary interfaces to other web resources.\n\n\nExperimentDB Installation\n=========================\n\nConfiguration\n-------------\nExperimentDB requires both a database and a webserver to be set up.  Ideally, the database should be hosted separately from the webserver and ExperimentDB installation, but this is not necessary, as both can be used from the same server.  If you are using a remote server for the database, it is best to set up a user for this database that can only be accessed from the webserver.  If you want to set up several installations (ie for different users or different laboratories), you need separate databases and ExperimentDB installations for each.  You will also need to set up the webserver with different addresses for each installation.\n\nSoftware Dependencies\n---------------------\n1. **ExperimentDB source code**.  Download from one of the following:  \n\n  a. http://github.com/davebridges/ExperimentDB/downloads for the current release\n  b. http://github.com/davebridges/ExperimentDB for the source code\n  c. from pypi by entering::\n\n      pip install experimentdb\n\nDownloading and/or unzipping will create a directory named ExperimentDB.  You can update to the newest revision at any time either using git or downloading and re-installing the newer version.  Changing or updating software versions will not alter any saved data, but you will have to update the localsettings.py file (described below).\n\n2. **Python**.  Requires Version 2.6, is not yet compatible with Python 3.0.  Download from Python_.\n3. **Django**.  Download from Django_.  This will be automatically installed if you installed experimentdb with pip.  This will be automatically installed if you installed experimentdb with pip.\n4. **Database software**.  Typically MySQL is used, but PostgreSQL, Oracle or SQLite can also be used.  You also need to install the python driver for this database (unless you are using SQLite, which is internal to Python 2.5+).  For more information see Instructions_.\n5. **Biopython Packages**.  Download and install from Biopython_. This will be automatically installed if you installed experimentdb with pip.\n6. **South**.  Install using pip (**pip install south**).  This will be automatically installed if you installed experimentdb with pip.\n7. **Django Ajax Select**.  Install using pip (**pip install django-ajax-selects**).  This will be automatically installed if you installed experimentdb with pip.\n8. **Python Imaging Library**.  Install using pip (**pip install pil**).  Available at PIL_.  This will be automatically installed if you installed experimentdb with pip.\n\n.. _Python: http://www.python.org/download\n.. _Django: http://www.djangoproject.com/download/\n.. _Instructions: http://docs.djangoproject.com/en/dev/topics/install/database-installation\n.. _Biopython: http://biopython.org\n.. _PIL: http://www.pythonware.com/products/pil/\n\nDatabase Setup\n--------------\n1. Create a new database.  You need to record the user, password, host and database name.  Refer to the database documentation for how to do this with a specific database engine.  If you are using SQLite3, you only need to set the engine and the database name.  It is recommended to use MySQL.\n2. Go to localsettings_empty.py and edit the settings::\n\n    ENGINE: 'mysql', 'postgresql_psycopg2' or 'sqlite3 depending on the database software used.\n    NAME: database name\n    USER: database user.  Unless using sqlite3\n    PASSWORD: database password.  Unless using sqlite3\n    HOST: database host.\n\n3. Save this file as localsettings.py in the main ExperimentDB directory.\n4. Run the test client by going into the experimentdb directory and running the following.  There should be no errors at this point::\n\n    python manage.py test\n\t \n5. Generate the initial database tables by entering::\n\n    python manage.py syncdb\n\n6. When asked generate an administrative superuser and set the email and password.\n\nWeb Server Setup\n----------------\nYou need to set up a server to serve both the django installation and saved files.  For the saved files.  I recommend using apache for both.  The preferred setup is to use Apache2 with mod\\_wsgi.  The following is a httpd.conf example where the code is placed in /usr/src/django/experimentdb::\n\n    Alias /static /usr/src/django/experimentdb/media\n    Alias /media /usr/src/django/experimentdb/media\n    \n\t<Directory /usr/src/django/experimentdb/media>\n        Order allow,deny\n        Allow from all\n    </Directory>\n\n    WSGIScriptAlias /experimentdb /usr/src/django/experimentdb/apache/django.wsgi\n\n    <Directory /usr/src/django/experimentdb/apache>\n        Order deny,allow\n        Allow from all\n    </Directory>\n\nIf you want to restrict access to these files, change the Allow from all directive to specific domains or ip addresses (for example Allow from 192.168.0.0/99 would allow from 192.168.0.0 to 192.168.0.99)\n\nFinal Configuration and User Setup\n----------------------------------\n1. Go to experimentdb/admin/auth/users/ and create users, selecting usernames, full names, password (or have the user set the password) and then choose group permissions."}}, {"pk": 462, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "yt", "license": "GPL-3", "author": "Matthew J. Turk", "author_email": "matthewturk@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://yt.enzotools.org/", "version": "2.0.1", "platform": "UNKNOWN", "keywords": "astronomy astrophysics visualization amr adaptivemeshrefinement", "summary": "An analysis and visualization toolkit for Astrophysical simulations, focusing on Adaptive Mesh Refinement data from Enzo, Orion, FLASH, and others.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: AIX\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization", "description": "UNKNOWN"}}, {"pk": 463, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "FuncDesigner", "license": "new BSD", "author": "('Dmitrey Kroshko',)", "author_email": "dmitrey-at-openopt-dot-org", "project_url": null, "maintainer_email": null, "home_page": "http://openopt.org", "version": "0.33", "platform": "UNKNOWN", "keywords": null, "summary": "A python module for function design and automatic derivatives", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": ""}}, {"pk": 464, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "trustlet", "license": "GPL", "author": "Kasper Souren, Paolo Massa and others", "author_email": "kasper.souren@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://trustlet.org/wiki/Code", "version": "0.1.1", "platform": "any", "keywords": null, "summary": "Analyse trust metrics on social networks", "classifiers": "Development Status :: 2 - Pre-Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "trustlet\n========\n\n   trustlet is a Python package for the study of trust metrics on\n   social networks.  As of October 2007 it is in alpha stage, with\n   support for several Advogato-like datasets and a bunch of trust\n   metrics.\n\n   http://trustlet.org/\n\nUsing \n-----\n\n   >>> from trustlet import *\n   >>> G=Advogato()\n   >>> G.add_edge(1,2)\n   >>> G.add_node(\"spam\")\n   >>> print G.nodes()\n   [1, 2, 'spam']\n   >>> print G.edges()\n   [(1, 2)]"}}, {"pk": 465, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "TraitsBackendWX", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/traits_gui", "version": "3.6.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "WxPython backend for Traits and TraitsGUI (Pyface).", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The TraitsBackendWX project contains an implementation of TraitsGUI using\nwxPython. It provides wx-based support for visualization and editing of\nTraits-based objects.\n\nPrerequisite\n------------\nYou must have the following libraries installed before building or installing\nTraitsBackendWX:\n\n* `wxPython <http://www.wxpython.org/>`_ version 2.8 or later\n* `setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 466, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "neurolab", "license": "LGPL-3", "author": "Zuev Evgenij", "author_email": "zueves@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/neurolab", "version": "0.0.6", "platform": "Any", "keywords": "neural network,neural networks,neural nets,backpropagation,python,matlab,numpy,machine learning", "summary": "Simple and powerfull neural network library for python", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "\ufeff************\nIntroduction\n************\n\nNeuroLab - a library of basic nueral networks algorithms with flexible network configurations and learning algorithms.\nTo simplify the using of the library, interface is similar to the package of Neural Network Toolbox (NNT) of MATLAB (c).\nThe library is based on the package numpy (http://numpy.scipy.org), some learning algorithms are used scipy.optymyze (http://scipy.org).\n\n:Create network:\n\t>>> import neurolab as nl\n\t>>> # create feed forward multilayer perceptron\n\t>>> net = nl.net.newff([[0, 0.5], [0, 0.5]], [3,1])\n\nCreated two-layer network(3-1) with 2-inputs and one output.\nInput layer contains 3 neurons, the output 1 neuron.\nInput range: 0.0, 0.5\n\n:Train:\n\t>>> # Create learning samples\n\t>>> input = [[0.1, 0.1], \n\t...          [0.1, 0.2], \n\t...          [0.1, 0.3], \n\t...          [0.1, 0.4], \n\t...          [0.2, 0.2], \n\t...          [0.2, 0.3], \n\t...          [0.2, 0.4], \n\t...          [0.3, 0.3], \n\t...          [0.3, 0.4], \n\t...          [0.4, 0.4]]\n\t>>> \n\t>>> target = [[i[0] + i[1]] for i in input]\n\t>>> # Train\n\t>>> error = net.train(input, target, epochs=500, goal=0.1)\n\n:Train error:\n\t>>> print \"Finish error:\", error[-1]\n\tFinish error: 0.125232586274\n\n:Simulate:\n\t>>> net.sim([[0.1, 0.5], [0.3, 0. 1]])\n\tarray([[ 0.59650825],\n           [ 0.41686071]])\n\n:Network Info:\n\t>>> # Number of network inputs:\n\t>>> net.ci\n\t2\n\t>>> # Number of network outputs:\n\t>>> net.co\n\t1\n\t>>> # Number of network layers:\n\t>>> len(net.layers)\n\t2\n\t>>> # Weight of first neuron of input layer (net.layers[0])\n\t>>> net.layers[0].np['w'][1]\n\tarray([-0.67211163, -0.87277918])\n\t>>> \n\t>>> # Bias output layer:\n\t>>> net.layers[-1].np['b']\n\tarray([-0.69717423])\n\t>>> # Train params\n\t>>> net.train.defaults\n\t{'goal': 0.01, \n\t 'show': 100, \n\t 'epochs': 1000, \n\t 'lr': 0.01, \n\t 'adapt': False, \n\t 'errorf': <neurolab.error.SSE instance at 0x03757EB8>}\n\t\n\n:Save/Load:\n\t>>> net.save('sum.net')\n\t>>> newnet = nl.load('sum.net')\n\n:Change train function:\n\t>>> net.trainf = nl.train.TrainCG()\n\t>>> # Change error function:\n\t>>> net.trainf.defaunts['trainf'] = nl.error.SAE()\n\n:Change transfer function on output layer:\n\t>>> net.layers[-1].transf = nl.trans.HardLim()"}}, {"pk": 467, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PyTOPKAPI", "license": "BSD", "author": "Theo Vischel & Scott Sinclair", "author_email": "theo.vischel@hmg.inpg.fr; sinclaird@ukzn.ac.za", "project_url": null, "maintainer_email": "", "home_page": "http://sahg.github.com/PyTOPKAPI", "version": "0.2.0", "platform": "UNKNOWN", "keywords": "", "summary": "TOPKAPI hydrological model in Python", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "PyTOPKAPI - a Python implementation of the TOPKAPI Hydrological model\r\n=====================================================================\r\n\r\nPyTOPKAPI is a BSD licensed Python library implementing the TOPKAPI\r\nHydrological model (Liu and Todini, 2002). The model is a\r\nphysically-based and fully distributed hydrological model, which has\r\nalready been successfully applied in several countries around the\r\nworld (Liu and Todini, 2002; Bartholomes and Todini, 2005; Liu et al.,\r\n2005; Martina et al., 2006; Vischel et al., 2008; Sinclair and Pegram, 2010)."}}, {"pk": 468, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.wav", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.7", "platform": "OS Independent", "keywords": "ObsPy,seismology,seismogram,WAV", "summary": "WAV(audio) read and write support for ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.wav package contains methods in order to read and write seismogram\nfiles in the WAV(audio) format. The data are squeezed to audible frequencies.\n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology. \n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 469, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.imaging", "license": "GNU General Public License (GPL)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.6", "platform": "OS Independent", "keywords": "ObsPy,seismology,imaging,beachball,focal mechanism,waveform,spectogram", "summary": "Provides tools for displaying features used in seismology.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "obspy.imaging - Provides tools for displaying features used in seismology\n\n    For more information visit http://www.obspy.org."}}, {"pk": 470, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "geopy", "license": "MIT", "author": "Brian Beck", "author_email": "exogen@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.geopy.org/", "version": "0.94.1", "platform": "UNKNOWN", "keywords": "geocode geocoding gis geographical maps earth distance", "summary": "Python Geocoding Toolbox", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 471, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Scapy", "license": "GPL", "author": "Philippe Biondi", "author_email": "biondi@cartel-securite.fr", "project_url": null, "maintainer_email": null, "home_page": "http://www.cartel-securite.fr/pbiondi/scapy.html", "version": "0.9.12beta", "platform": "posix", "keywords": "packet manipulation mangle assembly disassembly dissection forge build sniff OS fingerprinting scanning arping etherleak icmpleak traceroute p0f tcpdump irpas hping nmap", "summary": "Interactive packet manipulation tool", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Education :: Testing\nTopic :: Internet\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Security\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Software Development :: Testing\nTopic :: Software Development :: Testing :: Traffic Generation\nTopic :: System\nTopic :: System :: Networking\nTopic :: System :: Networking :: Firewalls\nTopic :: System :: Networking :: Monitoring", "description": null}}, {"pk": 472, "model": "importing.pypicache", "fields": {"maintainer": "Jeff Whitaker", "name": "NAGpy", "license": "OSI Approved", "author": "Jeff Whitaker", "author_email": "Jeffrey.S.Whitaker@noaa.gov", "project_url": null, "maintainer_email": "Jeffrey.S.Whitaker@noaa.gov", "home_page": "http://www.cdc.noaa.gov/people/jeffrey.s.whitaker/python/nagpy", "version": "0.1", "platform": null, "keywords": "math, numeric, scientific", "summary": "Python interface to NAG math library", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nOperating System :: POSIX\nProgramming Language :: Fortran\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "Python wrappers for commerical Numerical Algorithms Group (NAG) f77 math library."}}, {"pk": 473, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyopencl", "license": "MIT", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/pyopencl", "version": "0.92", "platform": "UNKNOWN", "keywords": null, "summary": "Python wrapper for OpenCL", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Apache Software License\nNatural Language :: English\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics", "description": "PyOpenCL lets you access GPUs and other massively parallel compute\n            devices from Python. It tries to offer computing goodness in the\n            spirit of its sister project `PyCUDA <http://mathema.tician.de/software/pycuda>`_:\n\n            * Object cleanup tied to lifetime of objects. This idiom, often\n              called\n              `RAII <http://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization>`_\n              in C++, makes it much easier to write correct, leak- and\n              crash-free code.\n\n            * Completeness. PyOpenCL puts the full power of OpenCL's API at\n              your disposal, if you wish.  Every obscure `get_info()` query and \n              all CL calls are accessible.\n\n            * Automatic Error Checking. All CL errors are automatically\n              translated into Python exceptions.\n\n            * Speed. PyOpenCL's base layer is written in C++, so all the niceties\n              above are virtually free.\n\n            * Helpful and complete `Documentation <http://documen.tician.de/pyopencl>`_\n              as well as a `Wiki <http://wiki.tiker.net/PyOpenCL>`_.\n\n            * Liberal license. PyOpenCL is open-source under the \n              `MIT license <http://en.wikipedia.org/wiki/MIT_License>`_\n              and free for commercial, academic, and private use.\n\n            * Broad support. PyOpenCL was tested and works with Apple's, AMD's, and Nvidia's \n              CL implementations."}}, {"pk": 474, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Pydap", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/", "version": "3.0.rc.15", "platform": "UNKNOWN", "keywords": "opendap dods dap data science climate oceanography meteorology", "summary": "Pure Python Opendap/DODS client and server.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. You can use Pydap to access scientific data on the internet\nwithout having to download it; instead, you work with special array\nand iterable objects that download data on-the-fly as necessary, saving\nbandwidth and time. The module also comes with a robust-but-lightweight\nOpendap server, implemented as a WSGI application."}}, {"pk": 475, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pytools", "license": "MIT", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/pytools", "version": "2011.2", "platform": "UNKNOWN", "keywords": null, "summary": "A collection of tools for Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries\nTopic :: Utilities", "description": "Pytools is a big bag of things that are \"missing\" from the Python standard\n      library. This is mainly a dependency of my other software packages, and is\n      probably of little interest to you unless you use those. If you're curious\n      nonetheless, here's what's on offer:\n\n      * A ton of small tool functions such as `len_iterable`, `argmin`, \n        tuple generation, permutation generation, ASCII table pretty printing,\n        GvR's mokeypatch_xxx() hack, the elusive `flatten`, and much more.\n      * Michele Simionato's decorator module\n      * A time-series logging module, `pytools.log`.\n      * Batch job submission, `pytools.batchjob`.\n      * A lexer, `pytools.lex`."}}, {"pk": 476, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.responses.matlab", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/responses.html#matlab", "version": "0.1.2", "platform": "UNKNOWN", "keywords": "matlab opendap dods dap data science climate oceanography meteorology", "summary": "Matlab response for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This response enables Pydap to serve data as Matlab files."}}, {"pk": 477, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "geolucidate", "license": "MIT", "author": "Kurt Raschke", "author_email": "kurt@kurtraschke.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/kurtraschke/geolucidate", "version": "0.2", "platform": "UNKNOWN", "keywords": null, "summary": "Turn coordinates in text into links.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering :: GIS\nTopic :: Text Processing :: Filters\nTopic :: Text Processing :: Markup :: HTML", "description": "UNKNOWN"}}, {"pk": 478, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "quaternionarray", "license": "GPL3", "author": "Andrea Zonca", "author_email": "code@andreazonca.com", "project_url": null, "maintainer_email": null, "home_page": "http://andreazonca.com/software/quaternion-array/", "version": "0.6.1", "platform": "UNKNOWN", "keywords": "quaternion,nlerp,rotate", "summary": "Python package for fast quaternion arrays math", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Office/Business\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 479, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "fortranformat", "license": "UNKNOWN", "author": "Brendan Arnold", "author_email": "brendanarnold@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/brendanarnold/py-fortranformat", "version": "0.1.2", "platform": "UNKNOWN", "keywords": "fortran,io,interface,format", "summary": "Mimics Fortran textual IO in Python", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Fortran\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Interpreters\nTopic :: Text Processing :: General", "description": "FORTRAN format interpreter for Python\n    -------------------------------------    \n\n    Generates text from some Python variables or will read a line of\n    text into Python variables according to the format statement passed"}}, {"pk": 480, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "hl7", "license": "BSD", "author": "John Paulett", "author_email": "john -at- 7oars.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.bitbucket.org/johnpaulett/python-hl7/wiki/Home", "version": "0.1.1", "platform": "POSIX,Windows", "keywords": "HL7,Health Level 7,healthcare,health care,medical record", "summary": "Python library parsing HL7 v2.x messages", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Healthcare Industry\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nTopic :: Communications\nTopic :: Scientific/Engineering :: Medical Science Apps.\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Simple library for parsing messages of Health Level 7 (HL7)\nversion 2.x. \n\nHL7 is a communication protocol and message format for \nhealth care data. It is the de facto standard for transmitting data\nbetween clinical information systems and between clinical devices.\nThe version 2.x series, which is often is a pipe delimited format\nis currently the most widely accepted version of HL7 (version 3.0\nis an XML-based format).\n\npython-hl7 currently only parses HL7 version 2.x messages into\nan easy to access data structure. The current implementation\ndoes not completely follow the HL7 specification, but is good enough\nto parse the most commonly seen HL7 messages. The library could \npotentially evolve into being fully complainant with the spec.\nThe library could eventually also contain the ability to create\nHL7 v2.x messages.\n\npython-hl7 parses HL7 into a series of wrapped hl7.Container objects.\nThe there are specific subclasses of hl7.Container depending on\nthe part of the HL7 message. The hl7.Container message itself\nis a subclass of a Python list, thus we can easily access the\nHL7 message as an n-dimensional list. Specically, the subclasses of\nhl7.Container, in order, are hl7.Message, hl7.Segment, and hl7.Field.\nEventually additional containers will be added to fully support\nthe HL7 specification.\n\nAs an example, let's create a HL7 message:\n\n>>> message = 'MSH|^~\\&|GHH LAB|ELAB-3|GHH OE|BLDG4|200202150930||ORU^R01|CNTRL-3456|P|2.4\r'\n>>> message += 'PID|||555-44-4444||EVERYWOMAN^EVE^E^^^^L|JONES|196203520|F|||153 FERNWOOD DR.^^STATESVILLE^OH^35292||(206)3345232|(206)752-121||||AC555444444||67-A4335^OH^20030520\r'\n>>> message += 'OBR|1|845439^GHH OE|1045813^GHH LAB|1554-5^GLUCOSE|||200202150730||||||||555-55-5555^PRIMARY^PATRICIA P^^^^MD^^LEVEL SEVEN HEALTHCARE, INC.|||||||||F||||||444-44-4444^HIPPOCRATES^HOWARD H^^^^MD\r'\n>>> message += 'OBX|1|SN|1554-5^GLUCOSE^POST 12H CFST:MCNC:PT:SER/PLAS:QN||^182|mg/dl|70_105|H|||F\r'\n\nWe call the `hl7.parse()` command with string message:\n\n>>> h = parse(message)\n\nWe get a hl7.Message object, wrapping a series of hl7.Segment\nobjects.\n\n>>> type(h)\n<class 'hl7.Message'>\n\nWe can always get the HL7 message back.\n\n>>> str(h) == message.strip()\nTrue\n\nInterestingly, this hl7.Message can be accessed as a list.\n\n>>> isinstance(h, list)\nTrue\n\nThere were 4 segments (MSH, PID, OBR, OBX):\n\n>>> len(h)\n4\n\nWe can extract the hl7.Segment from the hl7.Message instance.\n\n>>> h[3]\n[['OBX'], ['1'], ['SN'], ['1554-5', 'GLUCOSE', 'POST 12H CFST:MCNC:PT:SER/PLAS:QN'], [''], ['', '182'], ['mg/dl'], ['70_105'], ['H'], [''], [''], ['F']]\n\nWe can easily reconstitute this segment as HL7, using the\nappopriate separators.\n\n>>> str(h[3])\n'OBX|1|SN|1554-5^GLUCOSE^POST 12H CFST:MCNC:PT:SER/PLAS:QN||^182|mg/dl|70_105|H|||F'\n\nWe can extract individual elements of the message:\n\n>>> h[3][3][1]\n'GLUCOSE'\n>>> h[3][5][1]\n'182'\n\nWe can look up segments by the segment identifer:\n\n>>> pid = segment('PID', h)\n>>> pid[3][0]\n'555-44-4444'\n\n\nProject site: http://www.bitbucket.org/johnpaulett/python-hl7/wiki/Home\n\nHL7 References:\n * http://en.wikipedia.org/wiki/HL7\n * http://nule.org/wp/?page_id=99\n * http://www.hl7.org/\n * http://openmrs.org/wiki/HL7\n * http://comstock-software.com/blogs/ifaces/2007/01/hl7-message-wrappers.html"}}, {"pk": 481, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "genSpline", "license": "MIT License", "author": "Martin Laprise", "author_email": "martin.laprise.1@ulaval.ca", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/mlaprise/genSpline", "version": "0.1", "platform": "UNKNOWN", "keywords": "python genetic spline optimization", "summary": "Spline-based genetic optimization class", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "genSpline - Spline-based genetic optimization class\n===================================================\n\n\nRequirements\n---------------------------------------------------\n\n\nInstallation\n---------------------------------------------------"}}, {"pk": 482, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gmailpm", "license": "UNKNOWN", "author": "Wolfgang Lechner", "author_email": "wolfgang.lechner@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://homepage.univie.ac.at/wolfgang.lechner/gmailpm.html", "version": "0.0.3", "platform": "UNKNOWN", "keywords": "project,monitoring,scientific,gmail", "summary": "Project Monitoring based on GMail", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Other Environment\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Communications :: Email\nTopic :: Documentation\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Documentation\nTopic :: System :: Monitoring", "description": "gmailpm allows you to monitor the progress of extended applications using gmail.\n\n    Tutorial:\n\thttp://homepage.univie.ac.at/wolfgang.lechner/gmailpm.html\n   \n    Description:\n    1. Create a TGmailProjectMonitoring object\n\n       import gmailpm.gmailpm as gpm\n       pm = gpm.TGmailProjectMonitoring(emailAddress=\"youremailaddress@gmail.com\", emailPassword=\"yourpassword\",projectName=\"TestProject\")\n\n       Note, that the class TGmailProjectMonitoring requires 3 arguments, your emailaddress, your password and a discription of the job.\n       \n            \n    2. At the beginning of your code send a Mail to your gmail account with senStaretedMessage\n       \n       pm.sendStartMessage()\n\n       sendStartMessage without arguments sends a message with the projectname as subject and hostname and current directory as body. You can\n       override the body text with the optional argument info (eg. pm.sendStartMessage(info=\"started\nat CLUSTER:./mydir\") )\n       \n    3. In order to protocoll your progress you can send a progress message with\n    \n       pm.sendProgressMessage(\"After %d Steps: Avg=123456.7890\" % (i,))\n\n\n    Example:\n    if __name__==\"__main__\":\n        project = \"TestProject\"\n        pm = TGmailProjectMonitoring(emailAddress=\"test.test@gmail.com\",emailPassword=\"password\",projectName=project)\n        pm.sendStartMessage(info=\"startedat CLUSTER:./mydir\")\n        pm.sendProgressMessage(\"Progress 50%\")\n        pm.sendProgressMessage(\"Finished\")"}}, {"pk": 483, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "guidata", "license": "CECILL", "author": "Pierre Raybaut", "author_email": "pierre.raybaut@cea.fr", "project_url": null, "maintainer_email": "", "home_page": "http://guidata.googlecode.com", "version": "1.2.5", "platform": "UNKNOWN", "keywords": "", "summary": "dataset manipulation GUI generator", "classifiers": "Development Status :: 5 - Production/Stable\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering", "description": "Based on the Qt Python binding module PyQt4, guidata is a Python library generating graphical user interfaces for easy dataset editing and display. It also provides helpers and application development tools for PyQt4."}}, {"pk": 484, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "python-sbigudrv", "license": "Apache License 2.0", "author": "Paulo Henrique Silva", "author_email": "ph.silva@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/python-sbigudrv", "version": "0.5", "platform": "UNKNOWN", "keywords": null, "summary": "Python wrappers for SBIG (tm) Universal Driver", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Apache Software License\nNatural Language :: English\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Python wrappers for SBIG (tm) Universal Driver\n==============================================\n\nThis is a Python wrapper to SBIG (tm) Universal Driver libraries for\nLinux.\n\nThe installation is easily done using setuptools easy_install script,\nwhich will check the required Python packages and install install any\nif necessary.\n\n``easy_install python-sbigudrv``\n\nTo install this package you will need:\n\n`Numpy`_ >= 1.0.3.\n\n`SWIG`_ (optionally, but recommended). Only if you need to regenerate the included\npre-generated wrapper.\n\n`libusb`_. It's widely available. It works with the stable (0.1) version, not the new in\ndevelopment 1.0.\n\nYou'll also need Python developer package.\n\nOn Ubuntu, use the following to install all dependencies:\n\n``sudo apt-get install python-dev python-numpy swig libusb-dev``\n\n.. _Numpy: http://numpy.scipy.org\n.. _SWIG: http://www.swig.org\n.. _libusb: http://libusb.sourceforge.net\n\nAuthor\n------\n\nPaulo Henrique Silva <ph.silva@gmail.com>, `Astrophysics Group`_,\n`Universidade Federal de Santa Catarina`_.\n\n.. _Astrophysics Group: http://www.astro.ufsc.br\n.. _Universidade Federal de Santa Catarina: http://www.ufsc.br\n\n\nLICENSE\n=======\n\nCopyright 2008 Paulo Henrique Silva <ph.silva@gmail.com>\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\nDISCLAIMER\n==========\n\nThis is project is not sponsored or endorsed by Santa Barbara\nInstrument Group, Inc.\n\nThis package contains the original SBIG (tm) libraries for Linux\nkindly packaged by `Jan Soldan`_, Astronomical Institute, Ondrejov,\nCzech Republic.\n\n.. _Jan Soldan: http://pleione.asu.cas.cz/~soldan/software/software.html"}}, {"pk": 485, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "datarray", "license": "Simplified BSD", "author": "Numpy Developers", "author_email": "numpy-discussion@scipy.org", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/fperez/datarray", "version": "0.0.6", "platform": "OS Independent", "keywords": null, "summary": "NumPy arrays with named axes and named indices.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "========================================\n Datarray: Numpy arrays with named axes\n========================================\n\nScientists, engineers, mathematicians and statisticians don't just work with\nmatrices; they often work with structured data, just like you'd find in a\ntable. However, functionality for this is missing from Numpy, and there are\nefforts to create something to fill the void.  This is one of those efforts.\n\n.. warning::\n\n   This code is currently experimental, and its API *will* change!  It is meant\n   to be a place for the community to understand and develop the right\n   semantics and have a prototype implementation that will ultimately\n   (hopefully) be folded back into Numpy.\n\nDatarray provides a subclass of Numpy ndarrays that support:\n\n- individual dimensions (axes) being labeled with meaningful descriptions\n- labeled 'ticks' along each axis\n- indexing and slicing by named axis\n- indexing on any axis with the tick labels instead of only integers\n- reduction operations (like .sum, .mean, etc) support named axis arguments\n  instead of only integer indices.\n\nPrior Art\n=========\n\nAt present, there is no accepted standard solution to dealing with tabular data\nsuch as this. However, based on the following list of ad-hoc and proposal-level\nimplementations of something such as this, there is *definitely* a demand for\nit.  For examples, in no particular order:\n\n* [Tabular](http://bitbucket.org/elaine/tabular/src) implements a\n  spreadsheet-inspired datatype, with rows/columns, csv/etc. IO, and fancy\n  tabular operations.\n\n* [scikits.statsmodels](http://scikits.appspot.com/statsmodels) sounded as\n  though it had some features we'd like to eventually see implemented on top of\n  something such as datarray, and [Skipper](http://scipystats.blogspot.com/)\n  seemed pretty interested in something like this himself.\n\n* [scikits.timeseries](http://scikits.appspot.com/timeseries) also has a\n  time-series-specific object that's somewhat reminiscent of labeled arrays.\n\n* [pandas](http://pandas.sourceforge.net/) is based around a number of\n  DataFrame-esque datatypes.\n\n* [pydataframe](http://code.google.com/p/pydataframe/) is supposed to be a\n  clone of R's data.frame.\n\n* [larry](http://github.com/kwgoodman/la), or \"labeled array,\" often comes up\n  in discussions alongside pandas.\n\n* [divisi](http://github.com/commonsense/divisi2) includes labeled sparse and\n  dense arrays.\n\nProject Goals\n=============\n\n1. Get something akin to this in the numpy core.\n\n2. Stick to basic functionality such that projects like scikits.statsmodels and\npandas can use it as a base datatype.\n\n3. Make an interface that allows for simple, pretty manipulation that doesn't\nintroduce confusion.\n\n4. Oh, and make sure that the base numpy array is still accessible.\n\n  \nCode\n====\n\nYou can find our sources and single-click downloads:\n\n* `Main repository`_ on Github.\n* Documentation_ for all releases and current development tree.\n* Download as a tar/zip file the `current trunk`_.\n* Downloads of all `available releases`_.\n\n.. _main repository: http://github.com/fperez/datarray\n.. _Documentation: http://fperez.github.com/datarray-doc\n.. _current trunk: http://github.com/fperez/datarray/archives/master\n.. _available releases: http://github.com/fperez/datarray/downloads"}}, {"pk": 486, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pypol", "license": "MIT", "author": "Stefano Roberto Soleti", "author_email": "robiweb90@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pypol.sourceforge.net", "version": "0.5", "platform": "", "keywords": "pypol mathematics monomial polynomial", "summary": "A 100 percent pure Python module to manage monomials and polynomial", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries", "description": ""}}, {"pk": 487, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "TileCache", "license": "BSD", "author": "TileCache Contributors", "author_email": "tilecache@lists.osgeo.org", "project_url": null, "maintainer_email": null, "home_page": "http://tilecache.org/", "version": "2.11", "platform": "UNKNOWN", "keywords": null, "summary": "a web map tile caching system", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "=================\n Getting Started\n=================\n\n-------------------------\nCache and serve map tiles\n-------------------------\n\n:Author: labs@metacarta.com\n:Copyright: (c) 2006-2010 TileCache Contributors\n            Distributed under the BSD license.\n:Version: 2.11 \n:Manual section: 8\n:Manual group: GIS Utilities\n\nDescription\n===========\nTileCache is a BSD licensed tile caching mechanism.  The goal is to make it\neasy to set up a WMS or TMS frontend to any backend data services you might be\ninterested in, using a pluggable caching and rendering mechanism. \n\nTileCache was developed by MetaCarta Labs and released to the public under a\nBSD license.\n\nThe TileCache was designed as a companion to OpenLayers, the BSD licensed web\nmapping interface. If you are using TileCache with OpenLayers, please read the\nsection of this readme which describes how to do so. For additional help with\nsetting up TileCache for use with OpenLayers, please feel free to stop by\n#openlayers, on irc.freenode.net, or to send email to\ntilecache@openlayers.org. \n\nInstalling TileCache\n====================\n\nGenerally, installing TileCache is as simple as downloading a source\ndistribution and unpacking it. For installation systemwide, you can also use\nthe Python Package Index (aka pypi or Cheeseshop) to install TileCache. Simply\ntype easy_install TileCache. Once this is done, you will need to install the\nTileCache configuration file. A tool to do this is installed, called\ntilecache_install_config.py. A full installation likely looks like::\n  \n  $ sudo easy_install TileCache\n  ...\n  Installed\n  /usr/lib/python2.5/site-packages/TileCache-2.10-py2.5.egg\n  \n  $ sudo tilecache_install_config.py\n  Successfully copied file\n  /usr/lib/python2.5/site-packages/TileCache-2.10-py2.5.egg/TileCache/tilecache.cfg\n  to /etc/tilecache.cfg.\n  \nTileCache is also available as a Debian package from the TileCache homepage.\nThis Debian package is designed to install on Debian etch releases or later.\nThis Debian package should install on Ubuntu Feisty or Gutsy.  \n\nRunning Under CGI\n=================\n\n* Extract the code to some web directory (e.g. in /var/www).\n* Edit tilecache.cfg to point the DiskCache to the location you wish\n  to cache tiles, and the layers to point to the map file or WMS\n  server you wish to cache. On Debian, this file is in /etc/tilecache.cfg\n  by default.\n* Permit CGI execution in the TileCache directory.\n  For example, if TileCache is to be run with Apache, the\n  following must be added in your Apache configuration,   \n  where /var/www/tilecache is the directory resulting from\n  the code extraction. On Debian, this is typically /usr/lib/cgi-bin.\n  \n  ::\n\n    <Directory /var/www/tilecache>\n         AddHandler cgi-script .cgi\n         Options +ExecCGI\n    </Directory>\n\n* Visit:\n  \n  http://example.com/yourdir/tilecache.cgi?LAYERS=basic&SERVICE=WMS\n  &VERSION=1.1.1&REQUEST=GetMap&SRS=EPSG:4326&BBOX=-180,-90,0,90\n  &WIDTH=256&HEIGHT=256\n  \n* Or visit:\n\n  http://example.com/yourdir/tilecache.cgi/1.0.0/basic/0/0/0.png\n\n* If you see a tile you have set up your configuration correctly. Congrats!\n\nNon-standard Python Location\n----------------------------\nIf your Python is not at /usr/bin/python on your system, you will need to\nchange the first line of tilecache.cgi to reference the location of your Python\nbinary. A common example is:\n\n  ::\n\n     #!/usr/local/bin/python\n\nUnder Apache, you might see an error message like:\n\n  ::\n\n    [Wed Mar 14 19:55:30 2007] [error] [client 127.0.0.1] (2)No such file or \n      directory: exec of '/www/tilecache.cgi' failed\n\nto indicate this problem.\n\nYou can typically locate where Python is installed on your system via the\ncommand which python.\n\nWindows users: If you are using Windows, you should change the first line \nof tilecache.cgi to read:\n\n  ::\n\n    #!C:/Python/python.exe -u\n\nC:/Python should match the location Python is installed under on your \nsystem. In Python 2.5, this location is C:/Python25 by default.  \n\nRunning Under mod_python\n========================\n\n* Extract the code to some web directory (e.g. /var/www).\n* Edit tilecache.cfg to point the DiskCache to the location you wish\n  to cache tiles, and the layers to point to the map file or WMS\n  server you wish to cache\n* Add the following to your Apache configuration, under a <Directory> heading:\n  \n  ::\n  \n      AddHandler python-program .py\n      PythonHandler TileCache.Service \n      PythonOption TileCacheConfig /path/to/tilecache.cfg\n  \n* An example might look like:\n\n  ::\n  \n    <Directory /var/www/tilecache/>\n        AddHandler python-program .py\n        PythonHandler TileCache.Service \n        PythonOption TileCacheConfig /var/www/tilecache/tilecache.cfg\n    </Directory>\n  \n* In this example, /var/www/tilecache is the directory resulting from\n  the code extraction. If you've installed this from a Debian package, the\n  location of your .cfg file is probably /etc/tilecache.cfg.\n* Edit tilecache.cfg to point to the location of your 'Layers' directory,\n  as demonstrated inside the default tilecache.cfg.\n* Visit one of the URLs described above, replacing tilecache.cgi with \n  tilecache.py\n* If you see a tile you have set up your configuration correctly. Congrats!\n\nRunning Standalone under WSGI\n=============================\n\nTileCache as of version 1.4 comes with a standalone HTTP server which uses\nthe WSGI handler. This implementation depends on *Python Paste*, which can be\ndownloaded from:\n  \n  http://cheeseshop.python.org/pypi/Paste\n\nFor versions of Python earlier than 2.5, you will also need to install \nwsgiref:\n\n  http://cheeseshop.python.org/pypi/wsgiref\n\nOnce you have all the prerequisites installed, simply run:\n\n  ::\n  \n    python tilecache_http_server.py\n\nThis will start a webserver listening on port 8080, after which you should\nbe able to open:\n\n  ::\n  \n    http://hostname:8080/1.0.0/basic/0/0/0.png\n\nto see your first tile.\n\nRunning Under FastCGI\n=====================\n\nTileCache as of version 1.4 comes with a fastcgi implementation. In \norder to use this implementation, you will need to install flup, available\nfrom:\n  \n  http://trac.saddi.com/flup\n\nThis implementation also depends on Python Paste, which can be downloaded \nfrom:\n  \n  http://cheeseshop.python.org/pypi/Paste\n\nOnce you have done this, you can configure your fastcgi server to use\ntilecache.fcgi.\n\nConfiguring FastCGI is beyond the scope of this documentation.\n\nRunning Under IIS\n=================\n\nInstalling TileCache for use with IIS requires some additional configuration.\n\nA nice document for setting up TileCache on IIS is available from Vish's\nweblog: http://viswaug.wordpress.com/2008/02/03/setting-up-tilecache-on-iis/ .\n\nRunning Standalone with PasteScript and CherryPy\n================================================\n\nOne component of the CherryPy web framework is a pure Python, fast,\nHTTP/1.1-compliant, WSGI thread-pooled webserver.\nTo deploy Tilecache using this option you have to:\n\n * Install prerequisites:\n\n    easy_install PasteScript\n    easy_install CherryPy\n\n * Create a deployment config file specifying the http server and the\n   application with options.  The format of the configuration file is\n   documented here: http://pythonpaste.org/deploy/#the-config-file\n\nExample configuration file follows. Copy the lines into tc.ini, tweak\nthe tilecache_config variable, run paster serve tc.ini and enjoy at\nhttp://127.0.0.1:5000/tc\n\n::\n\n  [server:main]\n  #tested with Paste#http and PasteScript#wsgiutils, PasteScript#twisted\n  also possible after installing dependencies\n  use = egg:PasteScript#cherrypy\n  host = 127.0.0.1\n  port = 5000\n\n  [composite:main]\n  use = egg:Paste#urlmap\n  /tc = tilecache1\n\n  [app:tilecache1]\n  use = egg:TileCache\n  tilecache_config = tilecache.cfg\n  \nConfiguration\n=============\nTileCache is configured by a config file, defaulting to tilecache.cfg.\nThere are several parameters to control TileCache layers that are applicable\nto all layers:\n\n bbox\n     The bounding box of the Layer. The resolutions array defaults \n     to having resolutions which are equal to the bbox divided by\n     512 (two standard tiles).\n debug\n     Whether to send debug output to the error.log. Defaults to \"yes\",\n     can be set to \"no\"\n description\n     Layer description, used in some metadata responses. Default \n     is blank.\n extension\n     File extension of the layer. Used to request images from\n     WMS servers, as well as when writing cache files.\n layers\n     A string used to describe the layers. Typically passed directly\n     to the renderer. The WMSLayer sends this in the HTTP request,\n     and the MapServerLayer chooses which layer to render based on \n     this string. If no layer is provided, the layer name is used\n     to fill this property.\n levels\n     An integer, describing the number of 'zoom levels' or \n     scales to support. Overridden by resolutions, if passed.        \n mapfile\n     The absolute file location of a mapfile. Required for\n     MapServer and Mapnik layers. \n maxResolution\n     The maximum resolution. If this is set, a resolutions\n     array is automatically calculated up to a number of\n     levels controlled by the 'levels' option.\n metaTile\n     set to \"yes\" to turn on metaTiling. This will request larger\n     tiles, and split them up using the Python Imaging library.\n     Defaults to \"no\".\n metaBuffer\n     an integer number of pixels to request around the outside\n     of the rendered tile. This is good to combat edge effects\n     in various map renderers. Defaults to 10.\n metaSize\n     A comma seperated pair of integers, which is used to \n     determine how many tiles should be rendered when using\n     metaTiling. Default is 5,5.\n resolutions\n     Comma seperate list of resolutions you want the TileCache\n     instance to support.\n size\n    Comma seperated set of integers, describing the width/height\n    of the tiles. Defaults to 256,256 \n srs\n    String describing the SRS value. Default is \"EPSG:4326\"          \n type\n    The type of layer. Options are: WMSLayer, MapnikLayer, MapServerLayer,\n    ImageLayer\n url\n    URL to use when requesting images from a remote WMS server. Required\n    for WMSLayer.\n watermarkImage\n    The watermarkImage parameter is assigned on a per-layer basis.\n    This is a fully qualified path to an image you would like to apply to each\n    tile. We recommend you use a watermark image the same size as your tiles.\n    If using the default tile size, you should use a 256x256 image.\n    NOTE: Python Imaging Library DOES NOT support interlaced images.\n watermarkOpacity\n    The watermarkOpacity parameter is assigned on a per-layer basis.\n    This configures the opacity of the watermark over the tile, it is a floating\n    point number between 0 and 1. Usage is optional and will otherwise default.\n extent_type\n    Setting this to 'loose' will allow TileCache to generate tiles outside the\n    maximum bounding box. Useful for clients that don't know when to stop\n    asking for tiles.\n tms_type\n    Setting this to \"google\" will cause tiles to switch vertical order (that\n    is, following the Google style x/y pattern).\n\nUsing TileCache With OpenLayers\n===============================\n\nTo run OpenLayers with TileCache the URL passed to the OpenLayers.Layer.WMS\nconstructor must point to the TileCache script, i.e. tilecache.cgi or\ntilecache.py. As an example see the index.html file included in the TileCache\ndistribution.\n\nNote: index.html assumes TileCache is set up under CGI (see above). If you set\nup TileCache under mod_python you'd need to slighly modify index.html: the URL\npassed to the OpenLayers.Layer.WMS constructor must point to the mod_python\nscript as opposed to the CGI script, so replace tilecache.cgi with\ntilecache.py. Similarly, you would need to edit this URL if you were to use\nTileCache with the standalone HTTP Server or FastCGI.\n\nThe most important thing to do is to ensure that the OpenLayers Layer\nhas the same resolutions and bounding box as your TileCache layer. You can define\nthe resolutions in OpenLayers via the 'resolutions' option or the 'maxResolution' \noption on the layer. The maxExtent should be defined to match the bbox parameter\nof the TileCache layer. \n\nIf you are using TileCache for overlays, you should set the 'reproject' option\non the layer to 'false'.\n\nUsing TileCache With MapServer\n==============================\n\nMapServer has a map level metadata option, labelcache_map_edge_buffer, which\nis set automatically by TileCache to the metaBuffer plus five when metaTiling\nis on, if it is not set in the mapfile.\n\nIf you are using MetaTiling, be aware that MapServer generates interlaced\nPNG files, which PIL will not read. See \nhttp://www.mapserver.org/faq.html#why-doesn-t-pil-python-imaging-library-open-my-pngs on how to resolve this. \n\nUsing With Python-Mapscript\n===========================\n\nSeveral users have reported cases where large mapfiles combined with \npython-mapscript has caused memory leaks, which eventually lead to \nsegfaults. If you are having problems with Apache/TileCache segfaults\nwhen using python-mapscript, then you should switch to using a WMS\nLayer instead of a MapServer Layer.\n\nSeeding your TileCache\n======================\n\nThe tilecache_seed.py utility will seed tiles in a cache automatically. You will\nneed to have TileCache set up in one of the previously described configurations.\n\nUsage\n-----\n\n     tilecache_seed.py [options] <layer> [<zoom start> <zoom stop>]\n\nOptions\n-------\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit\n  -f, --force           force recreation of tiles even if they are already in\n                        cache\n  -b BBOX, --bbox=BBOX  restrict to specified bounding box\n  -p PADDING, --pading=PADDING\n                        extra margin tiles to seed around target area.\n                        Defaults to 0 (some edge tiles might be missing).\n                        A value of 1 ensures all tiles will be created, but\n                        some tiles may be wholly outside your bbox                        \n                        \nArguments\n---------\n\n    layer \n       same layer name that is in the tilecache.cfg\n    zoom start\n       Zoom level to start the process\n    zoom end\n       Zoom level to end the process\n\nSeeding by center point and radius\n----------------------------------\n \nIf called without zoom level arguments, tilecache_seed.py will assume\nthat it needs to read a list of points and radii from standard input, \nin the form:\n\n  ::\n  \n        <lat>,<lon>,<radius>\n        <lat>,<lon>,<radius> \n        <lat>,<lon>,<radius>\n        <lat>,<lon>,<radius>\n        <ctrl + d>\n\nThe format of this file is:\n\n  lon\n    the position(s) to seed longitude\n  lat\n    the position(s) to seed latitude\n  radius\n    the radius around the lon/lat to seed in degrees\n\nExamples\n--------\n\nAn example with zoom levels 5 through 12 and ~2 extra tiles around each zoom level would be like:\n\n    ::\n \n      $ tilecache_seed.py Zip_Codes 5 12 \"-118.12500,31.952162238,-116.015625,34.3071438563\" 2\n\nThe bbox can be dropped and defaults to world lonlat(-180,-90,180,90):\n\n    ::\n\n      $ tilecache_seed.py Zip_Codes 0 9\n \n\nIn center point/radius mode, the zoom level range is not specifiable from the\ncommand-line. An example usage might look like:\n\n     ::\n\n       $ tilecache_seed.py Zip_Codes\n       -118.12500,31.952162238,0.05\n       -121.46327,32.345345645,0.08\n       <Ctrl+D>\n\n... the seeding will then commence ...\n\nCleaning your TileCache\n=======================\n\nThe tilecache_clean.py utility will remove the least recently accessed\ntiles from a cache, down to a specified size.\n\nUsage\n-----\n    tilecache_clean.py [options] <cache_location>\n\nOptions\n-------\n    --version             show program's version number and exit\n    -h, --help            show this help message and exit\n    -s SIZE, --size=SIZE  Maximum cache size, in megabytes.\n    -e ENTRIES, --entries=ENTRIES\n                          Maximum cache entries. This limits the\n                          amount of memory that will be used to store\n                          information about tiles to remove.\n     \nNotes\n-----\nThe --entries option to tilecache_clean.py is optional, and is used to regulate\nhow much memory it uses to do its bookkeeping. The default value of 1 million\nwill hopefully keep RAM utilization under about 100M on a 32-bit x86 Linux\nmachine. If tilecache_clean.py doesn't appear to be keeping your disk cache\ndown to an appropriate size, try upping this value.\n\ntilecache_clean.py is designed to be run from a cronjob like so:\n\n  ::\n\n    00 05 * * *  /usr/local/bin/tilecache_clean.py -s500 /var/www/tilecache\n\nNote that, on non-POSIX operating systems (particularly Windows),\ntilecache_clean.py measures file sizes, and not disk usage. Because most\nfilesystems use entire file blocks for files smaller than a block, running du\n-s or similar on your disk cache after a cleaning may still return a total\ncache size larger than you expect.\n\nTroubleShooting\n===============\n\nOccasionally, for some reason, when using meta tiles, your server may leave\nbehind lock files. If this happens, there will be files in your cache directory\nwith the extension '.lck'. If you are seeing tiles not render and taking \nmultiple minutes before returning a 500 error, you may be suffering under\na stuck lock.\n\nRemoving all files with extension '.lck' from the cache directory will\nresolve this problem.\n\n\nSEE ALSO\n========\n\nmemcached(8)\n\nhttp://tilecache.org/\n\nhttp://openlayers.org/\n\nhttp://wiki.osgeo.org/index.php/WMS_Tiling_Client_Recommendation\n\nhttp://wiki.osgeo.org/index.php/Tile_Map_Service_Specification"}}, {"pk": 488, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "OpenElectrophy", "license": "CeciLL v2", "author": "Samuel Garcia, Nicolas Fourcaud-Trocme", "author_email": "sgarcia at olfac.univ-lyon1.fr", "project_url": null, "maintainer_email": null, "home_page": "http://neuralensemble.org/trac/OpenElectrophy", "version": "0.2.9", "platform": "UNKNOWN", "keywords": null, "summary": "OpenElectrophy : an electrophysiological data- and analysis-sharing framework", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "OpenElectrophy is a framework to facilitate storage, manipulation and analysis \nof electrophysiological data. It can import data from many different file formats \nand store them in a single SQL-type database.\n\nThe GUI have been design with a particular attention to provide fast and intuitive\nacces to data but OpenElectrophy is at the same time a base package to write\nnew analysis based on scripts.\n\nAnalysis tools included in OpenELectrophy are spike sorting and oscillation\ndetection. Further analysis have to be written but OpenElectrophy provides\na library of class and function which highly facilitates the querying of useful\ndata in the database and their manipulation. A full list of script examples\nare provided and can be simply modified to suit the need of any specific\ndata."}}, {"pk": 489, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyfuzzy", "license": "LGPL+", "author": "Rene Liebscher", "author_email": "R.Liebscher@gmx.de", "project_url": null, "maintainer_email": null, "home_page": "http://pyfuzzy.sourceforge.net", "version": "0.1.0", "platform": "OS Independent", "keywords": null, "summary": "pyfuzzy: Python Fuzzy Utilities", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "pyfuzzy is a python module for working with fuzzy sets \n(for example for controllers or other similar stuff, \nit can be also used for decision making in business.)"}}, {"pk": 490, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "parnasis", "license": "BSD", "author": "J. Brandon Keith", "author_email": "jbrkeith@gmail.edu", "project_url": null, "maintainer_email": null, "home_page": "http://docs.danse.us/inelastic/vsat/", "version": "0.3", "platform": "UNKNOWN", "keywords": "md simulations analysis scattering", "summary": "A toolkit for calculating scattering and dynamical information from phonons and molecular dynamics", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 491, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.scattpy", "license": "BSD", "author": "('Alexander Vinokurov',)", "author_email": "scattpy@googlegroups.com", "project_url": null, "maintainer_email": null, "home_page": "http://scattpy.github.com", "version": "0.1.1", "platform": "UNKNOWN", "keywords": null, "summary": "Light Scattering methods for Python", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics", "description": "ScattPy package.\n\nScattPy provides numerical methods for solving light scattering problem\nby non-spherical particles."}}, {"pk": 492, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "SimPy", "license": "GNU LGPL", "author": "Klaus Muller, Tony Vignaux", "author_email": "vignaux at user.sourceforge.net;kgmuller at users.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://SimPy.SourceForge.net", "version": "2.1.0", "platform": "UNKNOWN", "keywords": "simulation,discrete event simulation,process-oriented simulation", "summary": "Release 2.1.0 of SimPy simulation package", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "SimPy 2.1.0 is a major re-release of SimPy 2.0. It repairs\r\n        a number of errors in SimPy 2.0.1 libraries, models and documentation.\r\n        There has been significant code refactoring in Simulation.py,\r\n        SimulationStep.py, SimulationTrace.py, SimulationRT.py, and Lib.py.\r\n        This resulted in a significant reduction of code to be maintained.\r\n        \r\n        Documentation/tutorials on using the advanced OO API have been added.\r\n        \r\n        SimPy is a process-based discrete-event simulation language\r\n        based on standard Python and released under the GNU LGPL.\r\n        \r\n        It provides the modeller with components of a simulation\r\n        model. These include processes, for active components like\r\n        customers, messages, and vehicles, and resources, for\r\n        passive components that form limited capacity congestion\r\n        points like servers, checkout counters, and tunnels. It\r\n        also provides monitor variables to aid in gathering\r\n        statistics. SimPy comes with extensive plotting capabilities.\r\n        \r\n        The distribution contains in-depth documentation, tutorials,\r\n        and a large number of simulation models.\r\n        \r\n        Simulation model developers are encouraged to share their\r\n        SimPy modeling techniques with the SimPy community. Please\r\n        post a message to the simpy-Users mailing list,\r\n        \r\n        mailto:simpy-users at lists.sourceforge.net.\r\n        \r\n        Subscribe to simpy-users mailing list:\r\n        http://lists.sourceforge.net/lists/listinfo/simpy-users\r\n        \r\n        Software developers are also encouraged to interface SimPy with\r\n        other Python-accessible packages, such as GUI, data base or\r\n        mapping and to share these new capabilities with the\r\n        community under the GNU LGPL."}}, {"pk": 493, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "brian", "license": "UNKNOWN", "author": "Romain Brette, Dan Goodman", "author_email": "Romain.Brette at ens.fr", "project_url": null, "maintainer_email": null, "home_page": "http://www.briansimulator.org/", "version": "1.3.0", "platform": "UNKNOWN", "keywords": null, "summary": "A clock-driven simulator for spiking neural networks", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "Brian is a simulator for spiking neural networks available on almost all platforms.\nThe motivation for this project is that a simulator should not only save the time of\nprocessors, but also the time of scientists.\n\nBrian is easy to learn and use, highly flexible and easily extensible. The Brian package\nitself and simulations using it are all written in the Python programming language,\nwhich is an easy, concise and highly developed language with many advanced features and\ndevelopment tools, excellent documentation and a large community of users providing\nsupport and extension packages."}}, {"pk": 494, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "treedict", "license": "UNKNOWN", "author": "Hoyt Koepke", "author_email": "hoytak@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.stat.washington.edu/~hoytak/code/treedict/", "version": "0.12", "platform": "UNKNOWN", "keywords": null, "summary": "A fast and full-featured dict-like tree container to simplify the bookkeeping surrounding parameters, variables and data.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Cython\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 495, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scipy", "license": "BSD", "author": "SciPy Developers", "author_email": "scipy-dev@scipy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.scipy.org", "version": "0.9.0", "platform": "Windows,Linux,Solaris,Mac OS-X,Unix", "keywords": null, "summary": "SciPy: Scientific Library for Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "SciPy (pronounced \"Sigh Pie\") is open-source software for mathematics,\n        science, and engineering. The SciPy library\n        depends on NumPy, which provides convenient and fast N-dimensional\n        array manipulation. The SciPy library is built to work with NumPy\n        arrays, and provides many user-friendly and efficient numerical\n        routines such as routines for numerical integration and optimization.\n        Together, they run on all popular operating systems, are quick to\n        install, and are free of charge.  NumPy and SciPy are easy to use,\n        but powerful enough to be depended upon by some of the world's\n        leading scientists and engineers. If you need to manipulate\n        numbers on a computer and display or publish the results,\n        give SciPy a try!"}}, {"pk": 496, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.responses.json", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/responses/json", "version": "0.3", "platform": "UNKNOWN", "keywords": "json dap opendap dods data", "summary": "JSON response for pydap server", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "JSON representation of DAP datasets.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/responses/json#egg=dap.responses.json-dev>`_."}}, {"pk": 497, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pdsvex.profile", "license": "Proprietary", "author": "OODT Team", "author_email": "oodt-dev@list.jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://agility.jpl.nasa.gov/", "version": "1.0.0", "platform": "UNKNOWN", "keywords": "web zope plone jpl nasa caltech", "summary": "PDS VEX Profile Service content implementation", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Software Development :: Libraries :: Python Modules", "description": "PDS Venus Express Profile Service\n*********************************\n\nThis is the `profile service`_ for the Planetary Data System (PDS_) Venus\nExpress (VEX_) mission.  A profile server answers metadata queries for data.\nThis profile server looks up and responds to metadata for scientific and other\nmission data collected during VEX.\n\n\nInstallation\n============\n\nThis profile server is built using the Zope_ application framework and the\nPlone_ content management system.  To deploy this profile server, you can\ninclude this package in your buildout.  Alternatively, you can use the\n``pdsvex.policy`` package, which sets up a complete web site with the profile\nserver, online documentation, and other features.\n\n\nHow to Query\n============\n\nIf you're using the `Agile OODT`_ or the OODT_ query client_, use the\nfollowing string as your client's object key::\n\n    http://hostname:port/instance/prof\n    \nwhere\n\n*hostname*\n    is the name or IP address of the host where you deployed the server\n*port*\n    is the port number on which the server accepts HTTP requests\n*instance*\n    is the name of the Plone instance installed in the application server\n``prof``\n    is a fixed string ``prof`` that indicates acceptance of a profile query\n\nNote that it's common to shield the application server behind another web\nserver such as Apache HTTPD, NGINX, etc., which may rewrite URLs to omit one\nor more parts of the object key above.  Consult your system administrator.\n\n\n.. References:\n.. _Agile OODT: http://agility.jpl.nasa.gov/\n.. _client: http://oodt.jpl.nasa.gov/grid-query/\n.. _OODT: http://oodt.jpl.nasa.gov\n.. _PDS: http://pds.nasa.gov/\n.. _Plone: http://plone.org/\n.. _profile service: http://oodt.jpl.nasa.gov/grid-profile/\n.. _VEX: http://sci.esa.int/science-e/www/area/index.cfm?fareaid=64\n.. _Zope: http://zope.org/\n\n===========\n Changelog\n===========\n\n0.0.0 - Unreleased\n------------------\n\n* Initial release"}}, {"pk": 498, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.sparse", "license": "GPL", "author": "Nathaniel Smith", "author_email": "njs@pobox.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/scikits-sparse/", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Scikits sparse matrix package", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Scientific/Engineering", "description": "Sparse matrix tools.\n\nThis is a home for sparse matrix code in Python that plays well with\nscipy.sparse, but that is somehow unsuitable for inclusion in scipy\nproper. Usually this will be because it is released under the GPL.\n\nSo far we have a wrapper for the CHOLMOD library for sparse cholesky\ndecomposition. Further contributions are welcome!"}}, {"pk": 499, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "deap", "license": "LGPL", "author": "deap Development Team", "author_email": "deap-users@googlegroups.com", "project_url": null, "maintainer_email": "", "home_page": "http://deap.googlecode.com", "version": "0.6", "platform": "any", "keywords": "evolutionary algorithms, genetic algorithms, genetic programming, ga, gp, cma-es, es", "summary": "Distributed Evolutionary Algorithms in Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "EAP stands for Evolutionary Algorithm in Python, it is dedicated to people who\r\n        wish to learn how to use evolutionary algorithms and to those who wish to\r\n        rediscover evolutionary algorithms. EAP is the proof that evolutionary \r\n        algorithms do **not** need to be neither complex or complicated.\r\n        \r\n        EAP is part of the DEAP project, that also includes some facilities for the \r\n        automatic distribution and parallelization of tasks over a cluster of computers.\r\n        The D part of DEAP, called DTM, is under intense development and currently \r\n        available as an alpha version. DTM currently provides two and a half ways to \r\n        distribute work loads around a clusters or LAN of workstations, based MPI and \r\n        TCP communication managers."}}, {"pk": 500, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "winpdb", "license": "GPL", "author": "Nir Aides", "author_email": "nir@winpdb.org", "project_url": null, "maintainer_email": "", "home_page": "http://www.winpdb.org", "version": "1.4.8", "platform": "Platform Independent", "keywords": "debugger", "summary": "A platform independent GPL Python debugger.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications :: GTK\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Debuggers", "description": "Winpdb is a platform independent GPL Python debugger with support for multiple\r\nthreads, namespace modification, embedded debugging, encrypted communication and\r\nis up to 20 times faster than pdb."}}, {"pk": 501, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PyPDS", "license": "", "author": "Ryan Balfanz", "author_email": "ryan@ryanbalfanz.net", "project_url": null, "maintainer_email": "", "home_page": "http://github.com/RyanBalfanz/PyPDS", "version": "0.1", "platform": "", "keywords": "Planetary Data System, PDS, Astronomy", "summary": "PyPDS is a Python interface to Planetary Data System (PDS) data products", "classifiers": "Intended Audience :: Science/Research\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Utilities", "description": ""}}, {"pk": 502, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.excel", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.excel", "version": "3.0.5", "platform": "any", "keywords": "utility", "summary": "PyUtilib utilities that use Excel spreadsheets.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "=====================\npyutilib.excel README\n=====================\n\nThis Python package includes utilities that use Excel spreadsheets.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\n+ win32com"}}, {"pk": 503, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "taskjuggler_utils", "license": "PSF", "author": "Gustavo Sverzut Barbieri", "author_email": "barbieri@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://barbieri-playground.googlecode.com/svn/python/taskjuggler-utils/", "version": "0.1", "platform": "UNKNOWN", "keywords": "taskjuggler helper scripts tools project management gantt", "summary": "Tools to help use \"taskjuggler\" without its GUI and produce nice reports.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Information Technology\nLicense :: OSI Approved :: Python Software Foundation License\nProgramming Language :: Python\nTopic :: Office/Business :: Scheduling\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Text Processing :: Markup :: LaTeX", "description": "Tools to help use \"taskjuggler\" without its GUI and produce nice reports.\n\nThis package provides tools that will provide nice reports\n(taskjuggler-report), gantt charts (taskjuggler-gantt) and time shift\nthe whole taskjuggler project file (taskjuggler-timeshift).\n\nThe best thing is that you don't need to use Graphical User Interfaces\nfor that, so these can be automated from cron jobs, web servers and\nmakefiles.\n\nReports are generated using LaTeX syntax since I use them in my LaTeX\nfiles easily, but we can easily add code to generate HTML reports as\nwell in future."}}, {"pk": 504, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "swiginac", "license": "GNU General Public License", "author": "Ola Skavhaug", "author_email": "skavhaug@simula.no", "project_url": null, "maintainer_email": "", "home_page": "http://swiginac.berlios.de/", "version": "1.0.0", "platform": "posix", "keywords": "", "summary": "interface to GiNaC, providing Python with symbolic mathematics", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: POSIX\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "UNKNOWN"}}, {"pk": 505, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "vectorformats", "license": "BSD", "author": "MetaCarta Labs", "author_email": "labs@metacata.com", "project_url": null, "maintainer_email": null, "home_page": "http://featureserver.org/vectorformats/", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "geographic data serialization/deserialization library", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "This is a library for easy serialization and deserialization of geographic\nfeatures (geometries and properties) into various formats.\n\nFor more, see the doc/ subdirectory."}}, {"pk": 506, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pidsim-models", "license": "GPL-2", "author": "Rafael Goncalves Martins", "author_email": "rafael@rafaelmartins.eng.br", "project_url": null, "maintainer_email": null, "home_page": "http://pidsim.org/", "version": "0.2.1", "platform": "any", "keywords": null, "summary": "A set of reference models for PIDSIM", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "PIDSIM reference models package\n===============================\n\n.. warning::\n\n   This package just have the python modules, not any GUI.\n\nThis package implements a basic set of reference models for the simulation\nof PID controllers, using PIDSIM.\n\nIf you need some help with the use, or can help with the development,\nplease contact the author via email or visit our project website:\n\nhttp://pidsim.org/\n\nAll the help is welcome! :)\n\n\nBasic installation\n~~~~~~~~~~~~~~~~~~\n\nTo install, type::\n\n    # python setup.py install\n\nor use pip::\n\n    # pip install pidsim-models"}}, {"pk": 507, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.learn", "license": "new BSD", "author": "Fabian Pedregosa", "author_email": "fabian.pedregosa@inria.fr", "project_url": null, "maintainer_email": null, "home_page": "http://scikit-learn.sourceforge.net", "version": "0.7.1", "platform": "UNKNOWN", "keywords": null, "summary": "A set of python modules for machine learning and data mining", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": ".. -*- mode: rst -*-\n\nAbout\n=====\n\nscikits.learn is a python module for machine learning built on top of\nscipy.\n\nThe project was started in 2007 by David Cournapeau as a Google Summer\nof Code project, and since then many volunteers have contributed. See\nthe AUTHORS.rst file for a complete list of contributors.\n\nIt is currently maintained by a team of volunteers.\n\n\nDownload\n========\n\nYou can download source code and Windows binaries from SourceForge:\n\nhttp://sourceforge.net/projects/scikit-learn/files/\n\n\nDependencies\n============\n\nThe required dependencies to build the software are python >= 2.5,\nsetuptools, NumPy >= 1.2, SciPy >= 0.7 and a working C++ compiler.\n\nTo run the tests you will also need nose >= 0.10.\n\n\nInstall\n=======\n\nThis packages uses distutils, which is the default way of installing\npython modules. The install command is::\n\n  python setup.py install\n\n\nMailing list\n============\n\nThere's a general and development mailing list, visit\nhttps://lists.sourceforge.net/lists/listinfo/scikit-learn-general to\nsubscribe to the mailing list.\n\n\nIRC channel\n===========\n\nSome developers tend to hang around the channel ``#scikit-learn``\nat ``irc.freenode.net``, especially during the week preparing a new\nrelease. If nobody is available to answer your questions there don't\nhesitate to ask it on the mailing list to reach a wider audience.\n\n\nDevelopment\n===========\n\nCode\n----\n\nGIT\n~~~\n\nYou can check the latest sources with the command::\n\n    git clone git://github.com/scikit-learn/scikit-learn.git\n\nor if you have write privileges::\n\n    git clone git@github.com:scikit-learn/scikit-learn.git\n\nBugs\n----\n\nPlease submit bugs you might encounter, as well as patches and feature\nrequests to the tracker located at github\nhttps://github.com/scikit-learn/scikit-learn/issues\n\n\nTesting\n-------\n\nAfter installation, you can launch the test suite from outside the\nsource directory (you will need to have nosetest installed)::\n\n    python -c \"import scikits.learn as skl; skl.test()\"\n\nSee web page http://scikit-learn.sourceforge.net/install.html#testing\nfor more information."}}, {"pk": 508, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.example", "license": "MIT", "author": "David Cournapeau", "author_email": "david@ar.media.kyoto-u.ac.jp", "project_url": null, "maintainer_email": null, "home_page": "http://projects.scipy.org/scipy/scikits", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Scikits example package", "classifiers": "Development Status :: 1 - Planning\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": "Example package.\n        \n        This is a do nothing package, to show how to organize a scikit."}}, {"pk": 509, "model": "importing.pypicache", "fields": {"maintainer": "Erik Max Francis", "name": "BOTEC", "license": "GPL", "author": "Erik Max Francis", "author_email": "software@alcyone.com", "project_url": null, "maintainer_email": "software@alcyone.com", "home_page": "http://www.alcyone.com/botec/", "version": "0.3", "platform": "independent", "keywords": "physics, astronomy, astrophysics, orbital mechanics, course plotting, Hohmann transfer", "summary": "A simple astrophysics and orbital mechanics simulator", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "BOTEC is intended as a simple but useful calculator to assist with making\r\nastrophysical, orbital mechanics, and space navigation calculations. As the\r\norigin of the acronym applies, BOTEC is more of a \"back-of-the-envelope\r\ncalculator\" rather than an industrial-strength calculator, although this may\r\nchange in the future.\r\n\r\nBOTEC is primarily intended for people familiar with physics and Python, and as\r\nsuch is unlikely to be useful to the average enduser. BOTEC really consists of\r\ntwo parts: The BOTEC software, which knows what to do with the data, and the\r\nSolar System data itself, which is represented in a large data file (a Python\r\npickle, actually). This is deliberately modularized so that the Solar System\r\ndata BOTEC uses can be updated independently of thet software, and also that\r\nalternative data files (e.g., hypothetical stellar systems for fictional\r\npurposes) can be supported.\r\n\r\nAll values are strictly in SI units."}}, {"pk": 510, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyUblasExt", "license": "BSD", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/pyublas/pyublasext", "version": "0.92.4", "platform": "UNKNOWN", "keywords": null, "summary": "Added functionality for PyUblas", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Utilities", "description": "PyUblasExt is a companion to \n          `PyUblas <http://mathema.tician.de/software/pyublas>`_\n          and exposes a variety of useful additions to it:\n\n          * A cross-language \"operator\" class for building matrix-free algorithms\n          * CG and BiCGSTAB linear solvers that use this operator class\n          * An `ARPACK <http://mathema.tician.de/software/arpack>`_ interface that also uses this operator class\n          * An UMFPACK interface for PyUblas's sparse matrices\n          * An interface to the `DASKR <http://www.netlib.org/ode/>`_ ODE solver.\n\n          Please refer to the `PyUblas build documentation\n          <http://tiker.net/doc/pyublas>`_ for build instructions."}}, {"pk": 511, "model": "importing.pypicache", "fields": {"maintainer": "ms@cerenity.org", "name": "Kamaelia", "license": "MPL tri-license. (MPL1.1, GPL 2.0, LGPL 2.1)", "author": "Michael Sparks & Kamaelia Contributors", "author_email": "ms@cerenity.org", "project_url": null, "maintainer_email": "ms@cerenity.org", "home_page": "http://www.kamaelia.org/Home", "version": "0.6.0", "platform": "", "keywords": "Concurrency Components Networks Network Servers Clients Games OpenGL 3D Audio Video Dirac Vorbis Speex PVR DVB Freeview pymedia pygame whiteboarding", "summary": "Kamaelia - Multimedia & Server Development Kit", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: MacOS X\nEnvironment :: No Input/Output (Daemon)\nEnvironment :: Other Environment\nEnvironment :: Plugins\nEnvironment :: Web Environment\nEnvironment :: X11 Applications\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nLicense :: OSI Approved :: GNU General Public License (GPL)\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nLicense :: OSI Approved :: Mozilla Public License 1.1 (MPL 1.1)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Adaptive Technologies\nTopic :: Communications\nTopic :: Communications :: Conferencing\nTopic :: Communications :: Internet Phone\nTopic :: Education\nTopic :: Games/Entertainment\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics\nTopic :: Multimedia :: Graphics :: 3D Modeling\nTopic :: Multimedia :: Graphics :: 3D Rendering\nTopic :: Multimedia :: Graphics :: Presentation\nTopic :: Multimedia :: Graphics :: Viewers\nTopic :: Multimedia :: Sound/Audio\nTopic :: Multimedia :: Sound/Audio :: Capture/Recording\nTopic :: Multimedia :: Sound/Audio :: Conversion\nTopic :: Multimedia :: Sound/Audio :: Mixers\nTopic :: Multimedia :: Sound/Audio :: Players\nTopic :: Multimedia :: Sound/Audio :: Players :: MP3\nTopic :: Multimedia :: Video\nTopic :: Multimedia :: Video :: Conversion\nTopic :: Multimedia :: Video :: Display\nTopic :: Other/Nonlisted Topic\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development\nTopic :: Software Development :: Build Tools\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Application Frameworks\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Software Development :: User Interfaces\nTopic :: Software Development :: Widget Sets\nTopic :: System :: Distributed Computing\nTopic :: System :: Networking\nTopic :: Utilities", "description": "Kamaelia is a library of components you can take and bolt together, and\r\ncustomise. This includes components for TCP/multicast clients and servers,\r\nbackplanes, chassis, Dirac video encoding & decoding, Vorbis decoding, pygame &\r\nTk based user interfaces and Tk, visualisation tools, presentation tools, DVB\r\n(freeview) games tools, a visual system builder, open gl & bit torrent..."}}, {"pk": 512, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "brewery", "license": "GPL", "author": "Stefan Urbanek", "author_email": "stefan.urbanek@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.databrewery.org", "version": "0.6.0", "platform": "UNKNOWN", "keywords": "data analysis quality", "summary": "Framework for processing, analysing and measuring quality of structured data streams", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python\nTopic :: Database\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "UNKNOWN"}}, {"pk": 513, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ipdasite.policy", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/ipdasite.policy/", "version": "2.0.0", "platform": "UNKNOWN", "keywords": "web zope plone planetary data science policy", "summary": "International Planetary Data Alliance Site Policy and Component Orchestration", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Atmospheric Science\nTopic :: Software Development :: Libraries :: Python Modules", "description": "***************\nipdasite.policy\n***************\n\nThis is the \"policy\" product for the Plone-based site of the International\nPlanetary Data Alliance (IPDA_).  Its job is to orchestrate the dependencies\nand configure them in order to transform an ordinary Plone_ site into the IPDA\nsite.\n\nIt was developed by the Planetary Data System (PDS_).\n\n.. References:\n.. _PDS: http://pds.nasa.gov/\n.. _IPDA: http://planetarydata.org/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``ipdasite.policy`` to the list of eggs to install, e.g.::\n\n    [buildout]\n    ...\n    eggs =\n        ...\n        ipdasite.policy\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n\n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        ipdasite.policy\n        \n* Re-run buildout, e.g. with::\n  \n    $ ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\n2.0.0 - Plone 4\n---------------\n\nThis release of the IPDA Site Policy brings about Plone 4 compatibility.\n\n\nCopyright & License\n===================\n\nCopyright 2008-2011 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 514, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pysparse", "license": "BSD-style", "author": "PySparse Developers", "author_email": "{hamsel,d-orban,wd15}@sf.net,", "project_url": null, "maintainer_email": "", "home_page": "pysparse.sf.net", "version": "1.2-dev213", "platform": "Windows,Linux,Solaris,Mac OS-X,Unix", "keywords": "", "summary": "Fast sparse matrix library for Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "Pysparse is a fast sparse matrix library for Python. It provides several sparse\r\nmatrix storage formats and conversion methods. It also implements a number of\r\niterative solvers, preconditioners, and interfaces to efficient factorization\r\npackages. Both low-level and high-level interfaces are available, each with\r\ndifferent strengths. PySparse is distributed under the FreeBSD license.\r\n\r\nR. Geus    <hamsel@sf.net>\r\nD. Orban   <d-orban@sf.net>\r\nD. Wheeler <wd15@sf.net>"}}, {"pk": 515, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "IntelHex", "license": "BSD", "author": "Alexander Belchenko", "author_email": "bialix@ukr.net", "project_url": null, "maintainer_email": "", "home_page": "http://www.bialix.com/intelhex/", "version": "1.3", "platform": "paltform-independent", "keywords": "Intel HEX HEX8 hex2bin bin2hex", "summary": "Python library for Intel HEX files manipulations", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Telecommunications Industry\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Embedded Systems\nTopic :: Utilities", "description": "The Intel HEX file format widely used in microprocessors and microcontrollers\r\narea as the de-facto standard for representation of code for programming\r\nmicroelectronic devices.\r\n\r\nThis library provides support for reading, modifying, writing Intel HEX files.\r\nYou also can create new files from the scratch, convert from and/or to binary form,\r\nprint human-readable dump of data, merge 2 or more files into one, etc.\r\n\r\nThere are several helper scripts: hex2bin, bin2hex, hex2dump and hexmerge."}}, {"pk": 516, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "thinkgear", "license": "BSD", "author": "Kai Groner", "author_email": "kai@gronr.com", "project_url": null, "maintainer_email": "", "home_page": "http://github.com/groner/pythinkgear/", "version": "0.2", "platform": "UNKNOWN", "keywords": "", "summary": "thinkgear parses the ThinkGear protocol used by NeuroSky MindSet devices", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Human Machine Interfaces", "description": "UNKNOWN"}}, {"pk": 517, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nik2img", "license": "UNKNOWN", "author": "Dane Springmeyer", "author_email": "dane@dbsgeo.com", "project_url": null, "maintainer_email": null, "home_page": "http://mapnik-utils.googlecode.com/", "version": "0.7.0", "platform": "UNKNOWN", "keywords": "Mapnik,GIS,python,mapping,graphics,geospatial", "summary": "A command line style renderer for the Mapnik C++/Python mapping toolkit", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Scientific/Engineering :: GIS\nTopic :: Utilities", "description": "nik2img\n=======\n\nGenerate Mapnik graphics from the command line\n\nDescription\n===========\n\nUse nik2img to interact with the Mapnik C++/Python mapping toolkit from the command line.\n\n\nInstalling nik2img\n==================\n\nTo run this program::\n * Make sure you have Mapnik installed (https://trac.mapnik.org/wiki/MapnikInstallation)\n * Then install nik2img\n * See INSTALL.txt for details\n\nFor more info see: http://code.google.com/p/mapnik-utils/wiki/Nik2Img\n\n\nTroubleshooting\n===============\n\nPost issues you encounter at http://code.google.com/p/mapnik-utils/issues/list\n\n\nSee also\n========\n\nhttp://code.google.com/p/mapnik-utils/\n\nhttp://mapnik.org/\n\nhttp://trac.mapnik.org/"}}, {"pk": 518, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "libLAS", "license": "BSD", "author": "Howard Butler", "author_email": "hobu.inc@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://liblas.org", "version": "1.6.0", "platform": "UNKNOWN", "keywords": "DEM elevation LIDAR", "summary": "LAS 1.0/1.1/1.2 LiDAR data format translation", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "******************************************************************************\nlibLAS - LAS 1.0/1.1/1.2 ASPRS LiDAR data translation toolset\n******************************************************************************\n\n\nlibLAS is a C/C++ library for reading and writing the very common `LAS`\n`LiDAR`_ format. The `ASPRS LAS format`_ is a sequential binary format used to\nstore data from LiDAR sensors and by LiDAR processing software for data\ninterchange and archival. \n\nlibLAS' initial development was supported in 2007-2008 by the `IGSB`_ of the\nIowa DNR for use in its state-wide `LIDAR`_ project.  Ongoing support for \nlibLAS is provided by a number of organizations including the \n`U.S. Army Cold Regions Research and Engineering Laboratory`_.\n\n\n.. _`U.S. Army Cold Regions Research and Engineering Laboratory` : http://www.crrel.usace.army.mil/\n\n\nPre-requisites\n------------------------------------------------------------------------------\n\nThe Python bindings require the libLAS base C and C++ libraries be installed.  \nObtain a source copy of the library from http://liblas.org/download.html and \nfollow the compilation instructions at http://liblas.org/compilation.html to \nbuild and install the library.\n\nNews\n------------------------------------------------------------------------------\n\n02/02/2011\n\nlibLAS 1.6.0 adds a number of new features:\n\n* Compression/decompression support via `LASzip`_\n* Octree indexing\n* Tiling support via `lasblock`_\n* Loading data to `Oracle Point Cloud`_ via `las2oci`_\n* Horizontal and vertical reprojection\n* XML summary output via `lasinfo`_\n\nUpdates to the Python API include support for manipulating raw point data, \nrescaling support through manipulation of `point.header`, and a number of \nadditions to bring things in line with the libLAS C++ API.\n\nNotes\n------------------------------------------------------------------------------\n\nThe Windows builds provided by PyPI include statically-linked `LASzip`_ support, \nbut do not provide coordinate system support via `GDAL`_ or `libgeotiff`_.  \nBecause the Windows binaries provide `LASzip`_ support, which is LGPL, they \nshould be considered LGPL as well.  \n\nIf you need coordinate system support, or fully-featured `tools`_, obtain an \ninstall via `OSGeo4W`_.  `OSGeo4W`_ does include its own Python 2.5, however, \nwhich may what you need, but libLAS' bindings are not tied to any specific \nPython version (they use `ctypes`_), and you should be able to piece together \na system that way.\n\nDocumentation\n------------------------------------------------------------------------------\n\nA `tutorial`_ and `class documentation`_ are provided.\n\nLicense\n------------------------------------------------------------------------------\n\nlibLAS is available under the terms of the `BSD License`_. \nSee `License`_ for a copy.\n\n.. _`ctypes`: http://docs.python.org/library/ctypes.html\n.. _`tools`: http://liblas.org/utilities/\n.. _`GDAL`: http://gdal.org\n.. _`libgeotiff`: http://trac.osgeo.org/geotiff/\n.. _`lasblock`: http://liblas.org/utilities/lasblock.html\n.. _`LASzip`: http://laszip.org\n.. _`las2oci`: http://liblas.org/utilities/las2oci.html\n.. _`lasinfo`: http://liblas.org/utilities/lasinfo.html\n.. _`Oracle Point Cloud`: http://download.oracle.com/docs/cd/B28359_01/appdev.111/b28400/sdo_pc_pkg_ref.htm\"\n.. _`class documentation`: http://liblas.org/python.html\n.. _`tutorial`: http://liblas.org/tutorial/python.html\n\n.. _`LIDAR`: http://en.wikipedia.org/wiki/LIDAR\n.. _`IGSB`: http://www.igsb.uiowa.edu/\n.. _`Martin Isenburg`: http://www.cs.unc.edu/~isenburg/\n.. _`LAStools`: http://www.cs.unc.edu/~isenburg/lastools/\n.. _`Martin Isenburg and Jonathan Shewchuk`: http://www.cs.unc.edu/~isenburg/lastools/\n.. _`LAS Format`: http://www.lasformat.org/\n.. _`ASPRS Standards Committee`: http://www.asprs.org/society/committees/standards/lidar_exchange_format.html\n.. _`ASPRS LAS format`: http://www.asprs.org/society/committees/standards/lidar_exchange_format.html\n\n.. _`BSD license`: http://www.opensource.org/licenses/bsd-license.php\n.. _`OSGeo4W`: http://wiki.osgeo.org/wiki/OSGeo_Win32_Installer\n.. _`License`: http://liblas.org/copyright.html#license"}}, {"pk": 519, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.colin", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/coopr/coopr.colin", "version": "2.2.3", "platform": "any", "keywords": "optimization", "summary": "Coopr interfaces for COLIN optimizers", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==================\ncoopr.colin README\n==================\n\nThis Python package includes interfaces for COLIN optimization solvers.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * coopr-forum@googlegroups.com\n    - The main list for help and announcements\n  * coopr-developers@googlegroups.com\n    - Where developers of Coopr discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 520, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "zgeo.plone.geographer", "license": "GPL", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/projects/PrimaGIS/wiki/zgeo.plone.geographer", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "gis geography geospatial plone", "summary": "Geographic annotation for Plone", "classifiers": "Development Status :: 3 - Alpha\nFramework :: Plone\nFramework :: Zope2\nFramework :: Zope3\nIntended Audience :: Developers\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 521, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cdx.client", "license": "Copyright\n*********\n\nCopyright (c) 2008-2009 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission.", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cdx.jpl.nasa.gov/software/cdx-client", "version": "1.1.0", "platform": "UNKNOWN", "keywords": "climate data cdx python client", "summary": "CDX Client", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Front-Ends\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "**********\ncdx.client\n**********\n\n.. contents::\n\nCDX Client provides an API library and command-line tools for\naccessing CDX data.  CDX is the Climate Data Exchange, an effort of the Jet\nPropulsion Laboratory to create a virtual environment for the sharing of\nclimate data.\n\nInstallation\n************\n\nThis document tells you how to install cdx.client.\n\n\nQuick Instructions\n==================\n\nAs a user with administrative privileges, run::\n\n    easy_install cdx.client\n\nThat's it.\n\n\nFull Instructions\n=================\n\ncdx.client requires the Python_ programming language.  We recommend version 2.4\nor later.  As of this writing, 2.6 is the latest stable version.  If Python is\nnot yet installed on your system, you can find binary and and source\ndistributions from the Python website.\n\nTo test if a correct version of Python is available on your system, run::\n\n    python -V\n    \nYou should see output similar to::\n\n    Python 2.6\n    \nindicating the version of Python installed.  cdx.client also requires `Agile\nOODT`_.  OODT_ is Object Oriented Data Technology, a framework for metadata\nand data grids.  Agile OODT is a Python version of OODT that supports higher\nperformance and easier integration than the Java_ version.\n\nBy far the easiest, recommended, and encouraged way to install cdx.client is\nto use EasyInstall_.  If your Python installation has EasyInstall available to\nit, then this one command is all you need to run in order to download, build,\ninstall, and generate command-line tools all in one go for all users on your\nsystem::\n\n    easy_install cdx.client\n    \nBe sure to run that command as an administrative user.  For example, on Mac OS\nX and other Unix systems, you might need to run::\n\n    sudo easy_install cdx.client\n\nThat will also download and install all dependencies, including Agile OODT.\n\n\nExecutables\n-----------\n\nThe commands ``cdxls`` and ``cdxget`` will be generated and placed with your\nstandard installation directory for Python commands.  Usually, this is the\nsame location as the ``python`` executable itself.  For example, on Mac OS X\n10.5, the directory is::\n\n    /Library/Frameworks/Python.framework/Versions/Current/bin\n\nYou may want to add that directory to your shell's PATH variable, as well as\nforcing your shell to re-scan the PATH variable for new executables.\n\n\nInstalling EasyInstall\n----------------------\n\nIf you happen to be on a system where your Python installation lacks easy\ninstall, fret not.  Upgrading your system to gain EasyInstall's abilities is\nquite simple.  Follow these instructions:\n\n1.  Download http://peak.telecommunity.com/dist/ez_setup.py\n2.  As an administrative user, run the freshly-downloaded ez_setup.py file\n    using your system's Python.\n\nEasyInstall and its necessary libraries will be downloaded, built, and\ninstalled for you, and the ``easy_install`` executable generated.  The\nlocation of the ``easy_install`` executable is as described above.\n\n\nInstalling Without EasyInstall\n------------------------------\n\nIf EasyInstall is not available on your system, you can still make a proper\ninstallation of cdx.client. Follow these instructions:\n\n1.  Download the Agile OODT source distribution from\n    http://oodt.jpl.nasa.gov/dist/agile-oodt/oodt-0.0.1.tar.gz.\n    Substitute version numbers as appropriate.\n2.  Download the cdx.client source distribution from\n    http://cdx.jpl.nasa.gov/software/dist/cdx.client-0.0.3.tar.gz.\n    Substitute version numbers as appropriate.\n3.  Unpack each archive.\n4.  Change the current working directory to each newly-created subdirectory,\n    ``oodt-0.0.1`` and ``cdx.client-0.0.2``, again substituting version\n    numbers as appropriate.\n5.  As an administrative user, run:  ``python setup.py install`` in each\n    subdirectory.\n\n\nIssues and Questions\n====================\n\nTo report any problems with or ask for help about cdx.client, visit our\ncontact_  web page.\n\n\n.. References:\n.. _Agile OODT: http://agility.jpl.nasa.gov/\n.. _contact: http://cdx.jpl.nasa.gov/contact-info\n.. _EasyInstall: http://peak.telecommunity.com/DevCenter/EasyInstall\n.. _Java: http://tinyurl.com/5kng2h\n.. _OODT: http://oodt.jpl.nasa.gov/\n.. _Python: http://python.org/\n\nUsing CDX Client\n****************\n\nInstalling the CDX Client package makes available three things on your\ncomputer:\n\n``cdxls`` command\n    The ``cdxls`` command lets you list the contents of a CDX server from your\n    terminal prompt or a shell script.\n``cdxget`` command\n    The ``cdxget`` command lets you retrieve data from CDX from either your\n    terminal prompt or a shell script.\nCDX Library\n    The CDX Library is a Python-based API for using CDX servers.\n    \nThis document describes how to use the above three items, with special\nattention to the CDX Library.\n\n\nCommands\n========\n\nAfter installing the CDX Client package, two new command are made available on\nyour system, ``cdxls`` and ``cdxget``.  These commands enable you to list the\ncontents of the data on a CDX server and retrieve selected files from the\nserver.\n\nTo use these commands from your interactive prompt, you just need to make sure\nyour shell's PATH environment variable includes the directory where the\ncommands are installed.  On most systems, these two commands are installed in::\n\n    /usr/local/bin\n\nHowever, on Mac OS X, the installation location may be::\n\n    /Library/Frameworks/Python.framework/Versions/Current/bin\n    \nAnd on Windows, it may be::\n\n    c:\\Program Files\\Python\n    \nNote also that some interactive shells create a cache of commands in order to\nexecute your requests more quickly.  You may need to force your shell to\nre-build that cache.  The csh and tcsh shells are two such examples; you can\nmake these shells rebuild their caches by running the ``rehash`` command.\n\n\nUse from Shell Scripts\n----------------------\n\nThe ``cdxls`` and ``cdxget`` commands may be used from shell scripts as well.  The\nonly requirement for making these commands available to shell scripts is the\nsame as for interactive sessions:  the shell's PATH environment variable must\ninclude the directory that contains the ``cdxls`` and ``cdxget`` commands.\n\nHere is a sample shell script that retrieves the MLS Aura L2GP data files (and\nmetadata) files for HO2 and HOCl from day 325 in 2008::\n\n    #!/bin/sh\n    PATH=/usr/local/bin:/usr/bin:/bin; export PATH\n    CDX_SERVER=http://mlscdx.jpl.nasa.gov:8080/cdx/prod; export CDX_SERVER\n    \n    for kind in HO2 HOCl; do\n        for extension in he5 he5.met; do\n            cdxget 2008/325/MLS-Aura_L2GP-${kind}_v02-23-c01_2008d325.${extension}\n        done\n    done\n    \nThe above shell script assumes that ``cdxget`` will be found in\n``/usr/local/bin``, ``/usr/bin``, or ``/bin``.  It also sets the ``CDX_SERVER``\nenvironment variable to set what CDX server to talk to.  It then loops through\ntwo kinds of data (``HO2`` and ``HOCl``), and loops through two kinds of file\nextensions (``he5`` and ``he5.met``).  The results is it retrieves four files to\nthe current working directory, specifically:\n\n* 2008/325/MLS-Aura_L2GP-HO2_v02-23-c01_2008d325.he5\n* 2008/325/MLS-Aura_L2GP-HO2_v02-23-c01_2008d325.he5.met\n* 2008/325/MLS-Aura_L2GP-HOCl_v02-23-c01_2008d325.he5\n* 2008/325/MLS-Aura_L2GP-HOCl_v02-23-c01_2008d325.he5.met\n\n\nThe ``cdxsubset`` command may also be used from a shell script.  It is\nconfigured by two environment variables:\n\n* CDX_SUBSET_MODE - if set then local data wrapper mode will be used (remote\n  is assumed as default)\n* CDX_SERVER - set to the product server to talk to for subsetting\n\nSome example working commands are:\n\nSubset spatial bounding box from NCAR CCSM model output::\n\n    cdxsubset -b /esg/data18/commit/atm/da/hfls/ncar_ccsm3_0/run1/hfls_A2.Commit_1.CCSM.atmd.2000-01-01_cat_2039-12-31.nc\n\nSubset time range from NCAR CCSM model output::\n\n    cdxsubset -t /esg/data18/commit/atm/da/hfls/ncar_ccsm3_0/run1/hfls_A2.Commit_1.CCSM.atmd.2000-01-01_cat_2039-12-31.nc\n    \nGet time array variable data from the MLS L2 granule::\n\n    cdxsubset -p Time /mls/2005/100/MLS-Aura_L2GP-BrO_v01-51-c01_2005d100.he5\n\nGet spatial bounding box from AIRS level 2 granule::\n\n    cdxsubset -b /airs/data/s4pa/Aqua_AIRS_Level2/AIRX2RET.003/2007/005/AIRS.2007.01.05.240.L2.RetStd.v4.0.9.0.G07007180718.hdf\n\nSubset by lat lon and variable for an AIRS level 2 granule::\n\n    cdxsubset -p TAirStd --latitude-range=67.35:78.40 -longitude-range=172.226:176.10 /airs/2009/01/01/airx2ret/AIRS.2009.01.01.001.L2.RetStd.v5.2.2.0.G09002135510.hdf\n\nCDX Library\n===========\n\nThe CDX Library is a Python-based application programming interface (API) for\ncommunicating with CDX servers.  In fact, the two commands ``cdxls`` and\n``cdxget`` are implemented using the CDX Library.  If shell-script programming\nis not to your taste, and you know Python, then using the CDX Library may be\nright for you.\n\nThe CDX Library uses an object-oriented approach to model the contents of a\nCDX server.  Objects represent CDX files and directories, and you call methods\non those objects to determine file attributes, directory contents, or retrieve\na file's contents.\n\nThe remainder of this document describes the modules, classes, and functions\nthat comprise the CDX Library.  If you don't know Python, you may wish to skip\nthe rest.\n\n\nThe ``cdx`` Module\n------------------\n\nThe ``cdx`` module is a namespace module.  It provides no classes or functions.\nRather, it contains a single, nested module called ``client``.\n\n\nThe ``cdx.client`` Module\n-------------------------\n\nThe ``cdx.client`` module contains nested modules that provide the CDX Library.\nIt also contains implementations of the ``cdxls`` and ``cdxget`` commands.\n\n\nThe ``cdx.client.cdxfile`` Module\n---------------------------------\n\nThe ``cdx.client.cdxfile`` module is where all the action is.  It contains\nclasses and functions for communicating with and modeling the contents of CDX\nservers. It contains the following items:\n\n``CDXDirectory``\n    Objects of this class represent directories on a CDX server.  You can use\n    Python's iterator, length, and containment protocols to examine the\n    contents of the directory. They can also be sorted.\n``CDXFile``\n    Objects of this class represent files on a CDX server.  While you can\n    instantiate objects of this class, you'd typically instantiate a\n    CDXDirectory and examine its contents which will include CDXFile objects\n    for files in the directory and nested CDXDirectory objects for\n    subdirectories.  A CDXFile object also provides a method to let you\n    retrieve its data.\n``findFile``\n    The ``findFile`` function is a utility function that, given a starting\n    CDXDirectory and a path name, yields the matching CDXDirectory or CDXFile\n    on a CDX server.\n\n\nCDXDirectory Objects\n~~~~~~~~~~~~~~~~~~~~\n\n``CDXDirectory`` objects represent directories in a CDX server.  You can\ncreate these objects directly or you can use the ``findFile`` method in the\n``cdx.client.cdxfile`` module.\n\nclass CDXDirectory(*path*, *cdxURL* = None)\n    Create a ``CDXDirectory`` object with the given *path*.  You can also\n    specify the URL to a CDX server to use by passing in a string for\n    *cdxURL*.\nsort(*cmp* = cmp, *reverse* = False)\n    Return the contents of the directory, sorted, using the a comparison\n    function *cmp*, defaulting to Python's built-in ``cmp``.  If *reverse* is\n    True, reverse the order of the sort.  Comparison with *cmp* on ``CDXFile``\n    and ``CDXDirectory`` objects is by CDX server URL and by name.  You can\n    pass in your own *cmp* that, for example, sorts by file size.\nisFile()\n    Always returns False.\npath\n    The path name of the directory.\nname\n    The name of the directory; this is the last element of the path.\nsize\n    By convention sizes for directories are always zero.\n\n``CDXDirectory`` objects obey Python's protocols for hashing, comparison,\ncontainment testing, iteration, indexing, and length query.  Containment\ntesting with directories with with ``CDXDirectory`` objects, ``CDXFile``\nobjects, or plain strings::\n\n    >>> from cdx.client.cdxfile import CDXDirectory\n    >>> root = CDXDirectory('/', 'http://localhost:8192/cdx/prod')\n    >>> len(root)\n    3\n    >>> subdir = root['2005']\n    >>> subdir\n    CDXDirectory(path=/2005)\n    >>> subdir in root\n    True\n    >>> '2005' in root\n    True\n    >>> subdir < root\n    False\n    >>> subdir > root\n    True\n    >>> for i in root:\n    ...     print i\n    ...\n    /2008\n    /2007\n    /2005\n    >>> root.sort()\n    [CDXDirectory(path=/2005), CDXDirectory(path=/2007), CDXDirectory(path=/2008)]\n    \n\n``CDXFile`` Objects\n~~~~~~~~~~~~~~~~~~~\n\nTBD.\n\n\nChangelog\n*********\n\n1.1.0 - 11/13/2010\n==================\n\nThis release incorporates version 0.0.6 of the cdx.datawrappers package\nwhich includes CDX-103, which implements GetVariable by lat, lon, and \ntime. In turn this release also provides CDX-102, which incoprorates \nthis functionality into the basic cdxregrid functionality. At this point, \ncdxregrid is pretty much fully functional.\n\nFor the issue tracker, see\nhttp://oodt.jpl.nasa.gov/jira/browse/CDX.\n\n1.0.0 - 09/10/10\n================\n\nThis release made a minor improvement to the public cdxls API, exposing\nthe set of found and lost files from the listFiles function, taking away\nits function-local orchestration and exposing the lists of found and notfound \nfiles to the user. See CDX-93 for more information. This release additionally \nexposes the CDX MODIS product server via cdxls. See CDX-98 for more details. \nFinally, this release includes updates to fix CloudSat as a cdxsubset source, \nas described in CDX-99.\n\nFor the issue tracker, see\nhttp://oodt.jpl.nasa.gov/jira/browse/CDX.\n\n\n0.0.9 - 03/24/2010\n==================\n\nThis release includes improvements to cdxsubset, specifically the ability\nto print out the full numpy array returned from a DataWrapper. See \nCDX-82 for specific details. Additionally cdxsubset has been updated to expose\nthe subset by LatLon functionality per CDX-84 and CDX-85. Subset by range query\nallowing constraints to be specified was also included in this release (see \nCDX-86 for more information).\n\nFor the issue tracker, see\nhttp://oodt.jpl.nasa.gov/jira/browse/CDX.\n\n\n0.0.8 - Inclusion of improvements to cdxcd, virtual roots and new tools\n=======================================================================\n\nThis release includes improvements to cdxcd to make it work nicely \nwith cdx virtual roots, and includes integration with the other cdx client\ntoolkit including cdxls, cdxsubset and cdxget. See CDX-70 and CDX-71 for\nfurther details.\n\nFor the issue tracker, see\nhttp://oodt.jpl.nasa.gov/jira/browse/CDX.\n\n\n0.0.7 - Add Resource Files\n==========================\n\nRelease 0.0.6 was mis-configured and didn't include some important resource\nfiles.  This emergency release includes them!\n\n\n0.0.6 - Inclusion of cdxsubset and other tools, and some minor bug fixes\n========================================================================\n\nThis release includes the cdxsubset tool, as described in CDX-56.\nThis release also includes the cdxcd tool, as described in CDX-69.\nThis release also includes minor aestetic bug fixes that address pathing\nissues in cdxls, e.g., CDX-29.\n\nFor the issue tracker, see\nhttp://oodt.jpl.nasa.gov/jira/browse/CDX.\n\n\n0.0.5 - Repaired Unit Tests\n===========================\n\nThis release updates the unit tests and test data based on the changes in\n0.0.4 and the new behavior of actual product servers. In addition, it\nfixes some documentation problems (incorrect package name cdx-client\nwhich should've been cdx.client) in the INSTALL.txt file.\n\nThe sole bug report addressed in this release is CDX-45, \"Unit tests in\ncdx-client failing\". For the issue tracker, see\nhttp://oodt.jpl.nasa.gov/jira/browse/CDX.\n\n\n0.0.4 - Bugfix to 0.0.3 release\n===============================\n\nThis is a bugfix release to 0.0.3, which includes some error checking to\ndeal with some data format inconsistencies on the OODT OFSN product server\nend.\n\nJIRA issues addressed (see http://oodt.jpl.nasa.gov/jira/browse/CDX):\n\n* CDX-43 Directory structure shouldn't be preserved if cdxget is called\n  without the -r parameter\n* CDX-42 cdxget -r fails to retrieve MLS data\n* CDX-41 cdxls -R chokes if dir size not provided\n\n\n0.0.3 - Directory caching\n=========================\n\nThe major feature of this release is the ``cdx.client.dircache`` module which\nenables local-disk caching of a subset of a remote CDX product server's\ncontents.  It also introduces the concept of a ``cdx:`` scheme URL.  Such a\nURL has this form::\n\n    cdx://hostname[:port]/endpoint/prod/path/to/a/directory\n    \nwhere hostname is the name or IP address of a CDX product server, port is an\noptional port number on which the server is listening, endpoint is the\nWebGrid_  service identifier (typically just the string ``cdx``), prod is the\nfixed keyword ``prod``, and ``path/to/a/directory`` is an absolute path to a\ndirectory within that product server.\n\nSuch caching is intended to support the CCMValDiag_ software.\n\n\n0.0.2 - Bug fix for cdxls\n=========================\n\nThis release repairs a bug in cdxls that caused directories with only one item\nin them to not be listed properly.\n\n\n0.0.1 - URL specification\n=========================\n\nThis release provides support for a (-u url, --url=url) pair of command-line\noptions that enable specification of a specific URL to use, falling back to\nthe URL specified in the CDX_SERVER environment variable (and, if that's\nunset, then http://mlscdx.jpl.nasa.gov:8080/cdx/prod).  This supports two\nideas suggested in CDX-16 (the first two, not the third with a cdx:  style\nURL).\n\n\n0.0.0 - Initial\n===============\n\nThis is an initial release of cdx-client supporting minimal ``cdxls`` and\n``cdxget`` function.\n\n\n.. References:\n.. _WebGrid: http://agility.jpl.nasa.gov/products/agile-oodt/\n.. _CCMValDiag: http://www.pa.op.dlr.de/CCMVal/CCMVal_DiagnosticTool.html"}}, {"pk": 522, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.responses.html", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/responses/html.html", "version": "0.1", "platform": "UNKNOWN", "keywords": "html dap opendap dods data", "summary": "Simple HTML form for pydap server", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This is a simple HTML response, building a form to download data\nin ASCII format. The response builds the HTML page and redirects\nthe user to the ASCII response when a POST is done.\n\nEven though pydap uses Cheetah for templating, I decided to use a\ntemplating engine called ``templess`` for this response. Templess\nis lightweight (~25k) and fun to work with, justifying the choice.\n\nA nice thing about the response is that the redirection to the ASCII\nresponse and the error message when no variable is selected are\nboth done by raising exceptions. These exceptions are *not* captured\nby the server, that allows them to be captured by the Paste#httpexceptions\nmiddleware.\n\nIf you use this response, don't forget to edit the template file\nand add a link pointing to the HTML response when clicking a filename.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/responses/html#egg=dap.responses.html-dev>`_."}}, {"pk": 523, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "ndg-xacml", "license": "BSD - See LICENCE file for details", "author": "Philip Kershaw", "author_email": "Philip.Kershaw@stfc.ac.uk", "project_url": null, "maintainer_email": "", "home_page": "http://proj.badc.rl.ac.uk/ndg/wiki/Security/XACML", "version": "0.4.0", "platform": "UNKNOWN", "keywords": "", "summary": "XACML 2.0 implementation for the NERC DataGrid", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Security\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Distributed Computing", "description": "XACML 2.0 implementation for CEDA (the Centre for Environmental Data Archival)\r\n        STFC, Rutherford Appleton Laboratory.  This is follow on work from the NERC\r\n        (Natural Environment Research Council) DataGrid 3 Project.\r\n        \r\n        XACML (eXtensible Access Control Mark-up Language), is an XML based language for\r\n        expressing access control policies.\r\n        \r\n        See: http://www.oasis-open.org/committees/xacml/\r\n        \r\n        \r\n        Release 0.4.0\r\n        \r\n        Added support for custom DataTypes and functions. e.g.\r\n        \r\n        # Add attribute value type\r\n\r\n        AttributeValueClassFactory.addClass('<my new type uri',\r\n        MyAttributeValueClass)\r\n        \r\n        # ...and new parser for this type\r\n\r\n        DataTypeReaderClassFactory.addReader('<my new type uri',\r\n        ETreeMyDataTypeReaderClass)\r\n        \r\n        # Add new function\r\n\r\n        functionMap['<my function type uri'] = MyNewFunctionClass\r\n        \r\n\r\n        \r\n        Release 0.3\r\n        \r\n        Includes important fixes for equals functions, and improvement to at least one\r\n        member functions.  Unit tests improved with wider coverage of different rule\r\n        definitions and example request contexts.\r\n        \r\n        Improved and added to support for context handler and Policy Information Point\r\n        interfaces including the ability for the PDP to call back to a PIP via a\r\n        Context handler to retrieve additional subject attributes.\r\n        \r\n        \r\n        Release 0.2\r\n        \r\n        Only the parts of the specification immediately required for CEDA have been\r\n        implemented in this initial release:\r\n        Policy Decision Point;\r\n        Deny overrides and Permit overrides rule combining algorithms;\r\n        AttributeDesignators;\r\n        various function types: see ndg.xacml.core.functions;\r\n        and attribute types: see ndg.xacml.core.attribute;\r\n        incomplete support for <AttributeSelector>s, <VariableReference>,\r\n        <VariableDefinition>. <Obligations>;\r\n        includes an ElementTree based parser for Policies. No support for writing\r\n        out policies or read/write of XML representation of <Request> and <Response>;\r\n        \r\n        See ndg.xacml.test for unit tests and examples.\r\n        \r\n        The software follows a modular structure to allow it to be extended easily to\r\n        include new parsers, functions and attribute types"}}, {"pk": 524, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cache_ensembl", "license": "MIT", "author": "Leo Goodstadt", "author_email": "cache_ensembl@llew.org.uk", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/cache-ensembl/", "version": "1.01", "platform": "UNKNOWN", "keywords": "GTF Ensembl gene transcript parser GFF bioinformatics science", "summary": "Fast Ensembl data cache", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "***************************************\nOverview\n***************************************\n    We want an extremely fast, lightweight way to access in bulk data stored in Ensembl databases\n\n\n***************************************\nA Simple example\n***************************************"}}, {"pk": 525, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyMT", "license": "LGPL", "author": "PyMT Crew", "author_email": "pymt-dev@googlegroups.com", "project_url": null, "maintainer_email": null, "home_page": "http://pymt.eu/", "version": "0.5.1", "platform": "UNKNOWN", "keywords": null, "summary": "A framework for making accelerated multitouch UI", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: MacOS X\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: BSD :: FreeBSD\nOperating System :: POSIX :: Linux\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Artistic Software\nTopic :: Games/Entertainment\nTopic :: Multimedia :: Graphics :: 3D Rendering\nTopic :: Multimedia :: Graphics :: Capture :: Digital Camera\nTopic :: Multimedia :: Graphics :: Presentation\nTopic :: Multimedia :: Graphics :: Viewers\nTopic :: Multimedia :: Sound/Audio :: Players :: MP3\nTopic :: Multimedia :: Video :: Display\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Application Frameworks\nTopic :: Software Development :: User Interfaces", "description": "UNKNOWN"}}, {"pk": 526, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.core", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.7", "platform": "OS Independent", "keywords": "ObsPy,seismology", "summary": "ObsPy - a Python framework for seismological observatories.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.core package contains common methods and classes for ObsPy required by\nall other ObsPy packages. It includes the UTCDateTime, Stats, Stream and Trace\nclasses and methods for reading and writing seismograms.\n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology. \n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 527, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "oldowan.mitotype", "license": "MIT", "author": "Ryan Raaum", "author_email": "code@raaum.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.raaum.org/software/oldowan", "version": "1.0.1", "platform": "Any", "keywords": "", "summary": "Utilities to identify human mtDNA haplotypes.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "oldowan.mitotype is a set of utilities to haplotype human mtDNA sequences.\n\nInstallation Instructions\n=========================\n\nThis package is pure Python and has no dependencies outside of the standard\nlibrary. The easist way to install is using ``easy_install`` from the\nsetuptools_ package.  This usually goes something like this::\n\n\t$ easy_install oldowan.mitotype\n\nor on a unix-like system, assuming you are installing to the main Python\n``site-packages`` directory as a non-privileged user, this::\n\n\t$ sudo easy_install oldowan.mitotype\n\nYou may also use the standard python distutils setup method. Download the\ncurrent source archive from the file list towards the bottom of this page,\nunarchive it, and install. On Mac OS X and many other unix-like systems, having\ndownloaded the archive and changed to the directory containing this archive in\nyour shell, this might go something like::\n\n\t$ tar xvzf oldowan.mitotype*\n\t$ cd oldowan.mitotype*\n\t$ python setup.py install\n\nQuick Start\n===========\n\nTODO\n\nRelease History\n===============\n\nTODO (August 16, 2008)\n    initial release of module.\n\n\n.. _setuptools: http://peak.telecommunity.com/DevCenter/EasyInstall"}}, {"pk": 528, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "edrn.sync", "license": "Copyright\n*********\n\nCopyright (c) 2008-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission.", "author": "Chris Mattmann", "author_email": "chris.a.mattmann@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/", "version": "0.0.1", "platform": "UNKNOWN", "keywords": "edrn sync ldap dmcc informatics center", "summary": "EDRN Sync Services", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Front-Ends\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "**********\nedrn.sync\n**********\n\n.. contents::\n\nEDRN Sync provides an API for slurping up DMCC RDF representing\nEDRN users and groups and registering those users into our EDRN \nIC LDAP server.\n\nInstallation\n************\n\nThis document tells you how to install edrn.sync.\n\n\nQuick Instructions\n==================\n\nAs a user with administrative privileges, run::\n\n    easy_install edrn.sync\n\nThat's it.\n\n\nFull Instructions\n=================\n\nedrn.sync requires the Python_ programming language.  We recommend version 2.4\nor later.  As of this writing, 2.6 is the latest stable version.  If Python is\nnot yet installed on your system, you can find binary and and source\ndistributions from the Python website.\n\nTo test if a correct version of Python is available on your system, run::\n\n    python -V\n    \nYou should see output similar to::\n\n    Python 2.6\n    \nindicating the version of Python installed.  edrn.sync also requires `Agile\nOODT`_.  OODT_ is Object Oriented Data Technology, a framework for metadata\nand data grids.  Agile OODT is a Python version of OODT that supports higher\nperformance and easier integration than the Java_ version.\n\nBy far the easiest, recommended, and encouraged way to install edrn.sync is\nto use EasyInstall_.  If your Python installation has EasyInstall available to\nit, then this one command is all you need to run in order to download, build,\ninstall, and generate command-line tools all in one go for all users on your\nsystem::\n\n    easy_install edrn.sync\n    \nBe sure to run that command as an administrative user.  For example, on Mac OS\nX and other Unix systems, you might need to run::\n\n    sudo easy_install edrn.sync\n\nThat will also download and install all dependencies, including Agile OODT.\n\n\nExecutables\n-----------\n\nThe command ``dmccsync`` will be generated and placed with your\nstandard installation directory for Python commands.  Usually, this is the\nsame location as the ``python`` executable itself.  For example, on Mac OS X\n10.5, the directory is::\n\n    /Library/Frameworks/Python.framework/Versions/Current/bin\n\nYou may want to add that directory to your shell's PATH variable, as well as\nforcing your shell to re-scan the PATH variable for new executables.\n\n\nInstalling EasyInstall\n----------------------\n\nIf you happen to be on a system where your Python installation lacks easy\ninstall, fret not.  Upgrading your system to gain EasyInstall's abilities is\nquite simple.  Follow these instructions:\n\n1.  Download http://peak.telecommunity.com/dist/ez_setup.py\n2.  As an administrative user, run the freshly-downloaded ez_setup.py file\n    using your system's Python.\n\nEasyInstall and its necessary libraries will be downloaded, built, and\ninstalled for you, and the ``easy_install`` executable generated.  The\nlocation of the ``easy_install`` executable is as described above.\n\n\nInstalling Without EasyInstall\n------------------------------\n\nIf EasyInstall is not available on your system, you can still make a proper\ninstallation of edrn.sync. Follow these instructions:\n\n1.  Download the Agile OODT source distribution from\n    http://oodt.jpl.nasa.gov/dist/agile-oodt/oodt-0.0.1.tar.gz.\n    Substitute version numbers as appropriate.\n2.  Download the edrn.sync source distribution from\n    http://cancer.jpl.nasa.gov/dist/edrn-sync/edrn.sync-0.0.0.tar.gz.\n    Substitute version numbers as appropriate.\n3.  Unpack each archive.\n4.  Change the current working directory to each newly-created subdirectory,\n    ``oodt-0.0.1`` and ``edrn.sync-0.0.0``, again substituting version\n    numbers as appropriate.\n5.  As an administrative user, run:  ``python setup.py install`` in each\n    subdirectory.\n\n\nIssues and Questions\n====================\n\nTo report any problems with or ask for help about edrn.sync, visit our\ncontact_  web page.\n\n\n.. References:\n.. _Agile OODT: http://agility.jpl.nasa.gov/\n.. _contact: http://cancer.jpl.nasa.gov/\n.. _EasyInstall: http://peak.telecommunity.com/DevCenter/EasyInstall\n.. _Java: http://tinyurl.com/5kng2h\n.. _OODT: http://oodt.jpl.nasa.gov/\n.. _Python: http://python.org/\n\nUsing EDRN Sync Services\n************************\n\nInstalling the EDRN Sync Services package makes available the following\ncommands on your computer:\n\n``dmccsync`` command\n    The ``dmccsync`` command lets you slurp up a DMCC RDF file containing users\n    that need to be entered into EDRN IC LDAP.\n\nChangelog\n*********\n\n0.0.1 - Kumbaya\n===============\n\nThis release adds group creation programs and APIs including the ``dmccgroupsync``\nscript which implements Heather Kincaid's algorithm for adding groups and syncing them\nbased on the DMCC RDF. For more information see https://oodt.jpl.nasa.gov/jira/browse/CA-669.\n\nFor the issue tracker, see\nhttp://oodt.jpl.nasa.gov/jira/browse/CA.\n\n0.0.0 - Initial\n===============\n\nThis is an initial release of EDRN (_EDRN) Sync Services supporting minimal ``dmccsync``\nfunctionality.\n\n\n.. References:\n.. _EDRN: http://cancer.jpl.nasa.gov"}}, {"pk": 529, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "FSA", "license": "Artistic License", "author": "Oliver Steele", "author_email": "steele@osteele.com", "project_url": null, "maintainer_email": null, "home_page": "http://osteele.com/software/pyfsa/", "version": "1.0", "platform": "Platform independent", "keywords": null, "summary": "Finite State Automaton library", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Artistic License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This package contains functions for manipulating Finite-State Automata (FSAs). \r\nIt includes functions for minimizing and determinizing FSAs, computing FSA\r\nintersections and unions, compiling a (non-POSIX) regular expression into an\r\nFSA, and compiling a set of regular expression productions into a chart parser."}}, {"pk": 530, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "F2PY", "license": "LGPL", "author": "Pearu Peterson", "author_email": "pearu@cens.ioc.ee", "project_url": null, "maintainer_email": null, "home_page": "http://cens.ioc.ee/projects/f2py2e/", "version": "2.45.241_1926", "platform": "Unix,Windows (mingw|cygwin),Mac OSX", "keywords": "Fortran,f2py", "summary": "F2PY - Fortran to Python Interface Generaton", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: Fortran\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Code Generators", "description": "The Fortran to Python Interface Generator, or F2PY for short, is a\ncommand line tool (f2py) for generating Python C/API modules for\nwrapping Fortran 77/90/95 subroutines, accessing common blocks from\nPython, and calling Python functions from Fortran (call-backs).\nInterfacing subroutines/data from Fortran 90/95 modules is supported."}}, {"pk": 531, "model": "importing.pypicache", "fields": {"maintainer": "Paul Hughett", "name": "Pyvox", "license": "Similar to BSD, plus provisions for publication credit and prohibiting\r\ndiagnostic or medical use.", "author": "Paul Hughett", "author_email": "hughett@bbl.med.upenn.edu", "project_url": null, "maintainer_email": "hughett@bbl.med.upenn.edu", "home_page": "http://www.med.upenn.edu/bbl/downloads/pyvox/", "version": "0.72", "platform": "Pyvox is written in ANSI C and designed to be easily portable to any Unix or\r\nPosix-compatible platform, including Mac OS X.  Some programs also require the X\r\nWindow System.", "keywords": "Image processing, medical imaging", "summary": "Python extension module for volume image processing", "classifiers": "Intended Audience :: Science/Research\nLicense :: Freely Distributable\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nOperating System :: POSIX :: SunOS/Solaris\nOperating System :: Unix\nProgramming Language :: C\nTopic :: Scientific/Engineering :: Medical Science Apps.", "description": "Pyvox is a Python extension module for processing volume images, particularly\r\nmedical images; it also includes some examples and simple applications.\r\n\r\nFeatures added in release 0.72 include: The interface for constructing\r\nconvolution kernels has been completely redesigned and now supports the dynamic\r\nmodification of kernels.  Internal types now have min and max attributes which\r\ncontain the minimum and maximum possible finite positive values representable in\r\nthat type."}}, {"pk": 532, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyfft", "license": "UNKNOWN", "author": "Bogdan Opanchuk", "author_email": "mantihor@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/Manticore/pyfft", "version": "0.3.5", "platform": "UNKNOWN", "keywords": null, "summary": "FFT library for PyCuda and PyOpenCL", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Mathematics", "description": "PyFFT is a module containing Apple's FFT implementation ported for PyCuda and PyOpenCL.\nDocumentation can be found in `doc`, managed by `Sphinx <http://sphinx.pocoo.org>`_\n(or, in rendered form, on `project's page <http://packages.python.org/pyfft>`_).\n\nModule will work even if only one of PyCuda and PyOpenCL is present; that's why they are not\nadded to dependencies, and it is your responsibility to install the module you need."}}, {"pk": 533, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Jug", "license": "MIT", "author": "Luis Pedro Coelho", "author_email": "lpc@cmu.edu", "project_url": null, "maintainer_email": null, "home_page": "http://luispedro.org/software/jug", "version": "0.8", "platform": "Any", "keywords": null, "summary": "A Task Based Parallelization Framework", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: System :: Distributed Computing", "description": "Jug: A Task-Based Parallelization Framework\n-------------------------------------------\n\nJug allows you to write code that is broken up into\ntasks and run different tasks on different processors.\n\nIt uses the filesystem to communicate between processes and\nworks correctly over NFS, so you can coordinate processes on\ndifferent machines.\n\nJug is a pure Python implementation and should work on any platform.\n\n*Website*: `http://luispedro.org/software/jug <http://luispedro.org/software/jug>`_\n\n*Documentation*: `http://packages.python.org/Jug <http://packages.python.org/Jug>`_\n\n*Video*: On `vimeo <http://vimeo.com/8972696>`_ or `showmedo\n<http://showmedo.com/videotutorials/video?name=9750000;fromSeriesID=975>`_\n\n*Mailing List*: `http://groups.google.com/group/jug-users\n<http://groups.google.com/group/jug-users>`_\n\nShort Example\n.............\n\nHere is a one minute example. Save the following to a file called ``primes.py``::\n\n    from jug import TaskGenerator\n    from time import sleep\n\n    @TaskGenerator\n    def is_prime(n):\n        sleep(1.)\n        for j in xrange(2,n-1):\n            if (n % j) == 0:\n                return False\n        return True\n\n    primes100 = map(is_prime, xrange(2,101))\n\nOf course, this is only for didactical purposes, normally you would use a\nbetter method. Similarly, the ``sleep`` function is so that it does not run too\nfast.\n\nNow type ``jug status primes.py`` to get::\n\n    Task name                  Waiting       Ready    Finished     Running\n    ----------------------------------------------------------------------\n    primes.is_prime                  0          99           0           0\n    ......................................................................\n    Total:                           0          99           0           0\n\n\nThis tells you that you have 99 tasks called ``primes.is_prime`` ready to run.\nSo run ``jug execute primes.py &``. You can even run multiple instances in the\nbackground (if you have multiple cores, for example). After starting 4\ninstances and waiting a few seconds, you can check the status again (with ``jug\nstatus primes.py``)::\n\n    Task name                  Waiting       Ready    Finished     Running\n    ----------------------------------------------------------------------\n    primes.is_prime                  0          63          32           4\n    ......................................................................\n    Total:                           0          63          32           4\n\n\nNow you have 32 tasks finished, 4 running, and 63 still ready. Eventually, they\nwill all finish and you can inspect the results with ``jug shell primes.py``.\nThis will give you an ``ipython`` shell. The `primes100` variable is available,\nbut it is an ugly list of `jug.Task` objects. To get the actual value, you call\nthe `value` function::\n\n    In [1]: primes100 = value(primes100)\n\n    In [2]: primes100[:10]\n    Out[2]: [True, True, False, True, False, True, False, False, False, True]\n\n\nWhat's New\n..........\n\nversion **0.8**:\n- Tasklets\n- Fix bugs in sleep-until and cleanup\n- Fix bugs with CompoundTask (you needed to run jug execute twice before)\n\nversion **0.7.4**:\n- Fix case where ~/.jug/configrc does not exist\n- Print host name to lock file on file_store\n- Refactored implementation of options\n- Fix unloading tasks that have not run\n- Fix mapreduce for empty input\n\nVersion **0.7.3**:\n- Parse ~/.jug/configrc\n- Fix bug with waiting times\n- Special case saving of numpy arrays\n- Add more expressive jugdir syntax\n- Save dict_store backend to disk\n\nVersion **0.7.2**:\n- included missing files in the distribution\n\nVersion **0.7.1**:\n- ``sleep-until`` subcommand\n- bugfixes\n\nVersion **0.7 (starting with 0.6.9 in testing)**:\n- `barrier()`\n- better ``shell`` command\n\nRoadmap\n.......\n\nVersion 1.0\n'''''''''''\n\nVersion 1.0 is just around the corner. After 0.8 is done, there really are not\nthat many features left. More flexible configuration, a bit more caching, and\nwe are done.\n\nAfter version 1.0\n'''''''''''''''''\n\nI want to start adding bells&whistles through extensions. Things like timing,\nmore active monitoring, &c."}}, {"pk": 534, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.age", "license": "BSD", "author": "Carl Laird", "author_email": "carl.laird@tamu.edu", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/coopr/coopr.age", "version": "1.1", "platform": "any", "keywords": "optimization", "summary": "A QT interface for Coopr that supports the formulation and analysis of Pyomo models", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "================\ncoopr.age README\n================\n\nA QT Interface for formulating and solving Pyomo models.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * Carl Laird, carl.laird@tamu.edu\n\n+ Mailing List\n\n  * coopr-forum@googlegroups.com\n    - The main list for help and announcements\n  * coopr-developers@googlegroups.com\n    - Where developers of Coopr discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 535, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "nport", "license": "GPL", "author": "Brecht Machiels", "author_email": "brecht.machiels@esat.kuleuven.be", "project_url": null, "maintainer_email": "", "home_page": "https://github.com/bmachiel/python-nport", "version": "0.1", "platform": "UNKNOWN", "keywords": "two-port 2n-port s-parameters touchstone citi deembedding", "summary": "Python package for handling n-port data", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Scientific/Engineering :: Electronic Design Automation (EDA)", "description": "UNKNOWN"}}, {"pk": 536, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "garlicsim_lib", "license": "LGPL v2.1", "author": "Ram Rachum", "author_email": "cool-rr@cool-rr.com", "project_url": null, "maintainer_email": null, "home_page": "http://garlicsim.org", "version": "0.6.2", "platform": "UNKNOWN", "keywords": null, "summary": "Collection of GarlicSim simulation packages", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering", "description": "Collection of GarlicSim simulation packages, for various scientific fields.\n\nTo be used with `garlicsim` and possibly `garlicsim_wx`.\n\nVisit http://garlicsim.org for more info."}}, {"pk": 537, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ncreduce", "license": "GPL (v2 or later)", "author": "Luis Pedro Coelho", "author_email": "lpc@cmu.edu", "project_url": null, "maintainer_email": null, "home_page": "http://luispedro.org/software/ncreduce", "version": "0.2", "platform": "UNKNOWN", "keywords": null, "summary": "Fast reduce operations for numpy arrays", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Scientific/Engineering", "description": "UNKNOWN"}}, {"pk": 538, "model": "importing.pypicache", "fields": {"maintainer": "Ray Buvel", "name": "rpncalc", "license": "GPL", "author": "Ray Buvel", "author_email": "rlbuvel@gmail.com", "project_url": null, "maintainer_email": "rlbuvel@gmail.com", "home_page": "http://calcrpnpy.sourceforge.net/", "version": "2.7", "platform": "Platform independent", "keywords": "RPN Calculator math functions fractions rational arbitrary precision complex float", "summary": "RPN Calculator For Python", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Mathematics", "description": "Reverse Polish Notation (RPN) interpreter for use as an interactive calculator.\r\nEasily switch between the RPN interpreter and the Python interactive interpreter."}}, {"pk": 539, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "eke.review", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/eke-review", "version": "0.0.0", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers eke knowledge qc review quality", "summary": "Review and Quality Control for the EDRN Knowledge Environment", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "**********\neke.review\n**********\n\nThis component, ``eke.review``, enables researchers, clinicians, and\nscientists part of a collaborative group within the Early Detection\nResearch Network (EDRN_) to perform quality analysis of the products of EDRN.\nIt works with the rest of the EDRN Knowledge Environment (EKE_) on the EDRN\npublic portal to enable easy and rapid turnaround during review cycles.\n\nAlthough intended for the EDRN public portal, this product may be installed\ninto any Plone_ portal.\n\n.. References:\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _EKE: http://cancer.jpl.nasa.gov/documents/applications/knowledge-environment\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``eke.review`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        eke.review\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        eke.review\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nA retrospective of the various releases this component has had, what's been\nchanged, what's been fixed, and so forth, follows.\n\n\nRelease 0.0.0\n-------------\n\nBeta release. This release is destined to become the FCS_.\n\n\n.. References:\n.. _FCS: http://en.wikipedia.org/wiki/Development_stage\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 540, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.handlers.proxy", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/handlers.html#proxy", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "proxy opendap dods dap data science climate oceanography meteorology", "summary": "Remote dataset proxy for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This handler enables Pydap to serve remote datasets from other\nservers."}}, {"pk": 541, "model": "importing.pypicache", "fields": {"maintainer": "\u00c5smund \u00d8deg\u00e5rd", "name": "pyse", "license": "GPL", "author": "\u00c5smund \u00d8deg\u00e5rd", "author_email": "aasmund@simula.no", "project_url": null, "maintainer_email": "aasmund@simula.no", "home_page": "http://pyfdm.sourceforge.net", "version": "0.3.1", "platform": "", "keywords": "", "summary": "Python Stencil Environment - solving PDEs with Python", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics", "description": "PySE is an environemnt written in Python for solving partial differnetial\r\nequations, using the finite difference method. It is heavily based on the\r\n'Stencil' concept in FDM methods."}}, {"pk": 542, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "DerApproximator", "license": "new BSD", "author": "('Dmitrey Kroshko',)", "author_email": "dmitrey-at-openopt-dot-org", "project_url": null, "maintainer_email": null, "home_page": "http://openopt.org", "version": "0.33", "platform": "UNKNOWN", "keywords": null, "summary": "A python module for finite-differences derivatives approximation", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": ""}}, {"pk": 543, "model": "importing.pypicache", "fields": {"maintainer": "Erik Max Francis", "name": "PyDiscord", "license": "GPL", "author": "Erik Max Francis", "author_email": "software@alcyone.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.alcyone.com/software/discord/", "version": "1.0", "platform": "any", "keywords": "Gregorian date, date conversion, calendars, Discordian calendar", "summary": "A simple module for converting dates from Gregorian to Discordian", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This is a very simple module which allows for conversion from\r\n    normal dates (via 'time.time', 'time.localtime', etc.) to\r\n    Discordian dates (a silly made-up dating system that divides a\r\n    year into five seasons of 73 days each).  The module can either be\r\n    used as a standalone command line application (which prints the\r\n    current date in Discordian form) or as a extension module."}}, {"pk": 544, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "eke.publications", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/eke-publications", "version": "1.0.0", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers eke knowledge publication article journal document book", "summary": "Publications Management for the EDRN Knowledge Environment", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Internet :: Z39.50\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "****************\neke.publications\n****************\n\nThis product, ``eke.publications``, provides display and RDF_ ingest of\npublications (articles, books, journal entries, etc.) for the Early Detection\nResearch Network (EDRN_) Knowledge Environment (EKE_).  EDRN uses the EKE to\nmake it easy to discover, share, search for, and retrieve all of EDRN's\ncollective knowledge, including cancers and other diseases, biomarkers,\nspecimens, investigators, participants, studies, protocols, and-as in the\ncase of this product-publications.\n\nAlthough intended for the EDRN public portal, it can be installed in any\nPlone_ compatible site.\n\nThis software is developed by the `EDRN Informatics Center`_  at JPL_,\noperated by the California Institute of Technology, for NCI_.\n\n.. References:\n.. _EDRN Informatics Center: http://cancer.jpl.nasa.gov/\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _EKE: http://cancer.jpl.nasa.gov/documents/applications/knowledge-environment\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://cancer.gov/\n.. _Plone: http://plone.org/\n.. _RDF: http://w3.org/RDF\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``eke.publications`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        eke.publications\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        eke.publications\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.\n\n1.0.0 - Prime Time\n------------------\nThis release addresses a number of issues \nthat make this component (and some of its\nselected counterparts) \"prime time\" for\nthe operational NCI portal. \n\nThis release addresses the following issues:\n\n* CA-528 Automatic periodic ingest of RDF\n\nYou can find the issue tracker at https://oodt.jpl.nasa.gov/jira/browse/CA\n\n\n0.0.2\n-----\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-514 - Searching on publication\n  author names should yield the publications in the search results\n\n\n0.0.1 - HTML Cleanup and Citation Formats\n-----------------------------------------\n\nThe following issues are addressed in this release:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-474 - Publications need to be laid\n  out per NCI requirements\n* http://oodt.jpl.nasa.gov/jira/browse/CA-472 - Protocols and other items seem\n  to still have encoded ASCII characters in the titles\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 545, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gtf_to_genes", "license": "MIT", "author": "Leo Goodstadt", "author_email": "gtf_to_genes@llew.org.uk", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/gtf-to-genes/", "version": "1.07", "platform": "UNKNOWN", "keywords": "GTF Ensembl gene transcript parser GFF bioinformatics science", "summary": "Fast GTF parser", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "***************************************\nOverview\n***************************************\n    We want an extremely fast, lightweight way to access gene data stored in GTF format.\n    \n    The parsed data is held in an intuitive\n        Gene\n             -> transcript\n             -> transcript\n        with exons being stored as intervals\n    \n    Our aim is to \n       * cache data in binary format, which can be \n       * re-read in < 10s for even the largest genomes\n    \n    Currently initial parsing Ensembl Homo sapiens release 56 takes around 4.5 minutes.\n    The binary data can be reloaded in < 10s.\n    This contains *all* of the data structure in the original GTF file\n\n    Note that we sacrifice memory usage for speed. This is seldom a problem for modern computers\n    and genome sizes (There are around ~400,000 exons but there are stored as intervals / int pairs)\n\n***************************************\nA Simple example\n***************************************\n    ::\n        gene_structures = t_parse_gtf(\"Mus musculus\")\n\n        #\n        #   used cached data for speed\n        #    \n        ignore_cache = False\n    \n        # \n        #   get all protein coding genes only\n        # \n        genes_by_type = gene_structures.get_genes(gtf_file, logger, [\"protein_coding\"], ignore_cache = ignore_cache)\n    \n        #\n        #   print out gene counts\n        #\n        t_parse_gtf.log_gene_types (logger, genes_by_type)\n    \n        return genes_by_type"}}, {"pk": 546, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nebgbdiff", "license": "MIT", "author": "Paul Joseph Davis", "author_email": "davisp@neb.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/davisp/nebgbdiff", "version": "0.0.4", "platform": "any", "keywords": "bioinformatics Genbank diff", "summary": "Genbank file logical feature diffing", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "nebgbdiff - Logical Feature Diffing\n===================================\n\nCreate logical differences between Genbank files."}}, {"pk": 547, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.bvp_solver", "license": "BSD", "author": "John Salvatier", "author_email": "jsalvati@u.washington.edu", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/scikits.bvp_solver/", "version": "0.3.0", "platform": "any", "keywords": null, "summary": "Python package for solving two-point boundary value problems", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics", "description": "bvp_solver is a Python package for solving two-point boundary value problems that wraps\n        BVP_SOLVER (see http://cs.stmarys.ca/~muir/BVP_SOLVER_Webpage.shtml). It fully working \n        and in beta testing. A tutorial, examples and documentation can be found at \n        http://packages.python.org/scikits.bvp_solver/. If you have questions or suggestions \n        send an e-mail to the mailing list or me.\n\n        To join the mailing list send an e-mail to scikits-bvp_solver+subscribe@googlegroups.com"}}, {"pk": 548, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "garlicsim", "license": "LGPL v2.1", "author": "Ram Rachum", "author_email": "cool-rr@cool-rr.com", "project_url": null, "maintainer_email": null, "home_page": "http://garlicsim.org", "version": "0.6.2", "platform": "UNKNOWN", "keywords": null, "summary": "Pythonic framework for working with simulations", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering", "description": "GarlicSim is a platform for writing, running and analyzing simulations.\n\nIt can handle any kind of simulation: Physics, game theory, epidemic spread,\nelectronics, etc.\n\nVisit http://garlicsim.org for more info."}}, {"pk": 549, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pymcdream", "license": "BSD", "author": "John Salvatier", "author_email": "jsalvati@u.washington.edu", "project_url": null, "maintainer_email": null, "home_page": "pypi.python.org/pypi/dream", "version": "0.1.1", "platform": "UNKNOWN", "keywords": null, "summary": "Implements DREAM in Python based on PyMC for exploratory purposes", "classifiers": "Development Status :: 2 - Pre-Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics", "description": "A prototype based on the algorithm in \n                    J.A. Vrugt, C.J.F. ter Braak, C.G.H. Diks, D. Higdon, B.A. Robinson, and J.M. Hyman: Accelerating Markov chain Monte Carlo simulation by differential evolution with self-adaptive randomized subspace sampling.  International Journal of Nonlinear Sciences and Numerical Simulation, 2008, In Press."}}, {"pk": 550, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.component.app", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.component.app", "version": "3.1.5", "platform": "any", "keywords": "utility", "summary": "An application interface for the PyUtilib Component Architecture", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "=============================\npyutilib.component.app README\n=============================\n\nThis Python package defines application interfaces that simplify the\nuse of the PyUtilib Component Architecture.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\n* pyutilib.component.core"}}, {"pk": 551, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mahotas", "license": "GPL", "author": "Luis Pedro Coelho", "author_email": "lpc@cmu.edu", "project_url": null, "maintainer_email": null, "home_page": "http://luispedro.org/software/mahotas", "version": "0.6.3", "platform": "Any", "keywords": null, "summary": "Mahotas: Python Image Processing Library", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Image Recognition\nTopic :: Software Development :: Libraries", "description": "Image Processing Library for Python.\n\nIt includes a couple of algorithms implemented in C++ for speed while operating\nin numpy arrays.\n\nNotable algorithms:\n - watershed.\n - convex points calculations.\n - hit & miss. thinning.\n - Zernike & Haralick, LBP, and TAS features.\n - freeimage based numpy image loading (requires freeimage libraries to be\n   installed).\n - Speeded-Up Robust Features (SURF), a form of local features.\n - thresholding.\n - convolution.\n - Sobel edge detection.\n\nExamples\n--------\n\nThis is a simple example of loading a file (called `test.jpeg`) and calling\n`watershed` using above threshold regions as a seed (we use Otsu to define\nthreshold).\n\n::\n\n    import numpy as np\n    from scipy import ndimage\n    import mahotas\n    import pylab\n\n    img = mahotas.imread('test.jpeg')\n    T_otsu = mahotas.thresholding.otsu(img)\n    seeds,_ = ndimage.label(img > T_otsu)\n    labeled = mahotas.cwatershed(img.max() - img, seeds)\n\n    pylab.imshow(labeled)\n\n\nRecent Changes\n--------------\n\nFor version **0.6.3**:\n\n- Improve ``mahotas.stretch()`` function\n- Fix corner case in surf (when determinant was zero)\n- ``threshold`` argument in mahotas.surf\n- imreadfromblob() & imsavetoblob() functions\n- ``max_points`` argument for mahotas.surf.interest_points()\n- Add ``mahotas.labeled.borders`` function\n\nFor version **0.6.2**:\n\nBugfix release:\n\n- Fix memory leak in _surf\n- More robust searching for freeimage\n- More functions in mahotas.surf() to retrieve intermediate results\n- Improve compilation on Windows (patches by Christoph Gohlke)\n\nFor version **0.6.1**:\n\n- Release the GIL in morphological functions\n- Convolution\n- just_filter option in edge.sobel()\n- mahotas.labeled functions\n- SURF local features\n\nFor version **0.6**:\n\n- Improve Local Binary patterns (faster and better interface)\n- Much faster erode() (10x faster)\n- Faster dilate() (2x faster)\n- TAS for 3D images\n- Haralick for 3D images\n\nSupport\n-------\n\n*Website*: `http://luispedro.org/software/mahotas\n<http://luispedro.org/software/mahotas>`_\n\n*API Docs*: `http://packages.python.org/mahotas/\n<http://packages.python.org/mahotas/>`_\n\n*Mailing List*: Use the `pythonvision mailing list\n<http://groups.google.com/group/pythonvision?pli=1>`_ for questions, bug\nsubmissions, etc."}}, {"pk": 552, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "python-zibopt", "license": "UNKNOWN", "author": "Ryan J. O'Neil", "author_email": "ryan@chenoneil.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/python-zibopt/", "version": "0.5.beta-r97", "platform": "UNKNOWN", "keywords": "mixed binary integer programming optimization zib zibopt", "summary": "ZIB Optimization Suite interface for python", "classifiers": "Intended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Scientific/Engineering :: Mathematics", "description": "UNKNOWN"}}, {"pk": 553, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.autotest", "license": "BSD", "author": "William Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.autotest", "version": "1.4.4", "platform": "any", "keywords": "utility", "summary": "A framework for generating test suites from external configuration files.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "========================\npyutilib.autotest README\n========================\n\n.. _YAML: http://yaml.org/\n\n--------\nOverview\n--------\n\nThe ``pyutilib.autotest`` package provides a facility for automatically\nconfiguring tests that are executed with Python's unittest package.  This\ncapability is tailored for tests where one or more *solvers* are \napplied to one or more *problems*.  This testing structure is particularly\nuseful for evaluating the execution of external executables on datasets.\n\nThere are three main steps for configuring and applying pyutilib.autotest:\n\n1. Create a configuration file\n2. Create a test driver plugin\n3. Setup the Python module that will be used to apply the tests\n\nThese steps are described in the following subsections.\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nCreating a Configuration File\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nCurrently, ``pyutilib.autotest`` only supports a YAML_ configuration file.  The\ntop-level collection in this configuration is a mapping with the following\nkeys:\n\npython\n  This section contains a list of Python expressions that are executed while\n  setting up the test suites.\n\ndriver\n  This section specifies the name of the test driver that is used to \n  execute tests.\n\nsolvers\n  This section contains a mapping of solver names to solver options.\n\nproblems\n  This section contains a mapping of problem names to problem options.\n\nsuites\n  This section contains a mapping of test suite names to suite configurations.\n\nThe following example illustrates the structure of a YAML configuration file.\n(This example is the file ``pyutilib.autotest/examples/autotest/example1.yml`` in\nthe ``pyutilib.autotest`` distribution.)\n\n::\n\n    driver: example\n\n    python:\n        - import example\n\n    solvers:\n        cat:\n        cat2:\n            name: cat\n            cat_options: -n\n        echo:\n\n    problems:\n        p1:\n            file: README.txt\n        p2:\n            file: example.py\n        p3:\n            file: LoremIpsum1.txt\n\n    suites:\n\n        suite1:\n            categories:\n                - smoke\n                - suite1\n            solvers:\n                cat:\n                cat2:\n                echo:\n            problems:\n                p1:\n\n        suite2:\n            categories:\n                - nightly\n                - suite2\n            solvers:\n                cat:\n                cat2:\n                echo:\n            problems:\n                p1:\n                p2:\n                p3:\n            tests:\n                - solver: cat\n                  problem: p1\n                - solver: cat2\n                  problem: p2\n                - solver: echo\n                  problem: p3\n\n        suite3:\n            categories:\n                - suite3\n            solvers:\n                cat:\n                catx:\n                    solver: cat\n                    cat_options: -n\n            problems:\n                p1:\n\nThe test driver ``example`` is defined in the ``example.py`` file, which is\nimported with the directives in the ``python`` section.\n\nWithin the ``solvers`` and ``problems`` sections, each solver and problem can\nspecify additional options that are passed into the test.  Note that these\noptions are not distinguished for the test;  option name conflicts will\nresults in unpredictable behavior.\n\nThree solvers are defined in this example, which apply the unix ``cat`` and\n``echo`` commands.  By default, the name of the solver is assumed to be the\nname of the key for the solver map.  Solver ``cat2`` illustrates how a solver\nname can be specified separately from the solver key.\n\nThe ``suites`` section defines one or more test suites.  Each test suite\nconsists of a mapping with the following sections:\n\ncategories\n  This optional section contains a list of strings that are solver categories.\n  These categories can be used to select characteristics of the test suites\n  that are executed.\n\nsolvers\n  This section contains a mapping of solvers.  Note that additional options can\n  be provided here to further customize the solver behavior.  By default, the\n  solver name is assumed to be the key value, but the ``solver`` key can be\n  used to explicitly define the solver that is associated with a customized\n  solver mapping.\n\nproblems\n  This section contains a list of problems.  Note that additional options can\n  be provided here to further customize the test behavior. By default, the\n  problem name is assumed to be the key value, but the ``problem`` key can be\n  used to explicitly define the problem that is associated with a customized\n  problem mapping.\n\ntests\n  This optional section contains a list of ``solver``-``problem`` pairs, which\n  defines the actual tests that are defined.  Note that the ``solver`` and \n  ``problem`` values map to the keys defined in the ``solvers`` and\n  ``problems`` sections of a test suite;  thus, this section can use the names of customized\n  solvers and problems that are not defined in the top-level ``solvers`` and\n  ``problems`` sections.  Finally, if this section is omitted, then\n  all combinations of solvers and problems are used to create tests.\n  \nIn this example, three suites are defined to illustrate different features of\nthe test driver:\n\nsuite1\n  A simple test suite in which all solvers are applied to a single problem.\n\nsuite2\n  The ``tests`` section is specified to select a subset of all combinations of\n  solvers and problems to test.\n\nsuite3\n  The ``catx`` solver is customized from ``cat`` to operate like the ``cat2`` solver. \n\n\n~~~~~~~~~~~~~~~~~~~~~~\nCreating a Test Driver\n~~~~~~~~~~~~~~~~~~~~~~\n\nThe test configuration used by ``pyutilib.autotest`` is quite generic.  It\nspecifies what combinations of solvers and problems are to be tested, along\nwith their corresponding options.  However, it does not specify how the test\nis performed.  This is done by a test driver class.\n\nIn general, test driver classes are required to be plugins that can be\ndynamically created by ``pyutilib.autotest`` to execute tests.  The easiest\nway to define a test driver plugin is to inherit from the ``TestDriverBase``\nclass.  For example, the following test driver is used in by the earlier \ntest configuration;  this plugin is defined in\n``pyutilib.autotest/examples/autotest/example.py``.\n\n::\n\n    import pyutilib.autotest\n    from pyutilib.component.core import *\n    import pyutilib.subprocess\n\n\n    class ExampleTestDriver(pyutilib.autotest.TestDriverBase):\n        \"\"\"\n        This test driver executes a unix command and compares its output\n        with a baseline value.\n        \"\"\"\n\n        alias('example')\n\n        def run_test(self, testcase, name, options):\n            \"\"\"Execute a single test in the suite\"\"\"\n            name = options.suite+'_'+name\n            cmd = options.solver+' '\n            if not options.cat_options is None:\n                cmd += options.cat_options+' '\n            cmd += options.file\n            print \"Running test suite '%s'  test '%s'  command '%s'\" % \\\n                    (options.suite, name, cmd)\n            pyutilib.subprocess.run(cmd, outfile=options.currdir+'test_'+name+\".out\")\n            testcase.failUnlessFileEqualsBaseline(\n                    options.currdir+'test_'+name+\".out\", \n                    options.currdir+'test_'+name+\".txt\")\n\nThe ``alias`` function is used to specify the name of this plugin;  this is\nthe name of the test driver used in the test configuration file.\n\nThe ``run_test`` method executes a single test in the test suite.  Note that\nthis method is passed in ``testcase``, which is the test suite class.  Thus,\nthis method can directly apply the ``unittest`` methods that are defined in\nthis class (e.g. ``assertEquals``).\n\nIn this example, a unix command-line is create from the solver name, the\nsolver options, and the problem filename.  This is executed with the\n``pyutilib.subprocess.run`` function, which redirects output to a log file.\nThis log file is then compared with a baseline file using the\n``failUnlessFileEqualsBaseline``, which is defined in the ``unittest``\nextensions in ``pyutilib.th``.\n\nNote that a variety of other standard unit test methods can also be defined by\nthis test driver.  This driver is a ``ITestDriver`` plugin, and the API for\nthis plugin is:\n\n::\n\n    class ITestDriver(Interface):\n\n        def setUpClass(self, cls, options):\n            \"\"\"Set-up the class that defines the suite of tests\"\"\"\n\n        def tearDownClass(self, cls, options):\n            \"\"\"Tear-down the class that defines the suite of tests\"\"\"\n\n        def setUp(self, testcase, options):\n            \"\"\"Set-up a single test in the suite\"\"\"\n\n        def tearDown(self, testcase, options):\n            \"\"\"Tear-down a single test in the suite\"\"\"\n\n        def run_test(self, testcase, name, options):\n            \"\"\"Execute a single test in the suite\"\"\"\n\n\n~~~~~~~~~~~~~~~~~~~~~~\nCreating a Test Module\n~~~~~~~~~~~~~~~~~~~~~~\n\nVirtually all of the work needed to create test suites is automated by\n``pyutilib.autotest``.  The following test module is used in this example;\n(see ``pyutilib.autotest/examples/autotest/autotest.py``):\n\n::\n\n    import os\n    import sys\n    from os.path import abspath, dirname\n    currdir = dirname(abspath(__file__))+os.sep\n\n    import pyutilib.th as unittest\n    import pyutilib.autotest\n\n    if __name__ == \"__main__\":\n        pyutilib.autotest.create_test_suites(filename=currdir+'example1.yml', _globals=globals())\n        unittest.main()\n\nThe first four lines are needed to identify the current directory, where\nthe test configuration file resides.\n\nNote that ``pyutilib.th`` is imported as ``unittest``, which reminds the user\nthat this is a ``unittest`` extension package.  (Specifically, this package\ncontains hooks needed to dynamically add functions as test methods in test\nsuites.)\n\nThe ``pyutilib.autotest`` packages is imported so the ``create_test_suites``\nfunction can be executed.  The arguments to this function are the test\nconfiguration file, and the global dictionary.\n\nFinally, ``unittest.main()`` is executed, as in any ``unittest`` module.\nTests can be executed using standard unittest command-line options.  One\nextension to this behavior is the use of the PYUTILIB_AUTOTEST_CATEGORIES\nor PYUTILIB_UNITTEST_CATEGORIES environmental variables;  if one of these\nis specified, then ``pyutilib.autotest`` assumes that this data contains\na comma-separated list of categories that are used to select the test\nsuites that are constructed.  Specifically, if a test suite contains \none of the specified test categories, then it will be executed.\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nThe ``pyutilib_test_driver`` Command\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe ``pyutilib_test_driver`` command can be used to execute tests defined in a\nconfiguration file without creating a test module.  In practice, test modules\nare typically needed to support test discovery with tools like `nose`.\nHowever, this command provides several features that are useful when\ndiagnosing tests.\n\nThe command-line behavior of ``pyutilib_test_driver`` extends the API of\n``unittest.main()``.  The following additional options are provided to allow\nthe user to interrogate the tests that are defined by the test configuration\nfile:\n\n--help-suites\n    Print the test suites that can be executed\n--help-tests=HELP_TESTS\n    Print the tests in the specified test suite\n--help-categories\n    Print the test suite categories that can be specified\n\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 554, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "earth_distance", "license": "GNU General Public License Version 3", "author": "James Rowe", "author_email": "jnrowe@ukfsn.org", "project_url": null, "maintainer_email": "", "home_page": "http://www.jnrowe.ukfsn.org/projects/earth_distance.html", "version": "0.10.0", "platform": "UNKNOWN", "keywords": "navigation,xearth,trigpointing,cities,baken,weather,geonames,openstreetmap,nmea,gpx", "summary": "earth_distance - Modules for working with points on Earth", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: Other Environment\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database\nTopic :: Education\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Filters", "description": "**NOTE**: This package has been renamed to upoints_.\r\n\r\n.. _upoints: http://pypi.python.org/pypi/upoints/\r\n\r\n``earth_distance`` is a collection of `GPL v3`_ licensed modules for working\r\nwith points on Earth, or other near spherical objects.  It allows you to\r\ncalculate the distance and bearings between points, mangle xearth_/xplanet_ data\r\nfiles, work with online UK trigpoint databases, NOAA_'s weather station\r\ndatabase and other such location databases.\r\n\r\n.. _GPL v3: http://www.gnu.org/licenses/\r\n.. _xearth: http://www.cs.colorado.edu/~tuna/xearth/\r\n.. _xplanet: http://xplanet.sourceforge.net/\r\n.. _NOAA: http://weather.noaa.gov/"}}, {"pk": 555, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "tabular", "license": "MIT", "author": "Elaine Angelino and Daniel Yamins", "author_email": "elaine.angelino at gmail dot com, dyamins at gmail dot com", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/tabular/", "version": "0.0.8", "platform": "UNKNOWN", "keywords": "tabular data spreadsheet hierarchical", "summary": "Tabular data container and associated convenience routines in Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Text Processing", "description": "Tabular data can be easily represented in Python using the language's native objects -- e.g. by lists of tuples representing the records of the data set.    Though easy to create, these kind of representations typically do not enable important tabular data manipulations, like efficient column selection, matrix mathematics, or spreadsheet-style operations. \n\n**Tabular** is a package of Python modules for working with tabular data.     Its main object is the **tabarray** class, a data structure for holding and manipulating tabular data.  By putting data into a **tabarray** object, you'll get a representation of the data that is more flexible and powerful than a native Python representation.   More specifically, **tabarray** provides:\n\t\n*\tultra-fast filtering, selection, and numerical analysis methods, using convenient Matlab-style matrix operation syntax\n*\tspreadsheet-style operations, including row & column operations, 'sort', 'replace',  'aggregate', 'pivot', and 'join'\n*\tflexible load and save methods for a variety of file formats, including delimited text (CSV), binary, and HTML\n*\tsophisticated inference algorithms for determining formatting parameters and data types of input files\n*\tsupport for hierarchical groupings of columns, both as data structures and file formats\n\n**Note to NumPy Users:**  The **tabarray** object is based on the `ndarray <http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html?highlight=ndarray#numpy.ndarray>`_ object from the Numerical Python package (`NumPy <http://numpy.scipy.org/>`_), and the Tabular package is built to interface well with NumPy in general.  In particular, users of NumPy can get many of the benefits of Tabular, e.g. the spreadsheet-style operations, without having replace their usual NumPy objects with tabarrays, since most of the useful functional pieces of Tabular are written to work directly on NumPy ndarrays and record arrays.\n\nTabular requires Python 2.5 or higher but is not tested with Python 3k.  Tabular **requires** NumPy v1.3 or higher.  Any earlier version WILL NOT WORK.\n\nTabular is in beta!  \n\nSee documentation at http://www.parsemydata.com/tabular.\n\nYou can also clone our mercurial (hg) repository from bitbucket: http://bitbucket.org/elaine/tabular/."}}, {"pk": 556, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cubes", "license": "GPL", "author": "Stefan Urbanek", "author_email": "stefan.urbanek@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://databrewery.org", "version": "0.5.0", "platform": "UNKNOWN", "keywords": "olap multidimensional data analysis", "summary": "Framework for Online Analytical Processing (OLAP), multidimensional analysis and cube precomputation", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python\nTopic :: Database\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "UNKNOWN"}}, {"pk": 557, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mathdom", "license": "UNKNOWN", "author": "Stefan Behnel", "author_email": "scoder@users.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathdom.sourceforge.net/", "version": "0.8", "platform": "UNKNOWN", "keywords": "MathML xml DOM math parser validator", "summary": "MathDOM - Content MathML in Python", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Markup :: XML", "description": "MathDOM - Content MathML in Python\n\n**MathDOM** is a set of Python 2.4 modules (using PyXML_ or lxml_, and\npyparsing_) that import mathematical terms as a `Content MathML`_\nDOM. It currently parses MathML and literal infix terms into a DOM\ndocument and writes out MathML and literal infix/prefix/postfix/Python\nterms. The DOM elements are enhanced by domain specific methods that\nmake using the DOM a little easier. Implementations based on PyXML and\nlxml/libxml2 are available.\n\n.. _lxml:                  http://codespeak.net/lxml/\n.. _pyparsing:             http://pyparsing.sourceforge.net/\n.. _PyXML:                 http://pyxml.sourceforge.net/\n.. _`Content MathML`:      http://www.w3.org/TR/MathML2/chapter4.html\n.. _MathML:                http://www.w3.org/TR/MathML2/\n.. _PyMathML:              http://pymathml.sourceforge.net/\n\nYou can call it the shortest way between different term\nrepresentations and a Content MathML DOM. Ever noticed the annoying\ndifferences between terms in different programming languages? Build\nyour application around MathDOM and stop caring about the term\nrepresentation that users prefer or that your machine can execute. If\nyou need a different representation, add a converter, but don't change\nthe model of your application. Literal terms are connected through an\nintermediate AST step that makes writing converters for\nSQL/Java/Lisp/*your-favourite* easy.\n\nNew in version 0.8:\n\n- works with (and requires) lxml 2.0 or later\n\nNew in version 0.7.2:\n\n- works with (and requires) lxml 1.3 or later\n\nNew in version 0.7.1:\n\n- bug fix for operator qualifiers\n\nNew in version 0.7:\n\n- works with lxml 0.9 out-of-the-box\n\nNew in version 0.6.7:\n\n- added missing '%' operator (modulo)\n- adapted to updated lxml API\n\nNew in version 0.6.6:\n\n- closer APIs of mathdom and lmathdom\n- convenience functions to portably create apply, ci and cn elements\n\nNew in version 0.6.5:\n\n- XSLT extension function to include literal terms in output\n- bug fix in Python term serializer\n\nNew in version 0.6.4:\n\n- Updated setup.py script to use setuptools if available\n- Support for splitting package into two PyXML and lxml dependent packages\n- Now builds patched lxml during install\n\nNew in version 0.6.3.1:\n\n- Fixes a number of bugs in mathdom and lmathdom modules\n\nNew in version 0.6.2:\n\n- Generalized parser framework\n- Python term parser\n\nNew in version 0.6.1:\n\n- integration of the PyMathML_ renderer (untested!)\n- more generic integration of XSLT scripts\n\nNew in version 0.6:\n\n- RelaxNG validation (lxml)\n- Presentation MathML export (based on XSLT/lxml)\n- stricter spec conformance (encloses MathML output in <math> tag"}}, {"pk": 558, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pyRserve", "license": "MIT license", "author": "Ralph Heinkel", "author_email": "rh [at] ralph-heinkel.com", "project_url": null, "maintainer_email": "", "home_page": "http://pypi.python.org/pypi/pyRserve/", "version": "0.3", "platform": "unix,linux,cygwin,win32", "keywords": "", "summary": "A Python client to remotely access R statistic package via Rserve", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Scientific/Engineering :: Mathematics", "description": "pyRserve\n        =========\n        \n        What It Does\n        -------------\n        \n        pyRerve is a library for connecting Python to an `R process <http://www.r-project.org/>`_ (an excellent statistic package) running `Rserve <http://www.rforge.net/Rserve/>`_ as a RPC connection gateway. Through such a connection variables can be get and set in R from Python, and also R-functions can be called remotely.  In contrast to `rpy or rpy2 <http://rpy.sourceforge.net/>`_ the R process does not have to run on the same machine, it can run on a remote machine and all variable  access and function calls will be delegated there through the network.\n        \n        Furthermore - and this makes everything feel very pythonic - all data structures will automatically be converted from native\n        R to native Python types and back.\n        \n        \n        Version history\n        ----------------\n        * V 0.3 (2010-06-08)\n        \n            * Added conversion of more complex R structures into Python\n            * Updated documentation (installation, manual)\n        \n        * V 0.2 (2010-03-19) Fixed rendering of TaggedArrays\n        * V 0.1 (2010-01-10) Initial version\n        \n        \n        Supported Platforms\n        ----------------------------\n        \n        This package has been mainly developed under Linux, and hence should run on all standard unix platforms. It has also been\n        successfully used on Win32 machines. Unittests have only been used on the Linux side, however they might just work\n        fine for Win32.\n        \n        \n        License\n        -------\n        \n        pyRserve has been written by `Ralph Heinkel (www.ralph-heinkel.com) <http://www.ralph-heinkel.com/>`_ and is released under `MIT license <http://packages.python.org/pyRserve/license.html>`_.\n        \n        \n        Quick Installation\n        -------------------\n        Make sure that Numpy is installed.\n        \n        Then from your unix/windows command line run::\n        \n            easy_install pyRserve\n        \n        or download the tar.gz or zip package. After unpacking run `python setup.py install` from your command line.\n        \n        \n        Full Documentation\n        ------------------\n        \n        Documentation can be found at `<http://packages.python.org/pyRserve/>`_."}}, {"pk": 559, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyngram", "license": "MIT", "author": "Jay Liew", "author_email": "twitter.com/jaysern", "project_url": null, "maintainer_email": null, "home_page": "http://jayliew.com", "version": "1.0.1", "platform": "UNKNOWN", "keywords": "ngram,n-gram,bigram,digram,trigram,substitution,cipher,crackme,crypto,caesar,decodeme", "summary": "A simple Python n-gram calculator", "classifiers": "Topic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Security :: Cryptography\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing\nTopic :: Text Processing :: General\nTopic :: Text Processing :: Linguistic\nTopic :: Utilities", "description": "# A simple Python n-gram calculator.\n#\n# Given an arbitrary string, and the value of n as the size of the \n# n-gram (int), this module will show you the results, sorted from \n# most to least frequently occuring n-gram.\n#\n# The 'sort by value' operation for the dict follows the \n# PEP 265 recommendation.\n#\n# Installation: \n#\n# user@host:~$ sudo pip install pyngram\n#\n# Quick start:\n#\n# >>> from pyngram import calc_ngram\n#\n# method expects inputstring as 1st arg, size of n-gram as 2nd arg\n#\n# >>> calc_ngram('bubble bobble, bubble bobble, bubble bobble', 3)\n#\n# or straight from your *nix shell prompt\n#\n# user@host:~$ ./pyngram.py\n# \n# Enjoy!\n#\n# Jay Liew \n# @jaysern\n#"}}, {"pk": 560, "model": "importing.pypicache", "fields": {"maintainer": "Vit Novacek", "name": "eureeka", "license": "", "author": "Vit Novacek", "author_email": "vit.novacek@deri.org", "project_url": null, "maintainer_email": "vit.novacek@deri.org", "home_page": "http://pypi.python.org/pypi/eureeka/0.1", "version": "0.1", "platform": "", "keywords": "AI, knowledge representation, emergent knowledge", "summary": "EUREEKA knowledge store, inference engine and scripts", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: No Input/Output (Daemon)\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Text Processing :: Linguistic", "description": "A proof-of-concept implementation of a novel AI theory of emergent knowledge representation and processing (i.e., meaningful automated representation and processing of noisy, possibly poorly structured knowledge coming from many resources with varyin relevance). Details of the framework are elaborated in a PhD thesis at:\r\n\r\nhttp://140.203.154.209/~vit/resources/2010/pubs/phd-thesis.pdf\r\n\r\nDeveloped under the auspices of Digital Enterprise Research Institute (DERI), National University of Ireland Galway (see http://www.deri.ie)."}}, {"pk": 561, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydot", "license": "MIT", "author": "Ero Carrera", "author_email": "ero@dkbza.org", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/pydot/", "version": "1.0.2", "platform": "any", "keywords": "graphviz dot graphs visualization", "summary": "Python interface to Graphviz's Dot", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Graphviz's dot language Python interface.\n\nThis module provides with a full interface to create handle modify\nand process graphs in Graphviz's dot language.\n\nReferences:\n\npydot Homepage:\thttp://www.dkbza.org/pydot.html\nGraphviz:\thttp://www.research.att.com/sw/tools/graphviz/\nDOT Language:\thttp://www.research.att.com/~erg/graphviz/info/lang.html\n\nProgrammed and tested with Graphviz 1.16 and Python 2.3.4 on GNU/Linux\nby Ero Carrera (c) 2004\t[ero@dkbza.org]\n\nDistributed under MIT license [http://opensource.org/licenses/mit-license.html]."}}, {"pk": 562, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "CGNS", "license": "GPL-3", "author": "Oliver Borm", "author_email": "oli.borm@web.de", "project_url": null, "maintainer_email": "", "home_page": "http://sourceforge.net/projects/python-cgns/", "version": "2009.10.30", "platform": "UNKNOWN", "keywords": "", "summary": "Pythonbindings for CGNS library", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 563, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pycvf", "license": "LGPL3", "author": "pycvf Developers", "author_email": "nouvel@nii.ac.jp", "project_url": null, "maintainer_email": null, "home_page": "http://pycvf.sourceforge.net/", "version": "0.2.1", "platform": "Linux,Unix,Windows,Mac", "keywords": null, "summary": "Python Computer Vision Framework", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "Python Computer Vision Framework"}}, {"pk": 564, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyNomo", "license": "GPL", "author": "Leif Roschier", "author_email": "lefakkomies@users.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://pynomo.org/", "version": "0.2.2", "platform": "OS Independent", "keywords": null, "summary": "PyNomo - Python Nomograms", "classifiers": "Development Status :: 4 - Beta\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 565, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pysofa", "license": "MIT License", "author": "Fr\u00e9d\u00e9ric Grollier", "author_email": "fred.grollier@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/pysofa/", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "", "summary": "Python ctypes wrapper around the SOFA astronomical library", "classifiers": "Development Status :: 4 - Beta\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy", "description": "*pysofa* is a `Python <http://www.python.org/>`_ module for\r\naccessing `International Astronomical Union <http://www.iau.org/>`_'s\r\n`SOFA library <http://www.iausofa.org/>`_ from python. SOFA (Standards\r\nof Fundamental Astronomy) is a set of algorithms and procedures that\r\nimplement standard models used in fundamental astronomy.\r\n\r\n*pysofa* is not a port of SOFA routines but a wrapper around the SOFA_C\r\nlibrary. Thus, no calculations are made into the pysofa software, they are\r\nall delegated to the underlying SOFA_C library.\r\n\r\n*pysofa* is neither distributed, supported nor endorsed by the International\r\nAstronomical Union. In addition to *pysofa*'s license, any use of this module\r\nshould comply with `SOFA's license and terms of use\r\n<http://www.iausofa.org/copyr.pdf>`_. Especially, but not exclusively, any\r\npublished work or commercial products which includes results achieved by using\r\n*pysofa* shall acknowledge that the SOFA software was used in obtaining those\r\nresults."}}, {"pk": 566, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "osurf", "license": "AGPL", "author": "Open Knowledge Foundation", "author_email": "okfn-help@lists.okfn.org", "project_url": null, "maintainer_email": null, "home_page": "http://ordf.org/", "version": "0.2", "platform": "UNKNOWN", "keywords": "rdf rdflib provenance messaging", "summary": "ORDF - SurfRDF back-end", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nFramework :: Pylons\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Affero General Public License v3\nOperating System :: POSIX\nProgramming Language :: Python :: 2.6\nTopic :: Internet\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Open Knowledge Foundation RDF Library - SurfRDF support"}}, {"pk": 567, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "kdb", "license": "GPL", "author": "James Mills", "author_email": "James Mills, prologic at shortcircuit dot net dot au", "project_url": null, "maintainer_email": null, "home_page": "http://shortcircuit.net.au/~prologic/", "version": "0.8.2", "platform": "POSIX", "keywords": "Knowledge Database IRC Bot Framework", "summary": "Knowledge (IRC) Bot", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: No Input/Output (Daemon)\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Communications :: Chat :: Internet Relay Chat\nTopic :: Scientific/Engineering :: Artificial Intelligence", "description": "Knowledge (IRC) Database Bot\n\nkdb is an irc bot that resides on the ShortCircuit IRC\nNetwork and is used as a testbed for testing some aspects\nof the PyMills library. kdb offers an extensible\nplugin architecture and is completely event-driven.\n\nFor more information, come see kdb at\nirc://irc.shortcircuit.net.au#lab\n\n/server irc.shortcircuit.net.au\n/join #lab"}}, {"pk": 568, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pyswip", "license": "", "author": "Yuce Tekol", "author_email": "yucetekol at gmail com", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/pyswip/", "version": "0.2.2", "platform": "", "keywords": "", "summary": "PySWIP enables querying SWI-Prolog in your Python programs.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Prolog\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Libraries :: Python Modules", "description": "PySWIP 0.2.2\r\n============\r\n\r\nPySWIP is a GPL'd Python - SWI-Prolog bridge enabling to query SWI-Prolog\r\nin your Python programs. It features an (incomplete) SWI-Prolog foreign\r\nlanguage interface, a utility class that makes it easy querying with Prolog\r\nand also a Pythonic interface.\r\n\r\nSince PySWIP uses SWI-Prolog as a shared library and ctypes to access it,\r\nit doesn't require compilation to be installed.\r\n\r\nNote that this version of PySWIP is slightly incompatible with 0.1.x versions.\r\n\r\nRequirements:\r\n-------------\r\n\r\n* Python 2.3 and higher.\r\n* ctypes 1.0 and higher.\r\n* SWI-Prolog 5.6.x and higher (most probably other versions will also work).\r\n* libpl as a shared library.\r\n* Works on Linux and Win32, should work for all POSIX.\r\n\r\nNews\r\n----\r\n\r\n* Importing ``pyswip`` automatically initializes SWI-Prolog.\r\n* Fixed a bug with querying lists with the new interface.\r\n\r\nExample (Using Prolog):\r\n-----------------------\r\n\r\n    >>> from pyswip import Prolog\r\n    >>> prolog = Prolog()\r\n    >>> prolog.assertz(\"father(michael,john)\")\r\n    >>> prolog.assertz(\"father(michael,gina)\")\r\n    >>> list(prolog.query(\"father(michael,X)\"))\r\n    [{'X': 'john'}, {'X': 'gina'}]\r\n    >>> for soln in prolog.query(\"father(X,Y)\"):\r\n    ...     print soln[\"X\"], \"is the father of\", soln[\"Y\"]\r\n    ...\r\n    michael is the father of john\r\n    michael is the father of gina\r\n\r\nSince version 0.1.3 of PySWIP, it is possible to register a Python function as \r\na Prolog predicate through SWI-Prolog's foreign language interface.\r\n\r\nExample (Foreign Functions):\r\n----------------------------\r\n    \r\n    from pyswip import Prolog, registerForeign\r\n\r\n    def hello(t):\r\n        print \"Hello,\", t\r\n    hello.arity = 1\r\n\r\n    registerForeign(hello)\r\n\r\n    prolog = Prolog()\r\n    prolog.assertz(\"father(michael,john)\")\r\n    prolog.assertz(\"father(michael,gina)\")    \r\n    list(prolog.query(\"father(michael,X), hello(X)\"))\r\n\r\nOutputs:\r\n    Hello, john\r\n    Hello, gina\r\n\r\nSince version 0.2, PySWIP contains a 'Pythonic' interface which allows writing \r\npredicates in pure Python (*Note that interface is experimental.*)\r\n\r\nExample (Pythonic interface):\r\n-----------------------------\r\n\r\n    from pyswip import Functor, Variable, Query, call\r\n\r\n    assertz = Functor(\"assertz\", 1)\r\n    father = Functor(\"father\", 2)\r\n\r\n    call(assertz(father(\"michael\",\"john\")))\r\n    call(assertz(father(\"michael\",\"gina\")))\r\n\r\n    X = Variable()\r\n    q = Query(father(\"michael\",X))\r\n    while q.nextSolution():\r\n        print \"Hello,\", X.value\r\n\r\nOutputs:\r\n    Hello, john\r\n    Hello, gina"}}, {"pk": 569, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pytaylor", "license": "GPLv2", "author": "Jorn Baayen", "author_email": "", "project_url": null, "maintainer_email": "", "home_page": "http://gitorious.org/projects/pytaylor", "version": "0.1", "platform": "", "keywords": "", "summary": "Taylor models in Python", "classifiers": "Topic :: Scientific/Engineering :: Mathematics", "description": ""}}, {"pk": 570, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.plugins.grads", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/plugins/grads.html", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "grads grib dap opendap dods data", "summary": "GrADS/GRIB plugin for pydap server", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This is a plugin for serving data in a pydap server from GrADS/GRIB files.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/plugins/grads#egg=dap.plugins.grads-dev>`_."}}, {"pk": 571, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MSGNative", "license": "GNU GPL", "author": "Mario Cruz", "author_email": "duartecruz@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.projectfailure.org/msgnative", "version": "0.9.1", "platform": "UNKNOWN", "keywords": null, "summary": "MSG Native Format Support", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering :: Atmospheric Science", "description": "Provides access to the data and metadata from Meteosat Second Generation (MSG) Level 1.5 Native Format files."}}, {"pk": 572, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "glycomesite.theme", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://glycans.jpl.nasa.gov/", "version": "1.0.0", "platform": "UNKNOWN", "keywords": "web zope plone theme glycome glycomics glycans", "summary": "Basic look-and-feel for the GLYCANS websites", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Medical Science Apps.", "description": "Introduction\n============\n\nThis is the basic look-and-feel for the websites of the Alliance of\nGlycobiologists united for the detection of cancer and the detection of cancer\nrisk.\n\n\n===========\n Changelog\n===========\n\n0.0.0 - Unreleased\n------------------\n\n* Initial release"}}, {"pk": 573, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "oice.langdet", "license": "GPL 3.0", "author": "Universidad de las Ciencias Inform\u00e1ticas", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": "", "home_page": "http://www.uci.cu/", "version": "1.0dev-r781", "platform": "UNKNOWN", "keywords": "", "summary": "Automatic Language Detector", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "Language Detector\r\n-----------------\r\n\r\nThis is a simple (yet powerful) automatic language detector. Currently\r\nthe only languages we are capable to detect are:\r\n\r\n* English\r\n* Spanish\r\n* French\r\n\r\nInstallation and Usage\r\n----------------------\r\n\r\nTo install just run the easy_install_ tool::\r\n\r\n    easy_install oice.langdet\r\n\r\n.. _easy_install: http://peak.telecommunity.com/DevCenter/EasyInstall\r\n\r\nThis will install a console script ``langdet``. Run ``langdet``\r\npassing a plain text filename as the first parameter. Examples::\r\n\r\n    langdet simple.txt\r\n\r\nThis will return the 2-letters `ISO 639-1`_ code of\r\nthe detected language.\r\n\r\n.. _ISO 639-1: http://en.wikipedia.org/wiki/ISO_639\r\n\r\nYou may also use ``oice.langdet`` in Python scripts like this::\r\n\r\n    #!/usr/bin/env python2.5\r\n    from StringIO import StringIO\r\n\r\n    from oice.langdet import langdet\r\n    from oice.langdet import streams\r\n    from oice.langdet import languages\r\n\r\n    text = streams.Stream(StringIO(u\"Must be a Python Unicode text\"))\r\n    lang = langdet.LanguageDetector.detect(text)\r\n    if lang == languages.spanish:\r\n        print u'Texto en espa\u00f1ol'\r\n    elif lang == languages.english:\r\n        print u'English text'\r\n    else:\r\n        print u'France' # I don't speak/write French\r\n\r\nCaveats\r\n~~~~~~~\r\n\r\nCurrently there are some restrictions:\r\n\r\n* ``langdet`` does not work properly with standard input nor\r\n  pipelines.\r\n\r\n* You cannot use a file-like object directly with\r\n  ``LanguageDetector``, i.e, you must use the ``Stream`` wrapper.\r\n\r\n  This is so because we try to guess the text encoding and normalize\r\n  it to a Python Unicode String. However, we plan to remove this\r\n  normalization step and count the frequency of octets and pairs of\r\n  octets instead.\r\n\r\n* If the piece of text is not written in any of the languages we can\r\n  detect, the best match (see `How it works`_) is selected.\r\n\r\nWork in progress\r\n~~~~~~~~~~~~~~~~\r\n\r\nIn a sentence: trying to solve the first two caveats, and thinking in\r\nPython 2.6 and Python 3.0.\r\n\r\n\r\nHow it works\r\n------------\r\n\r\nLanguage detection is based on stats on the frequency of letters and\r\npairs of letters of the input text.\r\n\r\nThe modules in the package ``oice.language.languages`` contains a\r\n\"footprint\" of text in those languages.\r\n\r\nThe texts used in the generation of the footprints were:\r\n\r\n* El ingenioso hidalgo Don Quijote de la Mancha\r\n\r\n* The Holly Bible\r\n\r\n* La Folle Journ\u00e9e, ou Le Mariage de Figaro\r\n\r\nWhen trying to detect the language of some piece of text, first we\r\ncount the frequencies of letters and pairs of letters in the text and\r\nthen compare the results with the footprints of those language, the\r\nbest match is selected.\r\n\r\nWe use the simple `cosine similarity`__ equation to compare the text\r\nwith the footprints of those texts.\r\n\r\n__ `Cosine Similarity Wikipedia`_\r\n\r\n.. _Cosine Similarity Wikipedia: http://en.wikipedia.org/wiki/Cosine_similarity\r\n\r\n\r\nAccuracy of the detection\r\n-------------------------\r\n\r\nTo test the accuracy of this implementation we downloaded the full\r\n`European Parliament Proceedings Parallel Corpus 1996-2006`__ and ran\r\nthe `langdet` script to the sets of English, Spanish and French\r\ndocuments.\r\n\r\n__ http://www.statmt.org/europarl/\r\n\r\nFor each language we count the times the correct `ISO 639-1`_ code was\r\nreturned by `langdet` like this (for counting documents detected as\r\nSpanish written)::\r\n\r\n    find -type f -exec langdet {} \\; | grep es | wc -l\r\n\r\nThe results are summarized in the following table:\r\n\r\n.. table:: Summary of accuracy test for ``langdet``\r\n\r\n ============= ======= ======= ====== ===========\r\n Real language English Spanish French Errors [1]_\r\n ============= ======= ======= ====== ===========\r\n English       98.78%  0%      0%     1.22%\r\n Spanish       0%      100%    0%     0%\r\n French        0%      0%      100%   0%\r\n Danish        1.22%   16.08%  82.7%  0%\r\n German        1.97%   0.15%   97.88% 0%\r\n Finnish       0.65%   5.9%    93.45% 0%\r\n Italian       0%      99.54%  0.46%  0%\r\n ============= ======= ======= ====== ===========\r\n\r\n.. [1] Errors are generally produced when the detector cannot guess\r\n       the encoding of the input text.\r\n\r\n       In `Caveats`_ we propose a solution for this, however, it is\r\n       not clear the impact in the accuracy of detection.\r\n\r\nThe results shows that for documents in the languages that ``langdet``\r\ncan detect, ``langdet`` behaves almost perfect.\r\n\r\nHowever, the results for documents in other languages show how\r\nmisleading ``langdet`` could be in such cases. We ran those test for\r\nillustration purposes only.\r\n\r\nNevertheless this results also shows that it would be very difficult\r\nfor this simple algorithm to distinguish Spanish from Italian, and\r\nFrench from German."}}, {"pk": 574, "model": "importing.pypicache", "fields": {"maintainer": "Shiva Iyer", "name": "pykepler", "license": "GNU GPL v3.0 or later", "author": "Shiva Iyer", "author_email": "", "project_url": null, "maintainer_email": "", "home_page": "http://savannah.nongnu.org/projects/kepler", "version": "1.0", "platform": "", "keywords": "", "summary": "kepler is a library of routines for astronomical calculations. The library is implemented in ANSI C and the optional pykepler package provides support for programs written in Python.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "* The entire VSOP87 theory for calculating the positions of the eight planets.\r\n* The entire ELP 2000-82B theory for calculating the position of the Moon.\r\n* An analytical theory for calculating Pluto's position for the period 1700AD-2100AD.\r\n* The ability to convert osculating orbital elements to heliocentric coordinates.\r\n* A parser for MPCORB, the MPC Orbit Database.\r\n* The latest IAU 2006 precession and IAU 2000A nutation models.\r\n* Routines for calculating sidereal time using the current IAU resolutions.\r\n* An implementation of the Ron/Vondrak theory of annual aberration.\r\n* Routines for Julian date calculations.\r\n* Routines for coordinate transformations, rotations and parallax corrections."}}, {"pk": 575, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "spyder", "license": "MIT", "author": "Pierre Raybaut", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": null, "home_page": "http://spyderlib.googlecode.com", "version": "2.0.8", "platform": "any", "keywords": "PyQt4 editor shell console widgets IDE", "summary": "Scientific PYthon Development EnviRonment", "classifiers": "Development Status :: 5 - Production/Stable\nLicense :: OSI Approved :: MIT License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Widget Sets", "description": "The spyderlib module provides powerful console and\r\n        editor related widgets to your PyQt4 application. It also includes a\r\n        Scientific Python development environment named 'Spyder', an alternative to\r\n        IDLE with powerful interactive features such as variable explorer (with\r\n        GUI-based editors for dictionaries, lists, NumPy arrays, etc.), object\r\n        inspector, online help, and a lot more."}}, {"pk": 576, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Coopr", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/coopr", "version": "2.5.3890", "platform": "any", "keywords": "optimization", "summary": "Coopr: a COmmon Optimization Python Repository", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "============\nCoopr README\n============\n\nThe Coopr software project integrates a variety of Python\noptimization-related packages.  Coopr supports a diverse set of\noptimization capabilities that can be used formulate and analyze\noptimization applications:\n\n* Pyomo: Formulate algebraic models within Python's modern programming language\n* PySP: Generic solvers for stochastic programming problems\n* COLIN: Scripts that simplify IO between optimizers and black-box applications\n* SUCASA: Customize MIP solvers to expose model structure to the MIP solver engine \n\nThis is the main Coopr package, which simply creates a requirement that\nother Coopr packages are imported.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * coopr-forum@googlegroups.com\n    - The main list for help and announcements\n  * coopr-developers@googlegroups.com\n    - Where developers of Coopr discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 577, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ctypes-opencv", "license": "New BSD License", "author": "Minh-Tri Pham", "author_email": "pmtri80@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/ctypes-opencv/", "version": "0.8.0", "platform": "OS Independent,Windows,Linux,MacOS", "keywords": null, "summary": "ctypes-opencv - A Python wrapper for OpenCV using ctypes", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nTopic :: Multimedia :: Graphics\nTopic :: Multimedia :: Video\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: Libraries :: Python Modules", "description": "ctypes-opencv is a package that brings Intel's (now Willow Garage's) Open Source Computer Vision Library (OpenCV) to Python. OpenCV is a collection of algorithms and sample code for various computer vision problems. The goal of ctypes-opencv is to provide Python access to all documented functionality of OpenCV."}}, {"pk": 578, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyncomb", "license": "Apache 2.0", "author": "Sebastian Raaphorst", "author_email": "srcoding@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.site.uottawa.ca/~mraap046", "version": "1.0.2", "platform": "UNKNOWN", "keywords": "mathematics combinatorics permutations combinations subsets", "summary": "PYthoN COMBinatorics library", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: Apache Software License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "The pyncomb (PYthoN COMBinatorics) library is a collection of\n          functions to work with basic combinatorial objects (e.g. permutations,\n          subsets, tuples), and provides algorithms for ranking, unranking, and\n          iterating over all objects in a specified class.\n\n          1.0.2: Updated import statements to be Python 3 compatible.\n          1.0.1: Attempting to fix mysterious bug regarding imports.\n          1.0.0: Initial release."}}, {"pk": 579, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "BioNEB", "license": "MIT", "author": "Paul Joseph Davis", "author_email": "davisp@neb.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/davisp/bioneb", "version": "0.4", "platform": "UNKNOWN", "keywords": null, "summary": "BioNEB - Bioinformatics utilities", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "BioNEB - A collection of various parsers and other odds and ends I might\nend up writing."}}, {"pk": 580, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pyQPCR", "license": "GPLv3", "author": "Thomas Gastine", "author_email": "thomas.gastine@wanadoo.fr", "project_url": null, "maintainer_email": "", "home_page": "http://pyqpcr.sourceforge.net", "version": "0.7", "platform": "any", "keywords": "PCR", "summary": "pyQPCR: quantitative PCR data analysis", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Medical Science Apps.", "description": "pyQPCR is a GUI application that computes quantitative PCR (QPCR) raw data. Using quantification cycle values extracted from QPCR instruments, it uses a proven and universally applicable model (Delta-delta ct method) to give finalized quantification results."}}, {"pk": 581, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "SimpleHist", "license": "Copyright (c) 2011 Nicholas Devenish <n.e.devenish@sussex.ac.uk>\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in\r\nall copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\r\nTHE SOFTWARE.", "author": "Nicholas Devenish", "author_email": "n.e.devenish@sussex.ac.uk", "project_url": null, "maintainer_email": "", "home_page": "https://github.com/ndevenish/simplehistogram", "version": "0.1", "platform": "UNKNOWN", "keywords": "histogram", "summary": "Simple histogram classes, designed for data manipulation", "classifiers": "Development Status :: 2 - Pre-Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "SimpleHist\r\n==========\r\n\r\n:Description: A very simple ndarray-based histogram class.\r\n:Author:      Nicholas Devenish\r\n\r\nOverview\r\n--------\r\n\r\nMatplotlib histograms are geared around drawing, not\r\ndata manipulation. Numpy direct support for histograms is\r\nextremely limited, and not very different from matpotlib.\r\nThis is intended to turn into a set of very lightweight classes\r\nfor shuffling data around. This is very much a work-in-progress.\r\n\r\nThe only required depenency is numpy, and the package is designed\r\nto work for python >= 2.6\r\n\r\nUsage\r\n-----\r\n\r\nA summary of usage, taken from the hists.py docstring follows:\r\n\r\nImporting:\r\n  >>> from simplehist import Hist\r\n\r\nInitialise with bin indices:\r\n  >>> a = Hist([0, 1, 2, 3])\r\n  >>> a.bincount\r\n  3\r\n  >>> a.bins\r\n  (0, 1, 2, 3)\r\n  >>> a.data\r\n  array([ 0.,  0.,  0.])\r\n\r\nOptionally include data:\r\n  >>> a = Hist([0, 1, 2, 3], data=[1, 0.2, 3])\r\n  >>> a.data\r\n  array([ 1. ,  0.2,  3. ])\r\n\r\nOr just specify the blank data type:\r\n  >>> a = Hist([0, 1, 2, 3], dtype=int)\r\n  >>> a.data\r\n  array([0, 0, 0])\r\n\r\nYou can do arithmetic operations in place or seperately:\r\n  >>> a = Hist([0, 1, 2, 3], data=[1, 0.2, 3])\r\n  >>> b = a + a\r\n  >>> b -= a\r\n  >>> a.data == b.data\r\n  array([ True,  True,  True], dtype=bool)  \r\n\r\nAnd you can fill bins from values:\r\n  >>> a = Hist([0,1,2,3])\r\n  >>> a.fill(1.4, weight=3)\r\n  >>> a.data\r\n  array([ 0.,  3.,  0.])\r\n\r\nEven out of range:\r\n  >>> a = Hist([0,1])\r\n  >>> a.fill(-10)\r\n  >>> a.underflow\r\n  1.0\r\n\r\nIf you use pyROOT, you can convert from 1D histograms:\r\n  >>> type(source)\r\n  <class 'ROOT.TH1D'>\r\n  >>> convert = fromTH1(source)\r\n  >>> type(convert)\r\n  <class 'simplehist.hists.Hist'>\r\n\r\nAnd you can draw histograms, using any of the options\r\nthat can be passed to matplotlib.pyplot.hist:\r\n\r\n  >>> hist_object.draw_hist(lw=2)"}}, {"pk": 582, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "kunyittst", "license": "LGPL", "author": "Vee Satayamas", "author_email": "vsatayamas@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/kunyittst/", "version": "0.0.1", "platform": "UNKNOWN", "keywords": null, "summary": "A pure Python ternary search tree library", "classifiers": "Development Status :: 2 - Pre-Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Text Processing", "description": "A pure Python ternary search tree library"}}, {"pk": 583, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "python-nexus", "license": "BSD", "author": "Simon Greenhill", "author_email": "simon@simon.net.nz", "project_url": null, "maintainer_email": null, "home_page": "http://simon.net.nz/articles/python-nexus", "version": "0.8", "platform": "UNKNOWN", "keywords": "phylogenetics nexus newick paup splitstree", "summary": "A generic nexus (phylogenetics) file format (.nex, .trees) reader for python", "classifiers": "Intended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 584, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Traits", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/traits", "version": "3.6.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Explicitly typed attributes for Python.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The Traits project is at the center of all Enthought Tool Suite development\nand has changed the mental model used at Enthought for programming in the\nalready extremely efficient Python programming language. We encourage everyone\nto join us in enjoying the productivity gains from using such a powerful\napproach.\n\nThe Traits project allows Python programmers to use a special kind of type\ndefinition called a *trait*, which gives object attributes some additional\ncharacteristics:\n\n- **Initialization**: A trait has a *default value*, which is\n  automatically set as the initial value of an attribute before its\n  first use in a program.\n- **Validation**: A trait attribute's type is *explicitly declared*. The\n  type is evident in the code, and only values that meet a\n  programmer-specified set of criteria (i.e., the trait definition) can\n  be assigned to that attribute.\n- **Delegation**: The value of a trait attribute can be contained either\n  in the defining object or in another object *delegated* to by the\n  trait.\n- **Notification**: Setting the value of a trait attribute can *notify*\n  other parts of the program that the value has changed.\n- **Visualization**: User interfaces that allow a user to *interactively\n  modify* the value of a trait attribute can be automatically\n  constructed using the trait's definition. (This feature requires that\n  a supported GUI toolkit be installed. If this feature is not used, the\n  Traits project does not otherwise require GUI support.)\n\nA class can freely mix trait-based attributes with normal Python attributes,\nor can opt to allow the use of only a fixed or open set of trait attributes\nwithin the class. Trait attributes defined by a classs are automatically\ninherited by any subclass derived from the class.\n\nPrerequisites\n-------------\nYou must have the following libraries installed before building or installing\nTraits:\n\n* `Numpy <http://pypi.python.org/pypi/numpy/1.1.1>`_ to support the trait types\n  for arrays. Version 1.1.0 or later is preferred. Version 1.0.4 will work, but\n  some tests may fail.\n* `setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_"}}, {"pk": 585, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "garlicsim_lib_py3", "license": "LGPL v2.1", "author": "Ram Rachum", "author_email": "cool-rr@cool-rr.com", "project_url": null, "maintainer_email": null, "home_page": "http://garlicsim.org", "version": "0.6.2", "platform": "UNKNOWN", "keywords": null, "summary": "Collection of GarlicSim simulation packages", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nProgramming Language :: Python :: 3.2\nTopic :: Scientific/Engineering", "description": "Collection of GarlicSim simulation packages, for various scientific fields.\n\nTo be used with `garlicsim`.\n\nVisit http://garlicsim.org for more info."}}, {"pk": 586, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "astLib", "license": "UNKNOWN", "author": "Matt Hilton", "author_email": "mattyowl@users.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://astlib.sourceforge.net", "version": "0.4.0", "platform": "UNKNOWN", "keywords": null, "summary": "A set of python modules for producing simple plots, statistics, common calculations, coordinate conversions, and manipulating FITS images with World Coordinate System (WCS) information.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Software Development :: Libraries", "description": "astLib is a set of Python modules that provides some tools for research astronomers. It can be\n    used for simple plots, statistics, common calculations, coordinate conversions, and manipulating FITS images\n    with World Coordinate System (WCS) information through PyWCSTools - a simple wrapping of WCSTools by Doug Mink.\n    PyWCSTools is distributed (and developed) as part of astLib."}}, {"pk": 587, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.audiolab", "license": "LGPL", "author": "David Cournapeau", "author_email": "cournape@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://cournape.github.com/audiolab", "version": "0.11.0", "platform": "UNKNOWN", "keywords": null, "summary": "A python module to make noise from numpy arrays", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nTopic :: Multimedia :: Sound/Audio\nTopic :: Scientific/Engineering", "description": "Audiolab is a python package for audio file IO using numpy arrays. It supports\nmany different audio formats, including wav, aiff, au, flac, ogg, htk. It also\nsupports output to audio device (Mac OS X and Linux only).\n\nFor simplicity, a matlab-like API is provided for simple import/export; a more\ncomplete API is also available.\n\nAudiolab is essentially a wrapper around Erik de Castro Lopo's excellent\nlibsndfile:\n\nhttp://www.mega-nerd.com/libsndfile/\n\nLICENSE: audiolab is licensed under the LGPL, as is libsndfile itself. See\nCOPYING.txt for details.  \n\n2006-2008, David Cournapeau"}}, {"pk": 588, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.seishub", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.7", "platform": "OS Independent", "keywords": "ObsPy,seismology,SeisHub", "summary": "SeisHub database client for ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.seishub package contains a client for the seismological database\nSeisHub (http://www.seishub.org).\n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology. \n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 589, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyVTK", "license": "LGPL", "author": "Pearu Peterson", "author_email": "pearu@cens.ioc.ee", "project_url": null, "maintainer_email": null, "home_page": "http://cens.ioc.ee/projects/pyvtk/", "version": "0.4.67", "platform": "All", "keywords": "VTK", "summary": "PyVTK - tools for manipulating VTK files in Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Visualization", "description": "PyVTK provides tools for manipulating VTK (Visualization Toolkit)\nfiles in Python:\n  VtkData - create VTK files from Python / read VTK files to Python."}}, {"pk": 590, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Delny", "license": "GNU General Pucblic License (GPL)", "author": "Floris Bruynooghe", "author_email": "floris.bruynooghe@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://flub.stuffwillmade.org/delny", "version": "0.4.1", "platform": "any", "keywords": "delaunay,qhull,geometry,triangulation", "summary": "Delaunay triangulation", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: DFSG approved\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "Python package to create N-dimensional Delaunay triangulations.  It\nuses the libqhull library from the Qhull_ project for the\ntriangulation so a proven algorithm is used.\n\n.. _Qhull: http://www.qhull.org"}}, {"pk": 591, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyphylip", "license": "MIT", "author": "Alex Griffing", "author_email": "UNKNOWN", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/pyphylip", "version": "0.0.2", "platform": "UNKNOWN", "keywords": null, "summary": "a python module to read and write phylip alignment files", "classifiers": "Development Status :: 3 - Alpha\nNatural Language :: English\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "About pyphylip\n==============\n\nRead and write files in the phylip sequence format_.\n\n\nInstallation\n============\n\nBecause pyphylip has been packaged for pypi,\nit can be installed using::\n\n    $ pip install pyphylip\n\n\nUsage\n=====\n\nDecode a phylip sequence file given a source of lines in the file::\n\n    >>> with open('infile.phy') as f:\n    ...     headers, sequences = pyphylip.decode(f)\n\nEncode some headers and corresponding sequences as a phylip sequence file::\n\n    >>> with open('outfile.phy', 'w') as f:\n    ...     f.write(pyphylip.encode(headers, sequences) + '\\n')\n\n\n.. _format: http://evolution.genetics.washington.edu/phylip/doc/sequence.html"}}, {"pk": 592, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pycddlib", "license": "GPL", "author": "Matthias Troffaes", "author_email": "matthias.troffaes@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/pycddlib", "version": "1.0.3", "platform": "any", "keywords": "convex,polyhedron,linear programming,double description method", "summary": "pycddlib is a Python wrapper for Komei Fukuda's cddlib.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: Cython\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering :: Mathematics", "description": "`cddlib <http://www.ifor.math.ethz.ch/~fukuda/cdd_home/cdd.html>`_ is\nan implementation of the Double Description Method of Motzkin et\nal. for generating all vertices (i.e. extreme points) and extreme rays\nof a general convex polyhedron given by a system of linear\ninequalities.\n\nThe program also supports the reverse operation (i.e. convex hull\ncomputation). This means that one can move back and forth between an\ninequality representation and a generator (i.e. vertex and ray)\nrepresentation of a polyhedron with cdd.  Also, it can solve a linear\nprogramming problem, i.e. a problem of maximizing and minimizing a\nlinear function over a polyhedron.\n\n* Download: http://pypi.python.org/pypi/pycddlib/#downloads\n\n* Documentation: http://packages.python.org/pycddlib/\n\n* Development: http://github.com/mcmtroffaes/pycddlib/"}}, {"pk": 593, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "lazyrunner", "license": "UNKNOWN", "author": "Hoyt Koepke", "author_email": "hoytak@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.stat.washington.edu/~hoytak/code/lazyrunner/", "version": "0.01v3", "platform": "UNKNOWN", "keywords": null, "summary": "LazyRunner: Module based scientific experiment framework with lazy evaluation.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "UNKNOWN"}}, {"pk": 594, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "python-consume", "license": "BSD", "author": "Michael Billmire", "author_email": "mgbillmi@mtu.edu", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/python-consume", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "kml", "summary": "Python port of Consume, a software program developed by the USFS that calculates consumption and emissions from wildland fires", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==============\nPython-Consume\n==============\nPython-Consume is a Python package that is a port of Consume 3.0, a software \nprogram developed by the USFS that calculates consumption and emissions from \nwildland fires.\n\nConsume 3.0 was developed and designed originally in Java by US Forest \nService Fire and Environmental Research Applications (FERA) team.\n\nThis is a recoded version (2010) developed by Michigan Tech Research\nInstitute (MTRI) in consultation with FERA.  This version was developed\nfor use in MTRI's Wildfire Emissions Information System (WFEIS) \n(wfeis.mtri.org), but was also designed to include more user-friendly\nshell-based analysis options.\n\nDuring the recoding process, several errors were identified in the original\nConsume 3.0 source code, but were fixed (via consultation with original\ndevelopers Roger Ottmar and Susan Prichard) for this version. For this reason,\nresults from this version will not always align with results from the official\nConsume 3.0 GUI version of the software. Notable errors include:\n\n1. incorrect calculation of 'duff' reduction (p. 182 in the Consume 3.0)\n2. a bug that interchanges 'squirrel midden' density and radius when FCCS\n   values are loaded\n3. a typo that incorrectly calculates pm2.5 emissions from 'canopy'\n   consumption (thus influencing total pm2.5 emissions values as well)\n\n*For users familiar with the original Consume 3.0 GUI software, see the \nnotes section below for functionality and operational differences between\nthis version and the original.*\n\nReferences:\n\n* CONSUME: http://www.fs.fed.us/pnw/fera/research/smoke/consume/index.shtml\n* FCCS: http://www.fs.fed.us/pnw/fera/fccs/\n* FERA: http://www.fs.fed.us/pnw/fera/F\n* MTRI: http://www.mtri.org\n\nRequirements:\n\n* Python 2.4 or above (free from http://www.python.org)\n* numpy package (free from http://np.scipy.org/)\n\nFor questions/comments, contact:\n\n* Michael G. Billmire mgbillmi@mtu.edu\n* Tyler A. Erickson taericks@mtu.edu\n\n------------\nDependencies\n------------\n* Python 2.4 or above \n* python-numpy (free from http://np.scipy.org/)\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nNotes for users familiar with the original Consume 3.0 GUI software\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* This version relies entirely on FCCS fuelbed data and does NOT use SAF/SRM\n  cover type data except in the background for selecting the correct emissions\n  factor groups to use from a link table provided by FERA.\n* *Heat release* output is coupled with consumption outputs.\n* Instead of selecting a specific ecoregion from Bailey's set, this version only\n  requires the user to specify whether the fuelbed is located in *western*, \n  *boreal*, or *southern* regions. See the original Consume 3.0 User's Manual\n  to view which Bailey's ecoregions fit into these broader categories. \n\n------------\nInstallation\n------------\nPython-Consume can be installed from the Python Package Index, using either \neasy_install or pip:\n\n  $ sudo easy_install python-consume\n\nor\n\n  $ sudo pip install python-consume\n\nThe installation can be tested by running the following:\n\n  $ nosetests -s --with-coverage\n\n-------------------------------------------\nUsage\n-------------------------------------------\n\n(See next section for a complete, uninterrupted example...)\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nGetting Started with the Fuel Consumption Object\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nOpen a Python shell program (e.g. IDLE, ipython, etc.).\nImport the module:\n\n>>> from consume import consume\n\nDeclare a Consume FuelConsumption object:\n\n>>> fc_obj = consume.FuelConsumption()\n\n\n*Note: if the .xml fuel loading database is located somewhere other than\nthe default location, user can specify this using the 'fccs_file' argument,\ne.g.:\nfc_obj = consume.FuelConsumption(fccs_file=\"C:/Documents/FCCSLoadings.xml\")*\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nSETTING INPUT PARAMETERS\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThere are a number of alternative options for setting input values:\n\n1.  Start a program that will prompt the user for inputs:\n    >>> fc_obj.prompt_for_inputs()\n\n2.  Load inputs from a pre-formatted csv file (see example file:\n    \"consume_inputs_example.csv\" for correct formatting):\n    \n    >>> fc_obj.load_scenario(\"myscenario.csv\")\n    \n    OR to load, calculate outputs, and store outputs at once, use the\n    batch_process method:\n    \n    >>> fc_obj.batch_process(\"myscenario.csv\", \"myoutputs.csv\")\n\n3.  Individually set/change input values manually:\n    \n    >>> fc_obj.burn_type = <'natural' or 'activity'>\n    >>> fc_obj.fuelbed_fccs_ids = [FCCSID#1,FCCSID#2,...]\n    >>> fc_obj.fuelbed_area_acres = [AREA#1,AREA#2,...]\n    >>> fc_obj.fuelbed_ecoregion = [ECOREGION#1, ECOREGION#2,...]\n    >>> fc_obj.fuel_moisture_1000hr_pct = [1000hrFM#1, 1000hrFM#2,...]\n    >>> fc_obj.fuel_moisture_duff_pct = [DuffFM#1, DuffFM#2, ...]\n    >>> fc_obj.canopy_consumption_pct = [PctCan#1, PctCan#2,...]\n    >>> fc_obj.shrub_blackened_pct = [PercentShrub#1, PercentShrub#2,...]\n\n    inputs specific to 'activity' burns:\n    \n    >>> fc_obj.fuel_moisture_10hr_pct = [10HourFM#1, 10HourFM#2, ...]\n    >>> fc_obj.slope = [Slope#1, Slope#2, ...]\n    >>> fc_obj.windspeed = [Windspeed#1, Windspeed#2, ...]\n    >>> fc_obj.fm_type = <'MEAS-Th', 'ADJ-Th', or 'NFDRS-Th'>\n    >>> fc_obj.days_since_rain = [Days#1, Days#2, ...]\n    >>> fc_obj.lengthOfIgnition = [Length#1, Length#2, ...]\n\n\n    *Note: When setting input values, the user can also select a SINGLE \n    value (instead of a list) for any environment variable that will \n    apply to the entire scenario.\n    These environment variables include the following:\n    ecoregion, fuel_moisture_1000hr_pct,  fuel_moisture_duff_pct, \n    canopy_consumption_pct, shrub_blackened_pct, slope, windpseed, \n    fm_type, days_since_rain, lengthOfIgnition*\n\nDescription of the input parameters:\n\nburn_type\n    Use this variable to select 'natural' burn equations or \n    'activity' (i.e. prescribed) burn equations. Note that\n    'activity' burns require 6 additional input parameters:\n    10hr fuel moisture, slope, windpseed, fuel moisture type,\n    days since significant rainfall, and length of ignition.\n    \nfuelbed_fccs_ids\n    a list of Fuel Characteristic Classification System (FCCS)\n    (http://www.fs.fed.us/pnw/fera/fccs/index.shtml) fuelbed ID\n    numbers (1-291).  Use the .FCCS.browse() method to load a list\n    of all FCCS ID#'s and their associated site names. Use \n    .FCCS.info(id#) to get a site description of the\n    specified FCCD ID number. To get a complete listing of fuel\n    loadings for an FCCS fuelbed, use: \n    .FCCS.info(id#, detail=True)\n\nfuelbed_area_acres\n    a list (or single number to be used for all fuelbeds) of\n    numbers in acres that represents area for the corresponding\n    FCCS fuelbed ID listed in the 'fuelbeds_fccs_ids' variable.\n\nfuelbed_ecoregion\n    a list (or single region to be used for all fuelbeds) of\n    ecoregions ('western', 'southern', or 'boreal') that\n    represent the ecoregion for the corresponding FCCS fuelbed ID\n    listed in the 'fuelbeds_fccs_ids' variable. Regions within the\n    US that correspond to each broad regional description can be\n    found in the official Consume 3.0 User's Guide, p. 60. Further\n    info on Bailey's ecoregions can be found here:\n    www.eoearth.org/article/Ecoregions_of_the_United_States_(Bailey)\n    Default is 'western'\n\nfuel_moisture_1000hr_pct\n    1000-hr fuel moisture in the form of a number or list of\n    numbers ranging from 0-100 representing a percentage.\n    Default is 50%\n\nfuel_moisture_10hr_pct\n    <specific to 'activity' burns>\n    10-hr fuel moisture in the form of a number or list of\n    numbers ranging from 0-100 representing a percentage.\n    Default is 50%\n\nfuel_moisture_duff_pct\n    Duff fuel moisture. A number or list of numbers ranging from\n    0-100 representing a percentage.\n    Default is 50%.\n\ncanopy_consumption_pct\n    Percent canopy consumed. A number or list of numbers ranging\n    from 0-100 representing a percentage. Set to '-1' to\n    use an FCCS-fuelbed dependent precalculated canopy consumption\n    percentage based on crown fire initiation potential, crown to\n    crown transmissivity, and crown fire spreading potential.\n    (note: auto-calc is not available for FCCS ID's 401-456)\n    Default is -1\n\nshrub_blackened_pct\n    Percent of shrub that has been blackened. A number or list\n    of numbers ranging from 0-100 representing a percentage.\n    Default is 50%\n\nslope\n    <specific to 'activity' burns>\n    Percent slope of a fuelbed unit. Used in predicting 100-hr\n    (1-3\" diameter) fuel consumption in 'activity' fuelbeds.\n    Valid values: a number or list of numbers ranging from 0-100\n    representing a percentage.\n    Default is 5%\n\nwindspeed\n    <specific to 'activity' burns>\n    Mid-flame wind speed (mph) during the burn. Maximum is 35 mph.\n    Used in predicting 100-hr (1-3\" diameter) fuel consumption in \n    'activity' fuelbeds.\n    Default is 5 mph\n\nfm_type\n    <specific to 'activity' burns>\n    Source of 1000-hr fuel moisture data.\n        \n        * \"Meas-Th\" (default) : measured directly\n        * \"NFDRS-Th\" : calculated from NFDRS\n        * \"ADJ-Th\" : adjusted for PNW conifer types\n    \n    Note: 1000-hr fuel moisture is NOT calculated by Consume, \n    i.e. user must derive 1000-hr fuel moisture & simply select\n    the method used.\n\ndays_since_rain\n    <specific to 'activity' burns>\n    Number of days since significant rainfall. According to the\n    Consume 3.0 User's Guide, \"Significant rainfall is one-quarter\n    inch in a 48-hour period.\" Used to predict duff consumption\n    in 'activity' fuelbeds.\n\nlengthOfIgnition\n    <specific to 'activity' burns>\n    The amount of time (minutes) it will take to ignite the area\n    to be burned. Used to determine if a fire will be of high \n    intensity, which affects diameter reduction of large woody\n    fuels in 'activity' fuelbeds.\n\nThe user can also optionally set alternate output units. Use the\nlist_valid_units() method to view output unit options.\nDefault fuel consumption units are tons/acre ('tons_ac').\n\n>>> consume.list_valid_units()\n\nOutput::\n\n    ['lbs',\n     'lbs_ac',\n     'tons',\n     'tons_ac',\n     'kg',\n     'kg_m^2',\n     'kg_ha',\n     'kg_km^2'\n     'tonnes',\n     'tonnes_ha',\n     'tonnes_km^2']\n\n\n>>> fc_obj.output_units = 'lbs'\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nCUSTOMIZING FUEL LOADINGS\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nFuel loadings are automatically imported from the FCCS database based on the\nFCCS fuelbed ID#s selected by the user. If desired, the user can also \ncustomize FCCS fuel loadings by setting the '.customized_fuel_loadings' variable\nto a list of 3 value lists in this format:\n[fuelbed index number {interger}, fuel stratum {string}, loading value {number}]\n\ne.g.:\n\n>>> fc_obj.customized_fuel_loadings = [[1, 'overstory', 4.5],[2, 'shrub_prim', 5]]\n\nThe above command will change the canopy 'overstory' loading in the first ('1')\nfuelbed to 4.5 (tons/acre) and will change the 'shrub_prim' (primary shrub\nloading) in the second ('2') fuelbed to 5 tons/acre. To view all valid stratum\nnames and units, use the fc_obj.FCCS.list_fuel_loading_names() method.\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nOUTPUTS\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nConsumption outputs can be accessed by calling the .results(), .report(), or\n.batch_process() methods. Calling any of these methods will trigger the \ncalculation of all fuel consumption equation and will return the results in \na variety of different formats:\n\n\n>>> fc_obj.results()\n\n... generates & prints a python DICTIONARY of consumption\nresults by fuel category (major and minor categories)\nSee complete example below to see how individual\ndata categories can be accessed from this dictionary.\n\n>>> fc_obj.report(csv=\"\")\n\n...prints a TABULAR REPORT of consumption results for\nthe major fuel categories (similar to the \"Fuel\nConsumption by Combustion Stage\" report produced by the\nofficial Consume 3.0 GUI program).  To export a version \nof this report as a CSV FILE, use the 'csv' argument to \nspecify a file name, e.g.:\n>>> fc_obj.report(csv = \"consumption_report.csv\")\n\n>>> fc_obj.batch_process(csvin=\"\", csvout=\"\")\n\n...similar to the .report() method, although requires an\ninput csv file and will export results to the specified\nCSV output.\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nOTHER USEFUL METHODS\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n>>> consume.list_valid_units()        \n\n...displays a list of valid output unit options\n\n>>> consume.list_valid_consumption_strata()\n\n...displays a list of valid consumption strata group names\n\n>>> fc_obj.list_variable_names()\n\n...displays a list of the variable names used for each input parameter\n\n>>> fc_obj.FCCS.browse()\n\n...loads a list of all FCCS fuelbed ID numbers and their site names\n\n>>> fc_obj.FCCS.info(#)\n\n...provides site description of the FCCS fuelbed with the specified ID number. \nSet detail=True to print out detailed fuel loading information\n\n>>> fc_obj.FCCS.get_canopy_pct(#)\n\n...displays estimated canopy consumption percent as calculated by MTRI for the \nspecified FCCS ID number. This is the  value that will be used if \ncanopy_consumption_pct is set to -1.\n\n>>> fc_obj.load_example()\n\n...loads an example scenario with 2 Fuelbeds\n\n>>> fc_obj.reset_inputs_and_outputs()\n\n...clears input and output parameters\n\n>>> fc_obj.display_inputs()\n\n...displays a list of the input parameters.\nUseful for checking that scenario parameters were set correctly\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nWorking with the EMISSIONS Object\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nFor emissions data, declare a Consume Emissions object by nesting in the\nFuelConsumption object we were working on above as the only required argument.\n\n>>> e_obj = consume.Emissions(fc_obj)\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nSETTING INPUT PARAMETERS\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nInput parameters for emissions calculations are much easier to set than those\nfor FuelConsumption, as they are ALL ultimately automatically derived from the\nparameters set within the nested FuelConsumption object.\nThe input parameters required for the emissions calculations are as follows:\n\n*  FUEL CONSUMPTION (tons/ac) & the scenario of corresponding FCCS ID#s,\n   AREAS, and ECOREGIONS, all of which is derived from the FuelConsumption\n   object specified in the Emissions object declaration we just did\n\n*  EMISSIONS FACTOR GROUP ('efg'), which specifies the appropriate set of\n   emissions factors (lbs/tons consumed for each of 7 emissions species) \n   to use for the scenario. This is automatically selected based on the \n   FCCS fuelbeds in the consumption scenario, but the user can override\n   the auto-select process if desired as described below.\n\nAs with the FuelConsumption object, the user can also optionally set alternate \noutput units for the Emissions object. Use the consume.list_valid_units() method\nto view output unit options.\nDefault output units for emissions are lbs/ac.\n\n>>> e_obj.output_units = 'kg_ha'\n\nTo change the FuelConsumption units, simply modify the units of the FC object\nthat is nested within the Emissions object:\n\n>>> e_obj.FCobj.output_units = 'kg_ha'\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nOUTPUTS\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAs with the FuelConsumption object, Emissions outputs can be accessed by \ncalling the .results() or .report() methods. Calling either methods will trigger\nthe calculation of emissions and output results in a variety of different\nformats:\n\n>>> e_obj.results()\n\n...generates a python DICTIONARY similar to the one created\nby the FuelConsumption object, but with Emissions\nresults added (consumption data is also included).\nSee complete example below to see how specific\ndata categories can be accessed in this dictionary.\n\n>>> e_obj.report()\n\n...prints a TABULAR REPORT of emissions results for all\npollutants and combustion stages (similar to the\n\"Emissions by Combustion Stage\" report produced in \nthe official Consume 3.0 GUI program).  To export\na version of this report as a CSV FILE, use the\n'csv' argument to specify a file name, e.g.:\n>>> e_obj.report(csv = \"emissions_report.csv\")\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nOTHER USEFUL METHODS\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n>>> e_obj.display_inputs()\n\n...displays a list of the input parameters.\nUseful for checking that scenario\nparameters were set correctly\n\n>>> e_obj.efDB.browse()\n\n...displays a list of all emissions factor\ngroups and their associated fuel types\nand references\n\n>>> e_obj.efDB.info(#)\n\n...display detailed information about the\nspecified emissions factor group ID#\n(use the .browse() method above to view\nID#s). Includes the actual emissions\nfactor values.\n\nFor further help on specific methods or properties,\ntype \"help([CONSUME METHOD])\" within a python shell, e.g.:\n\n>>> help(fc_obj.FCCS.info)\n\nOutput::\n\n  Help on method info in module consume_obj:\n  \n  info(self, fccs_id, detail=False) method of consume_obj.FCCSDB instance\n      Display an FCCS fuelbed description.\n      \n      Prints fuel loading information on the fuelbed with the specified\n      FCCS ID. Requires one argument: an integer refering to a specific FCCS\n      ID. For a list of valid FCCS IDs, use the .browse() method.\"\n\n\n-------------------------------------------\nComplete Uninterrupted Example\n-------------------------------------------\n\nThe following example sets up a 'natural' burn scenario in which 100 acres FCCS \nfuelbed ID #1 (\"Black cottonwood - Douglas fir - Quaking aspen riparian forest\")\nand 200 acres of FCCS fuelbed ID #47 (\"Redwood - Tanoak forest\") are consumed.\n1000-hr and duff fuel moisture is set at 50% for fuelbed ID #1 and 40% for\nfuelbed ID #47. Canopy consumption and shrub percent black is set at 25% for\nboth fuelbeds.\n\n>>> from consume import consume\n>>> fc_obj = consume.FuelConsumption()\n>>> fc_obj.fuelbed_fccs_ids = [1, 47]\n>>> fc_obj.fuelbed_area_acres = [100, 200]\n>>> fc_obj.fuelbed_ecoregion = 'western'\n>>> fc_obj.fuel_moisture_1000hr_pct = [50, 40]\n>>> fc_obj.fuel_moisture_duff_pct = [50, 40]\n>>> fc_obj.canopy_consumption_pct = 25\n>>> fc_obj.shrub_blackened_pct = 25\n>>> fc_obj.output_units = 'kg_ha'\n>>> fc_obj.display_inputs()\n\nOutput::\n\n  Current scenario parameters:\n  \n  Parameter                   Value(s)\n  --------------------------------------------------------------\n  Burn type                   natural\n  FCCS fuelbeds (ID#)         [1, 47]\n  Fuelbed area (acres)        [100, 200]\n  Fuelbed ecoregion           western\n  Fuel moisture (1000-hr, %)  [50, 40]\n  Fuel moisture (duff, %)     [50, 40]\n  Canopy consumption (%)      25\n  Shrub blackened (%)         25\n  Output units                kg_ha\n\n\n>>> fc_obj.report()\n\nOutput::\n\n    FUEL CONSUMPTION\n    Consumption units: kg/ha\n    Heat release units: btu/ha\n    Total area: 300 acres\n\n    FCCS ID: 1\n    Area:    100\n    Ecoregion: western\n    CATEGORY        Flaming     Smoldering  Residual    TOTAL\n    canopy          1.25e+04    9.58e+02    1.51e+02    1.36e+04\n    shrub           1.26e+03    6.97e+01    0.00e+00    1.33e+03\n    nonwoody        3.95e+02    2.08e+01    0.00e+00    4.16e+02\n    llm             2.32e+03    2.20e+02    0.00e+00    2.54e+03\n    ground fuels    8.97e+02    1.51e+04    3.72e+04    5.32e+04\n    woody fuels     9.71e+03    5.61e+03    8.81e+03    2.41e+04\n    TOTAL:          2.70e+04    2.20e+04    4.61e+04    9.52e+04\n\n    Heat release:   1.19e+08    9.70e+07    2.03e+08    4.20e+08\n\n\n    FCCS ID: 47\n    Area:    200\n    Ecoregion: western\n    CATEGORY        Flaming     Smoldering  Residual    TOTAL\n    canopy          7.93e+03    2.48e+03    2.05e+03    1.25e+04\n    shrub           3.87e+03    2.69e+02    0.00e+00    4.13e+03\n    nonwoody        9.88e+02    5.20e+01    0.00e+00    1.04e+03\n    llm             4.93e+03    5.41e+02    0.00e+00    5.47e+03\n    ground fuels    3.59e+03    4.08e+04    6.98e+04    1.14e+05\n    woody fuels     2.56e+04    2.06e+04    2.49e+04    7.11e+04\n    TOTAL:          4.69e+04    6.47e+04    9.67e+04    2.08e+05\n\n    Heat release:    2.07e+08    2.85e+08    4.27e+08    9.18e+08\n\n\n    ALL FUELBEDS:\n\n    Consumption:    4.03e+04    5.04e+04    7.99e+04    1.71e+05\n    Heat release:   3.26e+08    3.82e+08    6.30e+08    1.34e+09\n\n\n\n>>> fc_obj.results()['consumption']['ground fuels']\n\nOutput::\n\n    {'basal accumulations': {'flaming': array([-0.,  0.]),\n                             'residual': array([-0.,  0.]),\n                             'smoldering': array([-0.,  0.]),\n                             'total': array([-0.,  0.])},\n     'duff, lower': {'flaming': array([ 0.,  0.]),\n                     'residual': array([ 35377.20573062,  62608.52081126]),\n                     'smoldering': array([  8844.30143266,  15652.13020281]),\n                     'total': array([ 44221.50716328,  78260.65101407])},\n     'duff, upper': {'flaming': array([  896.68092549,  3586.72370195]),\n                     'residual': array([ 1793.36185097,  7173.4474039 ]),\n                     'smoldering': array([  6276.76647841,  25107.06591365]),\n                     'total': array([  8966.80925487,  35867.23701949])},\n     'squirrel middens': {'flaming': array([ 0.,  0.]),\n                          'residual': array([ 0.,  0.]),\n                          'smoldering': array([ 0.,  0.]),\n                          'total': array([ 0.,  0.])}}\n\n\n>>> e_obj = consume.Emissions(fc_obj)\n>>> e_obj.display_inputs()\n\nOutput::\n\n    CONSUMPTION\n\n    Current scenario parameters:\n\n    Parameter                    Value(s)\n    --------------------------------------------------------------\n    Burn type                    ['natural']\n    FCCS fuelbeds (ID#)          [1, 47]\n    Fuelbed area (acres)         [ 100.  200.]\n    Fuelbed ecoregion            ['western']\n    Fuel moisture (1000-hr, %)   [ 50.  40.]\n    Fuel moisture (duff, %)      [ 50.  40.]\n    Canopy consumption (%)       [ 25.]\n    Shrub blackened (%)          [ 25.]\n    Output units                 ['kg_ha']\n\n    EMISSIONS\n\n    Current scenario parameters:\n\n    Parameter            Value(s)\n    --------------------------------------------------------------\n\n>>> e_obj.report()\n\nOutput::\n\n    EMISSIONS\n    Units: lbs_ac\n\n    FCCS ID: 1\n    Area:    100 ac. (40.5 ha)\n    Emissions factor group: 2\n    SPECIES Flaming     Smoldering  Residual    TOTAL\n    pm      2.77e+02    3.73e+02    7.82e+02    1.43e+03\n    pm10    1.69e+02    2.54e+02    5.33e+02    9.56e+02\n    pm2.5   1.47e+02    2.30e+02    4.82e+02    8.58e+02\n    co      1.11e+03    3.59e+03    7.53e+03    1.22e+04\n    co2     4.09e+04    2.80e+04    5.87e+04    1.28e+05\n    ch4     5.31e+01    1.92e+02    4.03e+02    6.49e+02\n    nmhc    6.27e+01    1.37e+02    2.88e+02    4.88e+02\n\n    FCCS ID: 47\n    Area:    200 ac. (80.9 ha)\n    Emissions factor group: 4\n    SPECIES Flaming     Smoldering  Residual    TOTAL\n    pm      4.60e+02    9.69e+02    1.45e+03    2.88e+03\n    pm10    2.45e+02    7.30e+02    1.09e+03    2.07e+03\n    pm2.5   2.01e+02    6.81e+02    1.02e+03    1.90e+03\n    co      1.11e+03    7.87e+03    1.18e+04    2.08e+04\n    co2     7.24e+04    8.72e+04    1.30e+05    2.90e+05\n    ch4     6.28e+01    5.08e+02    7.60e+02    1.33e+03\n    nmhc    6.70e+01    3.81e+02    5.70e+02    1.02e+03\n\n    ALL FUELBEDS:\n    Units: lbs_ac\n    Total area: 300 ac. (121.4 ha)\n    pm      3.99e+02    7.70e+02    1.23e+03    2.40e+03\n    pm10    9.45e+01    3.02e+01    2.14e+01    1.46e+02\n    pm2.5   2.96e+01    3.08e+00    0.00e+00    3.27e+01\n    co      7.81e+00    6.37e-01    0.00e+00    8.45e+00\n    co2     4.02e+01    6.65e+00    0.00e+00    4.68e+01\n    ch4     2.65e+01    4.93e+02    9.07e+02    1.43e+03\n    nmhc    2.01e+02    2.37e+02    2.99e+02    7.36e+02\n\n\n>>> e_obj.results()['emissions']['co2']\n\nOutput::\n\n    {'flaming': array([ 40877.14600611,  72354.16061005]),\n     'residual': array([  58664.90328723,  130457.66209735]),\n     'smoldering': array([ 27980.07467362,  87193.41115534]),\n     'total': array([ 127522.12396695,  290005.23386274])}\n\n\n\n-------------------------------------------\nNavigating the .results() dictionaries\n-------------------------------------------\n\nThe table below depicts all categories included in the .results() dictionaries\nthat are produced from the FuelConsumption and Emissions objects. Note that the\nFuelConsumption .results() dictionary does NOT include emissions data while the\nEmissions .results() dictionary includes BOTH consumption and emissions data.\n\nThe FINAL index in the dictionary will be always be an integer that indicates\nthe fuelbed unit in the scenario. In the example above, a [0] would access \ndata for the first fuelbed (FCCS ID #1) and a [1] would access data for the \nsecond fuelbed (FCCS ID #47). Use Python's built-in 'sum()' function to\ncalculate total consumption/emissions across ALL fuelbeds.\n\n\n~~~~~~~~~~~~~\nExamples\n~~~~~~~~~~~~~\n\nTo access TOTAL consumption for the given scenario for each fuelbed unit:\n\n>>> fc_obj.results()['consumption']['summary']['total']['total']\n\nTo access TOTAL consumption for only the first fuelbed unit in the scenario:\n\n>>> fc_obj.results()['consumption']['summary']['total']['total'][0]\n\nTo access TOTAL consumption for the given scenario across ALL fuelbeds*:\n\n>>> sum(fc_obj.results()['consumption']['summary']['total']['total'])\n\nTo access consumption data for all canopy strata:\n\n>>> fc_obj.results()['consumption']['canopy']\n\nTo access TOTAL canopy consumption:\n\n>>> fc_obj.results()['consumption']['summary']['canopy']['total']\n\nTo access 'co2' emissions from all combustion stages:\n\n>>> e_obj.results()['emissions']['co2']\n\nTo access total 'co2' emissions for the given scenario across ALL fuelbeds*:\n\n>>> sum(e_obj.results()['emissions']['co2']['total'])\n\nTo view units that the emissions data are in:\n\n>>> e_obj.results()['parameters']['units_emissions']\n\n    *Note: if outputs units are per-area units (i.e. tons/acre or kg/ha), these \n    sum' functions will not provide an accurate representation of the overall\n    consumption rate for the scenario.*\n\nOutput::\n\n    Index 1           Index 2              Index 3                     Index 4       Index 5    \n    -----------------------------------------------------------------------------------------------------------------------------\n\n    'parameters'   'fuel moisture: 1000hr'\n                   'fuel moisture duff'\n                   'fuel moisture pct canopy consumed'\n                   'fuel moisture pct shrub blackened'\n                   'fuelbed area'\n                   'fuelbed ecoregion'\n                   'fuelbed fccs id'\n                   'units consumption'\n                   'units emissions'\n    -----------------------------------------------------------------------------------------------------------------------------\n                         \n    'emissions'    'ch4'                'flaming','smoldering','residual', or 'total'\n                   'co'                 'flaming','smoldering','residual', or 'total'\n                   'co2'                'flaming','smoldering','residual', or 'total'\n                   'nmhc'               'flaming','smoldering','residual', or 'total'\n                   'pm'                 'flaming','smoldering','residual', or 'total'\n                   'pm10'               'flaming','smoldering','residual', or 'total'\n                   'pm25'               'flaming','smoldering','residual', or 'total'\n                   \n                   'stratum'            'ch4'                       'canopy'             'flaming','smoldering','residual', or 'total\n                                                                    'ground fuels'       ''\n                                                                    'litter-lichen-moss' ''\n                                                                    'nonwoody'           ''\n                                                                    'shrub'              ''\n                                                                    'woody fuels'        ''\n                                        'co'                        'canopy'             ''\n                                                                    'ground fuels'       ''\n                                                                    'litter-lichen-moss' ''\n                                                                    'nonwoody'           ''\n                                                                    'shrub'              ''\n                                                                    'woody fuels'        ''\n                                        'co2'   .....etc.....\n                                                \n\n    -----------------------------------------------------------------------------------------------------------------------------\n                         \n    'heat release' 'flaming'\n                   'smoldering'\n                   'residual'\n                   'total'\n\n    -----------------------------------------------------------------------------------------------------------------------------\n\n    'consumption'  'summary'            'total'                     'flaming','smoldering','residual', or 'total'\n                                        'canopy'                    'flaming','smoldering','residual', or 'total'\n                                        'ground fuels'              'flaming','smoldering','residual', or 'total'\n                                        'litter-lichen-moss'        'flaming','smoldering','residual', or 'total'\n                                        'nonwoody'                  'flaming','smoldering','residual', or 'total'\n                                        'shrub'                     'flaming','smoldering','residual', or 'total'\n                                        'woody fuels'               'flaming','smoldering','residual', or 'total\n\n                   'canopy'             'overstory'                 'flaming','smoldering','residual', or 'total'\n                                        'midstory'                  'flaming','smoldering','residual', or 'total'\n                                        'understory'                'flaming','smoldering','residual', or 'total'\n                                        'ladder fuels'              'flaming','smoldering','residual', or 'total'\n                                        'snags class 1 foliage'     'flaming','smoldering','residual', or 'total'\n                                        'snags class 1 non foliage' 'flaming','smoldering','residual', or 'total'\n                                        'snags class 1 wood'        'flaming','smoldering','residual', or 'total'\n                                        'snags class 2'             'flaming','smoldering','residual', or 'total'\n                                        'snags class 3'             'flaming','smoldering','residual', or 'total'\n        \n                   'ground fuels'       'duff upper'                'flaming','smoldering','residual', or 'total'\n                                        'duff lower'                'flaming','smoldering','residual', or 'total'\n                                        'basal accumulations'       'flaming','smoldering','residual', or 'total'\n                                        'squirrel middens'          'flaming','smoldering','residual', or 'total'\n\n                   'litter-lichen-moss' 'litter'                    'flaming','smoldering','residual', or 'total'\n                                        'lichen'                    'flaming','smoldering','residual', or 'total'\n                                        'moss'                      'flaming','smoldering','residual', or 'total'\n                   'nonwoody'           'primary dead'              'flaming','smoldering','residual', or 'total'\n                                        'primary live'              'flaming','smoldering','residual', or 'total'\n                                        'secondary dead'            'flaming','smoldering','residual', or 'total'\n                                        'secondary live'            'flaming','smoldering','residual', or 'total'\n\n                   'shrub'              'primary dead'              'flaming','smoldering','residual', or 'total'\n                                        'primary live'              'flaming','smoldering','residual', or 'total'\n                                        'secondary dead'            'flaming','smoldering','residual', or 'total'\n                                        'secondary live'            'flaming','smoldering','residual', or 'total'\n                   'woody fuels'        '1-hr fuels'                'flaming','smoldering','residual', or 'total'\n                                        '10-hr fuels'               'flaming','smoldering','residual', or 'total'\n                                        '100-hr fuels'              'flaming','smoldering','residual', or 'total'\n                                        '1000-hr fuels sound'       'flaming','smoldering','residual', or 'total'\n                                        '1000-hr fuels rotten'      'flaming','smoldering','residual', or 'total'\n                                        '10000-hr fuels sound'      'flaming','smoldering','residual', or 'total'\n                                        '10000-hr fuels rotten'     'flaming','smoldering','residual', or 'total'\n                                        '10k+-hr fuels sound'       'flaming','smoldering','residual', or 'total'\n                                        '10k+-hr fuels rotten'      'flaming','smoldering','residual', or 'total'\n                                        'stumps sound'              'flaming','smoldering','residual', or 'total'\n                                        'stumps rotten'             'flaming','smoldering','residual', or 'total'\n                                        'stumps lightered'          'flaming','smoldering','residual', or 'total'\n    -----------------------------------------------------------------------------------------------------------------------------"}}, {"pk": 595, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "AutoNetkit", "license": "UNKNOWN", "author": "Simon Knight, Hung Nguyen", "author_email": "simon.knight@adelaide.edu.au", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/AutoNetkit/", "version": "0.3.3", "platform": "UNKNOWN", "keywords": null, "summary": "Automated configuration generator for Netkit", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nIntended Audience :: Telecommunications Industry\nLicense :: Other/Proprietary License\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: System :: Networking\nTopic :: System :: Software Distribution", "description": "Automated configuration generator for Netkit"}}, {"pk": 596, "model": "importing.pypicache", "fields": {"maintainer": "Michael J.T. O'Kelly", "name": "PyTesser", "license": "Apache License 2.0", "author": "Michael J.T. O'Kelly", "author_email": "mokelly@mit.edu", "project_url": null, "maintainer_email": "mokelly@mit.edu", "home_page": "http://code.google.com/p/pytesser/", "version": "0.0.1", "platform": "", "keywords": "Python, OCR, Optical Character Recognition, Tesseract", "summary": "Optical Character Recognition module for Python", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Win32 (MS Windows)\nLicense :: OSI Approved :: Apache Software License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Image Recognition", "description": "PyTesser is an Optical Character Recognition module for Python. It takes as\r\ninput an image or image file and outputs a string.\r\n\r\nPyTesser uses the Tesseract OCR engine, converting images to an accepted format\r\nand calling the Tesseract executable as an external script. A Windows executable\r\nis provided along with the Python scripts. The scripts should work in other\r\noperating systems as well."}}, {"pk": 597, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pymbolic", "license": "MIT", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/pymbolic", "version": "2010.1", "platform": "UNKNOWN", "keywords": null, "summary": "A package for symbolic computation", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries\nTopic :: Utilities", "description": "Pymbolic is a small symbolic manipulation library. Two things set it apart\n      from other libraries of its kind:\n\n      * Users can easily write their own symbolic operations, simply by deriving\n        from the builtin visitor classes.\n      * Users can easily add their own symbolic entities to do calculations\n        with.\n\n      Pymbolic currently understands regular arithmetic expressions, derivatives,\n      sparse polynomials, fractions, term substitution, expansion. It automatically\n      performs constant folding, and it can compile its expressions into Python \n      bytecode for fast(er) execution.\n      \n      If you are looking for a full-blown Computer Algebra System, look at \n      `sympy <http://pypi.python.org/pypi/sympy>`_ or \n      `PyGinac <http://pyginac.sourceforge.net/>`_. If you are looking for a\n      basic, small and extensible set of symbolic operations, pymbolic may\n      well be for you."}}, {"pk": 598, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ete2", "license": "GPLv3", "author": "Jaime Huerta-Cepas", "author_email": "jhcepas@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://ete.cgenomics.org", "version": "2.0rev111", "platform": "OS Independent", "keywords": "bioinformatics phylogeny evolution phylogenomics genomics tree clustering phylogenetics phylogenetic ete orthology paralogy", "summary": "A python Environment for Tree Exploration", "classifiers": "Development Status :: 6 - Mature\nEnvironment :: Console\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "ETE is a python programming toolkit that assists in the automated manipulation, analysis and visualization of hierarchical trees. Besides a broad set of tree handling options, ETE provides specific methods to work on phylogenetics and clustering analyses. ETE supports large tree data structures, node annotation, topology manipulation and provides a highly customizable visualization framework."}}, {"pk": 599, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ieee754bin", "license": "GPLv3", "author": "Dan Lenski", "author_email": "lenski@umd.edu", "project_url": null, "maintainer_email": null, "home_page": "http://tonquil.homeip.net/~dlenski/ieee754bin", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Python IEEE 754 binary library", "classifiers": "Topic :: Scientific/Engineering :: Mathematics", "description": "This is a small Python extension which allows you to manipulate the\nbinary representation of floating-point values in the standard IEEE\n754 64-bit format (= C double type or Python float type).\n\nBasically, the module includes methods to print integers and floating\npoint values in binary format, to convert floating-point values to and\nfrom 64-bit integer representations, and to split/join floating-point\nvalues into (sign, exponent, mantissa) tuples."}}, {"pk": 600, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pystdf", "license": "UNKNOWN", "author": "Casey Marshall", "author_email": "casey.marshall@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/pystdf/", "version": "1.0.0", "platform": "UNKNOWN", "keywords": null, "summary": "Python module for working with STDF files", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Manufacturing\nLicense :: Free for non-commercial use\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Electronic Design Automation (EDA)\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Software Development :: Pre-processors\nTopic :: Utilities", "description": "PySTDF is a Python module that makes it easy to work with STDF (Teradyne's Standard Test Data Format). STDF is a commonly used file format in semiconductor test -- automated test equipment (ATE) from such vendors as Teradyne, Verigy, LTX, Credence, and others support this format.\n\nPySTDF provides event-based stream parsing of STDF version 4, along with indexers that can help you rearrange the data into a more useful tabular form, as well as generate missing summary records or new types of derivative records.\n\nThe parser architecture is very flexible and can easily be extended to support STDF version 3 as well as custom record types.\n\nPotential applications of PySTDF include:\n* Debugging a vendor's STDF implementation\n* Straight conversion to ASCII-readable form\n* Repairing STDF files\n* Developing an application that leverages STDF\n  - Conversion to tabular form for statistical analysis tools\n  - Loading data into a relational database\n\nPySTDF is released under a GPL license. Applications developed with PySTDF can only be released with a GPL-compatible license. Commercial applications can purchase an alternate license agreement for closed-source distribution."}}, {"pk": 601, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.handlers.nca", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/handlers.html#nca", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "netcdf opendap dods dap data science climate oceanography meteorology", "summary": "NetCDF aggregator handler for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This handler enables Pydap to serve aggregated NetCDF files on\nthe network for Opendap clients."}}, {"pk": 602, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "django-geoportail", "license": "BSD licence, see LICENCE file", "author": "Bruno Renie", "author_email": "bruno@renie.fr", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/bruno/django-geoportail", "version": "0.4.6", "platform": "UNKNOWN", "keywords": null, "summary": "Add maps and photos from the French National Geographic Institute to GeoDjango", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Web Environment\nFramework :: Django\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nProgramming Language :: JavaScript\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "=================\nDjango-Geoportail\n=================\n\nGeodjango with the maps and photos from the French National Geographic\nInstitute.\n\n* Installation and documentation: see INSTALL and the `online documentation`_\n\n  .. _online documentation: http://packages.python.org/django-geoportail/\n\n* Get involved: http://bitbucket.org/bruno/django-geoportail/\n\n* Bugs: http://bitbucket.org/bruno/django-geoportail/issues/"}}, {"pk": 603, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cassowarypy", "license": "MIT", "author": "svilen dobrev", "author_email": "svilen_dobrev at users point sourceforge point net", "project_url": null, "maintainer_email": null, "home_page": "http://dbcook.sourceforge.net/readme-cassowarypy", "version": "0.26unleak", "platform": "UNKNOWN", "keywords": null, "summary": "cassowarypy: python-wrap of Cassowary linear constraint solver", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This is a python wrapper over the (famous) Cassowary incremental constraint solver.\nIt uses the c++ implementation (0.6) as backend.\n\nThe original c++ code is somewhat refactored to remove memory leaks\nby using reference counting, and is usable alone.\n\nThe refactoring was done somewhen in 2002, and the code is not touched much since then.\nLast changes are workarounding recent template-things in new (gcc-4.x) c++ compilers.\nThe Finite-domain part (using GTL graph library) is not tried/tested; it might or might not work.\n\nrepository: svn co https://dbcook.svn.sf.net/svnroot/dbcook/cassowarypy\n\nhow to compile/install for python:\n * the c++ code now compiles on both g++ 3.3.3 and g++ 4.1.3.\n   it also compiles on some MSVC.\n * 'swig' is also needed\n * if the default C++ compiler is one of those, just 'python setup.py install' would do.\n   Then run python test.py to see if all works.\n * else, u have to install one of these compilers and fight with distutils to make it use that one.\n   e.g. \"CC=g++-3.3 python setup.py install\" might work; also check the link'ing part\n\nMy code is under MIT-license.\nOriginal Cassowary code is licensed under LGPL.\n\nOriginal cassowary Web Page: (last update about year 2000)\nhttp://www.cs.washington.edu/research/constraints/cassowary"}}, {"pk": 604, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "NeuroTools", "license": "GPLv2", "author": "The NeuralEnsemble Community", "author_email": "neurotools@neuralensemble.org", "project_url": null, "maintainer_email": "", "home_page": "http://neuralensemble.org/NeuroTools", "version": "0.1.0", "platform": "UNKNOWN", "keywords": "computational neuroscience,simulation,analysis,visualization,parameters", "summary": "A collection of tools to support all tasks associated with a neural simulation project which are not handled by the simulation engine", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: POSIX\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "UNKNOWN"}}, {"pk": 605, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "study", "license": "GPL3", "author": "Alexander Lamaison", "author_email": "awl03@doc.ic.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/python-study/", "version": "0.1.0", "platform": "UNKNOWN", "keywords": null, "summary": "Framework for building data studies in a pipe-and-filter style that abstracts over issues such as multiprocessing.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 606, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "quantities", "license": "BSD", "author": "Darren Dale", "author_email": "dsdale24@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://packages.python.org/quantities", "version": "0.9.0", "platform": "Any", "keywords": "quantities,physical quantities,units", "summary": "Support for physical quantities with units, based on numpy", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering", "description": "Quantities is designed to handle arithmetic and conversions\r\nof physical quantities, which have a magnitude, dimensionality specified by\r\nvarious units, and possibly an uncertainty. See the tutorial_ for examples.\r\nQuantities builds on the popular numpy library and is designed to work with\r\nnumpy ufuncs, many of which are already supported. Quantities is actively\r\ndeveloped, and while the current features and API are stable, test coverage\r\nis incomplete and so the package is not suggested for production use.\r\n\r\n.. _tutorial: http://packages.python.org/quantities/user/tutorial.html"}}, {"pk": 607, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gpk-voicing", "license": "GPL2", "author": "Greg Kochanski", "author_email": "gpk@kochanski.org", "project_url": null, "maintainer_email": null, "home_page": "http://kochanski.org/gpk/code/speechresearch/voicing", "version": "1.7.2", "platform": "All", "keywords": "phonetics speech computation linguistics scripts library python science perception feature vector loudness spectral slope", "summary": "Python Libraries and scripts for speech analysis.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "Python Libraries for speech analysis.\n\tSee http://kochanski.plus.com/code/speechresearch/voicing for documentation\n\tand http://sourceforge.net/projects/speechresearch for downloads,\n\tor look on the Python Cheese shop, http://pypi.python.org ."}}, {"pk": 608, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "sas_rigid", "license": "GPL", "author": "Christian Meesters", "author_email": "meesters@gmx.de", "project_url": null, "maintainer_email": null, "home_page": "http://sas-rigid.origo.ethz.ch/", "version": "0.8.1", "platform": "UNKNOWN", "keywords": null, "summary": "sas_rigid: rigid body modelling software for SAS data", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "sas_rigid is a modelling package designed to enable \nefficient rigid body modelling based on small angle scattering (SAS) data.\nThe package provides fast and easy access to rigid body modeling with\nmolecules of arbitrary symmetry. In order to speed up modeling the package \nenables the user to perform a Monte Carlo based 'rough' modeling followed by\na systematic search in a confined parameter range.\n\nThere are also basic facilities for manipulating or preparing PDB-files\nfor better handling for the purpose of rigid body modelling."}}, {"pk": 609, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "byCycleTripPlanner", "license": "Free For Home Use", "author": "Wyatt L Baldwin, byCycle.org", "author_email": "wyatt@byCycle.org", "project_url": null, "maintainer_email": null, "home_page": "http://bycycle.org/", "version": "0.4a0.dev-r1056", "platform": "UNKNOWN", "keywords": "bicycle bike cycyle trip planner route finder", "summary": "byCycle Trip Planner", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Web Environment\nFramework :: Pylons\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering :: GIS", "description": "byCycle Trip Planner Web Application"}}, {"pk": 610, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "diffpy.Structure", "license": "BSD", "author": "Pavol Juhas", "author_email": "pj2192@columbia.edu", "project_url": null, "maintainer_email": null, "home_page": "http://www.diffpy.org/", "version": "1.0-r5333-20100601", "platform": "UNKNOWN", "keywords": "diffpy Structure container", "summary": "Crystal structure container and parsers for structure formats.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 611, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "egenix-mx-base", "license": "eGenix.com Public License 1.1.0; Copyright (c) 1997-2000, Marc-Andre Lemburg, All Rights Reserved; Copyright (c) 2000-2009, eGenix.com Software GmbH, All Rights Reserved", "author": "eGenix.com", "author_email": "info@egenix.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.egenix.com/products/python/mxBase/", "version": "3.1.3", "platform": "Windows,Linux,FreeBSD,Solaris,Mac OS X,AIX", "keywords": null, "summary": "eGenix mx Base Distribution for Python - mxDateTime, mxTextTools, mxProxy, mxTools, mxBeeBase, mxStack, mxQueue, mxURL, mxUID", "classifiers": "Development Status :: 5 - Production/Stable\nDevelopment Status :: 6 - Mature\nEnvironment :: Console\nEnvironment :: No Input/Output (Daemon)\nIntended Audience :: Developers\nLicense :: Freely Distributable\nLicense :: OSI Approved :: Python License (CNRI Python License)\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: BeOS\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS/2\nOperating System :: OS Independent\nOperating System :: Other OS\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.3\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Communications\nTopic :: Database\nTopic :: Documentation\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Internet :: WWW/HTTP :: Dynamic Content :: CGI Tools/Libraries\nTopic :: Internet :: WWW/HTTP :: Site Management :: Link Checking\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Software Development\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Application Frameworks\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing\nTopic :: Text Processing :: Filters\nTopic :: Text Processing :: Markup", "description": "The eGenix mx Extension Series are a collection of Python extensions\nwritten in ANSI C and Python which provide a large spectrum of useful\nadditions to everyday Python programming.\n\nThe Base Distribution includes the Open Source subpackages of the\nseries and is needed by all other add-on packages of the series:\n\nmxDateTime - Date/Time Library for Python\n\n    mxDateTime implements three new object types, DateTime,\n    DateTimeDelta and RelativeDateTime and many tools based on these\n    for doing easy conversion between and parsing of various date/time\n    formats.\n\nmxTextTools - Fast Text Parsing and Processing Tools for Python\n\n    mxTextTools provides several useful functions and types that\n    implement high-performance text parsing, processing and search\n    algorithms.\n\nmxProxy - Object Access Control for Python\n\n    mxProxy implements a new proxy type to provide low-level object\n    access control, weak referencing and a cleanup protocol. It's\n    ideal for use in restricted execution environments.\n\nmxBeeBase - On-disk B+Tree Based Database Kit for Python\n\n    mxBeeBase is a high performance construction kit for disk based\n    indexed databases. It offers components which you can plug\n    together to easily build your own custom mid-sized databases.\n\nmxURL - Flexible URL Data-Type for Python\n\n    mxURL provides a new datatype for storing and manipulating URL\n    values as well as a few helpers related to URL building, encoding\n    and decoding.\n\nmxUID - Fast Universal Identifiers for Python\n\n    mxUID implements a fast mechanism for generating universal\n    identification strings (UIDs).\n\nmxStack - Fast and Memory-Efficient Stack Type for Python\n\n    mxStack implements a fast and memory efficient stack object type.\n\nmxQueue - Fast and Memory-Efficient Queue Type for Python\n\n    mxQueue implements a fast and memory efficient queue object type.\n\nmxTools - Fast Everyday Helpers for Python\n\n    mxTools provides a collection of handy functions and objects for\n    every day Python programming. It includes many functions that\n    you've often missed in Python.\n\nThis software is brought to you by eGenix.com and distributed under\nthe eGenix.com Public License 1.1.0."}}, {"pk": 612, "model": "importing.pypicache", "fields": {"maintainer": "Jose Riguera", "name": "csv2xmlgen", "license": "csv2xmlgen is free software: you can redistribute it and/or modify\r\nit under the terms of the GNU General Public License as published by\r\nthe Free Software Foundation, either version 3 of the License, or\r\n(at your option) any later version.\r\n\r\ncsv2xmlgen is distributed in the hope that it will be useful,\r\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\r\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\nGNU General Public License for more details.\r\n\r\nYou should have received a copy of the GNU General Public License\r\nalong with csv2xmlgen.  If not, see <http://www.gnu.org/licenses/>.", "author": "Jose Riguera", "author_email": "jriguera@gmail.com", "project_url": null, "maintainer_email": "jriguera@gmail.com", "home_page": "http://code.google.com/p/csv2xmlgen/", "version": "0.3.0", "platform": "Independent platform (python 2.6). Tested in Windows and Linux.", "keywords": "python xml  csv  template kml", "summary": "CVS to XML, a generator based on a simple XML Template method.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nNatural Language :: Spanish\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing\nTopic :: Text Processing :: General\nTopic :: Text Processing :: Markup :: XML\nTopic :: Utilities", "description": "csv2xmlgen is a python program for generating XML files based on a input\r\ntemplate. It has been developed for generating KML files (Google Earth layers)\r\nfrom CSV data, but it can be used to process any kind of XML defined with the\r\nsuitable template."}}, {"pk": 613, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "slepc4py", "license": "Public Domain", "author": "Lisandro Dalcin", "author_email": "dalcinl@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://slepc4py.googlecode.com/", "version": "1.1", "platform": "POSIX", "keywords": "scientific computing,parallel computing,SLEPc,PETSc,MPI", "summary": "SLEPc for Python", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: Public Domain\nOperating System :: POSIX\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Cython\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Python bindings for SLEPc libraries."}}, {"pk": 614, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.eartho", "license": "Modified BSD", "author": "Riaan van den Dool", "author_email": "riaan@lightwell.co.za", "project_url": null, "maintainer_email": null, "home_page": "http://riaanvddool.github.com/scikits.eartho", "version": "0.1dev", "platform": "UNKNOWN", "keywords": null, "summary": "Earth Observation routines for SciPy", "classifiers": "Development Status :: 1 - Planning\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": "Earth Observation SciKit\n\nEarth Observation algorithms for SciPy, including IO, filtering,\nhistogram matching, ortho-rectification, etc.\n\nPlease refer to the online documentation at\nhttp://riaanvddool.github.com/scikits.eartho"}}, {"pk": 615, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "openTMM", "license": "The MIT License", "author": "Alex J. Yuffa", "author_email": "ayuffa@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://mesoscopic.mines.edu/mediawiki/index.php/Free_Python_codes", "version": "0.0.1", "platform": "Linux,Unix,Mac OS X,Windows", "keywords": "", "summary": "Electrodynamic Transfer Matrix Code", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: Fortran\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: Atmospheric Science\nTopic :: Scientific/Engineering :: Physics", "description": "openTMM is an object-oriented electrodynamic transfer matrix code with modern applications.\n\nElectromagnetic wave propagation through planar stratified media (multilayer stack); the three-dimensional space is divided into layers.  The interfaces separating the layers are assumed to be perfectly planar and the layers are assumed to be isotropic and homogeneous, with a complex permittivity and permeability.  Moreover, the layers may be composed of a left-handed material (negative refractive material) and/or a right-handed material.  The implementation is suitable for the study of modern applications, e.g., Anderson localization of light and sub-wavelength imaging."}}, {"pk": 616, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "CROC", "license": "UNKNOWN", "author": "S. Joshua Swamidass", "author_email": "swamidass@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://swami.wustl.edu/CROC", "version": "1.0.60", "platform": "UNKNOWN", "keywords": null, "summary": "A package for calculating ROC curves and Concentrated ROC (CROC) curves.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: Free for non-commercial use\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Medical Science Apps.\nTopic :: Scientific/Engineering :: Visualization", "description": "================\nThe CROC Package\n================\n\nA package for calculating ROC curves and Concentrated ROC (CROC) curves written by `Dr. S. Joshua Swamidass <http://swami.wustl.edu>`_.\n\nCitation\n--------\n\n  | **A CROC Stronger than ROC: Measuring, Visualizing, and Optimizing Early Retrieval**\n  | S. Joshua Swamidass, Chloe-Agathe Azencott, Kenny Daily and Pierre Baldi\n  | *Bioinformatics*, April 2010, `doi:10.1093/bioinformatics/btq140 <http://bioinformatics.oxfordjournals.org/cgi/content/abstract/btq140>`_\n\nDescription\n-----------\n\nThis pure-python package is designed to be a standardized implementation of performance curves\nand metrics for use either in python scripts or through a simple commandline interface. As a standardized implementation\nits output is robust enough to be using in publishable scientific work.\n\nWith this package, one can easily:\n\n#. Compute the coordinates of both Accumulation Curves and ROC curves.\n#. Handle ties appropriately using several methods.\n#. Compute the BEDROC metric.\n#. Vertically add and average the performance curves of several cross-validation folds.\n#. Focus on the early part of the ROC curve by using several x-axis transforms.\n\nThe docstrings in this module are fairly complete and the scripts provide simple access to\nthe most common functions. Further documentation can be found at http://swami.wustl.edu/CROC/"}}, {"pk": 617, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "cosmocalc", "license": "", "author": "Tom Aldcroft", "author_email": "aldcroft@head.cfa.harvard.edu", "project_url": null, "maintainer_email": "", "home_page": "http://cxc.harvard.edu/contrib/cosmocalc/", "version": "0.1.2", "platform": "", "keywords": "cosmology", "summary": "Calculate useful values for a given redshift and cosmology", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Physics", "description": "The following values are calculated:\r\n\r\n    ====  ===================================  ===========\r\n    Name  Value                                Units\r\n    ====  ===================================  ===========\r\n    z     Input redshift \r\n    H0    Hubble constant\r\n    WR    Omega(radiation)                     \r\n    WK    Omega curvaturve = 1-Omega(total)     \r\n    WM    Omega matter\r\n    WV    Omega vacuum\r\n    DTT   Time from z to now                   Gyr\r\n    age   Age of Universe                      Gyr\r\n    zage  Age of Universe at redshift z        Gyr\r\n    DCMR  Comoving radial distance             Gyr Mpc cm\r\n    VCM   Comoving volume within redshift      Gpc3 \r\n    DA    Angular size distance                Gyr Mpc cm\r\n    DL    Luminosity distance                  Gyr Mpc cm\r\n    PS    Plate scale - distance per arcsec    kpc cm\r\n    ====  ===================================  ==========="}}, {"pk": 618, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.pysp", "license": "BSD", "author": "Jean-Paul Watson", "author_email": "jwatson@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/coopr/coopr.pysp", "version": "2.6", "platform": "any", "keywords": "optimization", "summary": "Coopr stochastic programming modeling and solver techniques", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "=================\ncoopr.pysp README\n=================\n\nThis Python package defines stochastic programming extensions for the Pyomo\nmodeling language.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * coopr-forum@googlegroups.com\n    - The main list for help and announcements\n  * coopr-developers@googlegroups.com\n    - Where developers of Coopr discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 619, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "oldowan.mtdna", "license": "MIT", "author": "Ryan Raaum", "author_email": "code@raaum.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.raaum.org/software/oldowan", "version": "1.0.1", "platform": "Any", "keywords": "", "summary": "Human reference mtdna sequence in Python formats.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "oldowan.mtdna contains the human revised Cambridge Reference Sequence (rCRS) in\nPython friendly formats.\n\nInstallation Instructions\n=========================\n\nThis package is pure Python and has no dependencies outside of the standard\nlibrary. The easist way to install is using ``easy_install`` from the\nsetuptools_ package.  This usually goes something like this::\n\n\t$ easy_install oldowan.mtdna\n\nor on a unix-like system, assuming you are installing to the main Python\n``site-packages`` directory as a non-privileged user, this::\n\n\t$ sudo easy_install oldowan.mtdna\n\nYou may also use the standard python distutils setup method. Download the\ncurrent source archive from the file list towards the bottom of this page,\nunarchive it, and install. On Mac OS X and many other unix-like systems, having\ndownloaded the archive and changed to the directory containing this archive in\nyour shell, this might go something like::\n\n\t$ tar xvzf oldowan.mtdna*\n\t$ cd oldowan.mtdna*\n\t$ python setup.py install\n\nQuick Start\n===========\n\nThis package provides the human rCRS in several Python friendly formats.\n\n  >>> from oldowan.mtdna import rCRS\n  >>> from oldowan.mtdna import rCRSlist\n  >>> from oldowan.mtdna import rCRSplus\n  >>> from oldowan.mtdna import rCRSplus_positions\n\n``rCRS`` is the raw sequence as a string::\n\n  >>> len(rCRS)\n  16569\n  >>> rCRS[0:10]\n  'GATCACAGGT'\n\n``rCRSlist`` is the rCRS sequence broken into a list. NOTE that this list is\npadded with a nonsense character in position 0 such that the indices match the\nstandard biologial sequence position numbering (i.e. starting at 1 rather than\n0)::\n\n  >>> rCRSlist[0]\n  '#'\n  >>> rCRSlist[1]\n  'G'\n\n``rCRSplus`` is a partially repeat of the rCRS sequence. Because the mtDNA molecule is circular, it cannot be properly represented by a linear string. This might not be that big of an issue if experimentally derived mtDNA sequences generally do not span the break, BUT as it happens, the most commonly sequenced region of the mitochondrial genome (the control region) spans the point where the circular sequence is conventionally broken for the linear sequence. Thus, ``rCRSplus`` repeats 1000bp on either end of the molecule to facilitate sequence alignment across the break. The ``rCRSplus_positions`` list remaps the indices of ``rCRSplus`` onto the conventional position numbering of the rCRS.\n\n  >>> len(rCRSplus)\n  18638\n  >>> rCRSplus[1]\n  'A'\n  >>> rCRSlist[1]\n  'G'\n  >>> rCRSlist[rCRSplus_positions[1]]\n  'A'\n\nFinally, the oldowan.mtdna package provides indices to extract common mtDNA regions from the rCRS.\n\n  >>> from oldowan.mtdna import HVR1_indices\n  >>> from oldowan.mtdna import HVR2_indices\n  >>> from oldowan.mtdna import HVR1and2_indices\n  >>> from oldowan.mtdna import HVR1to2_indices\n  >>> from oldowan.mtdna import coding_indices\n  >>> from oldowan.mtdna import all_indices\n  \n  >>> hvr1 = ''.join(list(rCRSlist[x] for x in HVR1_indices))\n\n\nRelease History\n===============\n\n1.0.0 (March 25, 2009)\n    initial release of module.\n\n1.0.1 (March 25, 2009)\n    minor version reporting fix\n\n.. _setuptools: http://peak.telecommunity.com/DevCenter/EasyInstall"}}, {"pk": 620, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nwalign", "license": "BSD", "author": "brentp", "author_email": "bpederse@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/brentp/biostuff/", "version": "0.3.1", "platform": "UNKNOWN", "keywords": "sequence bioinformatics alignment needleman-wunsch", "summary": "Needleman-Wunsch global sequence alignment", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Text Processing", "description": "------------------------------------------------------------------------------\nnwalign: fast `cython`_  - `Needleman-Wunsch`_ alignment\n------------------------------------------------------------------------------\n\n.. _`Needleman-Wunsch`: http://en.wikipedia.org/wiki/Needleman-Wunsch_algorithm \n.. _`scoring matrix`: http://en.wikipedia.org/wiki/Substitution_matrix\n.. _`cython`: http://cython.org\n\nThis module provides a python module and a command-line interface to do global-\nsequence alignment using the `Needleman-Wunsch` algorithm. It uses `cython`_ \nand numpy for speed.\n\nCommand-Line Usage \n==================\nthe nwalign executable is installed to the PATH by setuptools\n::\n\n    $ nwalign alphabet alpet\n    alphabet\n    alp---et\n\nspecify an alignment `scoring matrix`_ \n::\n\n    $ nwalign --matrix /usr/share/ncbi/data/BLOSUM62 EEAEE EEEEG\n    EEAEE-\n    EE-EEG\n\nwith specified penalties\n::\n\n    $ nwalign --gap_open -10 --gap_extend -4 --match 12 ASDFF ASFF\n    ASDFF\n    AS-FF\n\n\nPython Usage\n============\nAlignment\n---------\n::\n\n    >>> import nwalign as nw\n    >>> nw.global_align(\"CEELECANTH\", \"PELICAN\", matrix='PAM250')\n    ('CEELE-CANTH', '-PEL-ICAN--')\n\n    # with a specified penalty for open and extend.\n    >>> nw.global_align(\"CEELECANTH\", \"PELICAN\", gap_open=-10, gap_extend=-4, matrix='PAM250')\n    ('CEELECANTH', '-PELICAN--')\n\n\nthe `matrix` is specified as the full path to an `scoring matrix`_ as\nis distributed with the NCBI toolset.\n\nScoring\n-------\nget the score of an alignment. (the first 2 args are from an alignment\nand must have the same length.\n::\n\n    >>> nw.score_alignment('CEELECANTH', '-PELICAN--', gap_open=-5,\n    ...                     gap_extend=-2, matrix='PAM250')\n    11\n\n    >>> nw.score_alignment('CEELE-CANTH', '-PEL-ICAN--', gap_open=-5,\n    ...                     gap_extend=-2, matrix='PAM250')\n    6"}}, {"pk": 621, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "sampy", "license": "GNU General Public License", "author": "Luigi Paioro", "author_email": "luigi at iasf-milano.inaf.it", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/sampy/", "version": "1.2.1", "platform": "All", "keywords": null, "summary": "SAMPy is an IVOA SAMP (Simple Application Messaging Protocol) messaging system implementation in Python.", "classifiers": "Intended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Software Development :: Libraries", "description": "SAMPy is a Python implementation of the IVOA Simple Application\nMessaging Protocol [*] version 1.2 (with Web Profile support).\n\nSAMPy Python module (sampy.py) provides classes to easily:\n\n1) instantiate one or multiple Hubs;\n2) interface an application or script to a running Hub;\n3) create and manage a SAMP client.\n\nSAMPy package provides also a stand-alone program \"sampy\" capable to\ninstantiate a persistent Hub. In order to have a full description of\n\"sampy\" stand-alone program running options, type the command:\n\nshell > sampy -h\n\n\n[*] http://www.ivoa.net/Documents/latest/SAMP.html"}}, {"pk": 622, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "numarray", "license": "http://www.stsci.edu/resources/software_hardware/pyraf/LICENSE", "author": "Todd Miller", "author_email": "jmiller@stsci.edu", "project_url": null, "maintainer_email": null, "home_page": "http://www.stsci.edu/resources/software_hardware/numarray/", "version": "1.5.1", "platform": "Windows,Linux,Solaris,Mac OS-X", "keywords": null, "summary": "numarray: array processing for numbers, strings, records and objects.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "Numarray is an array processing package designed to efficiently\nmanipulate large multi-dimensional arrays.  Numarray is modelled after\nNumeric and features c-code generated from python template scripts,\nthe capacity to operate directly on arrays in files, and improved type\npromotions.  Numarray provides support for manipulating arrays\nconsisting of numbers, strings, records, or objects using the same\nbasic infrastructure and syntax."}}, {"pk": 623, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.plugins.matlab", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/plugins/matlab.html", "version": "0.3", "platform": "UNKNOWN", "keywords": "matlab dap opendap dods data", "summary": "Matlab plugin for pydap server", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This is a plugin for serving data in pydap server from Matlab 4/5 files.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/plugins/matlab#egg=dap.plugins.matlab-dev>`_."}}, {"pk": 624, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.plugins.netcdf", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/plugins/netcdf.html", "version": "0.3.5", "platform": "UNKNOWN", "keywords": "netcdf dap opendap dods data", "summary": "netCDF plugin for pydap server", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This is a plugin for serving data in a pydap server from netCDF 3\nfiles. It works either with the pynetcdf module or with pupynere,\nan experimental pure Python netCDF reader.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/plugins/netcdf#egg=dap.plugins.netcdf-dev>`_."}}, {"pk": 625, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyX", "license": "GPL", "author": "Joerg Lehmann, Andre Wobst", "author_email": "pyx-devel@lists.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://pyx.sourceforge.net/", "version": "0.10", "platform": "OS independent", "keywords": null, "summary": "Python package for the generation of PostScript and PDF files", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "PyX is a Python package for the creation of PostScript and PDF files. It\ncombines an abstraction of the PostScript drawing model with a TeX/LaTeX\ninterface. Complex tasks like 2d and 3d plots in publication-ready quality are\nbuilt out of these primitives."}}, {"pk": 626, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "improb", "license": "GPL", "author": "Matthias Troffaes", "author_email": "matthias.troffaes@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pypi.python.org/pypi/improb/", "version": "0.1.0", "platform": "any", "keywords": "statistics,lower prevision,imprecise probability,credal set", "summary": "improb is a Python module for working with imprecise probabilities.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Mathematics", "description": "The library supports arbitrary finitely generated conditional lower\r\nprevisions, belief functions, linear-vacuous mixtures, probability\r\nmeasures, n-monotone lower probabilities, and Mobius transforms.\r\n\r\nVarious decision criteria, such as Gamma-maximin, Gamma-maximax,\r\ninterval dominance, and maximality, are implemented. For sequential\r\ndecision problems, the library has a convenient interface for\r\nconstructing decision trees of any size, and has algorithms for\r\nsolving them by normal form, or by normal form backward induction.\r\n\r\n* Download: http://pypi.python.org/pypi/improb/#downloads\r\n\r\n* Documentation: http://packages.python.org/improb/\r\n\r\n* Development: http://github.com/mcmtroffaes/improb/"}}, {"pk": 627, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "spc", "license": "MIT", "author": "Michal Nowikowski", "author_email": "godfryd@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "https://launchpad.net/python-spc", "version": "0.3", "platform": "Any", "keywords": null, "summary": "Statistical Process Control library for monitoring process behaviour", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Bug Tracking\nTopic :: Software Development :: Quality Assurance", "description": "Statistical Process Control library for monitoring process behaviour."}}, {"pk": 628, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "arrayterator", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://taoetc.org/6", "version": "1.0.1", "platform": "UNKNOWN", "keywords": "data array math", "summary": "Buffered iterator for big arrays.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This class creates a buffered iterator for reading big arrays in small\ncontiguous blocks. The class is useful for objects stored in the\nfilesystem. It allows iteration over the object *without* reading\neverything in memory; instead, small blocks are read and iterated over.\n                \nThe class can be used with any object that supports multidimensional\nslices, like variables from Scientific.IO.NetCDF, pynetcdf and ndarrays.\n\nChangelog:\n    1.0.1 - Implemented the array interface.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/arrayterator#egg=arrayterator-dev>`_."}}, {"pk": 629, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "EnvisagePlugins", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/envisage_plugins.php", "version": "3.2.0", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Plug-ins for the Envisage framework.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The EnvisagePlugins project includes a number of plug-ins for the Envisage\nframework that Enthought has found useful for building scientific applications.\nEnvisage does not require that you use these plug-ins, but you may find them\nuseful to avoid having to reinvent these particular wheels.\n\n- **Workbench**: Provides an application GUI window that supports views and\n  perspectives, similar to the Eclipse IDE.\n- **Action**: Supports user-interaction command mechanisms, such as toolbars,\n  menus, and buttons.\n- **Single Project**: Supports a project paradigm for saving application data,\n  assuming an interaction model in which only one project can be open in the\n  application at a time.\n- **Text Editor**: Provides a rudimentary text editor interface.\n- **Python Shell**: Provides an interactive Python shell within a\n  Workbench-based application.\n- **Debug**: Provides the Frame Based Inspector from the ETSDevTools project\n  as an Envisage plug-in.\n\nPrerequisites\n-------------\nIf you want to build EnvisagePlugins from source, you must first install\n`setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 630, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "openbabel-python", "license": "http://www.gnu.org/copyleft/gpl.html", "author": "The Open Babel development team", "author_email": "openbabel-scripting@lists.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://openbabel.sourceforge.net/wiki/Python", "version": "1.3", "platform": "UNKNOWN", "keywords": null, "summary": "openbabel: Python interface to the Open Babel chemistry library", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Other Environment\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Software Development :: Libraries", "description": "Open Babel is a chemical toolbox designed to speak the\nmany languages of chemical data. It's an open, collaborative project\nallowing anyone to search, convert, analyze, or store data from\nmolecular modeling, chemistry, solid-state materials, biochemistry,\nor related areas."}}, {"pk": 631, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyGEP", "license": "GPL", "author": "Ryan J. O'Neil", "author_email": "ryanjoneil@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/pygep", "version": "0.2.1.beta-r100", "platform": "UNKNOWN", "keywords": "gene expression programming genetic evolutionary", "summary": "Gene Expression Programming for Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence", "description": "UNKNOWN"}}, {"pk": 632, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Bottleneck", "license": "Simplified BSD", "author": "Keith Goodman", "author_email": "bottle-neck@googlegroups.com", "project_url": null, "maintainer_email": null, "home_page": "http://berkeleyanalytics.com/bottleneck", "version": "0.4.3", "platform": "OS Independent", "keywords": null, "summary": "Fast NumPy array functions written in Cython", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Cython\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "Bottleneck is a collection of fast NumPy array functions written in Cython:\n        \n        ===================== =======================================================\n        NumPy/SciPy           ``median, nanmedian, rankdata, nansum, nanmin, nanmax,\n                              nanmean, nanstd, nanargmin, nanargmax`` \n        Functions             ``nanrankdata, nanvar``\n        Moving window         ``move_sum, move_nansum, move_mean, move_nanmean,\n                              move_std, move_nanstd, move_min, move_nanmin, move_max,\n                              move_nanmax``\n        ===================== =======================================================\n        \n        Let's give it a try. Create a NumPy array::\n            \n            >>> import numpy as np\n            >>> arr = np.array([1, 2, np.nan, 4, 5])\n        \n        Find the nanmean::\n        \n            >>> import bottleneck as bn\n            >>> bn.nanmean(arr)\n            3.0\n        \n        Moving window nanmean::\n        \n            >>> bn.move_nanmean(arr, window=2)\n            array([ nan,  1.5,  2. ,  4. ,  4.5])\n        \n        Fast\n        ====\n        \n        Bottleneck is fast::\n        \n            >>> arr = np.random.rand(100, 100)    \n            >>> timeit np.nanmax(arr)\n            10000 loops, best of 3: 90 us per loop\n            >>> timeit bn.nanmax(arr)\n            100000 loops, best of 3: 12.6 us per loop\n        \n        Let's not forget to add some NaNs::\n        \n            >>> arr[arr > 0.5] = np.nan\n            >>> timeit np.nanmax(arr)\n            10000 loops, best of 3: 133 us per loop\n            >>> timeit bn.nanmax(arr)\n            100000 loops, best of 3: 12.6 us per loop\n        \n        Bottleneck comes with a benchmark suite. To run the benchmark::\n            \n            >>> bn.bench(mode='fast', dtype='float64', axis=0)\n            Bottleneck performance benchmark\n                Bottleneck  0.4.3\n                Numpy (np)  1.5.1\n                Scipy (sp)  0.9.0\n                Speed is NumPy or SciPy time divided by Bottleneck time\n                NaN means one-third NaNs; float64 and axis=0 are used\n                High-level functions used (mode='fast')\n        \n                             no NaN     no NaN     no NaN      NaN        NaN        NaN    \n                            (10,10)   (100,100) (1000,1000)  (10,10)   (100,100) (1000,1000)\n            median            5.03       2.18       2.28       5.77       4.08       2.89\n            nanmedian       120.51      29.31       4.40     151.19      75.39       6.56\n            nansum           11.79       6.29       1.71      11.77       7.32       1.69\n            nanmax           12.31       6.22       1.67      13.25      10.42       1.68\n            nanmean          23.02      13.81       2.98      23.71      29.02       5.10\n            nanstd           27.88       9.66       2.66      29.18      17.78       3.67\n            nanargmax        10.97       5.87       2.65      11.25       8.73       2.81\n            rankdata         22.46      12.85       8.76      22.22      14.41       9.84\n            move_sum         11.34       8.55      14.29      11.05       9.03      13.84\n            move_nansum      29.18      20.42      29.05      29.58      25.72      29.40\n            move_mean        10.66       4.41      14.36      10.47       8.90      13.95\n            move_nanmean     31.35      12.07      29.77      32.50      15.50      30.61\n            move_std         17.40       3.42      22.98      22.37      21.23      29.89\n            move_nanstd      34.71       6.36      34.77      40.26       7.14      36.14\n            move_max          3.98       3.74       9.30       4.62       5.87      11.68\n            move_nanmax      21.64       6.47      19.59      24.89      15.40      26.98\n        \n            Reference functions:\n            median         np.median\n            nanmedian      local copy of sp.stats.nanmedian\n            nansum         np.nansum\n            nanmax         np.nanmax\n            nanmean        local copy of sp.stats.nanmean\n            nanstd         local copy of sp.stats.nanstd\n            nanargmax      np.nanargmax\n            rankdata       scipy.stats.rankdata based (axis support added)\n            move_sum       sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_nansum    sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_mean      sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_nanmean   sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_std       sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_nanstd    sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_max       sp.ndimage.maximum_filter1d based, window=a.shape[0]/5\n            move_nanmax    sp.ndimage.maximum_filter1d based, window=a.shape[0]/5\n        \n        Faster\n        ======\n        \n        Under the hood Bottleneck uses a separate Cython function for each combination\n        of ndim, dtype, and axis. A lot of the overhead in bn.nanmax(), for example,\n        is in checking that the axis is within range, converting non-array data to an\n        array, and selecting the function to use to calculate the maximum.\n        \n        You can get rid of the overhead by doing all this before you, say, enter\n        an inner loop::\n        \n            >>> arr = np.random.rand(10,10)\n            >>> func, a = bn.func.nanmax_selector(arr, axis=0)\n            >>> func\n            <built-in function nanmax_2d_float64_axis0> \n        \n        Let's see how much faster than runs::\n            \n            >>> timeit np.nanmax(arr, axis=0)\n            10000 loops, best of 3: 24.7 us per loop\n            >>> timeit bn.nanmax(arr, axis=0)\n            100000 loops, best of 3: 2.1 us per loop\n            >>> timeit func(a)\n            100000 loops, best of 3: 1.47 us per loop\n        \n        Note that ``func`` is faster than Numpy's non-NaN version of max::\n            \n            >>> timeit arr.max(axis=0)\n            100000 loops, best of 3: 4.78 us per loop\n        \n        So adding NaN protection to your inner loops comes at a negative cost!\n        \n        Benchmarks for the low-level Cython functions::\n        \n            >>> bn.bench(mode='faster', dtype='float64', axis=0)\n            Bottleneck performance benchmark\n                Bottleneck  0.4.3\n                Numpy (np)  1.5.1\n                Scipy (sp)  0.9.0\n                Speed is NumPy or SciPy time divided by Bottleneck time\n                NaN means one-third NaNs; float64 and axis=0 are used\n                Low-level functions used (mode='faster')\n        \n                             no NaN     no NaN     no NaN      NaN        NaN        NaN    \n                            (10,10)   (100,100) (1000,1000)  (10,10)   (100,100) (1000,1000)\n            median            6.07       2.20       2.29       7.51       4.13       2.89\n            nanmedian       145.48      29.33       4.41     201.33      77.24       6.54\n            nansum           20.22       6.66       1.72      20.02       7.95       1.69\n            nanmax           19.31       6.48       1.69      21.36      11.07       1.66\n            nanmean          37.43      14.38       3.00      39.66      30.58       5.01\n            nanstd           42.84       9.90       2.85      44.79      18.23       3.82\n            nanargmax        17.83       6.06       2.68      18.13       9.54       2.85\n            rankdata         23.62      12.63       8.83      23.59      14.30       9.87\n            move_sum         17.53       8.99      13.94      17.01       9.47      13.74\n            move_nansum      47.25      21.71      29.44      49.74      27.34      28.95\n            move_mean        16.45       4.48      14.27      16.19       9.08      13.85\n            move_nanmean     49.29      12.22      29.45      51.56      14.97      30.25\n            move_std         22.57       3.46      23.01      31.58      22.34      29.68\n            move_nanstd      46.73       6.34      34.83      56.56       7.18      35.95\n            move_max          5.69       3.81       9.25       6.70       5.97      11.73\n            move_nanmax      29.97       6.48      19.57      35.73      15.92      27.10\n        \n            Reference functions:\n            median         np.median\n            nanmedian      local copy of sp.stats.nanmedian\n            nansum         np.nansum\n            nanmax         np.nanmax\n            nanmean        local copy of sp.stats.nanmean\n            nanstd         local copy of sp.stats.nanstd\n            nanargmax      np.nanargmax\n            rankdata       scipy.stats.rankdata based (axis support added)\n            move_sum       sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_nansum    sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_mean      sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_nanmean   sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_std       sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_nanstd    sp.ndimage.convolve1d based, window=a.shape[0]/5\n            move_max       sp.ndimage.maximum_filter1d based, window=a.shape[0]/5\n            move_nanmax    sp.ndimage.maximum_filter1d based, window=a.shape[0]/5\n        \n        Slow\n        ====\n        \n        Currently only 1d, 2d, and 3d input arrays with data type (dtype) int32,\n        int64, float32, and float64 are accelerated. All other ndim/dtype\n        combinations result in calls to slower, unaccelerated functions.\n        \n        License\n        =======\n        \n        Bottleneck is distributed under a Simplified BSD license. Parts of NumPy,\n        Scipy and numpydoc, all of which have BSD licenses, are included in\n        Bottleneck. See the LICENSE file, which is distributed with Bottleneck, for\n        details.\n        \n        URLs\n        ====\n        \n        ===================   ========================================================\n         download             http://pypi.python.org/pypi/Bottleneck\n         docs                 http://berkeleyanalytics.com/bottleneck\n         code                 http://github.com/kwgoodman/bottleneck\n         mailing list         http://groups.google.com/group/bottle-neck\n         mailing list 2       http://mail.scipy.org/mailman/listinfo/scipy-user\n        ===================   ========================================================\n        \n        Install\n        =======\n        \n        Requirements:\n        \n        ======================== ====================================================\n        Bottleneck               Python, NumPy 1.5.1\n        Unit tests               nose\n        Compile                  gcc or MinGW\n        Optional                 SciPy 0.8.0 or 0.9.0 (portions of benchmark)\n        ======================== ====================================================\n        \n        Directions for installing a *released* version of Bottleneck (i.e., one\n        obtained from http://pypi.python.org/pypi/Bottleneck) are given below. Cython\n        is not required since the Cython files have already been converted to C source\n        files. (If you obtained bottleneck directly from the repository, then you will\n        need to generate the C source files using the included Makefile which requires\n        Cython.)\n        \n        **GNU/Linux, Mac OS X, et al.**\n        \n        To install Bottleneck::\n        \n            $ python setup.py build\n            $ sudo python setup.py install\n            \n        Or, if you wish to specify where Bottleneck is installed, for example inside\n        ``/usr/local``::\n        \n            $ python setup.py build\n            $ sudo python setup.py install --prefix=/usr/local\n        \n        **Windows**\n        \n        You can compile Bottleneck using the instructions below or you can use the\n        Windows binaries created by Christoph Gohlke:\n        http://www.lfd.uci.edu/~gohlke/pythonlibs/#bottleneck\n        \n        In order to compile the C code in Bottleneck you need a Windows version of the\n        gcc compiler. MinGW (Minimalist GNU for Windows) contains gcc.\n        \n        Install MinGW and add it to your system path. Then install Bottleneck with the\n        commands::\n        \n            python setup.py build --compiler=mingw32\n            python setup.py install\n        \n        **Post install**\n        \n        After you have installed Bottleneck, run the suite of unit tests::\n        \n            >>> import bottleneck as bn\n            >>> bn.test()\n            <snip>\n            Ran 68 tests in 42.457s\n            OK\n            <nose.result.TextTestResult run=68 errors=0 failures=0>"}}, {"pk": 633, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.common", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.common", "version": "3.0.4", "platform": "any", "keywords": "utility", "summary": "Commonly used PyUtilib data and methods.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "======================\npyutilib.common README\n======================\n\nThis Python package includes commonly used PyUtilib definitions and\ncommands.  For example, this package includes PyUtilib-specific \nexception definitions.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 634, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "summon", "license": "UNKNOWN", "author": "Matt Rasmussen", "author_email": "rasmus@mit.edu", "project_url": null, "maintainer_email": null, "home_page": "http://people.csail.mit.edu/rasmus/summon/", "version": "1.8.9", "platform": "UNKNOWN", "keywords": null, "summary": "A general 2D visualization prototyping module", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Artistic Software\nTopic :: Education\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Visualization", "description": "SUMMON is a python extension module that provides rapid prototyping of\n        2D visualizations.  By heavily relying on the python scripting language,\n        SUMMON allows the user to rapidly prototype a custom visualization for\n        their data,  without the overhead of designing a graphical user\n        interface or recompiling  native code.  By simplifying the task of\n        designing a visualization, users can  spend more time on understanding\n        their data. \n\n        SUMMON is designed to be a fast interface for developing interactive\n        visualizations (via scene graphs) for OpenGL. Although python libraries\n        already exist for accessing OpenGL, python is relatively slow for\n        real-time interaction with large visualizations (trees with 100,000\n        leaves, sparse matrices with a million non-zeros, etc.). Therefore, with\n        SUMMON all real-time interaction is handled with compiled native C++\n        code (via extension module). Python is only executed in the construction\n        and occasional interaction with the visualization. This arrangement\n        provides the best of both worlds. \n\n        SUMMON was designed with several philosophies.  First, a scripting\n        language  (Python) is used to speed up the development process and avoid\n        overhead such as code  compilation.  Second, design of graphical user\n        interfaces should be minimized.  Designing a good interface takes\n        planning and time to layout buttons, scrollbars, and dialog boxes.  Yet\n        a  poor interface is very painful to work with. Even when one has a good\n        interface, rarely can it be automated for batch mode.  Instead, SUMMON\n        relies on the Python  prompt for most interaction.  This allows the\n        users direct access to  the underlying code, which is more expressive,\n        and can be automated through scripting."}}, {"pk": 635, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pidsim", "license": "GPL-2", "author": "Rafael Goncalves Martins", "author_email": "rafael@rafaelmartins.eng.br", "project_url": null, "maintainer_email": null, "home_page": "http://pidsim.org/", "version": "1.0rc6", "platform": "any", "keywords": null, "summary": "PID Controllers simulator (core)", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "PIDSIM core package\n===================\n\n.. warning::\n\n   This package just have the python modules, not any GUI.\n\nThis package implements a basic toolbox for the study of the Control\nSystems and the simulation of PID controllers, using Python.\n\nTo use the examples, please initialize this package, using::\n\n    >>> from pidsim.types import *\n    >>> from pidsim.discretization import *\n    >>> from pidsim.pid_simulation import *\n    >>> from pidsim.error import *\n\nIf you need some help with the use, or can help with the development,\nplease contact the author via email or visit our project website:\n\nhttp://pidsim.org/\n\nAll the help is welcome! :)\n\n\nBasic installation\n~~~~~~~~~~~~~~~~~~\n\nTo install, type::\n\n    # python setup.py install\n\nor use pip::\n\n    # pip install pidsim\n\nTo build doc (you'll need sphinx), type::\n\n    # make -C doc html"}}, {"pk": 636, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.workflow", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.workflow", "version": "2.2.2", "platform": "any", "keywords": "utility", "summary": "PyUtilib workflow automation.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "========================\npyutilib.workflow README\n========================\n\nThis Python package includes a simple workflow management system.  This\nis inspired by other open-source workflow tools, such as pyphant and\nspiffworkflow.  What distinguished pyutilib.workflow is that it is\nnot strongly dependent on the datatypes being managed (e.g. the use of \nscipy or numpy types).  Also, pyutilib.workflow is designed to support\nPython-level definitions of the workflow (rather than a separate XML\nspecification).\n\nSee `Managing Scientific Workflows in Python with pyutilib.workflow <https://software.sandia.gov/svn/public/pyutilib/pyutilib.workflow/trunk/doc/workflow/workflow.pdf>`_ for a detailed description of PyUtilib workflows and examples of their use.\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 637, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "seeds", "license": "Apache Version 2", "author": "Brian Connelly", "author_email": "bdc@msu.edu", "project_url": null, "maintainer_email": null, "home_page": "https://github.com/briandconnelly/seeds", "version": "1.0.3", "platform": "UNKNOWN", "keywords": "simulation,evolution,ecology", "summary": "Stochastic Ecological and Evolutionary Dynamics System", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Apache Software License\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Artificial Life", "description": "==============================================================\nSEEDS - Stochastic Ecological and Evolutionary Dynamics System\n==============================================================\n\n:Created by:\n    Brian Connelly <bdc@msu.edu> and Luis Zaman <zamanlui@msu.edu>\n:Website:\n    https://github.com/briandconnelly/seeds\n\n\nExpanded Documentation:\n-----------------------\nThe primary source for documentation is the SEEDS Wiki_.  Here, detailed\ninstallation instructions, how-to guides, code templates, and example\nexperiments are provided.\n\n\nInstalling SEEDS:\n-------------------\nSEEDS requires Python version 2.6.5 or greater.  Additionally, SEEDS requires\nthe NetworkX_ package.\n\nInstallation is done using the standard Python Distribution Utilities and can\nbe as straightforward as running \"python setup.py install\".  For further\ninstructions on this process, please see the SEEDS Wiki_ or the official\nDistutils documentation at http://docs.python.org/install/index.html.\n\n\nRunning SEEDS:\n--------------\nOut of the box, SEEDS includes simple experiments in the examples directory.\nThese experiments can be run once SEEDS has been installed on your system.\nSee the README.txt file in a specific directory to learn about the experiment,\nhow to configure it, and how to perform it.\n\n\nExpanding SEEDS:\n----------------\nSEEDS is designed as a plugin-based framework.  This means that you can\ncreate and use your own cell types, topologies, and actions and use these\nimmediately without modifying the base SEEDS framework.\n\nTo create experiments that model behaviors of interest to you, a Cell type will\nneed to be created.  More information on this process can be found on the\nSEEDS website.  Additionally, sample Cell types can be found in the examples\ndirectory.\n\nOnce you have created your additional types or actions, place them in a\ndirectory called \"plugins\", and edit seeds.cfg, instructing the experiment to\nuse them.  For cell types, change the value of the \"cell\" parameter in the\n\"Experiment\" section.  For topologies, change the value of the \"topology\"\nparameter in the \"Experiment\" section.  For actions, add it to the\ncomma-separated \"actions\" parameter in the \"Experiment\" section.  Parameters to\nyour plugins can be set in the seeds.cfg file in the section you define in\nyour code.\n\n\nReporting Bugs and Feature Requests:\n------------------------------------\nSEEDS is under constant development.  To see which features and changes are\nplanned or to report bugs, visit http://github.com/briandconnelly/seeds/issues.\n\n\nLicense:\n--------\nSeeds is released under the `Apache License, Version 2.0`__.  For more\ninformation, see the files LICENSE.txt_ and NOTICE.txt_.\n\n\n.. _Wiki: https://github.com/briandconnelly/seeds/wiki\n.. _NetworkX: http://networkx.lanl.gov/\n.. _Apache: http://www.apache.org/licenses/LICENSE-2.0\n__ Apache_\n.. _LICENSE.txt: https://github.com/briandconnelly/seeds/blob/master/LICENSE.txt\n.. _NOTICE.txt: https://github.com/briandconnelly/seeds/blob/master/NOTICE.txt"}}, {"pk": 638, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "FiPy", "license": "------------\n        Terms of Use\n        ------------\n        \n        This software was developed at the `National Institute of Standards\n        and Technology`_ by employees of the Federal Government in the course\n        of their official duties.  Pursuant to `title 17 section 105`_ of the\n        United States Code this software is not subject to copyright\n        protection and is in the public domain.  FiPy is an experimental\n        system.  NIST_ assumes no responsibility whatsoever for its use by\n        other parties, and makes no guarantees, expressed or implied, about\n        its quality, reliability, or any other characteristic.  We would\n        appreciate acknowledgement if the software is used.\n        \n        This software can be redistributed and/or modified freely\n        provided that any derivative works bear some notice that they are\n        derived from it, and any modified versions bear some notice that\n        they have been modified.\n        \n        \n        .. _National Institute of Standards and Technology: http://www.nist.gov/\n        .. _NIST:                 http://www.nist.gov/\n        .. _title 17 section 105: http://www.nist.gov/cgi-bin/exit_nist.cgi?url=http://uscode.house.gov/uscode-cgi/fastweb.exe?getdoc+uscview+t17t20+9+0++", "author": "Jonathan Guyer, Daniel Wheeler, & Jim Warren", "author_email": "fipy@nist.gov", "project_url": null, "maintainer_email": null, "home_page": "http://www.ctcms.nist.gov/fipy/", "version": "2.1", "platform": "UNKNOWN", "keywords": null, "summary": "A finite volume PDE solver in Python", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: X11 Applications\nIntended Audience :: Science/Research\nLicense :: Public Domain\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "========\nOverview\n========\n\n.. only:: latex\n\n   :term:`FiPy` is an object oriented, partial differential equation (PDE) solver,\n   written in :term:`Python`, based on a standard finite volume (FV)\n   approach.  The framework has been developed in the `Metallurgy Division`_\n   and Center for Theoretical and Computational Materials Science (CTCMS_), in\n   the Materials Science and Engineering Laboratory (MSEL_) at the National\n   Institute of Standards and Technology (NIST_).\n\n   The solution of coupled sets of PDEs is ubiquitous to the numerical\n   simulation of science problems.  Numerous PDE solvers exist, using a\n   variety of languages and numerical approaches. Many are proprietary,\n   expensive and difficult to customize.  As a result, scientists spend\n   considerable resources repeatedly developing limited tools for\n   specific problems.  Our approach, combining the FV method and :term:`Python`,\n   provides a tool that is extensible, powerful and freely available. A\n   significant advantage to :term:`Python` is the existing suite of tools for\n   array calculations, sparse matrices and data rendering. \n\n   The :term:`FiPy` framework includes terms for transient diffusion,\n   convection and standard sources, enabling the solution of arbitrary\n   combinations of coupled elliptic, hyperbolic and parabolic PDEs. Currently\n   implemented models include phase field\n   [BoettingerReview:2002]_ [ChenReview:2002]_ [McFaddenReview:2002]_ treatments of\n   polycrystalline, dendritic, and electrochemical phase transformations as\n   well as a level set treatment of the electrodeposition process\n   [NIST:damascene:2001]_.\n\n.. only:: latex\n  \n   The latest information about :term:`FiPy` can be found at\n   http://www.ctcms.nist.gov/fipy/.\n\n---------------------------------\nEven if you don't read manuals...\n---------------------------------\n\n...please read :ref:`INSTALLATION` and the :ref:`FAQ`. \n\n--------------------------------\nWhat's new in version |release|?\n--------------------------------\n\nThe relatively small change in version number belies significant advances\nin :term:`FiPy` capabilities. This release did not receive a \"full\" version\nincrement because it is completely (er... [#almost]_) compatible with older scripts.\n\nThe significant changes since version 2.0.2 are:\n\n- :term:`FiPy` can use :term:`Trilinos` for `solving in parallel`_.\n\n- We have switched from :term:`MayaVi` 1 to :term:`Mayavi` 2. This \n  :class:`~fipy.viewers.viewer.Viewer` is an independent process that \n  allows interaction with the display while a simulation is running.\n\n- Documentation has been switched to :term:`Sphinx`, allowing the entire manual to \n  be available on the web and for our documentation to link to the\n  documentation for packages such as :mod:`numpy`, :mod:`scipy`,\n  :mod:`matplotlib`, and for :term:`Python` itself.\n\nTickets fixed in this release::\n\n    171\tupdate the mayavi viewer to use  mayavi 2\n    286\t'matplotlib: list index out of range' when no title given, but only sometimes\n    197\t~binOp doesn't work on branches/version-2_0\n    194\t`easy_install` instructions for MacOSX are broken\n    192\tbroken setuptools url with python 2.6\n    184\tThe FiPy webpage seems to be broken on Internet Explorer\n    168\tSwitch documentation to use `:math:` directive\n    198\tFiPy2.0.2 LinearJORSolver.__init__  calls Solver rather than PysparseSolver\n    199\t`gmshExport.exportAsMesh()` doesn't work\n    195\tbroken arithmetic face to cell distance calculations\n\n.. warning::\n\n   :term:`FiPy` 2 brought unavoidable syntax changes from :term:`FiPy` 1.\n   Please see :mod:`examples.updating.update1_0to2_0` for guidance on the\n   changes that you will need to make to your :term:`FiPy` 1.x scripts.\n   Few, if any, changes should be needed to migrate from :term:`FiPy` 2.0.x\n   to :term:`FiPy` 2.1.\n\n-------------------------\nDownload and Installation\n-------------------------\n\nPlease refer to :ref:`INSTALLATION` for details on download and\ninstallation. :term:`FiPy` can be redistributed and/or modified\nfreely, provided that any derivative works bear some notice that they\nare derived from it, and any modified versions bear some notice that\nthey have been modified.\n\n-------\nSupport\n-------\n\nYou can communicate with the :term:`FiPy` developers and with other users via our\n`mailing list`_ and we welcome you to use the `tracking\nsystem`_ for bugs, support requests, feature requests and\npatch submissions <http://matforge.org/fipy/report>. We welcome collaborative efforts on this project.\n\n:term:`FiPy` is a member of MatForge_, a project of the `Materials Digital Library\nPathway`_. This National Science Foundation funded service provides\nmanagement of our public source code repository, our bug tracking system, and\na \"wiki\" space for public contributions of code snippets, discussions, and\ntutorials.\n\n.. toctree::\n\n   documentation/MAIL\n\n------------------------\nConventions and Notation\n------------------------\n\n:term:`FiPy` is driven by :term:`Python` script files than you can view or modify in any\ntext editor.  :term:`FiPy` sessions are invoked from a command-line shell, such\nas :command:`tcsh` or :command:`bash`.\n\nThroughout, text to be typed at the keyboard will appear ``like this``.\nCommands to be issued from an interactive shell will appear::\n\n    $ like this\n\nwhere you would enter the text (\"``like this``\") following the shell prompt,\ndenoted by \"``$``\".\n\nText blocks of the form::\n\n    >>> a = 3 * 4\n    >>> a\n    12\n    >>> if a == 12:\n    ...     print \"a is twelve\"\n    ...\n    a is twelve\n\nare intended to indicate an interactive session in the :term:`Python` interpreter.\nWe will refer to these as \"interactive sessions\" or as \"doctest blocks\".\nThe text \"``>>>``\" at the beginning of a line denotes the *primary prompt*,\ncalling for input of a :term:`Python` command.  The text \"``...``\" denotes the\n*secondary prompt*, which calls for input that continues from the line\nabove, when required by :term:`Python` syntax.  All remaining lines, which begin\nat the left margin, denote output from the :term:`Python` interpreter.  In all\ncases, the prompt is supplied by the :term:`Python` interpreter and should not be\ntyped by you.\n\n.. warning::\n\n   :term:`Python` is sensitive to indentation and care should be taken to enter\n   text exactly as it appears in the examples.\n\nWhen references are made to file system paths, it is assumed that the\ncurrent working directory is the :term:`FiPy` distribution directory, refered to\nas the \"base directory\", such that::\n\n    examples/diffusion/steadyState/mesh1D.py\n\nwill correspond to, *e.g.*::\n\n    /some/where/FiPy-X.Y/examples/diffusion/steadyState/mesh1D.py\n\nPaths will always be rendered using POSIX conventions (path elements\nseparated by \"``/``\").  Any references of the form::\n\n    examples.diffusion.steadyState.mesh1D\n\nare in the :term:`Python` module notation and correspond to the equivalent POSIX\npath given above.\n\nWe may at times use a \n\n.. note::\n\n   to indicate something that may be of interest\n\nor a\n\n.. warning::\n\n   to indicate something that could cause serious problems.\n\n.. _PARALLEL:\n\n-------------------\nSolving in Parallel\n-------------------\n\n:term:`FiPy` can use :term:`Trilinos` to solve equations in parallel, as \nlong as they are defined on a \"``Grid``\" mesh \n(:class:`~fipy.meshes.numMesh.grid1D.Grid1D`, \n:class:`~fipy.meshes.numMesh.cylindricalGrid1D.CylindricalGrid1D`,\n:class:`~fipy.meshes.numMesh.grid2D.Grid2D`,\n:class:`~fipy.meshes.numMesh.cylindricalGrid2D.CylindricalGrid2D`, or\n:class:`~fipy.meshes.numMesh.grid3D.Grid3D`). \n\n.. attention::\n\n   :term:`Trilinos` *must* be compiled with MPI support.\n\n.. note::\n\n   A design wart presently *also* requires that :term:`PySparse` be\n   installed. We hope to alleviate this requirement in a future release.\n\n* It should not generally be necessary to change anything in your script. s\n  Simply invoke::\n\n     $ mpirun -np {# of processors} python myScript.py\n\n  instead of::\n\n     $ python myScript.py\n\nA complete list of the changes to FiPy's examples needed for parallel \ncan be found at\n\n  http://www.matforge.org/fipy/wiki/upgrade2_0examplesTo2_1\n\nMost of the changes were required to ensure that :term:`FiPy` provides the\nsame literal output for both single and multiple processor solutions and\nare not relevant to most \"real\" scripts. The two changes you *might* wish\nto make to your own scripts are:\n\n * It is now preferable to use the \n   :class:`~fipy.solvers.DefaultAssymetricSolver` instead of the \n   :class:`~fipy.solvers.linearLUSolver.LinearLUSolver`. \n\n * When solving in parallel, :term:`FiPy` essentially breaks the problem up \n   into separate sub-domains and solves them (somewhat) independently. \n   :term:`FiPy` generally \"does the right thing\", but if you find that you \n   need to do something with the entire solution, you can call\n   ``var.``:meth:`~fipy.variables.cellVariable.CellVariable.getGlobalValue`.\n\n.. [#almost] Only two examples from :term:`FiPy` 2.0 fail when run with :term:`FiPy` 2.1:\n\n    * :mod:`examples.phase.symmetry` fails because \n      :class:`~fipy.meshes.numMesh.mesh.Mesh` no longer provides a\n      :meth:`~fipy.meshes.numMesh.mesh.Mesh.getCells` method. The mechanism\n      for enforcing symmetry in the updated example is both clearer and \n      faster.\n\n    * :mod:`examples.levelSet.distanceFunction.circle` fails because of a \n      change in the comparison of masked values.\n\n   Both of these are subtle issues unlikely to affect very many \n   :term:`FiPy` users.\n\n.. _MSEL:                 http://www.msel.nist.gov/\n.. _CTCMS:                http://www.ctcms.nist.gov/\n.. _Metallurgy Division:  http://www.metallurgy.nist.gov/\n.. _NIST:                 http://www.nist.gov/\n.. _Subversion:           http://www.nist.gov/cgi-bin/exit_nist.cgi?url=http://matforge.org/fipy/browser\n.. _compressed archive:   http://www.ctcms.nist.gov/fipy/download/FiPy-1.1.tar.gz\n.. _tracking system:      http://www.nist.gov/cgi-bin/exit_nist.cgi?url=http://matforge.org/fipy/report\n.. _mailing list:         http://www.ctcms.nist.gov/fipy/mail.html\n.. _Sourceforge:          http://www.nist.gov/cgi-bin/exit_nist.cgi?url=http://www.sourceforge.net/projects/fipy\n.. _Materials Digital Library Pathway: http://www.nist.gov/cgi-bin/exit_nist.cgi?url=http://matdl.org\n.. _MatForge:             http://www.nist.gov/cgi-bin/exit_nist.cgi?url=http://matforge.org/"}}, {"pk": 639, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "FAST", "license": "BSD", "author": "William Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/trac/fast", "version": "2.5", "platform": "any", "keywords": "software testing", "summary": "FAST: Framework for Agile Software Testing", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "FAST provides a collection of Python tools that support software\ntesting."}}, {"pk": 640, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PyKoan", "license": "", "author": "Imri Goldberg", "author_email": "", "project_url": null, "maintainer_email": "", "home_page": "http://www.assembla.com/wiki/show/pykoan", "version": "0", "platform": "", "keywords": "Python, Expression Trees, Logic, Constraints", "summary": "Game of Logic", "classifiers": "Development Status :: 1 - Planning\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Games/Entertainment :: Puzzle Games\nTopic :: Scientific/Engineering :: Mathematics", "description": "Master creates a rule, players need to guess the rule.\r\nRules are applied to lists of integers (called koans), for example under the\r\nrule \"for each x holds x%2==0\" the list [0,2,6] is valid. Players first try out\r\nkoans, and then try to guess the rule."}}, {"pk": 641, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "boostmpi", "license": "Boost Software License V1", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/boostmpi", "version": "1.38.0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Boost MPI Python wrappers", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nNatural Language :: English\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "boostmpi is a high-quality Python wrapper around the \n            `Message Passing Interface <http://mpi-forum.org>`_ (MPI).\n            MPI is a standardized interface to libraries such as\n            `OpenMPI <http://www.open-mpi.org>`_ and \n            `MPICH <http://www.mcs.anl.gov/research/projects/mpich2/>`_\n            that provide high-performance inter-process communication\n            for distributed-memory computing.\n\n            boostmpi uses the \n            `Boost.MPI library <www.boost.org/doc/html/mpi.html>`_, which \n            gives MPI a very usable C++ interface.\n            This C++ interface is then made accessible to Python\n            via the \n            `Boost.Python library <www.boost.org/doc/libs/release/libs/python/doc/>`_.\n\n            boostmpi was originally distributed as part of the \n            `Boost C++ library <http://boost.org>`_. This separate\n            distribution aims to make the software more accessible.\n\n            boostmpi (born as Boost.MPI.Python) was written by \n            `Doug Gregor <http://www.osl.iu.edu/~dgregor/>`_\n            and is currently maintained by \n            `Andreas Kloeckner <http://mathema.tician.de>`_"}}, {"pk": 642, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pybufr-ecmwf", "license": "GPLv2", "author": "Jos de Kloe", "author_email": "josdekloe@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/pybufr-ecmwf/", "version": "0.2", "platform": "POSIX", "keywords": null, "summary": "a python interface around the ECMWF-BUFR library.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX\nProgramming Language :: Fortran\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "a python interface around the Fortran90 ECMWF-BUFR library\nconstructed using the f2py interface generation tool.\nThe equivalent subroutines to the ones in the ECMWF-BUFR\nlibrary are made available to python, but also a set of wrapper \nroutines/classes is implemented to\ncreate also a more object-oriented/pythonic interface.\nBuilding the interface is still a bit rough, and may require some\nediting of the setup.cfg file to choose the correct fortran and c-compiler.\nAlternatively some dedicated commandline options have been\nadded to the setup.py script to allow changing these settings.\nRun 'setup.py build --help' to get a list of the currently available\nbuild options."}}, {"pk": 643, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "cdecimal", "license": "BSD License", "author": "Stefan Krah", "author_email": "skrah@bytereef.org", "project_url": null, "maintainer_email": "", "home_page": "http://www.bytereef.org/mpdecimal/index.html", "version": "2.2", "platform": "Many", "keywords": "decimal,floating point,correctly-rounded,arithmetic,arbitrary precision", "summary": "Fast drop-in replacement for decimal.py", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nProgramming Language :: Python :: 3.2\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development", "description": ""}}, {"pk": 644, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ezplot", "license": "BSD License", "author": "William Baxter", "author_email": "wbaxter@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.billbaxter.com/projects/ezplot/", "version": "0.1.0a4", "platform": "UNKNOWN", "keywords": null, "summary": "Remote Procedure interface to Matplotlib", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Visualization", "description": "A remote procedure interface to Matplotlib.\nThis package allows you to invoke Matplotlib \n     (http://matplotlib.sourceforge.net) \nplotting commands over an XML-RPC interface.  The plotting\ncommands are issued by the 'plotclient', sent over XML-RPC,\nthen executed by a (local) 'plotserver'.  The advantage to\nthis is that the plotting commands are executed in a\ncompletely separate process from the client, thus there are\nno issues with getting stuck in the Matplotlib GUI's main\nloop.  Similar to what you get from\"ipython -pylab\", but this \nworks with any Python shell whether it's console-based or \nGUI based."}}, {"pk": 645, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "collective.geo.bundle", "license": "GPL", "author": "Giorgio Borelli", "author_email": "giorgio@giorgioborelli.it", "project_url": null, "maintainer_email": "", "home_page": "http://plone.org/products/collective.geo", "version": "0.1", "platform": "UNKNOWN", "keywords": "Zope Plone GIS KML Google Maps Bing Yahoo OpenLayers", "summary": "Plone Maps (collective.geo)", "classifiers": "Framework :: Plone\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering :: GIS", "description": "Introduction\r\n============\r\ncollective.geo allows to geo-reference Plone content types and to display this information over a map.\r\n\r\ncollective.geo bundle is composed by the following packages:\r\n\r\n`collective.geo.geographer <http://plone.org/products/collective.geo.geographer>`_\r\n    provides geo annotation for Plone.\r\n\r\n`collective.geo.openlayers <http://plone.org/products/collective.geo.openlayers>`_\r\n    enables openlayers machinery into Plone.\r\n\r\n`collective.geo.settings <http://plone.org/products/collective.geo.settings>`_\r\n    provides some utility to store settings of collective.geo packages.\r\n\r\n`collective.geo.mapwidget <http://plone.org/products/collective.geo.mapwidget>`_\r\n    provides some handy page macros and adapters to easily manage multiple maps on one page.\r\n\r\n`collective.geo.contentlocations <http://plone.org/products/collective.geo.contentlocations>`_\r\n    provides a GUI for collective.geo.geographer. It provides some simple forms to add geographical coordinates to Plone content types.\r\n\r\n`collective.geo.kml <http://plone.org/products/collective.geo.kml>`_\r\n    provides KML views for georeferenced objects, allowing Plone content types to be visualized in Google Earth.\r\n\r\n\r\nTo display the maps, **collective.geo** takes advantage of `Openlayers <http://www.openlayers.org>`_, a JavaScript library for displaying map data in web browsers, with no server-side dependencies.\r\n\r\nAs a default map source we can select `OpenStreetMap <http://www.openstreetmap.org/>`_, `Google Maps <http://maps.google.com>`_, `Yahoo Maps <http://maps.yahoo.com/>`_ or `Bing Maps <http://www.bing.com/maps>`_.\r\n\r\n\r\n.. image:: http://plone.org/products/collective.geo/screenshot\r\n\r\nRequirements\r\n------------\r\n\r\n* libgeos_c (2.2.3 or 3.0.0+)\r\n* `Shapely <http://trac.gispython.org/lab/wiki/Shapely>`_\r\n* BeautifulSoup (geopy)\r\n* geopy\r\n* Plone >= 4.0\r\n* zope.schema = 3.6.0 (z3c.form requirement)\r\n* plone.app.z3cform\r\n* `collective.geo.colorpicker <http://plone.org/products/collective.z3cform.colorpicker>`_\r\n\r\n\r\nInstallation\r\n------------\r\n\r\nAdd collective.geo.bundle to your buildout's list of eggs such as::\r\n\r\n    [buildout]\r\n    ...\r\n    eggs = \r\n        collective.geo.bundle\r\n    ...\r\n\r\nand run the buildout. Start Zope, go to Site Setup -> Add-on Products in your Plone site and install the Plone Maps (collective.geo) product.\r\n\r\nYou can find `a buildout example here <http://svn.plone.org/svn/collective/collective.geo.bundle/buildout/>`_\r\n\r\n\r\nContributors\r\n------------\r\n * Giorgio Borelli - gborelli\r\n * Silvio Tomatis - silviot\r\n * Gerhard Weis - gweis\r\n * David Breitkreutz - rockdj\r\n * Maurizio Delmonte - miziodel (Spingitore di Cavalieri)\r\n\r\nChangelog\r\n=========\r\n\r\n0.1 (2011-03-06)\r\n----------------\r\n\r\n- First release"}}, {"pk": 646, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ppgplot", "license": "UNKNOWN", "author": "Nick Patavalis", "author_email": "npat@efault.net", "project_url": null, "maintainer_email": null, "home_page": "http://efault.net/npat/hacks/ppgplot", "version": "1.2", "platform": "UNKNOWN", "keywords": null, "summary": "Python / Numeric-Python bindings for PGPLOT", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: X11 Applications\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: POSIX :: Linux\nOperating System :: POSIX :: SunOS/Solaris\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Fortran\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Multimedia :: Graphics :: Editors :: Vector-Based\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 647, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "oldowan.mtconvert", "license": "MIT", "author": "Ryan Raaum", "author_email": "code@raaum.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.raaum.org", "version": "1.0.2", "platform": "Any", "keywords": "bioinformatics", "summary": "Transform human mtDNA sequence to variant sites and vice versa.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "oldowan.mtconvert is a small, pure Python, bioinformatic utility to (1)\ntransform human mitochondral DNA sequence data into variant sites relative to\nthe revised Cambridge Reference Sequence (rCRS) and (2) transform variant sites\ndata into DNA sequence. Further information on the rCRS and variant site\nnomenclature for human mtDNA sequences is available at the mtconvert_ website. \n\nInstallation Instructions\n=========================\n\nThis package is pure Python and has no dependencies outside of the standard\nlibrary. The easist way to install is using ``easy_install`` from the\nsetuptools_ package.  This usually goes something like this::\n\n\t$ easy_install oldowan.mtconvert\n\nor on a unix-like system, assuming you are installing to the main Python\n``site-packages`` directory as a non-privileged user, this::\n\n\t$ sudo easy_install oldowan.mtconvert\n\nYou may also use the standard python distutils setup method. Download the\ncurrent source archive from the file list towards the bottom of this page,\nunarchive it, and install. On Mac OS X and many other unix-like systems, having\ndownloaded the archive and changed to the directory containing this archive in\nyour shell, this might go something like::\n\n\t$ tar xvzf oldowan.mtconvert*\n\t$ cd oldowan.mtconvert*\n\t$ python setup.py install\n\nQuick Start\n===========\n\nImport ``seq2sites`` and ``sites2seq`` from oldowan.mtconvert::\n\n  >>> from oldowan.mtconvert import seq2sites, sites2seq\n\nConvert sequence to sites::\n\n  >>> seq = \"\"\"TTCTTTCATGGGGAAGCAGATTTGGGTACCACCCAA\n  GTATTGACTCACCCATCAACAACCGCTATGTATTTCGTACATTACTGCC\n  AGCCACCATGAATATTGTACAGTACCATAAATACTTGACCACCTGTAGT\n  ACATAAAAACCCAATCCACATCAAAACCCCCTCCCCATGCTTACAAGCA\n  AGTACAGCAATCAACCTTCAACTATCACACATCAACTGCAACTCCAAAG\n  CCACCCCTCACCCACTAGGATACCAACAAACCTACCCACCCTTAACAGT\n  ACATAGTACATAAAGCCATTTACCGTACATAGCACATTACAGTCAAATC\n  CCTTCTCGTCCC\"\"\"\n  >>> seq2sites(seq)\n\nSequences must be contiguous! Separate runs of sequence, such as HVR1 and HVR2\nwithout the intervening sequence interval, must be analyzed separately.\n\nThere is also a cutoff on the number of ambigous sites (N) allowed in the\nsequence. By default, this is 10 - but this is an option that can be set::\n\n  >>> seq2sites(seq, ambig_cutoff=20)\n\nConvert a list of variable sites to sequence. The default sequence region that\nis returned is hypervariable region 1 (HVR1), which is positions 16024 to 16365\nof the rCRS (in biological one-based numbering)::\n\n  >>> sites2seq('16129A 16223T')\n\nPredefined sequence regions are:\n\n- HVR1: 16024-16365\n- HVR2: 73-340\n- HVR1to2: 16024-340\n- coding: 577-15992\n- all: 1-16559\n\nSo, to convert a list of HVR2 sites to sequence::\n\n  >>> sites2seq('73G', region='HVR2')\n\nSites may also be provided in a list::\n\n  >>> sites2seq(['16129A', '16223T', '73G'], region='HVR1to2')\n\nThe rCRS sequence will be returned given an empty string, empty list, or the\nstring 'rCRS'. All of the following are equivalent::\n\n  >>> sites2seq('')\n  >>> sites2seq([])\n  >>> sites2seq('rCRS')\n\nArbitrary positions may be selected by passing a list of sites to the\n``region`` option::\n\n  >>> sites2seq('', region=[1,2,3])\n\nThe Python range function is convenient for this, but you must remember that\nthe range does not include it's ending position::\n\n  >>> sites2seq('', region=range(73,341))  # include 340, but not 341\n    \nRelease History ===============\n\n1.0.0 (March 25, 2009)\n    initial release of module.\n\n1.0.1 (March 25, 2009)\n    minor versioning fix\n\n.. _setuptools: http://peak.telecommunity.com/DevCenter/EasyInstall"}}, {"pk": 648, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pywinusb", "license": "BSD", "author": "Rene F. Aguirre", "author_email": "rene.f.aguirre@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/pywinusb", "version": "0.2.5", "platform": "UNKNOWN", "keywords": "hid usb usages", "summary": "A package that simplifies USB/HID communications on windows", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Win32 (MS Windows)\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nOperating System :: Microsoft :: Windows\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: Embedded Systems\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Hardware\nTopic :: System :: Hardware :: Hardware Drivers\nTopic :: Utilities", "description": "=================================\nInstalling and Using pywinusb.hid\n=================================\n\n.. contents:: **Table of Contents**\n\n------------\nIntroduction\n------------\n\nThis project aims to be a simple USB/HID user application space (hence no system \ndrivers needed) 100% python package (without C extensions). Initially targeting \nsimple HID devices management, also planed, is `support for WinUSB`_ high level wrapping.\n\nThe vision for this project is to be something similar to `PySerial` or `PyParallel` \nbut for USB/HID hardware enthusiasts.\n\n.. _support for WinUSB: http://msdn.microsoft.com/en-us/library/aa476426.aspx\n\nAdvantages\n----------\n\n * All python code, using ctypes\n \n * Top level handling of HID events (usage events calling hook function handlers)\n\nCurrent limitations\n-------------------\n\nDepending on your application you might find these limitations\n\n * Windows only (so far...)\n \n * Not so fast top level interfacing. But you could still access, directly\n   your raw data reports.\n\n-------------------------\nInstallation Instructions\n-------------------------\n\nWindows\n-------\n\nNo package releases yet.  For now you can access the code using `the svn repository`_.\n\nI'm planning initially to have a mature pywinusb.hid name space (sub-package) \nimplementation before attempting any of the pywinusb.winusb stuff.\n\n.. _the svn repository: http://code.google.com/p/pywinusb/source/checkout\n\nOther\n-----\n\nSo far only Windows OS it's supported.\n\n------------------\nUsing pywinusb.hid\n------------------\n\nView the `./examples` directory for some (ok, few right now) scripts. These show,\nfor instance, how to use pywinusb.hid to handle events from HID class devices usages events.\n\nGernal purpose instructions can be found on the `main project code page`_.\n\n.. _main project code page: http://code.google.com/p/pywinusb\n\nUtilities\n---------\n\nMore on this later... \n\n * The module pywinusb.hid.tools contains a function to check HID class devices capabilities, \n   for now it provides a basic human readable text report (see the hid.core package, \n   run it as main while HID class devices are connected to your system)\n\n-------------------------\nFeedback and Contributing\n-------------------------\n\nFeel free to contact me! use the `main code project page`_, just tell what do you think \nabout the project or bring me anything you think might be cool to consider.\n\nAny participation it's appreciated, if you are willing to contribute but don't have any \nideas or spare time, `feel free to donate`_.\n\n.. _main code project page: http://code.google.com/p/pywinusb\n.. _feel free to donate: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=4640085\n\n-------------------------\nRelease changes\n-------------------------\n0.2.5,\n * Tweaked PnP example, added frame closing event handler, so the USB device is closed\n * Report reading threads and device closing optimizations\n\n0.2.4,\n * Fixed bugs preventing properly setting report usage variables after a HidReport().get()\n * Fixed raw_data.py example\n * Fixed bug preventing proper value array setting/getting items\n * Fixed deadlock when device unplugged\n\n0.2.3,\n * Added HidDevice.set_raw_data_handler(), and corresponding raw_data.py example script\n\n0.2.2,\n * Fixing output only mode (no input report for forced open)\n\n0.2.1,\n * Bringing a little bit of stability\n * Output only mode (no reading thread configured)\n * Kind of usable now\n\n0.1.0, \n * First public release\n\nnn"}}, {"pk": 649, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "hmmus", "license": "MIT", "author": "Alex Griffing", "author_email": "argriffi@ncsu.edu", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/argriffing/hmmus", "version": "0.3.1", "platform": "Linux", "keywords": null, "summary": "Posterior decoding with a hidden Markov model", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python :: 2.6\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules", "description": "About hmmus\n===========\n\nHmmus has some\nC implementations of HMM algorithms\nwith Python bindings,\nand it is meant to be useful under the following conditions:\n\n* The sequence of observations to be analyzed is so long\n  that it does not fit conveniently in RAM.\n* Likelihoods per hidden state per position have been precalculated.\n* Numerical stability is important, but is not so important\n  that error bounds on the output are required.\n* Speed is important.\n* The number of hidden states is small.\n* The matrix of probabilities of transitions between hidden states is dense.\n* Binary data files are acceptable as input and output.\n\nThis project would be especially useless in the following cases:\n\n* User friendly or pedagogically informative software is desired.\n* All of the data can fit in RAM and numerical stability is not an issue.\n* The hidden state transitions are defined by a large sparse graph.\n* The emission distributions are uncomplicated (e.g. finite or normal).\n* A variable number of observations are emitted per hidden state.\n* Silent states other than start and stop states are used.\n\n\nRequirements\n============\n\nOperating system requirements:\n\n* This project was developed using Ubuntu,\n  so it will probably work on Debian-based Linux distributions.\n* It might work with non-Debian-based Unix variants.\n* It probably will not work on Windows.\n\nMajor dependencies:\n\n* A recent version of Python-2.x_ (2.6+).\n* A C compiler which is not too different from gcc.\n\nPython package and module dependencies:\n\n* numpy_ (version 2.0+ to support the new-style buffer interface;\n  if this has not been released yet,\n  then use a development version from the subversion repository)\n* argparse_ (included in Python-2.7+ and in Python-3.2+)\n\n\nInstallation\n============\n\nSetting up virtualenv and pip\n-----------------------------\n\nA good way to install hmmus is with virtualenv_ and pip_.\nIf you are already using these programs and you've activated\na virtual environment, then you can ignore this section.\n\nThese programs have been packaged for Ubuntu and probably Debian,\nand can be installed from the Linux distribution package repository\nas follows::\n\n    $ sudo apt-get install python-virtualenv\n    $ sudo apt-get install python-pip\n\nAlternatively the development version can be downloaded::\n\n    $ hg clone http://bitbucket.org/ianb/virtualenv\n\nTo use a binary installation of virtualenv\nto create a virtual python environment::\n\n    $ virtualenv /path/to/myenv\n\nOr to use the source installation of virtualenv\nto create a virtual python environment::\n\n    $ /go/to/virtualenv.py --distribute --python=/go/to/python /go/to/myenv\n\nNow activate the virtual environment::\n\n    $ . /path/to/myenv/bin/activate\n\nInstalling required Python modules and packages\n-----------------------------------------------\n\nThe following packages and modules should be installed:\n\n* The ``numpy`` package should be installed\n  by ``sudo apt-get install python-numpy`` on Debian and Ubuntu.\n  Or to get a newer version, install from subversion.\n* The ``argparse`` module can be installed\n  by ``pip install argparse`` in the activated virtual environment.\n\nInstalling hmmus\n----------------\n\nThe easiest way to install hmmus is from the\npython package index pypi_ as follows::\n\n    $ pip install hmmus\n\nIf pypi is inaccessible for some reason,\nthen hmmus can alternatively be installed directly from its github_\nrepository as follows::\n\n    $ pip install git+git://github.com/argriffing/hmmus\n\nIf you are developing hmmus or have cloned the git repo\nas ``~/repos/hmmus`` for some other reason,\nhmmus can be installed from this local repository as follows::\n\n    $ pip install -e ~/repos/hmmus\n\n\nUninstalling hmmus\n------------------\n\nIt is easy to uninstall hmmus using pip::\n\n    $ pip uninstall hmmus\n\nIf this fails for some reason and you really want to get rid of hmmus,\nthen you can delete the virtual environment into which hmmus\nwas installed.\n\n\nDemo\n====\n\nIn its current incarnation\nhmmus provides some scripts for doing posterior decoding,\nusing unfriendly binary files for input and output.\nThe following commands create an empty directory\nand then fill it with some sample input files::\n\n    $ mkdir mydemo\n    $ cd mydemo\n    $ hmm-demo smith\n\nThis creates the files \n``distribution.bin``,\n``transitions.bin``, and\n``likelihoods.bin``\nfrom a numerical example in the paper\nhttp://www.cs.cmu.edu/~nasmith/papers/smith.tut04a.pdf\nwhich explains posterior decoding.\nThe first two binary files define the initial distribution\nand the transition matrix of the HMM.\nThe third binary file defines the sequence of\nlikelihoods at each position conditional on each hidden state.\n\nTo get the position specific posterior distributions of hidden states,\nrun these three commands::\n\n    $ hmm-forward\n    $ hmm-backward\n    $ hmm-posterior\n\nThis should create four more binary files in the ``mydemo`` directory,\nincluding one named ``posterior.bin`` which has the distributions of interest.\nTo look at this binary file, use the octal display utility with a format\nof 8-byte floating point numbers and a width of 24 bytes per row::\n\n    $ od --format=f8 --width=24 posterior.bin\n\nUntil better documentation is written,\ninformation about the usage of the hmmus-associated scripts can be found\nusing commands like this::\n\n    $ hmm-backward --help\n\n\nUsage\n=====\n\nFor now, the only interface to the\nposterior decoding is through the binary files.\n\n\n.. _Python-2.x: http://www.python.org\n.. _argparse: http://code.google.com/p/argparse\n.. _virtualenv: http://virtualenv.openplans.org\n.. _pip: http://pip.openplans.org\n.. _pypi: http://pypi.python.org\n.. _github: http://github.com\n.. _numpy: http://numpy.scipy.org"}}, {"pk": 650, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "gpib-devices", "license": "LGPL", "author": "Robert Jordens", "author_email": "jordens@phys.ethz.ch", "project_url": null, "maintainer_email": "", "home_page": "https://launchpad.net/gpib-devices", "version": "0.0.4", "platform": "", "keywords": "", "summary": "Python GPIB Device Library", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Hardware :: Hardware Drivers\nTopic :: System :: Networking", "description": "GPIB device driver library for python. A Generic IEEE 488 and\r\nIEEE 4882 class for any GPIB device is subclassed in various\r\ndevices for different laboratory equipment devices.\r\n\r\nThis library uses ctypes to directly access the GPIB library\r\nfrom either linux-gpib (http://linux-gpib.sourceforge.net/) or\r\nNational Instruments. It also includes a pure Python driver for the NI Enet Ethernet-to-GPIB adapters.\r\n\r\nIt does not yet mirror all functions from libgpib but tries to\r\nexploit many of Python's features that make GPIB programming\r\nmore fun."}}, {"pk": 651, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "WPServer", "license": "Clear BSD", "author": "Christohper Schmidt", "author_email": "crschmidt@crschmidt.net", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/webprocessingserver/", "version": "1.1", "platform": "UNKNOWN", "keywords": null, "summary": "a web mapping transformation library", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "====================\n webprocessingserver \n====================\n\n---------------------------------------\nSimple Python geographic feature server\n---------------------------------------\n\n:Author: crschmidt@metacarta.com\n:Copyright: 2007 Christohper Schmidt.\n:Version: 1.0 \n:Manual group: GIS Utilities\n\nDESCRIPTION\n===========\nWebProcessingServer is a simple Python-based geographic feature server. It\nallows you to transform geographic vector features via a number of different\nprocessing backends.\n\nWebProcessingServer will run under Python CGI, mod_python, or as a standalone\nserver. \n\nWebProcessingServer is released under a license similar to the BSD license.\n\nRUNNING UNDER CGI\n=================\n\n* Extract the code to some web directory (e.g. in /var/www).\n* Permit CGI execution in the WebProcessingServer directory.\n  For example, if WebProcessingServer is to be run with Apache, the\n  following must be added in your Apache configuration,   \n  where /var/www/webprocessingserver is the directory resulting from\n  the code extraction. \n  \n  ::\n\n    <Directory /var/www/webprocessingserver>\n         AddHandler cgi-script .cgi\n         Options +ExecCGI\n    </Directory>\n\nPython Prerequisites\n--------------------\nIn order to use WebProcessingServer, you must have the simplejson module\ninstalled. If you do not, you can add it by doing the following:\n\n  $ wget http://cheeseshop.python.org/packages/source/s/simplejson/simplejson-1.7.1.tar.gz\n  $ tar -zvxf simplejson-1.7.1.tar.gz\n  $ cp -r simplejson-1.7.1/simplejson /var/www/webprocessingserver\n\nNote that these instructions are for Linux systems: the end goal is to extract\nthe simplejson directory from the distribution and put it in the root of your\nWebProcessingServer install.\n\nNon-standard Python Location\n----------------------------\nIf your Python is not at /usr/bin/python on your system, you will need to\nchange the first line of wps.cgi to reference the location of\nyour Python binary. A common example is:\n\n  ::\n\n     #!/usr/local/bin/python\n\nUnder Apache, you might see an error message like:\n\n  ::\n\n    [Wed Mar 14 19:55:30 2007] [error] [client 127.0.0.1] (2)No such file or \n      directory: exec of '/www/wps.cgi' failed\n\nto indicate this problem.\n\nYou can typically locate where Python is installed on your system via the\ncommand 'which python'.\n\nWindows users: If you are using Windows, you should change the first line \nof wps.cgi to read:\n\n  ::\n\n    #!C:/Python/python.exe -u\n\nC:/Python should match the location Python is installed under on your \nsystem. In Python 2.5, this location is C:/Python25 by default.  \n\nRUNNING UNDER MOD_PYTHON\n========================\n\n* Extract the code to some web directory (e.g. /var/www).\n* Add the following to your Apache configuration, under a <Directory> heading:\n  \n  ::\n  \n      AddHandler python-program .py\n      PythonPath sys.path+['/path/to/webprocessingserver']\n      PythonHandler WebProcessingServer.Server\n      PythonOption WebProcessingServerConfig /path/to/webprocessingserver.cfg\n  \n* An example might look like:\n\n  ::\n  \n    <Directory /var/www/webprocessingserver/>\n       AddHandler python-program .py\n       PythonPath sys.path+['/var/www/webprocessingserver']\n       PythonHandler WebProcessingServer.Server \n       PythonOption WebProcessingServerConfig\n                    /var/www/webprocessingserver/webprocessingserver.cfg\n    </Directory>\n  \n* In this example, /var/www/webprocessingserver is the directory resulting from\n  the code extraction. \n* Visit the URL described above, replacing wps.cgi with \n  webprocessingserver.py\n* If you see an empty GeoRSS file you have set up your configuration correctly.\n  Congrats!\n* Note that mod_python has not yet been well tested, and may not work well\n  for all data sources.\n\n \nRUNNING STANDALONE (UNDER WSGI)\n===============================\n\nWebProcessingServer comes with a standalone HTTP server which uses the WSGI\nhandler.  This implementation depends on *Python Paste*, which can be\ndownloaded from:\n  \n  http://cheeseshop.python.org/pypi/Paste\n\nFor versions of Python earlier than 2.5, you will also need to install \nwsgiref:\n\n  http://cheeseshop.python.org/pypi/wsgiref\n\nOnce you have all the prerequisites installed, simply run:\n\n  ::\n  \n    python wps_http_server.py\n\nThis will start a webserver listening on port 8080.\n\n\nRUNNING UNDER FASTCGI\n=====================\n\nWebProcessingServer comes with a fastcgi implementation. In order to use this \nimplementation, you will need to install flup, available from:\n  \n  http://trac.saddi.com/flup\n\nThis implementation also depends on Python Paste, which can be downloaded \nfrom:\n  \n  http://cheeseshop.python.org/pypi/Paste\n\nOnce you have done this, you can configure your fastcgi server to use\nwebprocessingserver.fcgi.\n\nConfiguring FastCGI is beyond the scope of this documentation.\n\nCONFIGURATION\n=============\nWebProcessingServer is configured by a config file, defaulting to\nwebprocessingserver.cfg. \n\nSEE ALSO\n========\n\nhttp://code.google.com/p/webprocessingserver/"}}, {"pk": 652, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Theano", "license": "BSD", "author": "LISA laboratory, University of Montreal", "author_email": "theano-dev@googlegroups.com", "project_url": null, "maintainer_email": null, "home_page": "http://deeplearning.net/software/theano/", "version": "0.3.1", "platform": "Windows,Linux,Solaris,Mac OS-X,Unix", "keywords": "theano math numerical symbolic blas numpy gpu autodiff differentiation", "summary": "Optimizing compiler for evaluating mathematical expressions on CPUs and GPUs.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Compilers", "description": "Theano is a Python library that allows you to define, optimize, and efficiently evaluate mathematical expressions involving multi-dimensional arrays. It is built on top of NumPy_. Theano features:\n\n * **tight integration with NumPy:** a similar interface to NumPy's. numpy.ndarrays are also used internally in Theano-compiled functions.\n * **transparent use of a GPU:** perform data-intensive computations up to 140x faster than on a CPU (support for float32 only).\n * **efficient symbolic differentiation:** Theano can compute derivatives for functions of one or many inputs.\n * **speed and stability optimizations:** avoid nasty bugs when computing expressions such as log(1+ exp(x) ) for large values of x.\n * **dynamic C code generation:** evaluate expressions faster.\n * **extensive unit-testing and self-verification:** includes tools for detecting and diagnosing bugs and/or potential problems.\n\nTheano has been powering large-scale computationally intensive scientific\nresearch since 2007, but it is also approachable enough to be used in the\nclassroom (IFT6266 at the University of Montreal).\n\n.. _NumPy: http://numpy.scipy.org/\n\n\nModifications in the trunk since the last release\n\nTheano 0.3.1 (2011-02-21)\n----------------------------\n\nDeprecation:\n * The theano shared variable attribute `value` is deprecated, use `get_value()` or `set_value()`!\n    See http://deeplearning.net/software/theano/tutorial/aliasing.html\n\nBugs fixed:\n * The random number generator in theano/sandbox/rng_mrg.py did not always return the same sequence of number on the CPU and GPU.\n    * In some cases, there was a (possibly large) fraction of non-random garbage in the returned sequence.\n\n * In python mode (not the default mode) when input of elemwise operation was an empty ndarray, we were not returning an empty ndarray.\n * Scan cached the number of steps. This caused no problem because each time you called scan the number of steps would got refreshed.\n   The problem was when you called ScanGrad which would use the cached number of steps without refreshing it.\n   To be affected by this bug, one would have to compile two graph, one that would contain a Scan and the other the corresponding GradScan, and\n   call the first function to cache the number of steps, and then call the second function with a different number of steps.\n * In GpuConv, errors in conv_patch_stack_reduce when the entire kernel doesn't fit into shared memory.\n   The error was not found before as the impact was less then the relative tolerance of 1e-3. Now the relative tolerance is 1e-5.\n\nCrash fixed:\n * Add a feature to not have an exception that makes Theano crash when taking the gradient on DimShuffle in some particular case.\n * Compilation crash for GpuElemwise with tensor with high number of dimensions (~6 or more).\n * Disabled C code generator that make gcc crash on complex type.\n * Crash in optimization when an Op has no input.\n * Output shape is now computed correctly for matrix-vector multiplication on GPU.\n * In Scan, when using numbers as inputs, not symbolic variables.\n * In GradScan, when there is only 1 inputs in the Scan.\n * In GpuSum, bug in calculation of n_blocks for the 10 pattern. (Sum on the row of a matrix)\n * Some segfault at exit with GPU code.\n\nOptimization:\n * New SpecifyShape op that allow to pass more shape info in the graph.\n * Speed up gemv by a work around scipy gemv slowness when the matrix is in C order (the default).\n * Remove join of only 1 element.\n * During optimization, consider one more case in get_constant_value.\n\nGPU:\n * cuda_shared.value = X now works inplace!\n     * cuda_shared_var.set_value(new_ndarray) will overwrite the old value inplace in the most common case.\n * Allow to create a CudaNdarraySharedVariable from a CudaNdarray.\n * New init_gpu_device theano flags.\n * Fuse GpuElemwise more often (in the case where there are so many inputs that fusing them all would bust the 256 bytes limit of parameter to gpu function).\n * CPU join of only 1 element that was not moved to the GPU.\n\nNew features:\n * tensor.reshape now makes dimensions of length 1 broadcastable.\n * tensor.prod now implements the gradient.\n * DebugMode now warns if an Op declared itself as returning a view of the input but did not do so.\n    * This behaviour is a problem, because it can block other Ops from being inplace on the same inputs. This could lower the reuse of memory.\n * Sparse.structured_dot now works when both matrices are sparse\n * Sparse type is now supported by the shape op, and the ShapeFeature optimizer works correctly with them.\n * New 3D convolution ops, with CPU and GPU implementations.\n * New colors in pydotprint.\n\nDocumentation:\n * Documented lib.amdlibm and (new) init_gpu_device config variables.\n * A new page (was done for 0.3 but an error was hiding it on the web page) on the memory aliasing contract of Theano.\n * Revision to the Windows installation instructions.\n * The cuda documentation is now generated on the web server.\n * Better documentation of .theanorc and its sections.\n\nUnit tests:\n * Stop usage of deprecated functions or syntax in the unit tests.\n * Better testing of GPU convolution nets.\n * Make more tests able to use different random seeds.\n * Tests of sparse now use default mode, not a hard-coded one.\n * Remove some tests of unimplemented features.\n\nOther:\n * The name of compiledir now includes the Python version to make it easier for people with many Python versions\n * Added theano.tensor.std as a shortcut to sqrt(var(input=input, axis=axis)).\n * Whitespace, tabulation and indentation clean-up in the code.\n * Better detection of memory sharing between variables."}}, {"pk": 653, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "NodeBox", "license": "UNKNOWN", "author": "Frederik De Bleser", "author_email": "frederik@pandora.be", "project_url": null, "maintainer_email": null, "home_page": "http://nodebox.net/", "version": "1.9.1", "platform": "UNKNOWN", "keywords": null, "summary": "Simple application for creating 2-dimensional graphics and animation using Python code", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: MacOS X :: Cocoa\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: MIT License\nOperating System :: MacOS :: MacOS X\nProgramming Language :: Python\nTopic :: Artistic Software\nTopic :: Multimedia :: Graphics\nTopic :: Multimedia :: Graphics :: Editors :: Vector-Based\nTopic :: Multimedia :: Video\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: User Interfaces\nTopic :: Text Editors :: Integrated Development Environments (IDE)", "description": "NodeBox is a Mac OS X application that allows you to create visual output\nwith programming code. The application targets an audience of designers, with an easy set of state \ncommands that is both intuitive and creative. It is essentially a learning environment and an automation tool.\n\nThe current version features:\n\n* State-based graphics context\n* Extensive reference documentation and tutorials\n* PDF export for graphics\n* QuickTime export for animations\n* Manipulate every numeric variable in a script by command-dragging it, even during animation\n* Creating simple user interfaces using text fields, sliders, and buttons\n* Stop a running script by typing command-period\n* Universal Binary\n* Integrated bezier mathematics\n* Command-line interface"}}, {"pk": 654, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pdsvex.policy", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://agility.jpl.nasa.gov/products/pdsvex-policy", "version": "1.0.1", "platform": "UNKNOWN", "keywords": "web policy zope plone jpl nasa caltech esa vex venus planetary data oodt profile product", "summary": "PDS Venus Express site policy", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Software Development :: Libraries :: Python Modules", "description": "pdsvex.policy\n*************\n\nThis is the policy product for pdsvex.policy.  It orchestrates the\ndependencies necessary in order to run a PDS Venus Express profile server.\n\n\nInstallation\n============\n\nTo install this, create a buildout_ for Plone_ and add ``pdsvex.policy`` to\nyour list of eggs, as well as ``pdsvex.policy`` to your list of ZCML slugs.\nNo idea how to do this? Just follow these instructions:\n\n1.  Install Plone 3.  As of this writing, you can download_ Plone 3.2.2.\n    Download, extract, and follow the instructions for the \"Unified\n    Installer\".  Use the unified installer to install a *standalone* version.\n    Note the administrative account name and password once the installation is\n    complete.\n\n2.  Change the current working directory to the Plone installation directory\n    (usually /usr/local/plone, $HOME/Plone, etc.).\n\n3.  Edit the buildout.cfg file.  Add ``pdsvex.policy`` to the ``eggs`` entry,\n    right below ``Plone``.  Add ``pdsvex.policy`` to the ``zcml`` entry.\n    Finally, edit the ``http-address`` entry to select what TCP port number\n    the server will answer on.\n\n4.  Run ``bin/buildout``.  This will download and install the PDS VEX profile\n    server into the newly installed Plone environment.  Depending on your\n    installation, you may need root privileges to run ``bin/buildout``.\n\n5.  Run ``bin/plonectl start`` to start the server.  Depending on your\n    installation, you may need root privileges to run ``bin/plonectl``.\n\n6.  Visit http://hostname:port/Plone/plone_control_panel (substituting\n    hostname and port as needed) and, when prompted log in with the account\n    name and password from step 1.\n\n7.  Click on \"Add-on Products\".\n\n8.  Check the box next to \"PDS Venus Express Data\" Policy.\n\n9.  Click the \"Install\" button.\n\nThe PDS VEX Profile Server is now ready.\n\n\nAccess\n======\n\nTo access the PDS VEX Profile Server, use the following object key::\n\n    http://hostname:port/Plone/prof\n    \nwhere ``hostname`` is the name or IP address of the host on which your server\nis running and ``port`` is the port number.\n\n\n.. References:\n.. _buildout: http://pypi.python.org/pypi/zc.buildout\n.. _Plone: http://plone.org/\n.. _Python: http://python.org/download/releases/2.4.6/\n.. _PIL: http://www.pythonware.com/products/pil/\n.. _download: http://plone.org/products/plone\n\nChangelog\n*********\n\n1.0.1 - 2009.7.16 - Documentation\n=================================\n\nThis release addresses an issue where documentation for the profile server\nwasn't appearing.  It does now!\n\n\n1.0.0 - FCS\n===========\n\nFirst customer ship.\n\n\n0.0.0 - Unreleased\n==================\n\n* Initial release"}}, {"pk": 655, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "kohonen", "license": "MIT", "author": "Leif Johnson", "author_email": "leif@leifjohnson.net", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/python-kohonen/", "version": "1.0", "platform": "UNKNOWN", "keywords": "kohonen self-organizing-map neural-gas growing-neural-gas vector-quantization machine-learning", "summary": "A small library of Kohonen-style vector quantizers.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nTopic :: Scientific/Engineering :: Artificial Intelligence", "description": "This module contains some basic implementations of Kohonen-style vector\nquantizers: Self-Organizing Map (SOM), Neural Gas, and Growing Neural Gas.\n\nVector quantizers are useful for learning discrete representations of a\ndistribution over continuous space, based solely on samples drawn from the\ndistribution. Kohonen-style vector quantizers generally use some sort of\nexplicitly specified topology to encourage good separation among prototype\n\"neurons\".\n\nThe source distribution includes an interactive test module that uses PyGTK and\nCairo to render a set of quantizers that move around in real time as samples are\ndrawn from a known distribution and fed to the quantizers. Run this test with :\n\npython kohonen_test.py\n\nHave fun !"}}, {"pk": 656, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pycam", "license": "GPL v3", "author": "Lars Kruse", "author_email": "devel@sumpfralle.de", "project_url": null, "maintainer_email": null, "home_page": "http://sourceforge.net/projects/pycam", "version": "0.5", "platform": "UNKNOWN", "keywords": "3-axis,cnc,cam,toolpath,machining,g-code", "summary": "Open Source CAM - Toolpath Generation for 3-Axis CNC machining", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Win32 (MS Windows)\nEnvironment :: X11 Applications :: GTK\nIntended Audience :: Manufacturing\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering", "description": "IMPORTANT NOTE: Please read the list of requirements:\nhttp://sourceforge.net/apps/mediawiki/pycam/index.php?title=Requirements\nBasically you will need Python, GTK and OpenGL.\n\nWindows: select Python 2.5 in the following dialog."}}, {"pk": 657, "model": "importing.pypicache", "fields": {"maintainer": "Amin Al-Juffali", "name": "AJDecimalMathAdditions", "license": "", "author": "Amin Al-Juffali", "author_email": "ajuffali@mac.com", "project_url": null, "maintainer_email": "ajuffali@mac.com", "home_page": "http://www.ajgs.com/programming/PythonForDownload.html", "version": "0.2.0", "platform": "all", "keywords": "decimal, math, trig", "summary": "This Decimal math library will add additional trig and math functions to the decimal.py module in python.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": ""}}, {"pk": 658, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "egenix-mx-experimental", "license": "eGenix.com Public License 1.1.0 and other licenses; Copyright (c) 2000-2007, eGenix.com Software GmbH, All Rights Reserved", "author": "eGenix.com Software, Skills and Services GmbH", "author_email": "info@egenix.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.egenix.com/products/python/mxExperimental/", "version": "3.0.1", "platform": "Windows,Linux,FreeBSD,Solaris,Mac OS X", "keywords": null, "summary": "eGenix mx Experimental Distribution for Python - mxNumber, mxTidy", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: No Input/Output (Daemon)\nIntended Audience :: Developers\nLicense :: Free for non-commercial use\nLicense :: Freely Distributable\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: BeOS\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS/2\nOperating System :: OS Independent\nOperating System :: Other OS\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Documentation\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Internet :: WWW/HTTP :: Dynamic Content :: CGI Tools/Libraries\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Application Frameworks\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Markup", "description": "The eGenix mx Extension Series are a collection of\nPython extensions written in ANSI C and Python\nwhich provide a large spectrum of useful additions\nto everyday Python programming.\n\nThis package includes experimental subpackages of the \nseries. Please understand that the software in these \npackages is still in alpha state and does not meet the \nquality standards of production quality software.\n\nThis software is brought to you by eGenix.com. The included\nsubpackages are either covered by the eGenix.com Public\nLicense 1.1.0 or the eGenix.com Commercial License 1.2.0 \nand/or other licenses. Please check the  subpackage \ndocumentation for details or contact eGenix.com for more \nlicense information."}}, {"pk": 659, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyUtilib", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/trac/pyutilib", "version": "3.5.2313", "platform": "any", "keywords": "utility", "summary": "PyUtilib: A collection of Python utilities", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "===============\nPyUtilib README\n===============\n\nPyUtilib is a collection of Python utility packages.  Although each package\ncan be installed separately, this package can be used to install all\nof the PyUtilib packages, as well as the third-party packages that they depend on.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone"}}, {"pk": 660, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pymorphy-speedups", "license": "MIT license", "author": "Mikhail Korobov", "author_email": "kmike84@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "0.5.1", "platform": "UNKNOWN", "keywords": null, "summary": "Speedups for pymorphy", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nNatural Language :: German\nNatural Language :: Russian\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Linguistic", "description": "pymorphy-speedups\n=================\n\n\u041c\u043e\u0434\u0443\u043b\u044c \u0434\u043b\u044f \u0443\u0441\u043a\u043e\u0440\u0435\u043d\u0438\u044f pymorphy.\n\u041d\u0435 \u0432\u043a\u043b\u044e\u0447\u0435\u043d \u0432 \u043e\u0441\u043d\u043e\u0432\u043d\u043e\u0439 \u043f\u0430\u043a\u0435\u0442, \u0447\u0442\u043e\u0431\u044b \u043d\u0435 \u0443\u0441\u043b\u043e\u0436\u043d\u044f\u0442\u044c \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0443."}}, {"pk": 661, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "polipoly", "license": "BSD", "author": "James Turk", "author_email": "james.p.turk@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/polipoly/", "version": "0.1.0", "platform": "any", "keywords": "sunlight", "summary": "Library for working with political boundary polygons.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "polipoly is a library for working with political boundary polygons such as those\r\nobtained from census shapefiles."}}, {"pk": 662, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Sunflower", "license": "all rights reserved", "author": "Michael Hoffman", "author_email": "hoffman+sunflower@ebi.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://www.ebi.ac.uk/~hoffman/software/sunflower/", "version": "1.1.0", "platform": "UNKNOWN", "keywords": null, "summary": "model transcription factor binding to DNA", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "Sunflower models the simultaneous binding of transcription factors to\nDNA. It uses a hidden Markov model that resembles a sunflower."}}, {"pk": 663, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.plugins.hdf5", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/plugins/hdf5.html", "version": "0.1.2", "platform": "UNKNOWN", "keywords": "hdf5 pytables dap opendap dods data", "summary": "HDF5 plugin for pydap server based on Pytables", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This is a plugin for serving data in a pydap server from HDF5 files.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/plugins/hdf5#egg=dap.plugins.hdf5-dev>`_."}}, {"pk": 664, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mtrand", "license": "MIT", "author": "Robert Kern", "author_email": "robert.kern@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://starship.python.net/crew/kernr/source/", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "Mersenne Twister PRNG for Numeric", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Implements the Mersenne Twister PRNG for Numeric. It\nis intended to replace the RANLIB PRNG in SciPy."}}, {"pk": 665, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "chimera-python", "license": "GPLv2", "author": "P. Henrique Silva", "author_email": "henrique@astro.ufsc.br", "project_url": null, "maintainer_email": null, "home_page": "http://chimera.sf.net", "version": "0.1", "platform": "GNU/Linux", "keywords": null, "summary": "Chimera - Observatory Automation System", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nNatural Language :: Portuguese (Brazilian)\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy", "description": "Chimera: Observatory Automation System\n======================================\n\nChimera is a package to control astronomical observatories aiming the\ncreation of remote and even autonomous observatories with just a few\nclicks. Using Chimera you can easily control telescopes, CCD cameras,\nfocusers and domes in a very integrated way.\n\n**Distributed**\n   Fully distributed system. You can use different machines to\n   control each instrument and everything will looks like just one.\n\n**Powerful**\n   Very powerful autonomous mode. Give a target and exposure parameters\n   and Chimera does the rest.\n\n**Web interface**\n   Web interface to schedule and monitor observations (`in development`).\n\n**Hardware support**\n   Support for most common off-the-shelf components. See `supported\n   devices`_.\n\n   Very easy to add support for new instruments (it's Python code!).\n\n**Flexible**\n   Chimera can be used in a very integrated mode but also in standalone\n   mode to control just one instrument.\n\n**Free**\n   It's free (as in *free beer*) and written in a very modern\n   language. Python!.\n\nGetting start\n-------------\n\nTo try out Chimera, follow the installation instructions and make sure\nthat you have at least one `supported devices`_.\n\nThe easiest way to install Chimera is to use `easy_install\n<http://peak.telecommunity.com/DevCenter/EasyInstall>`_::\n\n   sudo easy_install chimera-python\n\n... and that's it! All dependencies are automagically installed.\n\nYou can also download the sources at `Chimera Development page\n<http://code.google.com/p/chimera>`_ and try to install it *by hands*.\n\n\nHelp and Development\n--------------------\n\nYou can help Chimera development, we are always looking for\ncontributors. If you don't write code, no problem! You can write\ndocumentation, help with this site, marketing. Everyone can help!\n\nSee our `Development <http://code.google.com/p/chimera>`_ page for\nmore information, to report a bug or just follow Chimera's development\nclosely.\n\n.. _supported_devices:\n\nSupported Devices\n-----------------\n\n**Telescopes**\n   `Meade <http://www.meade.com>`_ based LX-200 (Meade, Losmandy).\n\n   `Paramount ME <http://www.bisque.com>`_ using TheSky COM+ interfaces.\n\n**CCD Cameras**\n   `SBIG <http://www.sbig.com>`_ USB cameras.\n\n**Focusers**\n   `OPTEC <http://www.optecinc.com>`_  NGF-S\n\n**Domes**\n   COTE/LNA Dome (`LNA <http://www.lna.br>`_ specific).\n\n\nIn Development \n^^^^^^^^^^^^^^\n\n**CCD Cameras**\n   `Apogee <http://www.ccd.com>`_  USB/Ethernet cameras.\n\n.. note::\n   If you need support for any device which Chimera's doesn't\n   support, call us and we can try to develop it or help you to do it.\n\nLicense\n-------\n\nChimera is Free/Open Software licensed by `GPL v2\n<http://www.gnu.org/licenses/gpl.html>`_ or later (at your choice).\n\n\nAuthors\n-------\n\nChimera is mainly developed by Paulo Henrique Silva\n<ph.silva@gmail.com> at `Universidade Federal de Santa Catarina\n<http://www.ufsc.br>`_ in collaboration with his advisor Antonio\nKanaan.\n\nChimera is sponsored by `Laboratorio Nacional de Astrofisica\n<http://www.lna.br>`_ through a `CNPq <http://www.cnpq.br>`_ grant."}}, {"pk": 666, "model": "importing.pypicache", "fields": {"maintainer": "Sridhar Ratnakumar", "name": "Pycluster", "license": "Python License", "author": "Michiel de Hoon", "author_email": "mdehoon 'AT' gsc.riken.jp", "project_url": null, "maintainer_email": "sridhar.ratna@gmail.com", "home_page": "http://bonsai.ims.u-tokyo.ac.jp/~mdehoon/software/cluster/software.htm#pycluster", "version": "1.49", "platform": "", "keywords": "", "summary": "The C Clustering Library", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python License (CNRI Python License)\nTopic :: Scientific/Engineering", "description": ""}}, {"pk": 667, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "yard", "license": "MIT License", "author": "Tamas Nepusz", "author_email": "tamas@cs.rhul.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/ntamas/yard", "version": "0.1", "platform": "UNKNOWN", "keywords": "roc curve statistics mathematics machine learning auc", "summary": "Yet another ROC curve drawer", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Utilities", "description": "YARD - Yet Another ROC Drawer\n=============================\n\nThis is yet another Python package for drawing ROC curves. It also\nlets you draw precision-recall, accumulation and concentrated ROC\n(CROC) curves and calculate the AUC (area under curve) statistics.\nThe significance of differences between AUC scores can also be\ntested using paired permutation tests.\n\nYou may also be interested in CROC_, a similar package on the\nPython Package Index that implements ROC curves. ``yard`` was developed\nindependently from CROC_, but several features of CROC have inspired\nsimilar ones in ``yard``.\n\n.. _CROC: http://pypi.python.org/pypi/CROC"}}, {"pk": 668, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Quadtree", "license": "BSD", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://icon.stoa.org/trac/pleiades/wiki/QuadTree", "version": "0.1.2", "platform": "UNKNOWN", "keywords": "spatial index", "summary": "Quadtree spatial index for Python GIS", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Database\nTopic :: Scientific/Engineering :: GIS", "description": "UNKNOWN"}}, {"pk": 669, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.signal", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.8", "platform": "OS Independent", "keywords": "ObsPy,seismology,signal,processing,filter,trigger,instrument correction,picker,instrument simulation,features,envelope,hob", "summary": "Signal processing routines for ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.signal package contains signal processing routines for seismology.\nCapabilities include filtering, triggering, rotation, instrument correction and\ncoordinate transformations.\n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology. \n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 670, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "seishub.plugins.seismology", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "Robert Barsch", "author_email": "barsch@lmu.de", "project_url": null, "maintainer_email": null, "home_page": "http://www.seishub.org", "version": "1.2.2", "platform": "OS Independent", "keywords": "SeisHub,seismology", "summary": "Seismology package for SeisHub.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "seishub.plugins.seismology - Seismology package for SeisHub.\n\n    For more information visit http://www.seishub.org."}}, {"pk": 671, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "oroboros", "license": "UNKNOWN", "author": "S.Marquis", "author_email": "stnsls@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "UNKNOWN", "version": "20080712", "platform": "UNKNOWN", "keywords": "Astrology Ephemeris Swisseph", "summary": "Astrology software", "classifiers": "Development Status :: 7 - Inactive\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: Religion\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Religion\nTopic :: Scientific/Engineering :: Astronomy", "description": "*Oroboros* is an astrology software written in Python.\r\nIt is based on the following modules:\r\n\r\n  - AstroDienst's Swiss Ephemeris (pyswisseph_) version >= 1.74.00-0\r\n  - Olson timezones (pytz_)\r\n  - Qt toolkit (PyQt4_) version >= 4.3\r\n\r\nOptionally:\r\n\r\n  - Docutils_ version = 0.5\r\n  - Mercurial_ (for distant charts repositories)\r\n  - Supybot_ (for IRC plugin)\r\n\r\n===========\r\nWhat's new?\r\n===========\r\n\r\n  - Usual bug fixes\r\n  - Additional asteroids: Eris, Sedna, Quaoar, Nessus, Varuna\r\n\r\n========\r\nFeatures\r\n========\r\n\r\n  - Charts: natal/radix, transits, progression, harmonics, profection\r\n  - Open Astrolog or Skylendar charts too\r\n  - Save charts as images in various formats (png, jpg, bmp, svg,...)\r\n  - Query the online GeoNames.org_ atlas database\r\n  - Calculates all planets, nodes\r\n  - More than 300 fixed stars\r\n  - Asteroids (Eris, Quaoar, Sedna, etc)\r\n  - Uses Swiss, JPL, or Moshier Ephemeris \r\n  - A flexible and powerfull configuration system\r\n  - Geocentric, topocentric, heliocentric or barycentric charts\r\n  - Various house systems, including Gauquelin sectors\r\n  - Tropical or sidereal zodiacs\r\n  - Midpoints calculations and drawings\r\n  - Format comments with Docutils_ reStructured Text\r\n  - Synchronize your charts with a distant repository (using Mercurial_)\r\n  - A few toys for IRC chat addicts (Supybot_ plugin)\r\n  - And easy extension capabilities with the Python language...\r\n\r\n.. _pyswisseph: http://pypi.python.org/pypi/pyswisseph\r\n.. _pytz: http://pytz.sourceforge.net\r\n.. _PyQt4: http://www.riverbankcomputing.co.uk/pyqt\r\n.. _Docutils: http://docutils.sourceforge.net\r\n.. _Mercurial: http://www.selenic.com/mercurial\r\n.. _Supybot: http://supybot.com\r\n.. _GeoNames.org: http://www.geonames.org\r\n\r\n===============\r\nOroboros manual\r\n===============\r\n\r\nInstallation\r\n------------\r\nDownload and install the package and the required modules (most of them\r\nare available in your distro repositories). For example, uncompress the latest\r\nsource package of *Oroboros* with ``tar jxf oroboros-xxxxxxxx.tar.bz2``, then\r\n``cd oroboros-xxxxxxxx``, finally (with super-user permission) type ``python\r\nsetup.py install``.\r\n\r\nEphemeris files\r\n~~~~~~~~~~~~~~~\r\nYou should also install the compressed ephemeris data files on your system\r\n(``/usr/local/share/swisseph`` looks like a good idea). These files are freely\r\ndistributed on `AstroDienst public FTP server`_.\r\n\r\n.. _`AstroDienst public FTP server`: ftp://ftp.astro.com/pub/swisseph/ephe\r\n\r\nA simple installation would require that you download the following files,\r\nallowing calculations over the period from 1800 to 2399:\r\n\r\n  - ``sepl_18.se1``\r\n  - ``semo_18.se1``\r\n  - ``seas_18.se1``\r\n  - ``fixstars.cat``\r\n  - ``seorbel.txt``\r\n\r\nYou can also grab the following asteroids files (other asteroids can be\r\nimplemented on demand):\r\n\r\n  - ``136199 Eris``\r\n  - ``7066 Nessus``\r\n  - ``50000 Quaoar``\r\n  - ``90377 Sedna``\r\n  - ``20000 Varuna``\r\n  - ``128 Nemesis``\r\n\r\nUsage\r\n-----\r\nIf everything goes well you will be able to start the application by typing\r\n``oroboros`` in your shell.\r\n\r\nFirst steps\r\n~~~~~~~~~~~\r\nUpdate the configuration settings, especially the path to ephemeris files.\r\nYou may also create an aspects filter and an orbs filter for the midpoints\r\nsettings, otherwise you'll have some surprises.\r\n\r\n========\r\nDownload\r\n========"}}, {"pk": 672, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "datetime2", "license": "Expat License", "author": "Francesco Ricciardi", "author_email": "francescor2010 at yahoo dot it", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/datetime", "version": "0.1plan", "platform": "Platform independent", "keywords": null, "summary": "New date and time classes", "classifiers": "Development Status :: 1 - Planning\nOperating System :: OS Independent\nProgramming Language :: Python :: 3.2\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "=========\ndatetime2\n=========\n\nDatetime2 provides new classes for date and times.\n\nThis module will provide date and time classes, as the original \n`datetime <http://docs.python.org/py3k/library/datetime.html>`_ module does.\nThe new classes on the one hand will separate date and time handling from\ntheir representation, on the other hand they will provide new calendars and\ntime measurement systems."}}, {"pk": 673, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "reconstruct", "license": "Public Domain", "author": "Symbols", "author_email": "simplesymbols at gmail dot com", "project_url": null, "maintainer_email": null, "home_page": "http://construct.wikispaces.com/", "version": "2.03dev", "platform": "any", "keywords": "parsing,binary,bitwise,bit level,constructing,struct", "summary": "library for constructing (parsing and building) of binary and textual data structures", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nLicense :: Public Domain\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Networking\nTopic :: System :: Networking :: Monitoring\nTopic :: Text Processing", "description": "ReConstruct is a continuation of the excellent 'Construct' library by \nTomer Filiba <tomerfiliba [at] gmail dot com>. \nThe original description is reproduced below. This version is maintained by \nSymbols <simplesymbols [at] gmail dot com>.\n\nOriginal Description\n====================\nConstruct is a library for parsing and building of data structures (binary or\ntextual).\n\nThe original description is \nIt is based on the concept of defining data structures in a declarative manner,\nrather than procedural code: more complex constructs are composed of a hierarchy\nof simpler ones. It's the first library that makes parsing fun, instead of the\nusual headache it is today.\n\nConstruct features bit and byte granularity, symmetrical operation (parsing\nand building), component-oriented design (declarative), easy debugging and\ntesting, easy to extend (subclass constructs), and lots of primitive constructs\nto make your work easier (fields, structs, unions, repeaters, meta constructs,\nswitches, on-demand parsing, pointers, etc.)"}}, {"pk": 674, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "picalo", "license": "Picalo itself is released under the GNU General Public License (GPL).\nIt is NOT public domain software.  It has some limitations on your\nuse of the product.  In short, here are the rules:\n\n * I give this software to the analysis and fraud detection community\n   in good faith that those using it will contribute modules and additions\n   back to me and other users.  This is enforced by the license.  But\n   beyond the legal issues, please support the community by developing\n   your routines in general ways that all can use.\n   \n * You can use Picalo free of charge (commercial or otherwise)\n \n * You can modify the source code as you wish for personal use.\n \n * If you release, sell, or otherwise distribute Picalo to others,\n   you MUST release the product and any changes you make to\n   the software under the GPL.  This means you must provide the source\n   code to whoever asks for it, including your changes.  You cannot\n   change the license, even on derivative works.\n   (This prevents companies or individuals from benefiting from this\n   product without allowing others to use their modifications.)\n\nAlthough I release the software for free under the GPL, I do make money\nusing the software in consulting.  I am also often willing to make \nadditions that companies or individuals need for consulting fees.\nFinally, I actively consult in training people on how to use Picalo.\nContact me if you wish to discuss these options.\n\nPicalo uses the following extra packages.  Picalo's license\nis compatible with all of the licenses of these products. Thanks\nto the host of individuals who worked many long hours to release these\nproducts.  Picalo is my contribution to the open source community.\n\n * Python (Core language, http://www.python.org/)\n * wxPython (Widget set, http://www.wxpython.org/)\n * pstat.py (Statistics library, Gary Strangman)\n * Nuvola icon set (David Vignoni, ICON KING - www.icon-king.com)\n * pyodbc (ODBC driver)\n * psycopg2 (PostgreSQL driver)\n * MySQLdb (MySQL driver)\n \n\n=======================================================================\n\n\n\t\t    GNU GENERAL PUBLIC LICENSE\n\t\t       Version 2, June 1991\n\n Copyright (C) 1989, 1991 Free Software Foundation, Inc.\n                       59 Temple Place, Suite 330, Boston, MA  02111-1307  USA\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n\t\t\t    Preamble\n\n  The licenses for most software are designed to take away your\nfreedom to share and change it.  By contrast, the GNU General Public\nLicense is intended to guarantee your freedom to share and change free\nsoftware--to make sure the software is free for all its users.  This\nGeneral Public License applies to most of the Free Software\nFoundation's software and to any other program whose authors commit to\nusing it.  (Some other Free Software Foundation software is covered by\nthe GNU Library General Public License instead.)  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthis service if you wish), that you receive source code or can get it\nif you want it, that you can change the software or use pieces of it\nin new free programs; and that you know you can do these things.\n\n  To protect your rights, we need to make restrictions that forbid\nanyone to deny you these rights or to ask you to surrender the rights.\nThese restrictions translate to certain responsibilities for you if you\ndistribute copies of the software, or if you modify it.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must give the recipients all the rights that\nyou have.  You must make sure that they, too, receive or can get the\nsource code.  And you must show them these terms so they know their\nrights.\n\n  We protect your rights with two steps: (1) copyright the software, and\n(2) offer you this license which gives you legal permission to copy,\ndistribute and/or modify the software.\n\n  Also, for each author's protection and ours, we want to make certain\nthat everyone understands that there is no warranty for this free\nsoftware.  If the software is modified by someone else and passed on, we\nwant its recipients to know that what they have is not the original, so\nthat any problems introduced by others will not reflect on the original\nauthors' reputations.\n\n  Finally, any free program is threatened constantly by software\npatents.  We wish to avoid the danger that redistributors of a free\nprogram will individually obtain patent licenses, in effect making the\nprogram proprietary.  To prevent this, we have made it clear that any\npatent must be licensed for everyone's free use or not licensed at all.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n\t\t    GNU GENERAL PUBLIC LICENSE\n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n\n  0. This License applies to any program or other work which contains\na notice placed by the copyright holder saying it may be distributed\nunder the terms of this General Public License.  The \"Program\", below,\nrefers to any such program or work, and a \"work based on the Program\"\nmeans either the Program or any derivative work under copyright law:\nthat is to say, a work containing the Program or a portion of it,\neither verbatim or with modifications and/or translated into another\nlanguage.  (Hereinafter, translation is included without limitation in\nthe term \"modification\".)  Each licensee is addressed as \"you\".\n\nActivities other than copying, distribution and modification are not\ncovered by this License; they are outside its scope.  The act of\nrunning the Program is not restricted, and the output from the Program\nis covered only if its contents constitute a work based on the\nProgram (independent of having been made by running the Program).\nWhether that is true depends on what the Program does.\n\n  1. You may copy and distribute verbatim copies of the Program's\nsource code as you receive it, in any medium, provided that you\nconspicuously and appropriately publish on each copy an appropriate\ncopyright notice and disclaimer of warranty; keep intact all the\nnotices that refer to this License and to the absence of any warranty;\nand give any other recipients of the Program a copy of this License\nalong with the Program.\n\nYou may charge a fee for the physical act of transferring a copy, and\nyou may at your option offer warranty protection in exchange for a fee.\n\n  2. You may modify your copy or copies of the Program or any portion\nof it, thus forming a work based on the Program, and copy and\ndistribute such modifications or work under the terms of Section 1\nabove, provided that you also meet all of these conditions:\n\n    a) You must cause the modified files to carry prominent notices\n    stating that you changed the files and the date of any change.\n\n    b) You must cause any work that you distribute or publish, that in\n    whole or in part contains or is derived from the Program or any\n    part thereof, to be licensed as a whole at no charge to all third\n    parties under the terms of this License.\n\n    c) If the modified program normally reads commands interactively\n    when run, you must cause it, when started running for such\n    interactive use in the most ordinary way, to print or display an\n    announcement including an appropriate copyright notice and a\n    notice that there is no warranty (or else, saying that you provide\n    a warranty) and that users may redistribute the program under\n    these conditions, and telling the user how to view a copy of this\n    License.  (Exception: if the Program itself is interactive but\n    does not normally print such an announcement, your work based on\n    the Program is not required to print an announcement.)\n\nThese requirements apply to the modified work as a whole.  If\nidentifiable sections of that work are not derived from the Program,\nand can be reasonably considered independent and separate works in\nthemselves, then this License, and its terms, do not apply to those\nsections when you distribute them as separate works.  But when you\ndistribute the same sections as part of a whole which is a work based\non the Program, the distribution of the whole must be on the terms of\nthis License, whose permissions for other licensees extend to the\nentire whole, and thus to each and every part regardless of who wrote it.\n\nThus, it is not the intent of this section to claim rights or contest\nyour rights to work written entirely by you; rather, the intent is to\nexercise the right to control the distribution of derivative or\ncollective works based on the Program.\n\nIn addition, mere aggregation of another work not based on the Program\nwith the Program (or with a work based on the Program) on a volume of\na storage or distribution medium does not bring the other work under\nthe scope of this License.\n\n  3. You may copy and distribute the Program (or a work based on it,\nunder Section 2) in object code or executable form under the terms of\nSections 1 and 2 above provided that you also do one of the following:\n\n    a) Accompany it with the complete corresponding machine-readable\n    source code, which must be distributed under the terms of Sections\n    1 and 2 above on a medium customarily used for software interchange; or,\n\n    b) Accompany it with a written offer, valid for at least three\n    years, to give any third party, for a charge no more than your\n    cost of physically performing source distribution, a complete\n    machine-readable copy of the corresponding source code, to be\n    distributed under the terms of Sections 1 and 2 above on a medium\n    customarily used for software interchange; or,\n\n    c) Accompany it with the information you received as to the offer\n    to distribute corresponding source code.  (This alternative is\n    allowed only for noncommercial distribution and only if you\n    received the program in object code or executable form with such\n    an offer, in accord with Subsection b above.)\n\nThe source code for a work means the preferred form of the work for\nmaking modifications to it.  For an executable work, complete source\ncode means all the source code for all modules it contains, plus any\nassociated interface definition files, plus the scripts used to\ncontrol compilation and installation of the executable.  However, as a\nspecial exception, the source code distributed need not include\nanything that is normally distributed (in either source or binary\nform) with the major components (compiler, kernel, and so on) of the\noperating system on which the executable runs, unless that component\nitself accompanies the executable.\n\nIf distribution of executable or object code is made by offering\naccess to copy from a designated place, then offering equivalent\naccess to copy the source code from the same place counts as\ndistribution of the source code, even though third parties are not\ncompelled to copy the source along with the object code.\n\n  4. You may not copy, modify, sublicense, or distribute the Program\nexcept as expressly provided under this License.  Any attempt\notherwise to copy, modify, sublicense or distribute the Program is\nvoid, and will automatically terminate your rights under this License.\nHowever, parties who have received copies, or rights, from you under\nthis License will not have their licenses terminated so long as such\nparties remain in full compliance.\n\n  5. You are not required to accept this License, since you have not\nsigned it.  However, nothing else grants you permission to modify or\ndistribute the Program or its derivative works.  These actions are\nprohibited by law if you do not accept this License.  Therefore, by\nmodifying or distributing the Program (or any work based on the\nProgram), you indicate your acceptance of this License to do so, and\nall its terms and conditions for copying, distributing or modifying\nthe Program or works based on it.\n\n  6. Each time you redistribute the Program (or any work based on the\nProgram), the recipient automatically receives a license from the\noriginal licensor to copy, distribute or modify the Program subject to\nthese terms and conditions.  You may not impose any further\nrestrictions on the recipients' exercise of the rights granted herein.\nYou are not responsible for enforcing compliance by third parties to\nthis License.\n\n  7. If, as a consequence of a court judgment or allegation of patent\ninfringement or for any other reason (not limited to patent issues),\nconditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot\ndistribute so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you\nmay not distribute the Program at all.  For example, if a patent\nlicense would not permit royalty-free redistribution of the Program by\nall those who receive copies directly or indirectly through you, then\nthe only way you could satisfy both it and this License would be to\nrefrain entirely from distribution of the Program.\n\nIf any portion of this section is held invalid or unenforceable under\nany particular circumstance, the balance of the section is intended to\napply and the section as a whole is intended to apply in other\ncircumstances.\n\nIt is not the purpose of this section to induce you to infringe any\npatents or other property right claims or to contest validity of any\nsuch claims; this section has the sole purpose of protecting the\nintegrity of the free software distribution system, which is\nimplemented by public license practices.  Many people have made\ngenerous contributions to the wide range of software distributed\nthrough that system in reliance on consistent application of that\nsystem; it is up to the author/donor to decide if he or she is willing\nto distribute software through any other system and a licensee cannot\nimpose that choice.\n\nThis section is intended to make thoroughly clear what is believed to\nbe a consequence of the rest of this License.\n\n  8. If the distribution and/or use of the Program is restricted in\ncertain countries either by patents or by copyrighted interfaces, the\noriginal copyright holder who places the Program under this License\nmay add an explicit geographical distribution limitation excluding\nthose countries, so that distribution is permitted only in or among\ncountries not thus excluded.  In such case, this License incorporates\nthe limitation as if written in the body of this License.\n\n  9. The Free Software Foundation may publish revised and/or new versions\nof the General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\nEach version is given a distinguishing version number.  If the Program\nspecifies a version number of this License which applies to it and \"any\nlater version\", you have the option of following the terms and conditions\neither of that version or of any later version published by the Free\nSoftware Foundation.  If the Program does not specify a version number of\nthis License, you may choose any version ever published by the Free Software\nFoundation.\n\n  10. If you wish to incorporate parts of the Program into other free\nprograms whose distribution conditions are different, write to the author\nto ask for permission.  For software which is copyrighted by the Free\nSoftware Foundation, write to the Free Software Foundation; we sometimes\nmake exceptions for this.  Our decision will be guided by the two goals\nof preserving the free status of all derivatives of our free software and\nof promoting the sharing and reuse of software generally.\n\n\t\t\t    NO WARRANTY\n\n  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY\nFOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN\nOTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES\nPROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED\nOR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS\nTO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE\nPROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,\nREPAIR OR CORRECTION.\n\n  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR\nREDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING\nOUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED\nTO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY\nYOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER\nPROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGES.\n\n\t\t     END OF TERMS AND CONDITIONS", "author": "Conan C. Albrecht", "author_email": "conan@warp.byu.edu", "project_url": null, "maintainer_email": null, "home_page": "http://www.picalo.org/", "version": "4.94", "platform": "UNKNOWN", "keywords": "data log analysis spreadsheet database", "summary": "A data analysis/structure library with tables, type-aware columns, records, and cells.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nTopic :: Database\nTopic :: Internet :: Log Analysis\nTopic :: Office/Business :: Financial :: Spreadsheet\nTopic :: Scientific/Engineering\nTopic :: Text Processing", "description": "Picalo\n                          \n                  Data Analysis Library\n                  \n                  http://www.picalo.org/\n\nPicalo is a Python library to help anyone who works with data files, \nespecially those who work with data in relational/spreadsheet format.  \nIt is primarily created for investigators and auditors search through \ndata sets for anomalies, trends, ond other information, but it is \ngenerally useful for any type of data or text files.\n\nPicalo is different from NumPy/Numarray in that it is meant for\nheterogeneous data rather than homogenous data.  In NumPy, you\nhave an array (table) of the same type--all ints, for example.\nIn Picalo, you have a table made up of different column types,\nvery similar to a database.\n\nOne of Picalo's primary purposes is making relational\ndatabases easier to work with.  Once you have a Picalo table, \nyou can add, move, or delete columns; work with records (horizontal\nslices of the data); select and group records in various ways;\nand run analyses on tables.  Picalo includes adapters for popular\ndatabases, and it provides a Query object that make queries seem\njust like regular Tables (except they are live from the database).\n\nIf you work with relational databases, delimited (CSV/TSV) files, \nEBCDIC files, MS Excel files, log files, text files, or other \nheterogeneous datasets, Picalo might make your life easier.\n\nPicalo is programmed to be as Pythonic as possible.  It's core objects--\ntables, columns, records--they act like lists.  A column is a list of cells.\nA record is a list of cells.  A table is a list of records.  Tables can be \nsorted via the sort function, just like the Sorting HowTo shows.  The return\nvalues of almost all functions are new tables, so functions can be chained\ntogether like pipes in Unix.\n\nPicalo includes an optional Project object that stores tables in\nZope Object DB files.  When Projects are used, Picalo automatically\nswaps records in and out of memory as needed to ensure efficient use of \nresources.  Projects allow Picalo to work with essentially an unlimited\namount of data.\n\nThe project was started in 2003 by Conan C. Albrecht, a professor\nin Information Systems at Brigham Young University.  Conan remains\nthe primary developer of Picalo.\n\nHere's an example of Picalo code loading a CSV and working with it:\n\n    # import the picalo libraries and turn off visual progress bars\n    import picalo, StringIO\n    picalo.use_progress_indicators(False)\n\n    # load the csv, could have been from a filename\n    csv = '''Name,Age\n    Homer,35\n    Marge,34\n    Lisa,8\n    Bart,10\n    '''\n    table = picalo.load_csv(StringIO.StringIO(csv))\n\n    table.set_type('Age', int)  # set the type of the Age column (csv defaults types to str)\n    table.view()                # prints a formatted table\n    print table[0].Age          # prints 35\n    print table[0]['Age']       # also prints 35\n    print table[0][1]           # again prints 35\n    print table[-1].Name        # prints Bart\n    table2 = table[0:2]         # get a slice of records\n    for name in table.column('Name'):\n      print name                # prints the names, one by one\n\n    # insert a column, which defaults cells to None\n    table.insert_column(1, 'DoubleAge', int)\n    # change cells using an expression\n    table.replace_column_values('DoubleAge', 'record.Age * 2')\n\n    # sort by Name, then Age\n    picalo.Simple.sort(table, True, 'Name', 'Age')\n    # sort in more Pythonic way (only by Name this time)\n    table.sort(key=lambda r: r.Name)\n\n    # print the std. dev. of the age column\n    print picalo.stdev(table.column('Age'))\n\n    # select records by regex, those containing 'a'\n    table2 = picalo.Simple.select_by_regex(table, Name='^.*a.*$')\n\n    # filter the existing table, then clear the filter\n    table.filter('record.Age > 20')\n    print len(table)            # prints 2\n    table.clear_filter()\n    print len(table)            # prints 4\n\n    # reorder the columns \n    table.reorder_columns(['Age', 'Name', 'DoubleAge'])\n\n    # add a live, calculated column\n    table.append_calculated('ReverseName', unicode, 'record.Name[::-1].capitalize()')\n    print table[0][3]           # prints 'Trab'\n    table[0].Name = 'Maggie'\n    print table[0][3]           # prints 'Eiggam'\n\n    # split into multiple tables by value\n    table.append_column('FavNum', int, [ 5, 5, 2, 2 ])\n    tablelist = picalo.Grouping.stratify_by_value(table, 'FavNum')\n    tablelist[0].view()         # view first table in list (has two records)\n    tablelist[1].view()         # view second table in list (has two records)\n    # any operations to a list of tables is made to all tabels in list\n    # this sets the type of the FavNum column in *both* tables\n    tablelist.set_type('FavNum', float)\n  \n\nPicalo is released in two formats:\n  1) As a pure-Python library that is used by issuing one of the\n     following:\n        from picalo import *\n        # or #\n        import picalo\n     Python programmers will be primarily interested in the library\n     version.\n     \n     This format is installed in the typical Python fashion, either\n     as an .egg via setuptools, or via \"python setup.py install\" from\n     the source.\n        \n  2) As a standalone, wx-Python-based GUI environment that allow\n     end users to access the Picalo libraries.\n     \n     This version is packaged as a Windows setup.exe file, Mac\n     application bundle, and Linux rpm and deb files.  The user\n     may not realize Python is even being used when running the\n     full application environment.\n\nPlease see the following:\n  - HOW TO RUN at the bottom of this file for running the source\n    distribution or compiling a new bundle.\n  \n  - CHANGELOG.TXT has good information about what's changed in recent\n    versions.\n\n  - LICENSE.TXT for the GNU Public License that Picalo is released under.\n    For those who don't want to read the license, here's the higlights:\n    \n      1. You may use Picalo free of charge.  I hope it is helpful to you.\n         Please improve the code and share back with the community.\n      \n      2. Picalo has NO warrantee.  I don't guarantee it will do anything\n         correctly or even incorrectly.  It may do unsightly things to your\n         machine.  It may munch your data or even corrupt your hard drive.\n         Picalo might fry your computer or ruin your marriage.  You take \n         all risks upon yourself.\n   \n      3. You must release any additions to Picalo under the GPL.\n         \n      4. Picalo source code cannot be included or used in any products that \n         are licensed with something other than the GPL.\n         \n      5. More information on these issues can be found in LICENSES.TXT\n    \n      \n  - doc/PicaloCookbook.pdf has some of the best information right now.\n        \n      \n  - doc/Manual.pdf for installation instructions (see the Installation section)\n  \n  \n  - doc/Manual.pdf for detailed usage instructions, tutorial, etc.\n  \nEnjoy!  Please report any bugs to me.  I also welcome additions to the toolkit.\n  \nDr. Conan C. Albrecht\nconan@warp.byu.edu\n\n\n=======================================\n     HOW TO RUN/COMPILE THE SOURCE\n=======================================\n\n###   TO INSTALL THE PICALO LIBRARY ONLY:\n\nIf you want to install the library version for use in your Python environment and \nyou have setuptools installed, you can simply use easy_install:\n\n  easy_install picalo\n  \nIf you don't have setuptools or want to install manually, expand the \npicalo-x.xx.tar.gz file and run the traditional Python setup.py file:\n\n  (first install ZODB from the Zope libraries)\n  (this assumes you downloaded picalo-5.12.tar.gz)\n  tar xvfz picalo-5.12.tar.gz\n  cd picalo-5.12\n  python setup.py install\n  \n\n\n###   TO BUILD THE FULL GUI APPLICATION:\n\nNote that this section is primarily for developers.  If you simply want to\ninstall and run Picalo, visit http://www.picalo.org/ and download a pre-built\nbundle for Windows, Mac, or Linux.\n\nPicalo has several dependencies that you'll need to ensure your Python \ninstallation has.  These include the following:\n\nNOTE: Don't install eggs on Windows because py2exe chokes on them.  When doing a \n      manual setup, use \"python setup.py install_lib\" to disable the egg building.\n      This only applies to people wanting to compile the Windows exe files.\nNOTE: To build on Mac, you need to be using the Framework version of Python.  This\n      is the version on python.org, not the one that comes with an Apple.  Be sure\n      to explicitly install Python and ensure it is being used.\n\nREQUIRED:\n  - Python 2.5+ (http://www.python.org) - It probably runs on version 2.4 and earlier, \n    but all testing is now being done on Python 2.5+. \n    We have not made the jump to Python 3 because some libraries aren't there yet\n    (especially wxPython).\n  - wxPython (http://www.wxpython.org) - We're on version 2.8.x.x right now.  \n    We try to keep current with wxPython, so try the most recent version of wxPython.  \n    If you hit GUI snags, email Conan and ask what version we're currently on. wxPython\n    often changes the API from one version to another, so you'll know right away if\n    it says some wx method doesn't exist.  Note that for the command-line version of\n    Picalo, wxPython is not required -- the code can run entirely without any dependencies\n    here.\n  - ZODB - Zope Object Database\n  - zc.blist - A tree-based list optimized for storage in ZODB.\n  - pyODBC (http://pyodbc.sourceforge.net/) - This allows you to access ODBC databases. \n    Picalo should be able to run without it, although the database GUI dialogs will fail.\n  - pysycopg2 - This allows you to access PostgreSQL directly.   \n    The Windows build is at Stickpeople.com.\n    Picalo should be able to run without it, although the database GUI dialogs will fail.\n  - pygresql - An alternative driver to access PostgreSQL directly.\n    Picalo should be able to run without it, although the database GUI dialogs will fail.\n  - MySQLdb - This allows you to access MySQL directly.\n    Picalo should be able to run without it, although the database GUI dialogs will fail.\n  - cx_Oracle - Allows you to connect to Oracle 10.\n    Picalo should be able to run without it, although the database GUI dialogs will fail.\n  - MX Base distribution - I'm not sure if this is still required or not.  Picalo itself\n    doesn't use it, but some of the dependencies above might.\n  - chardet.universaldetector (http://chardet.feedparser.org/) \n  - Windows Only: py2exe - if you want to compile Picalo on Windows\n  - Windows Only: InnoSetup - if you want to compile Picalo on Windows\n  - Mac OS X Only: py2app - if you want to compile Picalo on Mac OS X (installs easily \n    with easy_install).\n  \nOnce you are sure the above are running, change to the trunk/ directory.  Run the following:\n\npython Picalo.pyw\n\nAlternatively, to run the command line version, execute the following from within the\nPython interpreter:\n\n>>> from picalo import *"}}, {"pk": 675, "model": "importing.pypicache", "fields": {"maintainer": "Wolfgang Lipp", "name": "tracy", "license": "free for non-commercial use", "author": "Wolfgang Lipp", "author_email": "castor@snafu.de", "project_url": null, "maintainer_email": "castor@snafu.de", "home_page": "http://paragate.net", "version": "0.1", "platform": "OS Independent", "keywords": "trace, tracing, debug, debugging, dev, develop, developer, inspect, inspection, system, tool, tools", "summary": "Live tracing of Python programs", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: Free for non-commercial use\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Debuggers\nTopic :: Software Development :: Testing\nTopic :: Utilities", "description": "Tracy provides a simple but informative and configurable view at live, running \r\nPython programs. The basic functionality is to render the source of each line \r\ntraversed, complete with graphical call stack level depth indication and \r\nsourceline reference. Using magic comments, users can choose to print out \r\nvariable values at interesting points or hide lines for minimized clutter. More \r\nfeatures planned. Sorry, no distutils as yet, just drop the folder into a place \r\non your path. Snazzy epydocs provided. Pls have a try and do feed back, if you \r\nlike."}}, {"pk": 676, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "BlockCanvas", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/block_canvas.php", "version": "3.2.1", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Numerical Modeling", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The BlockCanvas project provides a visual environment for creating simulation\nexperiments, where function and data are separated. Thus, you can define your\nsimulation algorithm by visually connecting function blocks into a data flow\nnetwork, and then run it with various data sets (known as \"contexts\");\nlikewise, you can use the same context in a different functional simulation.\n\nThe project provides support for plotting, function searching and inspection,\nand optimization. It includes a stand-alone application that demonstrates the\nblock-canvas environment, but the same functionality can be incorporated into\nother applications.\n\nThe BlockCanvas project relies on included libraries that allow multiple data\nsets using Numeric arrays to be incorporated in a Traits-based model in a\nway that is simple, fast, efficient, and consistent.\n\nPrerequisites\n-------------\nIf you want to build BlockCanvas from source, you must first install\n`setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 677, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "owyl", "license": "UNKNOWN", "author": "David Eyk", "author_email": "eykd@eykd.net", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/owyl/", "version": "0.3", "platform": "UNKNOWN", "keywords": null, "summary": "The goal of Owyl: provide a fast and flexible Behavior Tree library implemented in python.", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Games/Entertainment\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Libraries", "description": "You have Pyglet. You've got Rabbyt. But who do your sprites go to for advice? Owyl, of course.\n\nThe goal of Owyl: provide a fast and flexible Behavior Tree library implemented in python. For more information on Behavior Trees, see the articles at http://aigamedev.com/hierarchical-logic"}}, {"pk": 678, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "SphinxReport", "license": "BSD", "author": "Andreas Heger", "author_email": "andreas.heger@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/sphinx-report/", "version": "1.0", "platform": "any", "keywords": "report generator sphinx matplotlib sql", "summary": "SphinxReport : a report generator in python based on Sphinx and matplotlib", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "SphinxReport : a report generator in python based on Sphinx and matplotlib"}}, {"pk": 679, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "slepc", "license": "LGPL", "author": "Lisandro Dalcin", "author_email": "dalcinl@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.grycap.upv.es/slepc/", "version": "3.1.post6", "platform": "POSIX", "keywords": "SLEPc,PETSc,MPI", "summary": "SLEPc: Scalable Library for Eigenvalue Problem Computations", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: Public Domain\nOperating System :: POSIX\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Fortran\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "SLEPc is a software library for the solution of large scale sparse\neigenvalue problems on parallel computers. It is an extension of PETSc\nand can be used for either standard or generalized eigenproblems, with\nreal or complex arithmetic. It can also be used for computing a\npartial SVD of a large, sparse, rectangular matrix, and to solve\nquadratic eigenvalue problems"}}, {"pk": 680, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "numbyte", "license": "gpl", "author": "kai zhu", "author_email": "kaizhu256@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pypi.python.org/pypi/numbyte", "version": "2009.12.24.py3k.cpp", "platform": "UNKNOWN", "keywords": "", "summary": "numbyte - numerical bytearray - c++ numerical buffer interface extending bytearray into numpy-like, 2d array", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "numbyte - numerical bytearray - c++ numerical buffer interface extending bytearray into numpy-like, 2d array\n\n  REQUIRES PYTHON3.1\n\n  QUICK TEST: $ python3.1 setup.py build dev --quicktest\n\n  DESCRIPTION: numbyte - numerical bytearray - c++ numerical buffer interface extending bytearray into numpy-like, 2d array\n\nSUMMARY:\nnumbyte is a python3.1 extension module, efficiently implementing numerical 2d arrays.\nnumbyte uses python bytearray as the underlying data structure, simplifying io operation with other python objects.\n\nRECENT CHANGELOG:\n20091224 - modularized package - fix install issues - added sdist check\n20091209 - improved documentation\n20091205 - moved source code to c++\n20091116 - package integrated\n\n  DEMO USAGE:\n\n>>> from numbyte import *\n>>> ## subclass numbyte\n>>> class numbyte2(numbyte): pass\n\n>>> ## create bytearray containing 3x4 array of longlong\n>>> integers = numbyte2('i', range(12), shape0 = 3, shape1 = 4)\n>>> print( integers.debug() )\n<class 'numbyte.numbyte2'> i refcnt=4 tcode=i tsize=8 offset=0 shape=<3 4> stride=<4 1> transposed=0\n[[          0           1           2           3]\n[          4           5           6           7]\n[          8           9          10          11]]\n\n>>> ## modify underlying bytearray\n>>> integers.bytes()[0] = 0xff; integers.bytes()[1] = 0xff\n>>> print( integers.bytes() )\nbytearray(b'\\xff\\xff\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x00')\n>>> print( integers.debug() )\n<class 'numbyte.numbyte2'> i refcnt=4 tcode=i tsize=8 offset=0 shape=<3 4> stride=<4 1> transposed=0\n[[      65535           1           2           3]\n[          4           5           6           7]\n[          8           9          10          11]]\n\n>>> ## bytearray as sequence\n>>> print( 2 in integers )\nTrue\n>>> print( integers.count(2) )\n1\n>>> print( integers.index(2) )\n2\n>>> for aa in integers.rows(): print( aa )\n[[      65535           1           2           3]]\n[[          4           5           6           7]]\n[[          8           9          10          11]]\n>>> ## slice\n>>> print( integers[1:, 2:].debug() )\n<class 'numbyte.numbyte2'> i refcnt=3 tcode=i tsize=8 offset=6 shape=<2 2> stride=<4 1> transposed=0\n[[          6           7]\n[         10          11]]\n>>> ## transpose\n>>> print( integers.T()[2:, 1:].debug() )\n<class 'numbyte.numbyte2'> i refcnt=3 tcode=i tsize=8 offset=6 shape=<2 2> stride=<1 4> transposed=1\n[[          6          10]\n[          7          11]]\n>>> ## reshape\n>>> print( integers.reshape(2, -1).debug() )\n<class 'numbyte.numbyte2'> i refcnt=3 tcode=i tsize=8 offset=0 shape=<2 6> stride=<6 1> transposed=0\n[[      65535           1           2           3           4           5]\n[          6           7           8           9          10          11]]\n>>> ## setslice\n>>> integers.T()[2:, 1:] = range(4); print( integers )\n[[      65535           1           2           3]\n[          4           5           0           2]\n[          8           9           1           3]]\n\n>>> ## almost all arithmetic operations are inplace - use copy to avoid side-effects\n>>> ## recast to double\n>>> floats = integers.recast('f') / 3; print( floats )\n[[        21845      0.333333      0.666667             1]\n[      1.33333       1.66667             0      0.666667]\n[      2.66667             3      0.333333             1]]\n>>> ## copy\n>>> print( floats.copy() + integers[0, :] )\n[[        87380       1.33333       2.66667             4]\n[      65536.3       2.66667             2       3.66667]\n[      65537.7             4       2.33333             4]]\n>>> ## inplace\n>>> print( floats + integers[:, 0] )\n[[        87380       65535.3       65535.7         65536]\n[      5.33333       5.66667             4       4.66667]\n[      10.6667            11       8.33333             9]]\n>>> ## inplace\n>>> print( floats - integers[:, 0] )\n[[        21845      0.333333      0.666667             1]\n[      1.33333       1.66667             0      0.666667]\n[      2.66667             3      0.333333             1]]\n>>> ## inplace\n>>> print( floats ** 2 )\n[[  4.77204e+08      0.111111      0.444444             1]\n[      1.77778       2.77778             0      0.444444]\n[      7.11111             9      0.111111             1]]\n>>> ## inplace\n>>> print( floats.sqrt() )\n[[        21845      0.333333      0.666667             1]\n[      1.33333       1.66667             0      0.666667]\n[      2.66667             3      0.333333             1]]\n\n>>> ## the only inplace exception are logical comparisons, which return new char arrays\n>>> print( floats )\n[[        21845      0.333333      0.666667             1]\n[      1.33333       1.66667             0      0.666667]\n[      2.66667             3      0.333333             1]]\n>>> ## copy as char\n>>> print( floats == floats[:, 1] )\n[[ 00  01  00  00]\n[ 00  01  00  00]\n[ 00  01  00  00]]\n>>> ## copy as char\n>>> print( floats > 1.5 )\n[[ 01  00  00  00]\n[ 01  01  00  00]\n[ 01  01  00  00]]"}}, {"pk": 681, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "SciMath", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/sci_math.php", "version": "3.0.7", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Scientific and Mathematical calculations.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The SciMath project includes packages to support scientific and mathematical\ncalculations, beyond the capabilities offered by SciPy.\n\n- enthought.interpolate\n- enthought.mathematics\n- enthought.units\n\nPrerequisites\n-------------\nYou must have the following libraries installed before building or installing\nSciMath:\n\n* `Numpy <http://pypi.python.org/pypi/numpy/1.1.1>`_ version 1.1.0 or later is\n  preferred. Version 1.0.4 will work, but some tests may fail.\n* `setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_."}}, {"pk": 682, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "ASCII-Plotter", "license": "", "author": "Imri Goldberg", "author_email": "lorgandon@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://www.algorithm.co.il/blogs/index.php/ascii-plotter/", "version": "1.0", "platform": "", "keywords": "", "summary": "Allows plotting of simple graphs in ASCII-art", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": ""}}, {"pk": 683, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "img2txt", "license": "UNKNOWN", "author": "kai zhu", "author_email": "kaizhu256@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pypi.python.org/pypi/img2txt", "version": "2008.11.20", "platform": "UNKNOWN", "keywords": "", "summary": "superseded by asciiporn, http://pypi.python.org/pypi/asciiporn", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nNatural Language :: English\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.0\nTopic :: Multimedia :: Graphics\nTopic :: Multimedia :: Graphics :: Graphics Conversion\nTopic :: Multimedia :: Graphics :: Viewers\nTopic :: Scientific/Engineering", "description": "################################################################################\r\nthis is a moderately sophisticated python3.0 script fully utilizing\r\nextensions, & demonstrated to run under python2.6 via py3to2.\r\nfor performance, portions of it have been inlined w/ direct C code using\r\nscipy.weave.  the algorithm also heavily uses bitwise operations.\r\nit takes a jpg, gif... image file & outputs it in colorized ascii art.\r\nalso serves dual purpose as a 3-d colorized scientific plotter in text terminals\r\n(screenshots of image conversion & 3d plot in putty terminal included)\r\n\r\nif something fails, try updating ur install of py3to2 to the latest version @:\r\nhttp://pypi.python.org/pypi/py3to2\r\n\r\nhow to enable 256 color on putty: http://www.emacswiki.org/emacs/PuTTY#toc2\r\nhow to enable 256 color on xterm: http://www.frexx.de/xterm-256-notes/\r\n\r\nimg2txt is hard-coded to use lucida-console font, but courier looks ok.\r\nthe screenshot shows putty w/ lucida-console 5pt.\r\n\r\nAUTHOR:\r\n  kai zhu\r\n  kaizhu256@gmail.com\r\n\r\nREQUIREMENTS:\r\n- posix/unix os (Windows currently unsupported)\r\n- py3to2\r\n- Python Imaging Library\r\n- scipy\r\n\r\nAPI:\r\n  img2txt module:\r\n  - img2plaintxt - converts image file to portable plain txt\r\n                   u can copy & paste in documents\r\n  - img2txt - converts image to high-quality colorized txt\r\n              for display on terminals supporting 256 color (putty, xterm...)\r\n  - tplot3d - 3d color scientific plotter\r\n\r\nUSAGE:\r\n  start up the py3to2 interpreter by typing \"py3to2\" in ur terminal &\r\n  import img2txt:\r\n    $ py3to2\r\n\r\n    Python 2.6.py3to2 (r26:66714, Nov 18 2008, 00:56:43)\r\n    [GCC 3.4.6 20060404 (Red Hat 3.4.6-10)] on linux2\r\n    Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n    >>>\r\n    >>> import img2txt\r\n    created...\r\n    py3k server starting...\r\n    >>> ...py3k server started w/...\r\n    >>>\r\n\r\n  in this example, u'll b loading the image file included w/ this distribution,\r\n  \"mario.jpg\".  its a fairly large image, so u probably want to scale it down\r\n  to 0.5 (or less):\r\n    >>> colortxt = img2txt.img2txt('mario.jpg', scale = 0.5)\r\n    >>> print( colortxt )\r\n\r\n    ... beautiful image appears ^_-\r\n\r\n    >>> plaintxt = img2txt.img2plaintxt('mario.jpg', scale = 0.5)\r\n    >>> print( plaintxt )\r\n\r\n    ... rather plain b/w img -_-, but u can copy & paste it in documents\r\n\r\n  actually, the plaintxt prolly won't look well when pasted,\r\n  b/c most document readers invert the color:\r\n    >>> plaintxt = img2txt.img2plaintxt('mario.jpg', scale = 0.5, invert = True)\r\n    >>> print( plaintxt )\r\n\r\n    ... b/w img w/ colors inverted.  may look funny now :/\r\n        but it'll b normal when u paste it into ur document\r\n\r\n  the 3d plotting feature is a bit more complicated.  for the time being,\r\n  simply run the test.  (if u want to kno how to use it,\r\n  u'll need to look @ the img2txt.tplot3d.test() method in img2txt.py)\r\n    >>> img2txt.tplot3d.test()\r\n\r\n################################################################################\r\nRECENT CHANGELOG:\r\ncurrent\r\n  fixed bug where 64bit  gets truncated to 32 on 32bit machine\r\n  256 color support\r\n20081119\r\n  fixed bugs in setup.py"}}, {"pk": 684, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cutadapt", "license": "MIT", "author": "Marcel Martin", "author_email": "marcel.martin@tu-dortmund.de", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/cutadapt/", "version": "0.9.3", "platform": "UNKNOWN", "keywords": null, "summary": "trim adapters from high-throughput sequencing reads", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "UNKNOWN"}}, {"pk": 685, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "AppTools", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/app_tools.php", "version": "3.4.1", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "ETS Application Tools", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The AppTools project includes a set of packages that Enthought has found useful\nin creating a number of applications. They implement functionality that is\ncommonly needed by many applications\n\n- **enthought.appscripting**: Framework for scripting applications.\n- **enthought.help**: Provides a plugin for displaying documents and examples\n  and running demos in Envisage Workbench applications.\n- **enthought.io**: Provides an abstraction for files and folders in a file\n  system.\n- **enthought.naming**: Manages naming contexts, supporting non-string data\n  types and scoped preferences\n- **enthought.permissions**: Supports limiting access to parts of an\n  application unless the user is appropriately authorised (not full-blown\n  security).\n- **enthought.persistence**: Supports pickling the state of a Python object\n  to a dictionary, which can then be flexibly applied in restoring the state of\n  the object.\n- **enthought.preferences**: Manages application preferences.\n- **enthought.resource**: Manages application resources such as images and\n  sounds.\n- **enthought.scripting**: A framework for automatic recording of Python\n  scripts.\n- **enthought.sweet_pickle**: Handles class-level versioning, to support\n  loading of saved data that exist over several generations of internal class\n  structures.\n- **enthought.template**: Supports creating templatizable object hierarchies.\n- **enthought.type_manager**: Manages type extensions, including factories\n  to generate adapters, and hooks for methods and functions.\n- **enthought.undo**: Supports undoing and scripting application commands.\n\nPrerequisites\n-------------\nIf you want to build AppTools from source, you must first install\n`setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_ and"}}, {"pk": 686, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "eke.study", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/eke-study", "version": "1.0.2", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers eke study protocol", "summary": "Study and protocol information for the EDRN Knowledge Environment", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "*********\neke.study\n*********\n\nThis product, ``eke.study``, provides display and RDF ingest of participating\nstudies and medical protocols that are being executed, will be executed, or\nhave been executed by the Early Detection Research Network (EDRN_).  Studies\nand protocols are the major research efforts (and therefore funded entities)\nthat EDRN researchers pursue, and therefore are a vital component of the EDRN\nKnowledge Environment (EKE_).  EDRN uses the EKE to make it easy to discover,\nshare, search for, and retrieve all of EDRN's collective knowledge, including\ncancers and other diseases, biomarkers, specimens, participants, staff, and-as\nin the case of this product-studies and protocols.\n\nAlthough intended for the EDRN public portal, it can be installed in any\nPlone_ compatible site.\n\nThis software is developed by the `EDRN Informatics Center`_  at JPL_,\noperated by the California Institute of Technology, for NCI_.\n\n*Note for Developers*: Tests for this package do not work correctly under the\nRoadRunner.  Use the standard instance test runner instead.  (It's not the\nfault of the RoadRunner; it has to do with co-dependency of this project with\neke.biomarker).\n\n\n.. References:\n.. _EDRN Informatics Center: http://cancer.jpl.nasa.gov/\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _EKE: http://cancer.jpl.nasa.gov/documents/applications/knowledge-environment\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://cancer.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``eke.study`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        eke.study\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        eke.study\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nA retrospective of the various releases this component has had, what's been\nchanged, what's been fixed, and so forth, follows.  For issue IDs mentioned\nbelow, see the issue tracker at https://oodt.jpl.nasa.gov/jira/browse/CA\n\n\n1.0.2 - A Mixed Bag\n-------------------\n\nThis release fixes a couple of issues:\n\n* CA-583 - Add PDFs to Protocols\n* CA-620 - Locks appear on biomarkers listed under a protocol incorrectly\n  (implementation)\n\n\n1.0.1 - Protocol IDs\n--------------------\n\nThis release addresses just one tiny little issue:\n\n* CA-659 - Add protocol ID to protocol view\n\nYou can find the issue tracker at https://oodt.jpl.nasa.gov/jira/browse/CA\n\n\n1.0.0 - Prime Time\n------------------\n\nThis release addresses a number of issues \nthat make this component (and some of its\nselected counterparts) \"prime time\" for\nthe operational NCI portal. \n\nThis release addresses the following issues:\n\n* CA-528 Automatic periodic ingest of RDF\n\nYou can find the issue tracker at https://oodt.jpl.nasa.gov/jira/browse/CA\n\n\n0.0.3 - Filler Text\n-------------------\n\nThis release addresses the following issues:\n\n* CA-586 - Show alternative text (if abstract text is empty) on protocol list\n  page\n* CA-604 - Add PI to Protocol List\n\nYou can find the issue tracker at https://oodt.jpl.nasa.gov/jira/browse/CA\n\n\n0.0.2 - To Be Named At Release Time\n-----------------------------------\n\nThis release addresses the following issues:\n\n* https://oodt.jpl.nasa.gov/jira/browse/CA-551 - Add lock icon to biomarkers\n  and science data that are \"secure\" to protocol pages\n* https://oodt.jpl.nasa.gov/jira/browse/CA-523 - Create search indexes; in\n  particular, searches are enabled for abbreviated protocol name, biomarker\n  names, PI names, collaborative group text, dataset names (courtesy of\n  updates to ``eke.ecas``), and involved investigator sites.\n\n\n0.0.1 - HTML Formatting\n-----------------------\n\nThe following issue is the sole issue addressed in this release:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-472 - Protocols and other items seem\n  to still have encoded ASCII characters in the titles\n\n\nRelease 0.0.0\n-------------\n\nBeta release. This release is destined to become the FCS_.\n\n\n.. References:\n.. _FCS: http://en.wikipedia.org/wiki/Development_stage\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 687, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "fms", "license": "BSD", "author": "Jean-Charles Bagneris", "author_email": "jcbagneris@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/jcbagneris/fms", "version": "0.1.5", "platform": "UNKNOWN", "keywords": null, "summary": "A Financial Market Simulator", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering", "description": "==============================================\r\nFMS, An agent-based Financial Market Simulator\r\n==============================================\r\n\r\nFMS is (c) 2008,2009 Jean-Charles Bagneris. See LICENSE for redistribution\r\ninformation and usual disclaimer.\r\n\r\nThanks for downloading FMS !\r\n\r\nWhat is FMS ?\r\n=============\r\n\r\nFMS is an agent-based financial market simulator. The intended audience is\r\nfinancial markets researchers and experimentators, looking to simulate various\r\nagents behaviours on different types of markets through the resulting\r\ntransactions on a fictitious asset. Agents, markets and the environment (the\r\n\"world\") are Python classes, derived from abstract ones provided with FMS.\r\n\r\nAs the resulting output (the transactions) is in comma separated values format,\r\nit is easy to use it as an input for whichever processing needed (produce\r\ngraphics, import in spreadsheet, crunch in various statistical procedures, ...)\r\n\r\nFMS is a command line application, configured through very simple flat files. As\r\nyou may write your own agents, markets, engines and world classes, it is as\r\ncustomizable as it could be. But you do not have to be a programmer to use it:\r\nFMS is provided with a comprehensive set of classes ready to use, and there is\r\nmore to come.\r\n\r\nIf you program your own classes, remember these may be of interest for others:\r\nfeel free to drop me an email and to contribute (see `How could I contribute ?`_\r\nbelow).\r\n\r\nWhat FMS is not\r\n===============\r\n\r\nFMS is a simulation tool intended for research only. Thus, FMS is NOT (and will\r\nnot be in the foreseeable future):\r\n\r\n- a game,\r\n- a portfolio management simulation or helper,\r\n- a learning tool intended for classroom use [1]_,\r\n- a shiny GUI application, providing with coloured graphics and multiple drop\r\n  down menus, smileys and icons,\r\n- a coffee-machine.\r\n\r\n.. [1] Although FMS intention is not primarily pedagogical, it *might* be useful \r\n    in classroom environment with PhD students, for an example.\r\n\r\nRationale and history\r\n=====================\r\n\r\nFMS was primarily developed for my own research projects. The idea came from many\r\nother agent based simulation programs, but the design was especially inspired by\r\nJulien Derveeuw thesis (in french) : Derveeuw J., Simulation multi-agents de\r\nmarch\u00e9s financiers, Universit\u00e9 des Sciences et Technologies de Lille, 2008 (see\r\nhttp://cisco.univ-lille1.fr/papers/ for more information). \r\n\r\nFMS is slightly different than Derveeuw's platform in some ways, mainly because\r\nFMS can simulate a multi-stages market, e.g. with a pre-opening period where\r\norders accumulate, then a fixing, then a continuous order driven market,\r\nstarting with the remaining orders after fixing. In addition, FMS is fully\r\nopen-source (as far as I know, Derveeuw's platform is freely usable, but sources\r\nare not available) and written in Python_, which (in my opinion) is easier to\r\nlearn than Java for researcher whose primary concern is finance, not computer\r\nprogramming.\r\n\r\n.. _Python: http://www.python.org/\r\n\r\nInstall or uninstall FMS\r\n========================\r\n\r\nSee INSTALL file.\r\n\r\nQuick start\r\n===========\r\n\r\nTo use FMS, you first need to install it on your system (obviously). Follow the\r\nINSTALL file instruction, and do not forget to run the tests once you are done.\r\n\r\nThen, you should describe an experiment for FMS to run. Experiments are\r\ndescribed in config file in the YAML_ format, which is hopefully rather easy to\r\nread and write. A minimal configuration file should contain three items with\r\ntheir required parameters: world, engines/markets, agents.\r\n\r\n.. _YAML: http://www.yaml.org/\r\n\r\nWorld\r\n-----\r\n\r\nThis is a \"global environment\" class, providing agents with so called exogenous\r\ninformation on request. Such information might typically be the level of\r\ninterest rates, or energy price, for an example. A NullWorld class is provided\r\nwith FMS, it does not provide any special information.\r\n\r\nEngines/markets\r\n---------------\r\n\r\nThe engines/markets tuples describe what you would simply call \"the market\" in\r\nthe real world. Engines are the \"traffic controlers\" : they give speak to the\r\nagents in a (simulated) synchronous or asynchronous manner, choosing which\r\nagents speak and when at will. For an example, FMS provides with an\r\nAsynchronousRandWReplace engine class, which is asynchronous (market clearing is\r\nrequired as soon as an agent spoke) and chooses agents randomly, with\r\nreplacement. Markets basically are responsible for recording the orders, and\r\ndoing the clearing (for an example, auction style \"fixing\" clearing once in a\r\nwhile, or continuous book based clearing). FMS provides with two basic market\r\nclasses, ContinuousOrderDriven and HighestQtyFixing.\r\n\r\nAgents\r\n------\r\n\r\nAgents act when the engines give them speak. Acting is either do nothing, or\r\nplace an order. Order should at least have a direction (buy or sell) but may in\r\naddition specify price and/or quantity. A ZeroIntelligenceTrader class is\r\nprovided: this agent takes fully random decisions.\r\n\r\nPutting it all together\r\n-----------------------\r\n\r\nOnce you have chosen or written your world, engines/markets and agents classes,\r\nyou describe those and their parameters in the experiment configuration file.\r\nExamples are provided in the docs/examples directory. The yaml syntax is\r\navailable on http://www.yaml.org/. Try with one of the example configuration\r\nfiles in ``docs/examples`` to begin with.\r\n\r\nChoose one of the examples, cd to the config file directory and run::\r\n\r\n\tstartfms.py -v check <config file name>\r\n\r\nThe ``check`` command is some sort of dry-run : it will perform anything except\r\nrunning the experiment itself. Thus, it will try to find, import and instanciate\r\nall the classes in your config file, which is probably the best way to check it.\r\nThe -v option is the verbose one, hopefully outputting clever error messages if\r\nsomething went wrong. If it went ok, then run::\r\n\r\n\tstartfms.py -v run <config file name>\r\n\r\nThis will really run the experiment, outputting transaction data either on the\r\nconsole or in a comma separated value file, depending on your configuration\r\nfile.\r\n\r\nWhat now ?\r\n==========\r\n\r\nIf you read all this, then you certainly have a good reason to use FMS. If the\r\nworld, engines, markets and agent classes included in FMS do not meet your\r\nneeds, then you may either write yours, or even (politely) require us to write\r\nit for you. Of course, your problem has to be interesting enough for us to do\r\nthis, and the resulting classes would be part of FMS next release. By the way,\r\nif you write yourself an interesting class for FMS, please submit it for\r\ninclusion (you would of course be credited for your work).\r\n\r\nHow could I contribute ?\r\n========================\r\n\r\nReport bugs, write new classes, translate documentation, write documentation and\r\nadditional example, request new features, watch or fork `the project`_, use FMS and\r\nlet people know you use it. Think of other ways to contribute. Thank you :)\r\n\r\n.. _the project: http://github.com/jcbagneris/fms/tree/master"}}, {"pk": 688, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "imposm.parser", "license": "Apache Software License 2.0", "author": "Oliver Tonnhofer", "author_email": "olt@omniscale.de", "project_url": null, "maintainer_email": null, "home_page": "http://dev.omniscale.net/imposm.parser/", "version": "1.0.2", "platform": "UNKNOWN", "keywords": null, "summary": "Fast and easy OpenStreetMap XML/PBF parser.", "classifiers": "Development Status :: 4 - Beta\nLicense :: OSI Approved :: Apache Software License\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries", "description": ".. # -*- restructuredtext -*-\n\nimposm.parser - OpenStreetMap XML/PBF parser for Python\n=======================================================\n\n``imposm.parser`` is a Python library that parses OpenStreetMap data in `XML <http://wiki.openstreetmap.org/wiki/.osm>`_ and `PBF <http://wiki.openstreetmap.org/wiki/PBF_Format>`_ format.\n\nIt has a simple API and it is fast and easy to use. It also works across multiple CPU/cores for extra speed.\n\nIt is developed and supported by `Omniscale <http://omniscale.com>`_ and released under the `Apache Software License 2.0 <http://www.apache.org/licenses/LICENSE-2.0>`_.\n\nExample\n-------\n\nHere is an example that parses an OSM file and counts all ways that are tagged as a highway.\n::\n\n  from imposm.parser import OSMParser\n\n  # simple class that handles the parsed OSM data.\n  class HighwayCounter(object):\n      highways = 0\n    \n      def ways(self, ways):\n          # callback method for ways\n          for osmid, tags, refs in ways:\n              if 'highway' in tags:\n                self.highways += 1\n\n  # instantiate counter and parser and start parsing\n  counter = HighwayCounter()\n  p = OSMParser(concurrency=4, ways_callback=counter.ways)\n  p.parse('germany.osm.pbf')\n  \n  # done\n  print counter.highways\n\n\nSource and issue tracker\n------------------------\n\nSource code and issue tracker are available at `<https://bitbucket.org/olt/imposm.parser/src>`_.\n\nChangelog\n---------\n\n1.0.2 2011-03-10\n~~~~~~~~~~~~~~~~\n\n- improved regexp based XML coord parser\n- prevent mmap overflow in XMLChunker without coord_callback\n- successfully parsed whole planet.osm\n\n1.0.0 2011-02-22\n~~~~~~~~~~~~~~~~\n\n- first release"}}, {"pk": 689, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "csc-pysparse", "license": "BSD-style", "author": "Rob Speer", "author_email": "rspeer@mit.edu", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/rspeer/csc-pysparse", "version": "1.1.1.4", "platform": "Windows,Linux,Solaris,Mac OS-X,Unix", "keywords": null, "summary": "A fast sparse matrix library for Python (Commonsense Computing version)", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "Pysparse is a fast sparse matrix library for Python. It provides several sparse\nmatrix storage formats and conversion methods. It also implements a number of\niterative solvers, preconditioners, and interfaces to efficient factorization\npackages. Both low-level and high-level interfaces are available, each with\ndifferent strengths.\n\nThis is not the official source to PySparse. This is csc-pysparse, a downstream\npackage maintained by the Commonsense Computing Group\n(http://csc.media.mit.edu) with the goal of making it install automatically\nthrough Pip or easy_install.\n\nOriginal authors of PySparse:\n\n- R. Geus    <hamsel@sf.net>\n- D. Orban   <d-orban@sf.net>\n- D. Wheeler <wd15@sf.net>\n\nPackaged by: Rob Speer <rspeer@mit.edu>"}}, {"pk": 690, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "graph-tool", "license": "", "author": "Tiago de Paula Peixoto", "author_email": "tiago@skewed.de", "project_url": null, "maintainer_email": "", "home_page": "http://graph-tool.skewed.de", "version": "2.2.11", "platform": "", "keywords": "graph, graph theory, network, science, math, physics", "summary": "An efficient python module for manipulation and statistical analysis of  graphs.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: POSIX :: Linux\nOperating System :: POSIX :: Other\nOperating System :: Unix\nProgramming Language :: C++\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.3\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics", "description": "graph-tool is an efficient python module for manipulation and statistical\r\nanalysis of graphs.\r\n\r\nDespite its nice, soft outer appearance of a regular python module, the core\r\nalgorithms and data structures of graph-tool are written in C++, making use of\r\nthe  Boost Graph Library and template metaprogramming, with performance in mind.\r\nMost of the time, you can expect the algorithms to run just as fast as if\r\ngraph-tool were a pure C++ library.\r\n\r\nIt contains several algorithms present in the Boost Graph Library, and many\r\nothers, such as random graph generation (with arbitrary degree sequence and\r\ncorrelations), clustering, motifs, community detection, graph randomization,\r\nsubgraph isomorphism, etc."}}, {"pk": 691, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pygts", "license": "GNU Library General Public License (LGPL) version 2 or higher", "author": "Thomas J. Duck", "author_email": "tom.duck@dal.ca", "project_url": null, "maintainer_email": null, "home_page": "http://pygts.sourceforge.net/", "version": "0.3.1", "platform": "Platform-Independent", "keywords": null, "summary": "PyGTS creates, manipulates and analyzes triangulated surfaces", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics :: 3D Modeling\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization", "description": "PyGTS is a python package that can be used to construct, \nmanipulate, and perform computations on 3D triangulated surfaces.  \nIt is a hand-crafted and \"pythonic\" binding for the GNU Triangulated \nSurface (GTS) Library."}}, {"pk": 692, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyamg", "license": "BSD", "author": "PyAMG Developers", "author_email": "wnbell@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/pyamg", "version": "1.0.0", "platform": "Windows,Linux,Solaris,Mac OS-X,Unix", "keywords": null, "summary": "PyAMG: Algebraic Multigrid Solvers in Python", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development", "description": "PyAMG is a library of Algebraic Multigrid (AMG) solvers \nwith a convenient Python interface."}}, {"pk": 693, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Enable", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/enable", "version": "3.4.1", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Drawing and interaction packages.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The Enable *project* provides two related multi-platform *packages* for drawing\nGUI objects.\n\n- **Enable**: An object drawing library that supports containment and event\n  notification.\n- **Kiva**: A multi-platform DisplayPDF vector drawing engine.\n\nEnable\n------\n\nThe Enable package is a multi-platform object drawing library built on top of\nKiva. The core of Enable is a container/component model for drawing and event\nnotification. The core concepts of Enable are:\n\n- Component\n- Container\n- Events (mouse, drag, and key events)\n\nEnable provides a high-level interface for creating GUI objects, while\nenabling a high level of control over user interaction. Enable is a supporting\ntechnology for the Chaco and BlockCanvas projects.\n\n\nKiva\n----\nKiva is a multi-platform DisplayPDF vector drawing engine that supports\nmultiple output backends, including Windows, GTK, and Macintosh native\nwindowing systems, a variety of raster image formats, PDF, and Postscript.\n\nDisplayPDF is more of a convention than an actual specification. It is a\npath-based drawing API based on a subset of the Adobe PDF specification.\nBesides basic vector drawing concepts such as paths, rects, line sytles, and\nthe graphics state stack, it also supports pattern fills, antialiasing, and\ntransparency. Perhaps the most popular implementation of DisplayPDF is\nApple's Quartz 2-D graphics API in Mac OS X.\n\nKiva Features\n`````````````\nKiva currently implements the following features:\n\n- paths and compiled paths; arcs, bezier curves, rectangles\n- graphics state stack\n- clip stack, disjoint rectangular clip regions\n- raster image blitting\n- arbitrary affine transforms of the graphics context\n- bevelled and mitered joins\n- line width, line dash\n- Freetype or native fonts\n- RGB, RGBA, or grayscale color depths\n- transparency\n\nPrerequisites\n-------------\n\nYou must have the following libraries installed before building or installing\nthe Enable project:\n\n* `setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_\n* `SWIG <http://www.swig.org/>`_ version 1.3.30 or later.\n* `Cython <http://www.cython.org>`_ version 0.13 or later\n* `Numpy <http://pypi.python.org/pypi/numpy/1.3.1>`_  version 1.3.1\n* `ReportLab Toolkit <http://www.reportlab.org/rl_toolkit.html/>`_ for PDF\n  backend support in Kiva."}}, {"pk": 694, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.math", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.math", "version": "3.0.5", "platform": "any", "keywords": "utility", "summary": "PyUtilib math utilities.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "====================\npyutilib.math README\n====================\n\nThis Python package includes math utilities.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 695, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "NZMATH", "license": "UNKNOWN", "author": "NZMATH development group", "author_email": "nzmath-user@tnt.math.se.tmu.ac.jp", "project_url": null, "maintainer_email": "", "home_page": "http://tnt.math.se.tmu.ac.jp/nzmath/", "version": "1.0.1", "platform": "UNKNOWN", "keywords": "number theory, mathematics", "summary": "number theory oriented calculation system", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: Mathematics", "description": "UNKNOWN"}}, {"pk": 696, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PyCifRW", "license": "UNKNOWN", "author": "James Hester", "author_email": "jamesrhester at gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pycifrw.berlios.de", "version": "3.3", "platform": "UNKNOWN", "keywords": "", "summary": "CIF/STAR file support for Python", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Software Development :: Libraries :: Python Modules", "description": "UNKNOWN"}}, {"pk": 697, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "munkres", "license": "BSD-style license", "author": "Brian Clapper", "author_email": "bmc@clapper.org", "project_url": null, "maintainer_email": null, "home_page": "http://bmc.github.com/munkres/", "version": "1.0.5.4", "platform": "UNKNOWN", "keywords": null, "summary": "munkres algorithm for the Assignment Problem", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Introduction\n============\n\nThe Munkres module provides an implementation of the Munkres algorithm\n(also called the Hungarian algorithm or the Kuhn-Munkres algorithm),\nuseful for solving the Assignment Problem.\n\nAssignment Problem\n==================\n\nLet *C* be an *n*\\ x\\ *n* matrix representing the costs of each of *n* workers\nto perform any of *n* jobs. The assignment problem is to assign jobs to\nworkers in a way that minimizes the total cost. Since each worker can perform\nonly one job and each job can be assigned to only one worker the assignments\nrepresent an independent set of the matrix *C*.\n\nOne way to generate the optimal set is to create all permutations of\nthe indexes necessary to traverse the matrix so that no row and column\nare used more than once. For instance, given this matrix (expressed in\nPython)::\n\n    matrix = [[5, 9, 1],\n              [10, 3, 2],\n              [8, 7, 4]]\n\nYou could use this code to generate the traversal indexes::\n\n    def permute(a, results):\n        if len(a) == 1:\n            results.insert(len(results), a)\n\n        else:\n            for i in range(0, len(a)):\n                element = a[i]\n                a_copy = [a[j] for j in range(0, len(a)) if j != i]\n                subresults = []\n                permute(a_copy, subresults)\n                for subresult in subresults:\n                    result = [element] + subresult\n                    results.insert(len(results), result)\n\n    results = []\n    permute(range(len(matrix)), results) # [0, 1, 2] for a 3x3 matrix\n\nAfter the call to permute(), the results matrix would look like this::\n\n    [[0, 1, 2],\n     [0, 2, 1],\n     [1, 0, 2],\n     [1, 2, 0],\n     [2, 0, 1],\n     [2, 1, 0]]\n\nYou could then use that index matrix to loop over the original cost matrix\nand calculate the smallest cost of the combinations::\n\n    n = len(matrix)\n    minval = sys.maxint\n    for row in range(n):\n        cost = 0\n        for col in range(n):\n            cost += matrix[row][col]\n        minval = min(cost, minval)\n\n    print minval\n\nWhile this approach works fine for small matrices, it does not scale. It\nexecutes in O(*n*!) time: Calculating the permutations for an *n*\\ x\\ *n*\nmatrix requires *n*! operations. For a 12x12 matrix, that's 479,001,600\ntraversals. Even if you could manage to perform each traversal in just one\nmillisecond, it would still take more than 133 hours to perform the entire\ntraversal. A 20x20 matrix would take 2,432,902,008,176,640,000 operations. At\nan optimistic millisecond per operation, that's more than 77 million years.\n\nThe Munkres algorithm runs in O(*n*\\ ^3) time, rather than O(*n*!). This\npackage provides an implementation of that algorithm.\n\nThis version is based on\nhttp://www.public.iastate.edu/~ddoty/HungarianAlgorithm.html.\n\nThis version was written for Python by Brian Clapper from the (Ada) algorithm\nat the above web site. (The ``Algorithm::Munkres`` Perl version, in CPAN, was\nclearly adapted from the same web site.)\n\nUsage\n=====\n\nConstruct a Munkres object::\n\n    from munkres import Munkres\n\n    m = Munkres()\n\nThen use it to compute the lowest cost assignment from a cost matrix. Here's\na sample program::\n\n    from munkres import Munkres, print_matrix\n\n    matrix = [[5, 9, 1],\n              [10, 3, 2],\n              [8, 7, 4]]\n    m = Munkres()\n    indexes = m.compute(matrix)\n    print_matrix(matrix, msg='Lowest cost through this matrix:')\n    total = 0\n    for row, column in indexes:\n        value = matrix[row][column]\n        total += value\n        print '(%d, %d) -> %d' % (row, column, value)\n    print 'total cost: %d' % total\n\nRunning that program produces::\n\n    Lowest cost through this matrix:\n    [5, 9, 1]\n    [10, 3, 2]\n    [8, 7, 4]\n    (0, 0) -> 5\n    (1, 1) -> 3\n    (2, 2) -> 4\n    total cost=12\n\nThe instantiated Munkres object can be used multiple times on different\nmatrices.\n\nNon-square Cost Matrices\n========================\n\nThe Munkres algorithm assumes that the cost matrix is square. However, it's\npossible to use a rectangular matrix if you first pad it with 0 values to make\nit square. This module automatically pads rectangular cost matrices to make\nthem square.\n\nNotes:\n\n- The module operates on a *copy* of the caller's matrix, so any padding will\n  not be seen by the caller.\n- The cost matrix must be rectangular or square. An irregular matrix will\n  *not* work.\n\nCalculating Profit, Rather than Cost\n====================================\n\nThe cost matrix is just that: A cost matrix. The Munkres algorithm finds\nthe combination of elements (one from each row and column) that results in\nthe smallest cost. It's also possible to use the algorithm to maximize\nprofit. To do that, however, you have to convert your profit matrix to a\ncost matrix. The simplest way to do that is to subtract all elements from a\nlarge value. For example::\n\n    from munkres import Munkres, print_matrix\n\n    matrix = [[5, 9, 1],\n              [10, 3, 2],\n              [8, 7, 4]]\n    cost_matrix = []\n    for row in matrix:\n        cost_row = []\n        for col in row:\n            cost_row += [sys.maxint - col]\n        cost_matrix += [cost_row]\n\n    m = Munkres()\n    indexes = m.compute(cost_matrix)\n    print_matrix(matrix, msg='Highest profit through this matrix:')\n    total = 0\n    for row, column in indexes:\n        value = matrix[row][column]\n        total += value\n        print '(%d, %d) -> %d' % (row, column, value)\n\n    print 'total profit=%d' % total\n\nRunning that program produces::\n\n    Highest profit through this matrix:\n    [5, 9, 1]\n    [10, 3, 2]\n    [8, 7, 4]\n    (0, 1) -> 9\n    (1, 0) -> 10\n    (2, 2) -> 4\n    total profit=23\n\nThe ``munkres`` module provides a convenience method for creating a cost\nmatrix from a profit matrix. Since it doesn't know whether the matrix contains\nfloating point numbers, decimals, or integers, you have to provide the\nconversion function; but the convenience method takes care of the actual\ncreation of the cost matrix::\n\n    import munkres\n\n    cost_matrix = munkres.make_cost_matrix(matrix,\n                                           lambda cost: sys.maxint - cost)\n\nSo, the above profit-calculation program can be recast as::\n\n    from munkres import Munkres, print_matrix, make_cost_matrix\n\n    matrix = [[5, 9, 1],\n              [10, 3, 2],\n              [8, 7, 4]]\n    cost_matrix = make_cost_matrix(matrix, lambda cost: sys.maxint - cost)\n    m = Munkres()\n    indexes = m.compute(cost_matrix)\n    print_matrix(matrix, msg='Lowest cost through this matrix:')\n    total = 0\n    for row, column in indexes:\n        value = matrix[row][column]\n        total += value\n        print '(%d, %d) -> %d' % (row, column, value)\n    print 'total profit=%d' % total\n\nReferences\n==========\n\n1. http://www.public.iastate.edu/~ddoty/HungarianAlgorithm.html\n\n2. Harold W. Kuhn. The Hungarian Method for the assignment problem.\n   *Naval Research Logistics Quarterly*, 2:83-97, 1955.\n\n3. Harold W. Kuhn. Variants of the Hungarian method for assignment\n   problems. *Naval Research Logistics Quarterly*, 3: 253-258, 1956.\n\n4. Munkres, J. Algorithms for the Assignment and Transportation Problems.\n   *Journal of the Society of Industrial and Applied Mathematics*,\n   5(1):32-38, March, 1957.\n\n5. http://en.wikipedia.org/wiki/Hungarian_algorithm\n\nCopyright and License\n=====================\n\nThis software is released under a BSD license, adapted from\n<http://opensource.org/licenses/bsd-license.php>\n\nCopyright (c) 2008 Brian M. Clapper\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice,\n  this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name \"clapper.org\" nor the names of its contributors may be\n  used to endorse or promote products derived from this software without\n  specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE."}}, {"pk": 698, "model": "importing.pypicache", "fields": {"maintainer": "Ray Buvel", "name": "EphemPy", "license": "MIT", "author": "Ray Buvel", "author_email": "rlbuvel@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "", "version": "1.3", "platform": "", "keywords": "ephemeris", "summary": "Python tools for working with the JPL ephemeris files.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy", "description": "Version 1.3 corrects some issues that prevented the extension module from\r\nworking on 64-bit systems."}}, {"pk": 699, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyDAQmx", "license": "This software can be used under one of the following two licenses: (1) The BSD license. (2) Any other license, as long as it is obtained from the original author.", "author": "Pierre Clad\u00e9", "author_email": "pierre.clade@spectro.jussieu.fr", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/PyDAQmx/", "version": "1.2.0", "platform": "UNKNOWN", "keywords": "DAQmx,National Instrument,Data Acquisition,nidaq,nidaqmx", "summary": "Interface to the National Instrument PyDAQmx driver", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Overview\n========\n\nThis package allows users to use data acquisition hardware from `National \nInstrument`_ with python. It makes an interface between the NIDAQmx driver \nand python. It currently works only on Windows.\n\nThe package is not an open source driver from NI acquisition hardware. You first need to install the driver provided by NI\n\nCompare to similar package, the PyDAQmx module is a full interface to\nthe NIDAQmx ansi C driver. It imports all the functions from the\ndriver and also imports all the predefined constants. This provided an\nalmost one to one match between C and python code. Examples using\ncallback functions are provided.\n\nA more convenient Object oriented interface is provided, where the mecanism \nof taskHandle in C is replace with a Task object.\n\n**Detailed information** about this package can be found on its `main\nwebsite`_.\n\n\n\nInstallation\n============\n\nYou need first to install the NI DAQmx driver which is provided with your \ndata-acquisition hardware. Please verify that you have install together with \nthe driver the C API (which should be the case by default). \n\nTo install PyDAQmx, download the package and run the command:: \n\n  python setup.py install\n\nYou can also directly move the PyDAQmx directory to a location\nthat Python can import from (directory in which scripts \nusing PyDAQmx are run, etc.)\n\nContact\n=======\n\nPlease send bug reports or feedback to `Pierre Clad\u00e9`_.\n\nVersion history\n===============\nMain changes:\n\n* 1.2 Support of callback function\n* 1.1 Add linux support\n\n\n.. _National Instrument: http://www.ni.com\n.. _Pierre Clad\u00e9: mailto:pierre.clade@spectro.jussieu.fr\n.. _main website: http://packages.python.org/PyDAQmx/"}}, {"pk": 700, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyQuante", "license": "BSD", "author": "Rick Muller", "author_email": "rmuller@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "http://pyquante.sourceforge.net", "version": "1.5.0", "platform": "any", "keywords": null, "summary": "PyQuante: Quantum Chemistry in Python", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "PyQuante is an open-source suite of programs\n        for developing quantum chemistry methods. The program is written in\n        the Python programming language, and has many 'rate-determining' modules\n        also written in C for speed. The resulting code is not nearly as fast as\n        Jaguar, Gaussian, or GAMESS, but the resulting code is much easier to\n        understand and modify. The goal of this software is not necessarily to\n        provide a working quantum chemistry program (although it will hopefully\n        do that), but rather to provide a well-engineered set of tools so that\n        scientists can construct their own quantum chemistry programs without\n        going through the tedium of having to write every low-level routine. More\n        information, including links to the download page, is available at\n        http://pyquante.sourceforge.net."}}, {"pk": 701, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PhyloSequel", "license": "LGPL 3+", "author": "Jeet Sukumaran", "author_email": "jeetsukumaran@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://jeetworks.org/", "version": "0.0.2", "platform": "UNKNOWN", "keywords": "phylogenetics evolution biology SQL database", "summary": "Toolkit and library for BioSQL database interaction and operations.", "classifiers": "Environment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Front-Ends\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "Simple wrappers to facilitate the import and export of phylogenetic data\nto and from files and a BioSQL database,"}}, {"pk": 702, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyTAPS", "license": "UNKNOWN", "author": "Jim Porter", "author_email": "jvporter@wisc.edu", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/PyTAPS/", "version": "1.2", "platform": "UNKNOWN", "keywords": null, "summary": "Python bindings for ITAPS interfaces", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nTopic :: Scientific/Engineering", "description": ".. PyTAPS\n   Jim Porter, <jvporter -at- wisc.edu>\n   Revision 1.2, March 25, 2011\n\nInstallation\n============\n\nPyTAPS requires the following to be installed on your system:\n\n* Python 2.5+\n* `NumPy <http://numpy.scipy.org/>`_ 1.3.0+\n* At least one of...\n\n  * `MOAB <http://trac.mcs.anl.gov/projects/ITAPS/wiki/MOAB>`_ (or other iMesh\n    interface)\n  * `CGM <http://trac.mcs.anl.gov/projects/ITAPS/wiki/CGM>`_ (or other iGeom\n    interface)\n  * `Lasso <http://trac.mcs.anl.gov/projects/ITAPS/wiki/Lasso>`_ (or other iRel\n    interface)\n\nOnce you have the prerequisites, the easiest way to install PyTAPS is to use\n`Pip <http://pypi.python.org/pypi/pip>`_ (0.7+ recommended)::\n\n  pip install pytaps\n\nThis will download, compile, and install PyTAPS automatically. If you have some\nbut not all of the ITAPS interfaces (e.g. only iMesh), this will only install\ninterfaces for the libraries you have, as described in `Autodetection of\nLibraries`_.\n\nBuilding Manually\n-----------------\n\nLike many Python packages, PyTAPS uses Setuptools for installation, so in\ngeneral setup consists simply of downloading the tarball, extracting it, and\ntyping ``python setup.py install`` inside the extracted directory. However,\ncertain ITAPS interfaces may require some additional setup.\n\nAutodetection of Libraries\n__________________________\n\nThe PyTAPS setup script supports importing definitions from the\n`iXxx-Defs.inc` files, where `iXxx` is the name of the interface. PyTAPS will\nattempt to find these files automatically, by searching in some common\nlocations:\n\n#. The files specified in the environment variables ``IXXX_DEFS``\n#. For each directory `dir` in the environment variables ``PATH`` and\n   ``CPATH``, look in `dir/../lib`\n#. Each directory in the environment variable ``LD_LIBRARY_PATH``\n#. `/usr/local/lib`\n#. `/usr/lib`\n\nIf the PyTAPS setup script cannot find the `iXxx-Defs.inc` file, it will\nassume you do not have that interface installed and automatically disable it in\nPyTAPS.\n\nIf you have the `iXxx-Defs.inc` files installed but not in any of the above\nlocations, you can specify where they are in the global command-line options\n``--iXxx-path=PATH``, like so::\n\n  python setup.py --iMesh-path=PATH install\n\nUsage\n=====\n\nThe following example illustrates the basics of using iMesh. This script gets\nall the faces of a mesh and prints out the coordinates of their vertices::\n\n  from itaps import iBase, iMesh\n\n  mesh = iMesh.Mesh()\n  mesh.load(\"mesh.vtk\")\n\n  faces = mesh.getEntities()\n  adj = mesh.getEntAdj(faces, iBase.Type.vertex)\n\n  for i in adj:\n      for j in i:\n          x, y, z = mesh.getVtxCoords(j)\n          print \"%f, %f, %f\" % (x, y, z)\n      print\n\nTesting\n=======\n\nBasic tests of the interfaces are located in test/. To run all tests, run\n``python setup.py test``."}}, {"pk": 703, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "obspy.sh", "license": "GNU Lesser General Public License, Version 3 (LGPLv3)", "author": "The ObsPy Development Team", "author_email": "devs@obspy.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.obspy.org", "version": "0.4.7", "platform": "OS Independent", "keywords": "ObsPy,seismology,seismogram,ASC,Q,Seismic Handler", "summary": "Q and ASC (Seismic Handler) read and write support for ObsPy.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Physics", "description": "The obspy.sh package contains methods in order to read and write seismogram\nfiles in the Q and ASC format used by the Seismic Handler software package\n(http://www.seismic-handler.org).\n\nObsPy is an open-source project dedicated to provide a Python framework for\nprocessing seismological data. It provides parsers for common file formats and\nseismological signal processing routines which allow the manipulation of\nseismological time series (see  Beyreuther et. al. 2010). The goal of the ObsPy\nproject is to facilitate rapid application development for seismology. \n\nFor more information visit http://www.obspy.org.\n\n:copyright:\n    The ObsPy Development Team (devs@obspy.org)\n:license:\n    GNU Lesser General Public License, Version 3\n    (http://www.gnu.org/copyleft/lesser.html)"}}, {"pk": 704, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gmisclib", "license": "GPL2", "author": "Greg Kochanski", "author_email": "gpk@kochanski.org", "project_url": null, "maintainer_email": null, "home_page": "http://kochanski.org/gpk/code/speechresearch/gmisclib", "version": "0.69.0", "platform": "All", "keywords": "phonetics speech computational linguistics basic library python science optimize", "summary": "Various Python Libraries, mostly scientific purposes", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "Various Python Libraries, mostly scientific purposes.\n\tSee http://kochanski.plus.com/code/speechresearch/gmisclib for documentation\n\tand http://sourceforge.net/projects/speechresearch for downloads,\n\tor look on the Python Cheese shop, http://pypi.python.org .\n\n\tNote that most of the algorithms here are carefully tested, but the stuff that\n\tI don't use may have suffered from bit rot."}}, {"pk": 705, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydicom", "license": "MIT license", "author": "Darcy Mason", "author_email": "darcymason@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pydicom.googlecode.com", "version": "0.9.5", "platform": "UNKNOWN", "keywords": "dicom python medical imaging", "summary": "Pure python package for DICOM medical file reading and writing", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: Medical Science Apps.\nTopic :: Scientific/Engineering :: Physics\nTopic :: Software Development :: Libraries", "description": "pydicom is a pure python package for parsing DICOM files. \n      DICOM is a standard (http://medical.nema.org) for communicating \n      medical images and related information such as reports \n      and radiotherapy objects. \n      \n      pydicom makes it easy to read these complex files into natural \n      pythonic structures for easy manipulation. \n      Modified datasets can be written again to DICOM format files.\n      See the `Getting Started <http://code.google.com/p/pydicom/wiki/GettingStarted>`_ \n      wiki page for installation and basic information, and the \n      `Pydicom User Guide <http://code.google.com/p/pydicom/wiki/PydicomUserGuide>`_ page \n      for an overview of how to use the pydicom library."}}, {"pk": 706, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PyGouda", "license": "MIT", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/pycuda", "version": "1.0", "platform": "UNKNOWN", "keywords": null, "summary": "The EasyCheese of GPU programming", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries\nTopic :: Utilities", "description": "Maybe you were looking for our newest `top seller <http://pypi.python.org/pypi/pycuda>`_\n      in the `cheese shop <http://pypi.python.org/pypi>`_?"}}, {"pk": 707, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "anfft", "license": "UNKNOWN", "author": "Andrew Collette", "author_email": "andrew dot collette at gmail dot com", "project_url": null, "maintainer_email": null, "home_page": "http://anfft.googlecode.com", "version": "0.1", "platform": "UNKNOWN", "keywords": null, "summary": "A fast FFT package for Python, based on FFTW", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: Linux\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "ANFFT is an FFT package for Python, based on FFTW.  It provides a\nmulti-threaded, self-tuning FFT interface via high-level functions\nsimilar to the \"fft\" and \"fftn\" routines found in NumPy and SciPy.\n\nANFFT is intended to be used in situations where large numbers of expensive\nFFTs are required, for which the built-in NumPy or SciPy FFTs are not\nacceptable. By default, ANFFT provides immediate results by using\nFFTW's \"estimate\" mode, which does not require tuning.  However, each\nhigh-level function provides a keyword named \"measure\" which will invoke the\nfull FFTW planning machinery.  Plans for a given shape and type of array\nare cached for the length of a Python session, and accummulated FFTW \"wisdom\"\nis stored across Python sessions in a dotfile.  You don't need to know anything\nabout FFTW internals to use ANFFT."}}, {"pk": 708, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pykml", "license": "BSD", "author": "Tyler Erickson", "author_email": "tylerickson@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://pypi.python.org/pypi/pykml", "version": "0.0.3", "platform": "UNKNOWN", "keywords": "kml", "summary": "Python KML library", "classifiers": "Development Status :: 2 - Pre-Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics :: Viewers\nTopic :: Scientific/Engineering :: GIS\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": "=========\r\n        PyKML\r\n        =========\r\n        PyKML is a Python package for parsing and authoring KML documents. It is based\r\n        on the lxml.objectify API (http://codespeak.net/lxml/objectify.html) which\r\n        provides Pythonic access to XML documents.\r\n        \r\n        ------------\r\n        Dependencies\r\n        ------------\r\n        * lxml (`instructions for installing lxml`_)\r\n        \r\n        ..  _`instructions for installing lxml`: http://codespeak.net/lxml/installation.html\r\n        \r\n        To verify that the lxml library has been installed correctly, open up a Python\r\n        shell and type:\r\n        \r\n        >>> import lxml\r\n        >>>\r\n        \r\n        ------------\r\n        Installation\r\n        ------------\r\n        PyKML can be installed from the Python Package Index, using either easy_install\r\n        or pip:\r\n        \r\n          $ sudo easy_install pykml\r\n          \r\n        or\r\n        \r\n          $ sudo pip install pykml\r\n        \r\n        The installation can be tested by running the following:\r\n        \r\n          $ nosetests -s --with-coverage\r\n        \r\n        ------\r\n        Usage\r\n        ------\r\n        \r\n        KML documents can be constructed by using element factory objects.  The\r\n        following example uses two factory objects, corresponding to the OGC KML and\r\n        ATOM namespaces:\r\n        \r\n        >>> from pykml.factory import KML_ElementMaker as K\r\n        >>> from pykml.factory import ATOM_ElementMaker as ATOM\r\n        >>> doc = K.kml(\r\n        ...         K.Document(\r\n        ...           ATOM.author(\r\n        ...             ATOM.name(\"J. K. Rowling\")\r\n        ...           ),\r\n        ...           ATOM.link(href=\"http://www.harrypotter.com\"),\r\n        ...           K.Placemark(\r\n        ...             K.name(\"Hogwarts\"),\r\n        ...             K.Point(\r\n        ...               K.coordinates(\"1,1\")\r\n        ...             )\r\n        ...           )\r\n        ...         )\r\n        ...       )\r\n        \r\n        Constructed documents can be converted to a string representation:\r\n        \r\n        >>> from lxml import etree\r\n        >>> etree.tostring(doc)\r\n        \r\n        And can be validated against the official KML XML Schema: \r\n        \r\n        >>> from pykml.parser import Schema\r\n        >>> print Schema('ogckml22.xsd').validate(doc)\r\n        \r\n        Existing KML documents can also be parsed:\r\n        \r\n        >>> import urllib2\r\n        >>> from pykml.parser import parse\r\n        >>> url = 'http://code.google.com/apis/kml/documentation/KML_Samples.kml'\r\n        >>> fileobject = urllib2.urlopen(url)\r\n        >>> doc = parse(fileobject, schema=Schema('ogckml22.xsd'))\r\n        \r\n        Documents that make use of the Google Extension namespace elements can be \r\n        created and validate using the Google Extensions schema:\r\n        \r\n        >>> from pykml.factory import Schema\r\n        >>> from pykml.factory import KML_ElementMaker as K\r\n        >>> from pykml.factory import ATOM_ElementMaker as ATOM\r\n        >>> from pykml.factory import GX_ElementMaker as GX\r\n        >>> schema = Schema('kml22gx.xsd')\r\n        >>> doc = K.kml(\r\n        ...       GX.Tour(\r\n        ...         GX.Playlist(\r\n        ...           GX.SoundCue(\r\n        ...             K.href(\"http://dev.keyhole.com/codesite/cntowerfacts.mp3\")\r\n        ...           ),\r\n        ...           GX.Wait(\r\n        ...             GX.duration(10)\r\n        ...           ),\r\n        ...           GX.FlyTo(\r\n        ...             GX.duration(5),\r\n        ...             GX.flyToMode(\"bounce\"),\r\n        ...             K.LookAt(\r\n        ...               K.longitude(-79.387),\r\n        ...               K.latitude(43.643),\r\n        ...               K.altitude(0),\r\n        ...               K.heading(-172.3),\r\n        ...               K.tilt(10),\r\n        ...               K.range(1200),\r\n        ...               K.altitudeMode(\"relativeToGround\"),\r\n        ...             )\r\n        ...           )\r\n        ...         )\r\n        ...       )\r\n        ... )\r\n        >>> print schema.validate(doc)"}}, {"pk": 709, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "oldowan.polymorphism", "license": "MIT", "author": "Ryan Raaum", "author_email": "code@raaum.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.raaum.org/software/oldowan", "version": "1.0.1", "platform": "Any", "keywords": "", "summary": "Utilities for the management of molecular polymorphism data.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "oldowan.polymorphism is a small bioinformatic utility for the management\nof molecular polymorphism data.\n\nInstallation Instructions\n=========================\n\nThis package is pure Python and has no dependencies outside of the standard\nlibrary. The easist way to install is using ``easy_install`` from the\nsetuptools_ package.  This usually goes something like this::\n\n\t$ easy_install oldowan.polymorphism\n\nor on a unix-like system, assuming you are installing to the main Python\n``site-packages`` directory as a non-privileged user, this::\n\n\t$ sudo easy_install oldowan.polymorphism\n\nYou may also use the standard python distutils setup method. Download the\ncurrent source archive from the file list towards the bottom of this page,\nunarchive it, and install. On Mac OS X and many other unix-like systems, having\ndownloaded the archive and changed to the directory containing this archive in\nyour shell, this might go something like::\n\n\t$ tar xvzf oldowan.polymorphism*\n\t$ cd oldowan.polymorphism*\n\t$ python setup.py install\n\nQuick Start\n===========\n\nThis package provides a single utility class, ``Polymorphism``. Import\nthis class from oldowan.polymorphism::\n\n  >>> from oldowan.polymorphism import Polymorphism\n\nCreate a new Polymorphism object::\n\n  >>> p1 = Polymorphism(16223,0,'A','T')\n\nThe Polymorphism constructor requires 3 arguments and accepts and optional\nfourth argument. These are (in order):\n\n  1. ``position``, integer.  \n  2. ``insert``, 0 if polymorphism is exactly at that position, or 1,2,3,... if\n     insertion after.  \n  3. ``value``, character value of polymorphism \n  4. ``reference``, optional value of a reference sequence at that position\n\n\nRelease History\n===============\n\n1.0.0 (March 25, 2009)\n    initial release of module.\n\n1.0.1 (March 25, 2009)\n    minor update for correct version numbering\n\n.. _setuptools: http://peak.telecommunity.com/DevCenter/EasyInstall"}}, {"pk": 710, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "IntPy", "license": "GPL", "author": "Rafael Menezes Barreto", "author_email": "rmb3@cin.ufpe.br, rafaelbarreto87@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://code.google.com/p/intpy/", "version": "0.1.3", "platform": "Windows,Linux", "keywords": "", "summary": "Interval Arithmetic package", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nTopic :: Scientific/Engineering :: Mathematics", "description": "This package provides types and functions for Maximum Accuracy Interval\nArithmetic.\n\nThe Interval Arithmetic is a mathematical tool for the solution of problems\nrelated to numerical errors, based on an algebraic system formed by all closed\nintervals of Real Line (or rectangles of Complex Plane) and operations defined\non it. Rather than usual numerical algorithms, it's used interval algorithms\nproducing intervals containing the correct answer as a result.\n\nThe Maximum Accuracy, on the other hand, provides an axiomatic method for\narithmetic operations performed in computers that capture essential properties\nassociated with rounding.\n\nFor more information about it, see:\n\n[1] Moore, R. E., Interval Analysis. Prentice-Hall, Englewood Cliffs, New\n    Jersey, 1966.\n[2] Moore, R. E., Methods and Applications of Interval Analysis. SIAM Studies\n    in Applied Mathematics, Philadelphia, 1979.\n[3] Kulisch, U. W., Miranker, W. L., Computer Arithmetic in Theory and\n    Practice. Academic Press, 1981.\n\nCurrently only Real Intervals are available. No Complex Intervals, no Interval\nVectors and Matrixes, and no extensions of basic functions. These will be our\nnext work.\n\nIt was developed in CIn/UFPE (Brazil) by Rafael Menezes Barreto\n<rmb3@cin.ufpe.br, rafaelbarreto87@gmail.com> and it's free software."}}, {"pk": 711, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "myhdl", "license": "LGPL", "author": "Jan Decaluwe", "author_email": "jan@jandecaluwe.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.myhdl.org", "version": "0.7", "platform": "Any", "keywords": "HDL ASIC FPGA hardware design", "summary": "Python as a Hardware Description Language", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Electronic Design Automation (EDA)", "description": "See home page."}}, {"pk": 712, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "htmlserver", "license": "gpl", "author": "kai zhu", "author_email": "kaizhu256@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/htmlserver", "version": "2010.02.07.appengine", "platform": "UNKNOWN", "keywords": null, "summary": "DESCRIPTION: htmlserver - google appengine for python3.1", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: C++\nProgramming Language :: Python\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.1\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development\nTopic :: Software Development :: Code Generators\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "DESCRIPTION: htmlserver - google appengine for python3.1\n\n  REQUIRES: LINUX OS AND PYTHON3.1\n\n  QUICK TEST: $ python3.1 setup.py build dev --quicktest\n\n  SUMMARY:\n    1 contains py3to2 script converter - converts python3.1 scripts to python2.5 by reverse compiling the ast\n    2 runs on top of google appengine\n    3 is file-less by design\n      webpages are dynamically served by tree-based objects in memory instead of physical files on disk\n      other than png/jpg/media files, htmlserver maintains a website with just two files:\n        1 main.py - python3.1 script containing url request handlers\n        2 index.html - html code repository\n    4 example site: http://kai-zhu.appspot.com\n  \nRECENT CHANGELOG:\n  20100206 - added htmlserver\n  20100121 - added ast2src\n  20091231 - added <<<< and >>>> sugar\n  20091224 - added pseudomethod interactive console - revamped pseudomethod import hook\n  20091224 - modularized package - fix install issues - added sdist check\n  20091209 - improved documentation\n  20091205 - moved source code to c++\n  20091116 - package integrated\n\nDEMO USAGE:\n\n  PseudoSugar - adding hook <htmlserver.PseudoSugar object at 0x8a40a6c> to sys.meta_path\n\n$ python3.1 setup.py htmlserver --name=htmlserver\nPseudoSugar - adding hook <htmlserver.PseudoSugar object at 0x8f1ab2c> to sys.meta_path\n\nrunning htmlserver\nPython 2.5.2\nINFO     2010-02-08 16:50:59,019 appengine_rpc.py:157] Server: appengine.google.com\nINFO     2010-02-08 16:50:59,026 appcfg.py:348] Checking for updates to the SDK.\nINFO     2010-02-08 16:50:59,281 appcfg.py:362] The SDK is up to date.\nINFO     2010-02-08 16:50:59,381 dev_appserver_main.py:399] Running application htmlserver on port 8080: http://localhost:8080\nINFO     2010-02-08 16:50:59,615 dev_appserver_main.py:404] Server interrupted by user, terminating\ntouch index2.html"}}, {"pk": 713, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pydt", "license": "UNKNOWN", "author": "Angel Yanguas-Gil", "author_email": "angel.yanguas@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "UNKNOWN", "version": "0.1.0", "platform": "UNKNOWN", "keywords": "", "summary": "utilities for managing numerical data files", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Console\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "UNKNOWN"}}, {"pk": 714, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "edrnsite.calendar", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/edrnsite-calendar", "version": "0.0.0", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers calendar", "summary": "EDRN Site Calendar", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Office/Business :: Scheduling\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "*****************\nedrnsite.calendar\n*****************\n\nThis product, ``edrnsite.calendar``, provides calendaring features for the\nEarly Detection Research Network's public portal (EDRN_).  Although intended\nfor the EDRN public portal, it can be installed in any Plone_ 3 (or later)\nsite.  It was developed by the Informatics Center (IC_), operated by JPL_.\n\n.. References:\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _IC: http://cancer.jpl.nasa.gov/\n.. _JPL: http://www.jpl.nasa.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``edrnsite.calendar`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        edrnsite.calendar\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        edrnsite.calendar\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 715, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pymorphy", "license": "MIT license", "author": "Mikhail Korobov", "author_email": "kmike84@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/kmike/pymorphy/", "version": "0.5.1", "platform": "UNKNOWN", "keywords": null, "summary": "Morphological analyzer for Russian and English (+perhaps German) languages.", "classifiers": "Development Status :: 3 - Alpha\nFramework :: Django\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nNatural Language :: German\nNatural Language :: Russian\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Linguistic", "description": "Morphological analyzer for Russian and English languages\nusing converted AOT (http://www.aot.ru/download.php) dictionaries.\n\nDocumentation (mostly in Russian) can be found here: http://packages.python.org/pymorphy/\n\nAuthor:  Mikhail Korobov <kmike84@gmail.com>\nLicense: MIT\n\n=============\n\n\u041c\u043e\u0440\u0444\u043e\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0430\u043d\u0430\u043b\u0438\u0437\u0430\u0442\u043e\u0440 \u0434\u043b\u044f \u0440\u0443\u0441\u0441\u043a\u043e\u0433\u043e \u0438 \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u043e\u0433\u043e\n(\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u0435\u0449\u0435 \u043d\u0435\u043c\u0435\u0446\u043a\u043e\u0433\u043e) \u044f\u0437\u044b\u043a\u0430.\n\n\u0412\u0441\u044f \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0442\u0443\u0442: http://packages.python.org/pymorphy/\n\n\u0418\u0441\u0442\u043e\u0440\u0438\u044f \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0439\n=================\n\n0.5.1 (2011-02-10)\n------------------\n* Sqlite-\u0431\u044d\u043a\u0435\u043d\u0434 \u0442\u0435\u043f\u0435\u0440\u044c \u0434\u043e\u043b\u0436\u0435\u043d \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0432 \u043c\u043d\u043e\u0433\u043e\u043f\u043e\u0442\u043e\u0447\u043d\u043e\u043c \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u0438;\n* \u0438\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0430 \u043e\u0448\u0438\u0431\u043a\u0430 \u0441 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u043c \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435\u043c \u0448\u0430\u0431\u043b\u043e\u043d\u043d\u044b\u0445 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432\n  \u0434\u043b\u044f django.\n\n0.5.0 (2010-11-15)\n------------------\n* \u0438\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0438 \u0434\u043e\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438\n* \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u043e\u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f unittest2\n* \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043e\u043f\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u043c\u043e\u0434\u0443\u043b\u044f\n  `pymorphy-speedups <http://pypi.python.org/pypi/pymorphy-speedups>`_ \u0441\n  \u0440\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u0438\u0435\u043c \u043d\u0430 Cython (\u0442\u0443\u0434\u0430 \u0442\u0430\u043a\u0436\u0435 \u043f\u0435\u0440\u0435\u043d\u0435\u0441\u0435\u043d \u043c\u0435\u0442\u043e\u0434 setup_psyco). \u041f\u0440\u0438\n  \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438 pickle-\u0441\u043b\u043e\u0432\u0430\u0440\u0435\u0439 \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u043f\u0440\u0438 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0435 \u0440\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u0438\u044f \u0434\u043e\u043b\u0436\u043d\u0430\n  \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0442\u044c\u0441\u044f \u0432 2+ \u0440\u0430\u0437\u0430. \u0414\u043b\u044f \u0434\u0440\u0443\u0433\u0438\u0445 (\u0431\u043e\u043b\u0435\u0435 \u043c\u0435\u0434\u043b\u0435\u043d\u043d\u044b\u0445) \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043e\u0432 \u0441\u043b\u043e\u0432\u0430\u0440\u0435\u0439\n  \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u0438\u0440\u043e\u0441\u0442 \u0431\u0443\u0434\u0435\u0442 \u043d\u0435 \u0442\u0430\u043a\u0438\u043c \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u043c. \u041e\u0441\u0442\u043e\u0440\u043e\u0436\u043d\u043e: \u043f\u0440\u0438 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u043d\u043e\u043c\n  \u043c\u043e\u0434\u0443\u043b\u0435 \u0432\u0441\u0435 \u0441\u0442\u0440\u043e\u043a\u0438 \u0434\u043e\u043b\u0436\u043d\u044b \u043f\u0435\u0440\u0435\u0434\u0430\u0432\u0430\u0442\u044c\u0441\u044f \u043a\u0430\u043a \u044e\u043d\u0438\u043a\u043e\u0434\u043d\u044b\u0435 (\u0432.\u0442.\u0447. \u043b\u0430\u0442\u0438\u043d\u0441\u043a\u0438\u0435 \u0438\n  \u043f\u0443\u0441\u0442\u044b\u0435).\n* \u0443\u0431\u0440\u0430\u043d\u0430 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u043e\u0442 simplejson (\u043d\u043e \u0435\u0433\u043e \u043b\u0443\u0447\u0448\u0435 \u0432\u0441\u0435 \u0440\u0430\u0432\u043d\u043e \u043f\u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c, \u0442.\u043a. \u0441\n  simplejson \u0440\u0430\u0431\u043e\u0442\u0430 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u0441\u043b\u043e\u0432\u0430\u0440\u044f\u043c\u0438, \u043a\u0440\u043e\u043c\u0435 pickle, \u0443\u0441\u043a\u043e\u0440\u044f\u0435\u0442\u0441\u044f \u0432 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0440\u0430\u0437)\n* \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\u0435 \u0441\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u0435 \u0441\u043b\u043e\u0432 \u0432\u043e \u0432\u0442\u043e\u0440\u043e\u043c \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u043d\u043e\u043c, \u0440\u043e\u0434\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u043c \u0438\u043b\u0438 \u0432\u0438\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u043c\n  \u043f\u0430\u0434\u0435\u0436\u0430\u0445\n* \u043c\u0435\u0442\u043e\u0434 pluralize_inflected_ru \u0442\u0435\u043f\u0435\u0440\u044c \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0432\u0430\u0435\u0442 \u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435\n* \u0431\u043e\u043b\u0435\u0435 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\u0435 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043d\u0430 \u0441\u043b\u043e\u0432\u0430 \u0432 \u0444\u0438\u043b\u044c\u0442\u0440\u0430\u0445\n* \u0420\u0430\u0431\u043e\u0442\u0430 \u0441\u043e \u0441\u043b\u043e\u0432\u0430\u043c\u0438, \u0437\u0430\u043f\u0438\u0441\u0430\u043d\u043d\u044b\u043c\u0438 \u0447\u0435\u0440\u0435\u0437 \u0434\u0435\u0444\u0438\u0441.\n* \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u043d\u043d\u044b\u0445 \u0442\u0435\u043a\u0441\u0442\u043e\u0432 (\u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u043d\u044b\u0435 \u0437\u0430\u043c\u0435\u043d\u044b \u0431\u0443\u043a\u0432). \u0414\u043e\u0432\u043e\u043b\u044c\u043d\u043e\n  \u0431\u0435\u0441\u043f\u043e\u043b\u0435\u0437\u043d\u0430\u044f \u0448\u0442\u0443\u043a\u0430.\n* \u0423\u0431\u0440\u0430\u043d \u043c\u0435\u0442\u043e\u0434 get_normal_forms, \u0442.\u043a. \u043c\u0435\u0442\u043e\u0434 get_gram_info \u0438 \u0442\u0430\u043a \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442\n  \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0441\u043b\u043e\u0432\u0430 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u0443\u044e \u0444\u043e\u0440\u043c\u0443.\n\n0.4.3 (2010-02-06)\n------------------\n\u0423\u0441\u0442\u0440\u0430\u043d\u0435\u043d\u044b \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0438\u0435 \u043e\u0448\u0438\u0431\u043a\u0438.\n\n0.4.0 (2010-01-07)\n------------------\n\u0423\u043f\u0440\u043e\u0449\u0435\u043d\u0430 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430: \u0434\u043e\u0431\u0430\u0432\u0438\u043b\u0430\u0441\u044c \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043a\u0440\u043e\u0441\u0441\u043f\u043b\u0430\u0442\u0444\u043e\u0440\u043c\u0435\u043d\u043d\u044b\u0445 \u0441\u043b\u043e\u0432\u0430\u0440\u0435\u0439 \u0432 sqlite\n\n0.3.5 (2009-12-15)\n------------------\n\u0418\u043d\u0442\u0435\u0433\u0440\u0430\u0446\u0438\u044f \u0441 django: \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u044b \u0448\u0430\u0431\u043b\u043e\u043d\u043d\u044b\u0435 \u0444\u0438\u043b\u044c\u0442\u0440\u044b \u0434\u043b\u044f \u0441\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u044f \u0438 \u0441\u043e\u0433\u043b\u0430\u0441\u043e\u0432\u0430\u043d\u0438\u044f\n\u0441\u043b\u043e\u0432. \u041f\u0435\u0440\u0435\u0434\u0435\u043b\u0430\u043d\u044b \u043f\u0440\u0430\u0432\u0438\u043b\u0430 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u044b\u0445 \u0444\u043e\u0440\u043c \u0441\u043b\u043e\u0432\u0430 (\u043f\u0435\u0440\u0435\u0434\u0435\u043b\u043a\u0430 \u043e\u0448\u0438\u0431\u043e\u0447\u043d\u0430\u044f).\n\n0.1.0 (2009-12-07)\n------------------\npymorphy \u043f\u043e\u0447\u0442\u0438 \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e \u043f\u0435\u0440\u0435\u043f\u0438\u0441\u0430\u043d, \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u043d, \u043e\u0444\u043e\u0440\u043c\u043b\u0435\u043d \u043a\u0430\u043a\npython-\u043f\u0430\u043a\u0435\u0442 \u0438 \u0437\u0430\u0433\u0440\u0443\u0436\u0435\u043d \u043d\u0430 pypi.python.org\n\n0.0.1 (2009-01-18)\n------------------\n\u043f\u0435\u0440\u0432\u0430\u044f \u0432\u0435\u0440\u0441\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u043e\u0441\u043b\u0435 \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u0438\u044f \u0431\u044b\u043b\u0430 \u0437\u0430\u0431\u0440\u043e\u0448\u0435\u043d\u0430 \u043d\u0430 \u0433\u043e\u0434"}}, {"pk": 716, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "IbPy", "license": "BSD License", "author": "Troy Melhase", "author_email": "troy@gci.net", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/ibpy/", "version": "0.7.2-9.00", "platform": "any", "keywords": null, "summary": "IbPy - Interactive Brokers Python API", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Office/Business :: Financial\nTopic :: Office/Business :: Financial :: Investment\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules", "description": "IbPy is a third-party implementation of the API used for accessing the\nInteractive Brokers on-line trading system.  IbPy implements functionality\nthat the Python programmer can use to connect to IB, request stock ticker\ndata, submit orders for stocks and options, and more."}}, {"pk": 717, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "oldowan.mitomotifs", "license": "MIT", "author": "Ryan Raaum", "author_email": "code@raaum.org", "project_url": null, "maintainer_email": null, "home_page": "http://mitomotifs.raaum.org", "version": "1.0.2", "platform": "Any", "keywords": "bioinformatics", "summary": "Transform human mtDNA sequence to variant sites and vice versa.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "oldowan.mitomotifs is a small, pure Python, bioinformatic utility to (1)\ntransform human mitochondral DNA sequence data into variant sites relative to\nthe revised Cambridge Reference Sequence (rCRS) and (2) transform variant sites\ndata into DNA sequence. Further information on the rCRS and variant site\nnomenclature for human mtDNA sequences is available at the MitoMotifs_ website. \n\nInstallation Instructions\n=========================\n\nThis package is pure Python and has no dependencies outside of the standard\nlibrary. The easist way to install is using ``easy_install`` from the\nsetuptools_ package.  This usually goes something like this::\n\n\t$ easy_install oldowan.mitomotifs\n\nor on a unix-like system, assuming you are installing to the main Python\n``site-packages`` directory as a non-privileged user, this::\n\n\t$ sudo easy_install oldowan.mitomotifs\n\nYou may also use the standard python distutils setup method. Download the\ncurrent source archive from the file list towards the bottom of this page,\nunarchive it, and install. On Mac OS X and many other unix-like systems, having\ndownloaded the archive and changed to the directory containing this archive in\nyour shell, this might go something like::\n\n\t$ tar xvzf oldowan.mitomotifs*\n\t$ cd oldowan.mitomotifs*\n\t$ python setup.py install\n\nQuick Start\n===========\n\nImport ``seq2sites`` and ``sites2seq`` from oldowan.mitomotifs::\n\n  >>> from oldowan.mitomotifs import seq2sites, sites2seq\n\nConvert sequence to sites::\n\n  >>> seq = \"\"\"TTCTTTCATGGGGAAGCAGATTTGGGTACCACCCAA\n  GTATTGACTCACCCATCAACAACCGCTATGTATTTCGTACATTACTGCC\n  AGCCACCATGAATATTGTACAGTACCATAAATACTTGACCACCTGTAGT\n  ACATAAAAACCCAATCCACATCAAAACCCCCTCCCCATGCTTACAAGCA\n  AGTACAGCAATCAACCTTCAACTATCACACATCAACTGCAACTCCAAAG\n  CCACCCCTCACCCACTAGGATACCAACAAACCTACCCACCCTTAACAGT\n  ACATAGTACATAAAGCCATTTACCGTACATAGCACATTACAGTCAAATC\n  CCTTCTCGTCCC\"\"\"\n  >>> seq2sites(seq)\n\nSequences must be contiguous! Separate runs of sequence, such as HVR1 and HVR2\nwithout the intervening sequence interval, must be analyzed separately.\n\nThere is also a cutoff on the number of ambigous sites (N) allowed in the\nsequence. By default, this is 10 - but this is an option that can be set::\n\n  >>> seq2sites(seq, ambig_cutoff=20)\n\nConvert a list of variable sites to sequence. The default sequence region that\nis returned is hypervariable region 1 (HVR1), which is positions 16024 to 16365\nof the rCRS (in biological one-based numbering)::\n\n  >>> sites2seq('16129A 16223T')\n\nPredefined sequence regions are:\n\n- HVR1: 16024-16365\n- HVR2: 73-340\n- HVR1to2: 16024-340\n- coding: 577-15992\n- all: 1-16559\n\nSo, to convert a list of HVR2 sites to sequence::\n\n  >>> sites2seq('73G', region='HVR2')\n\nSites may also be provided in a list::\n\n  >>> sites2seq(['16129A', '16223T', '73G'], region='HVR1to2')\n\nThe rCRS sequence will be returned given an empty string, empty list, or the\nstring 'rCRS'. All of the following are equivalent::\n\n  >>> sites2seq('')\n  >>> sites2seq([])\n  >>> sites2seq('rCRS')\n\nArbitrary positions may be selected by passing a list of sites to the\n``region`` option::\n\n  >>> sites2seq('', region=[1,2,3])\n\nThe Python range function is convenient for this, but you must remember that\nthe range does not include it's ending position::\n\n  >>> sites2seq('', region=range(73,341))  # include 340, but not 341\n    \nRelease History ===============\n\n1.0.0 (August 16, 2008)\n    initial release of module.\n\n1.0.1 (August 22, 2008)\n    new 'add16k' option to sites2seq for abbreviated HVR1 sites (i.e. 16129A as 129A)\n\n\n.. _MitoMotifs: http://mitomotifs.raaum.org\n.. _setuptools: http://peak.telecommunity.com/DevCenter/EasyInstall"}}, {"pk": 718, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "edrnsite.funding", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/edrnsite-funding", "version": "0.0.0", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers funding funds", "summary": "EDRN Funding Opportunities", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "****************\nedrnsite.funding\n****************\n\nThis product, ``edrnsite.funding``, provides content types for Plone_ 3 (or\nlater) to announce, search, discover, and manage funding opportunities of the\nEarly Detection Research Network (EDRN_).  Although intended for the EDRN\npublic portal, it can be installed in any Plone-compatible site.\n\nIt was developed by the Informatics Center (IC_), operated by JPL_.\n\n.. References:\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _IC: http://cancer.jpl.nasa.gov/\n.. _JPL: http://www.jpl.nasa.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``edrnsite.funding`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        edrnsite.funding\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        edrnsite.funding\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 719, "model": "importing.pypicache", "fields": {"maintainer": "Brandon Stafford", "name": "Pysolar", "license": "", "author": "Brandon Stafford", "author_email": "brandon@pingswept.org", "project_url": null, "maintainer_email": "brandon@pingswept.org", "home_page": "pysolar.org", "version": "0.3.0RC2", "platform": "", "keywords": "ephemeris solar photovoltaic vsop87", "summary": "Pysolar is a collection of Python libraries for simulating the irradiation of any point on earth by the sun. It includes code for extremely precise ephemeris calculations, and more.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Atmospheric Science\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules", "description": ""}}, {"pk": 720, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.plugins.sql", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/plugins/sql.html", "version": "0.2.7", "platform": "UNKNOWN", "keywords": "sql dap opendap dods data", "summary": "SQL plugin for pydap server", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This plugin should work with any database module that conforms with the\nPython DB-API 2 specification:\n\n    http://www.python.org/peps/pep-0249.html\n\nYou can find a list of database modules here:\n\n    http://www.python.org/topics/database/modules.html\n\nIt currently has been tested with SQLite, MySQL and PostgreSQL, but it\nalso should work with Oracle, MSSQL and ODBC.\n\nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/plugins/dap_plugin_sql#egg=dap_plugin_sql-dev>`_."}}, {"pk": 721, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.image", "license": "Modified BSD", "author": "Stefan van der Walt", "author_email": "stefan@sun.ac.za", "project_url": null, "maintainer_email": null, "home_page": "http://stefanv.github.com/scikits.image", "version": "0.2.2", "platform": "UNKNOWN", "keywords": null, "summary": "Image processing routines for SciPy", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nTopic :: Scientific/Engineering", "description": "Image Processing SciKit\n\nImage processing algorithms for SciPy, including IO, morphology, filtering,\nwarping, color manipulation, object detection, etc.\n\nPlease refer to the online documentation at\nhttp://stefanv.github.com/scikits.image"}}, {"pk": 722, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "asciitable", "license": "BSD", "author": "Tom Aldcroft", "author_email": "aldcroft@head.cfa.harvard.edu", "project_url": null, "maintainer_email": null, "home_page": "http://cxc.harvard.edu/contrib/asciitable", "version": "0.5.1", "platform": "any", "keywords": null, "summary": "Extensible ASCII table reader and writer", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Scientific/Engineering :: Physics", "description": "Asciitable can read and write a wide range of ASCII table formats via built-in\nExtension Reader Classes:\n\n* **Basic**: basic table with customizable delimiters and header configurations\n* **Cds**: `CDS format table <http://vizier.u-strasbg.fr/doc/catstd.htx>`_ (also Vizier and ApJ machine readable tables)\n* **CommentedHeader**: column names given in a line that begins with the comment character\n* **Daophot**: table from the IRAF DAOphot package\n* **Ipac**: `IPAC format table <http://irsa.ipac.caltech.edu/applications/DDGEN/Doc/ipac_tbl.html>`_\n* **Memory**: table already in memory (list of lists, dict of lists, etc)\n* **NoHeader**: basic table with no header where columns are auto-named\n* **Rdb**: tab-separated values with a column types line after the column names line\n* **Tab**: tab-separated values\n\nAt the top level asciitable looks like many other ASCII table interfaces\nsince it provides default read() and write() functions with long lists of\nparameters to accommodate the many variations possible in commonly encountered\nASCII table formats.  Below the hood however asciitable is built on a\nmodular and extensible class structure.  The basic functionality required for\nreading or writing a table is largely broken into independent base class\nelements so that new formats can be accomodated by modifying the underlying\nclass methods as needed."}}, {"pk": 723, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyephem", "license": "LGPL", "author": "Brandon Craig Rhodes", "author_email": "brandon@rhodesmill.org", "project_url": null, "maintainer_email": null, "home_page": "http://rhodesmill.org/pyephem/", "version": "3.7.4.1", "platform": "UNKNOWN", "keywords": null, "summary": "Scientific-grade astronomy routines", "classifiers": "Development Status :: 6 - Mature\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nTopic :: Scientific/Engineering :: Astronomy", "description": "==============\nPyEphem README\n==============\n\n.. _ephem: http://pypi.python.org/pypi/ephem/\n.. _pyephem: http://pypi.python.org/pypi/pyephem/\n.. _XEphem: http://www.clearskyinstitute.com/xephem/\n.. _Quick Reference: http://rhodesmill.org/pyephem/quick\n.. _Tutorial: http://rhodesmill.org/pyephem/tutorial\n.. _PyEphem web site: http://rhodesmill.org/pyephem/\n\n**This version of PyEphem,\nnamed** `pyephem`_ **in the Python Package Index,\nis the version for the Python 2.x series.\nIf you have gone ahead and transitioned to Python 3.0,\nthen look for the package named** `ephem`_\n**instead.**\n\nPyEphem provides an ``ephem`` Python package\nfor performing high-precision astronomy computations.\nThe underlying numeric routines are coded in C\nand are the same ones that drive the popular `XEphem`_ astronomy application,\nwhose author, Elwood Charles Downey,\ngenerously gave permission for their use in PyEphem.\nThe name *ephem* is short for the word *ephemeris*,\nwhich is the traditional term for a table\ngiving the position of a planet, asteroid, or comet for a series of dates.\n\nThe `PyEphem web site`_ offers documentation\nand also links to the project bug tracker, user support forum,\nand source code repository.\n\nThe design of PyEphem emphasizes convenience and ease of use.\nBoth celestial bodies and the observer's location on Earth\nare represented by Python objects,\nwhile dates and angles automatically print themselves\nin standard astronomical formats::\n\n >>> import ephem\n >>> mars = ephem.Mars()\n >>> mars.compute('2008/1/1')\n >>> print mars.ra, mars.dec\n 5:59:27.35 26:56:27.4\n\nThe documentation includes both a `Quick Reference`_ and a `Tutorial`_,\nwhich are included in text files within the module itself\nas well as being available on the `PyEphem web site`_.\n\nThe features provided by PyEphem include:\n\n* Find where a planet, comet, or asteroid is in the sky.\n\n  * High-precision orbital routines are provdied\n    for the Moon, Sun, planets, and the major planet moons.\n  * The user can supply the orbital elements of a comet, asteroid,\n    or Earth-orbiting satellite, and have its location computed.\n  * The positions of 94 bright stars come built-in,\n    and the user can create further fixed objects as needed\n    for their calculations.\n\n* Determine where in the sky an object appears for a particular observer.\n\n  * The user can supply the longitude, latitude, and altitude\n    of the location from which they will be observing.\n  * For convenience, a small database of longitudes and latitudes\n    for 122 world cities is included.\n  * For specified weather conditions (temperature and pressure),\n    PyEphem will compensate for atmospheric refraction\n    by adjusting the positions of bodies near the horizon.\n\n* Compute when a body will rise, transit overhead, and set\n  from a particular location.\n\n* Parse and use orbital data in either the traditional XEphem file format,\n  or the standard TLE format used for tracking Earth-orbiting satellites.\n\n* Determine the dates of the equinoxes and solstices.\n\n* Compute the dates of the various phases of the Moon.\n\n* Convert from the Greenwich Time (more precisely, Ephemeris Time)\n  which PyEphem uses to the local time of the user.\n\n* Convert positions between the equatorial, ecliptic, and galactic\n  coordinate systems.\n\n* Determine on which page of the Uranometria or the Millennium Star Atlas\n  a particular star should appear.\n\n* Return the Julian Date corresponding to any calendar date."}}, {"pk": 724, "model": "importing.pypicache", "fields": {"maintainer": "Erik Max Francis", "name": "LSystem", "license": "GPL", "author": "Erik Max Francis", "author_email": "software@alcyone.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.alcyone.com/software/lsystem/", "version": "1.0", "platform": "any", "keywords": "Lindenmayer systems, Lindemeyer systems, L-systems, fractals, algorithmic beauty of plants, artificial life", "summary": "A Lindenmayer system explorer module", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "A simple implementation of Lindenmayer systems (also called\r\n    L-systems, substitution systems) is provided.  In basic form, a\r\n    Lindenmayer system consists of a starting string of symbols from\r\n    an alphabet, and has repeated transitions applied to it, specified\r\n    by a list of transition search-and-replace rules.\r\n\r\n    In addition to the standard formulation, two alternative\r\n    implementations are included: sequential systems, in which at most\r\n    one rule is applied; and tag systems, in which the transition only\r\n    takes place at the beginning and end of the string."}}, {"pk": 725, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MindTree", "license": "Apache License 2.0", "author": "Ron Longo", "author_email": "ron.longo@cox.net", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/mindtree", "version": "1.0.0-a002", "platform": "UNKNOWN", "keywords": null, "summary": "Notes organizer/Outliner/PIM for Python 2.5.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Healthcare Industry\nIntended Audience :: Information Technology\nIntended Audience :: Manufacturing\nIntended Audience :: Other Audience\nIntended Audience :: Religion\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nIntended Audience :: Telecommunications Industry\nLicense :: OSI Approved :: Apache Software License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Documentation\nTopic :: Education\nTopic :: Internet :: WWW/HTTP\nTopic :: Office/Business\nTopic :: Scientific/Engineering :: Information Analysis", "description": "MindTree is an outliner application designed for taking and organizing notes and publishing these notes to the web.  Requires Python 2.5."}}, {"pk": 726, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "SyFi", "license": "LGPL", "author": "Kent-Andre Mardal and Martin Sandve Alns", "author_email": "kent-and@simula.no", "project_url": null, "maintainer_email": "", "home_page": "http://www.fenics.org/syfi", "version": "0.6.0", "platform": "UNKNOWN", "keywords": "", "summary": "Symbolic Finite Elements", "classifiers": "License :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: C++\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics", "description": "The finite element package SyFi is a C++ library built on top of the symbolic\r\nmath library GiNaC. The name SyFi stands for Symbolic Finite Elements. The\r\npackage provides polygonal domains, polynomial spaces, and degrees of freedom as\r\nsymbolic expressions that are easily manipulated. This makes it easy to define\r\nfinite elements and variational forms.\r\n\\\r\n\r\n\r\nThe release of SyFi 0.6.0 includes a \r\nrewritten version of SFC, which is now \r\nbased on UFL. Most notable in this release \r\nis the capability for exploiting \r\nthe automatic differentiation tools in UFL."}}, {"pk": 727, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nx_spatial", "license": "MPL", "author": "Ben Reilly", "author_email": "gallipoli@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/gallipoli/nx_spatial", "version": "0.4dev", "platform": "UNKNOWN", "keywords": "spatial,gis,topology,networkx", "summary": "Additional GIS focused functions for networkx graphs.", "classifiers": "Topic :: Scientific/Engineering :: GIS", "description": "This project is designed as an add-on for networkx, a graph library for\n      Python. It accepts a variety of different spatial formats to generate\n      directional graphs and provides simple modules to correct flow errors,\n      find specific nodes by attribute, and run a depth first search (trace)\n      with stopping points."}}, {"pk": 728, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "periodictable", "license": "UNKNOWN", "author": "Paul Kienzle", "author_email": "pkienzle@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.reflectometry.org/danse/elements.html", "version": "1.3.0", "platform": "UNKNOWN", "keywords": null, "summary": "Extensible periodic table of the elements", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: Public Domain\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Scientific/Engineering :: Physics", "description": "=========================================\nExtensible periodic table of the elements\n=========================================\n\nRelease 1.3, Dec 7, 2010\n\nThis package provides a periodic table of the elements with\nsupport for mass, density and xray/neutron scattering information.\n\nMasses, densities and natural abundances come from the\nNIST Physics Laboratory, but do not represent a critical\nevaluation by NIST scientists.\n\nNeutron scattering calculations use values collected by the \nAtomic Institute of the Austrian Universities.  These values\ndo corresponding to those from other packages, though there \nare some differences depending to the tables used.  Bound \ncoherent neutron scattering for gold in particular is significantly \ndifferent from older value: 7.63(6) as measured in 1974\ncompared to 7.90(7) as measured in 1990.\n\nX-ray scattering calculations use a combination of empirical and\ntheoretical values from the LBL Center for X-ray Optics.  These\nvalues differ from those given in other sources such as the\nInternational Tables for Crystallography, Volume C, and so may\ngive different results from other packages.\n\n\nChange history\n==============\n\n1.3  2010-12-05\n---------------\n\nNew:\n\n* mix_by_weight and mix_by_volume formula constructors\n* use natural density to set density for isotope specific formulas\n* add neutron_scattering function which returns xs, sld and penetration depth\n\nModified:\n\n* need wavelength= or energy= for xray/neutron sld\n* improved docs and testing\n\n1.2  2010-04-28\n---------------\n\nNew:\n\n* support pickle: id(H) == id(loads(dumps(H)))\n* support ions, with magnetic form factors and x-ray f0 scattering factor\n* support py2exe wrappers\n* allow density to be calculated from structure (bcc, fcc, hcp, cubic, diamond)\n* estimate molecular volume\n* support private tables with some values replaced by application\n\nModified:\n\n* rename package periodictable\n* rename table to periodictable.elements\n* neutron sld returns real and imaginary coherent and incoherent\n  instead of coherent, absorption and incoherent\n* bug fix: sld for H[2] was wrong when queried before sld for H.\n* remove CrysFML ionic radius definitions\n\n1.1  2009-01-20\n---------------\n\nModified:\n\n* Restructure package, separating tests into different directory\n* When defining table extensions, you should now do::\n\n      from elements.core import periodic_table, Element, Isotope\n\n  rather than::\n\n      from elements import periodic_table\n      from elements.elements import Element, Isotope"}}, {"pk": 729, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.handlers.netcdf", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/handlers.html#netcdf", "version": "0.5.0", "platform": "UNKNOWN", "keywords": "netcdf opendap dods dap data science climate oceanography meteorology", "summary": "NetCDF handler for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This handler enables Pydap to serve NetCDF files on the\nnetwork for Opendap clients."}}, {"pk": 730, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "codepy", "license": "MIT", "author": "Andreas Kloeckner", "author_email": "inform@tiker.net", "project_url": null, "maintainer_email": null, "home_page": "http://mathema.tician.de/software/codepy", "version": "2011.1", "platform": "UNKNOWN", "keywords": null, "summary": "Generate and execute native code at run time.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries\nTopic :: Utilities", "description": "CodePy is a C/C++ metaprogramming toolkit for Python. It handles two aspects of\n      native-code metaprogramming:\n\n      * Generating C/C++ source code.\n      * Compiling this source code and dynamically loading it into the\n        Python interpreter.\n\n      Both capabilities are meant to be used together, but also work\n      on their own. In particular, the code generation facilities work\n      well in conjunction with `PyCuda <http://mathema.tician.de/software/pycuda>`_.\n      Dynamic compilation and linking are so far only supported in Linux\n      with the GNU toolchain."}}, {"pk": 731, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cdx.datawrappers", "license": "Copyright\n********\n\nCopyright 2009 by the California Institute of Technology. ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions. The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for \nuse by any person, organization, or other entity without prior, specific\nwritten permission.\n\n\n\nPyDAP\n*****\n\nThis software includes modifications to PyDAP, a Python library implementing\nthe Data Access Protocol, Copyright 2003-2009 Roberto De Almeida.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell \ncopies of the Software, and to permit persons to whom the Software is \nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, \nINCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR \nPURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE \nFOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, \nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE \nSOFTWARE.", "author": "Chris Mattmann", "author_email": "chris.a.mattmann@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cdx.jpl.nasa.gov/software/cdx-data-wrappers-code-for-mls-airs-misr-and-ncar-ccsm", "version": "0.0.6", "platform": "UNKNOWN", "keywords": "climate data cdx datawrappers python", "summary": "CDX Data Wrappers", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database :: Front-Ends\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "******************\n cdx.datawrappers\n******************\n\n.. contents::\n\nCDX DataWrappers provides an API into the CDX data systems that enables subsetting and spatial \nand temporal access to date made available from CDX.  CDX is the Climate Data Exchange, \nan effort of the Jet Propulsion Laboratory to create a virtual environment for the sharing of\nclimate data.\n\nInstallation\n************\n\nThis document tells you how to install cdx-datawrappers.\n\n\nQuick Instructions\n==================\n\nAs a user with administrative privileges, run::\n\n    easy_install cdx-datawrappers\n\nThat's it.\n\n\nFull Instructions\n=================\n\ncdx-datawrappers requires the Python_ programming language.  We recommend version 2.4\nor later.  As of this writing, 2.6 is the latest stable version.  If Python is\nnot yet installed on your system, you can find binary and and source\ndistributions from the Python website.\n\nTo test if a correct version of Python is available on your system, run::\n\n    python -V\n    \nYou should see output similar to::\n\n    Python 2.6\n    \nindicating the version of Python installed. \n\nBy far the easiest, recommended, and encouraged way to install cdx-datawrappers is\nto use EasyInstall_.  If your Python installation has EasyInstall available to\nit, then this one command is all you need to run in order to download, build,\ninstall, and generate command-line tools all in one go for all users on your\nsystem::\n\n    easy_install cdx-datawrappers\n    \nBe sure to run that command as an administrative user.  For example, on Mac OS\nX and other Unix systems, you might need to run::\n\n    sudo easy_install cdx-datawrappers\n\nThat will also download and install all dependencies, including Setuptools.\n\n\nExecutables\n-----------\n\n\n\nInstalling EasyInstall\n----------------------\n\nIf you happen to be on a system where your Python installation lacks easy\ninstall, fret not.  Upgrading your system to gain EasyInstall's abilities is\nquite simple.  Follow these instructions:\n\n1.  Download http://peak.telecommunity.com/dist/ez_setup.py\n2.  As an administrative user, run the freshly-downloaded ez_setup.py file\n    using your system's Python.\n\nEasyInstall and its necessary libraries will be downloaded, built, and\ninstalled for you, and the ``easy_install`` executable generated.  The\nlocation of the ``easy_install`` executable is as described above.\n\n\nInstalling Without EasyInstall\n------------------------------\n\nIf EasyInstall is not available on your system, you can still make a proper\ninstallation of cdx-client. Follow these instructions:\n\n1.  Download the cdx-datawrappers source distribution from\n    http://cdx.jpl.nasa.gov/software/dist/cdx-datawrappers/cdx-datawrappers-0.0.0.tgz\n    Substitute version numbers as appropriate.\n2.  Unpack each archive.\n3.  Change the current working directory to each newly-created subdirectory,\n    ``cdx.datawrappers-0.0.0``, again substituting version\n    numbers as appropriate.\n4.  As an administrative user, run:  ``python setup.py install`` in each\n    subdirectory.\n\n\nIssues and Questions\n====================\n\nTo report any problems with or ask for help about cdx-datawrappers, visit our\ncontact_  web page.\n\n\n.. References:\n.. _contact: http://cdx.jpl.nasa.gov/contact-info\n.. _EasyInstall: http://peak.telecommunity.com/DevCenter/EasyInstall\n.. _Java: http://tinyurl.com/5kng2h\n.. _OODT: http://oodt.jpl.nasa.gov/\n.. _Python: http://python.org/\n\nChangelog\n*********\n\n0.0.6 - 11/13/2010\n===================\n\nThis release adds in functionality to do subsetting by \nlatitude, longitude, and time (adding the time dimension) \nto improve upon the work in CDX-94. See CDX-103 for more \ndetails.\n\nFor the issue tracker, see \nhttp://oodt.jpl.nasa.gov/jira/browse/CDX\n\n\n0.0.5 - 09/10/2010\n==================\n\nThis release updates the CloudSAT datawrappers URL. See CDX-99 for \nmore details.\n\nFor the issue tracker, see \nhttp://oodt.jpl.nasa.gov/jira/browse/CDX\n\n0.0.4 - 09/03/2010\n==================\n\nThis release includes a subtle, but important improvement to the GetVariableByLatLon\nfunctionality provided by each data wrapper. Instead of returning an 1 or 2 dimensional\narray of values (1 dimension if the original array was 2d, and 2 dimensional if it was \n3d) that fall within the provided lat/lon range, the data wrappers have been modified \nto return a 1 or 2 dimensional array of tuples of the form lat, lon, value, so that the \nvalues can be remapped onto a new spatial grid to support the conditional analysis scenario. \nSee CDX-94 for more details.\n\nFor the issue tracker, see \nhttp://oodt.jpl.nasa.gov/jira/browse/CDX\n\n\n0.0.3 - 03/24/2010\n==================\n\nThis release includes improvements to the MLS, MISR, CloudSAT and CCSM\ndata wrappers, adding in the subsetByLatLon function (per CDX-84). Additionally\nthis release includes modifications to the GetVariable function in the CDXDataWrapper.py \ninterface and all subsequent implementations to allow a constraint to be specified for \nfurther subsetting (see CDX-86 for more details).\n\nFor the issue tracker, see \nhttp://oodt.jpl.nasa.gov/jira/browse/CDX\n\n0.0.2 - 02/27/2010\n==================\n\nThis release includes improvements to the CDXDataWrapper interface including the\nability to subset by lat and lon for AIRS data on the AIRSDataWrapper.\n\nFor the issue tracker, see\nhttp://oodt.jpl.nasa.gov/jira/browse/CDX.\n\n\n0.0.1 - 10/02/2009\n==================\n\nThis release includes its own specially modified version of PyDAP to work\naround some outstanding issues in that library.\n\n\n0.0.0 - Initial\n===============\n\nThis is an initial release of cdx-datawrappers providing local data access to\nMISR, MLS AIRS and NCAR's Community Climate Simulation Model (CCSM) output\nnetCDF data, and remote access to MLS, AIRS and CCSM data."}}, {"pk": 732, "model": "importing.pypicache", "fields": {"maintainer": "Arc Riley", "name": "PySoy", "license": "GNU General Public License version 3 (GPLv3)", "author": "PySoy Group", "author_email": "pysoy-dev@pysoy.org", "project_url": null, "maintainer_email": "arc@pysoy.org", "home_page": "http://www.pysoy.org/", "version": "1.0-beta2", "platform": "UNKNOWN", "keywords": "", "summary": "3D Game Engine for Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nTopic :: Education\nTopic :: Games/Entertainment\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Scientific/Engineering :: Visualization", "description": ""}}, {"pk": 733, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "teatime", "license": "Public Domain", "author": "Etienne Robillard", "author_email": "robillard.etienne@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://www.gthc.org/", "version": "1.0.2", "platform": "", "keywords": "teatime", "summary": "A simple to learn script for making great tea recipes", "classifiers": "Development Status :: 5 - Production/Stable\nLicense :: Public Domain\nTopic :: Scientific/Engineering :: Mathematics", "description": ""}}, {"pk": 734, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Helmholtz", "license": "CeCILL http://www.cecill.info", "author": "Neuroinformatics research group, UNIC, CNRS", "author_email": "neuroinformatique@unic.cnrs-gif.fr", "project_url": null, "maintainer_email": null, "home_page": "http://www.dbunic.cnrs-gif.fr/helmholtz/", "version": "0.1.0", "platform": "UNKNOWN", "keywords": "neuroscience database Django metadata", "summary": "A framework for creating neuroscience databases", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Web Environment\nFramework :: Django\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database\nTopic :: Scientific/Engineering", "description": "UNKNOWN"}}, {"pk": 735, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "django-facebook", "license": "Copyright (c) Thierry Schellenbach\n\n (http://www.mellowmorning.com)\nAll rights reserved.\n\nRedistribution and use of this software in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n- Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n- Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n- Neither the name of Thierry Schellenbach. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission of Thierry Schellenbach.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "author": "Thierry Schellenbach", "author_email": "thierryschellenbach@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/tschellenbach/Django-facebook", "version": "2.0.15", "platform": "UNKNOWN", "keywords": null, "summary": "Facebook open graph API client in python. Enables django applications to register users using facebook.\nFixes issues with the official but unsupported Facebook python-sdk. Enables mobile facebook authentication.\nCanvas page authentication for facebook applications. FQL access via the server side api.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "######################################################################\nDjango Facebook by Thierry Schellenbach (http://www.mellowmorning.com)\n######################################################################\n\nFirst\n-----\nPlease contribute code :) \n\nThis project is actively maintained and I appreciate improvements to the code.\n\nContact me here or `@tschellenbach <http://www.twitter.com/tschellenbach>`_\n\nNew in Version 2.0 Alpha\n------------------------\n* canvas page support for facebook applications\n* mobile facebook registration support (tested with titanium FB flow)\n* less requirements (jinja, view decorator, django notify and cjson requirements removed)\n* fql support\n* django static support\n\nAbout Django Facebook\n---------------------\nDjango Facebook allows you to connect to the Facebook Open Graph API.\nIntegrated with Django it becomes easy to setup a login/register via Facebook flow for your users.\n\n**Features**\n\n* Access the Facebook API, from:\n   * Your website (Using javascript OAuth)\n   * Facebook canvas pages (For building facebook applications)\n   * Mobile (Or any other flow giving you a valid access token)\n* Django User Registration (Convert Facebook user data into a user model\n* Use Facebook data to register a user with your Django app. Facebook connect using the open graph API.\n* Facebook FQL access\n\nWorks best with (not required)\n------------------------------\n* Django registration\n* Django 1.3\n* Django static files\n    \nTODO (again help is appreciated!)\n---------------------------------\n* testing (especially a dummy FB api)\n* separate user data conversion and FB api improvements\n* fully replace the facebook GraphAPI which they no longer support\n   \n\nInstallation\n------------\n\nDownload the source code or use pip install django_facebook.\n\n\n**Create a Facebook App**\n\nIn case you don't yet have a facebook app. You need an app to use the open graph api and make the login process work.\nYou can create a facebook app at this url: http://www.facebook.com/developers/createapp.php \n\n**Settings**\n\nDefine the following settings in your settings.py file:\n\n::\n\n    FACEBOOK_API_KEY\n    FACEBOOK_APP_ID\n    FACEBOOK_APP_SECRET\n        \n**Url config, context processor, auth backend**\n\n::\n\n\tadd django facebook to your installed apps\n\t'django_facebook',\n    add this line to your url config\n    (r'^facebook/', include('django_facebook.urls')),\n    add this line to your context processors\n    'django_facebook.context_processors.facebook',\n    add this to your AUTHENTICATION_BACKENDS\n    'django_facebook.auth_backends.FacebookBackend',\n\n**Update your models**\n\nAdd the following fields to your profile model:\n\n::\n\n    about_me = models.TextField(blank=True, null=True)\n    facebook_id = models.IntegerField(blank=True, null=True)\n    facebook_name = models.CharField(max_length=255, blank=True, null=True)\n    facebook_profile_url = models.TextField(blank=True, null=True)\n    website_url = models.TextField(blank=True, null=True)\n    blog_url = models.TextField(blank=True, null=True)\n    image = models.ImageField(blank=True, null=True, upload_to='profile_images')\n    date_of_birth = models.DateField(blank=True, null=True)\n    raw_data = models.TextField(blank=True, null=True)\n\nAn abstract model is specified for convenience django_facebook/models.py FacebookProfileModel\n    \n**Check the example**\n\nRight now you should have a working registration/connect/login in flow available at /facebook/connect/\nTest if everything is working and ensure you didn't miss a step somewhere.\n\n** Common bugs **\n\nDjango Facebook expects that you are using static files in order to load the required javascript.\nIf you are not using staticfiles you should load facebook.js provided in the static directory manually.\n\nAnother common issue are the url matching settings from Facebook. Facebook requires you to fill in a domain for your application.\nIn order for things to work with local development you need to use the same domain. So if you production site is www.mellowmorning.com you \nshould run your development server on something like local.mellowmorning.com in order for facebook to allow authentication.\n \nIf you encounter any difficulties please open an issue.\n\n**Customize and integrate into your site**\n\nThis is the hardest step of the install. \nFor an example you can look at connect.html in the templates directory.\n\nFirst load the javascript (it loads the facebook library asynchronously).\nI recommend that you insert this code at the bottom of your page.\n\n::\n\n    <script src=\"{{ MEDIA_URL }}js/original/facebook.js\" type=\"text/javascript\"></script>\n    <script>\n    facebookAppId = '{{ FACEBOOK_APP_ID }}';\n    function facebookJSLoaded(){\n    FB.init({appId: facebookAppId, status: false, cookie: true, xfbml: true});\n    }\n    window.fbAsyncInit = facebookJSLoaded;\n    F = new facebookClass(facebookAppId);\n    F.load();\n    </script>\n\nSubsequently implement a form which calls Facebook via javascript.\nNote that you can control which page to go to after connect using the next input field.\n\n::\n\n<form action=\"{% url facebook_connect %}?facebook_login=1\" method=\"post\">\n<a href=\"javascript:void(0);\" style=\"font-size: 20px;\" onclick=\"F.connect(this.parentNode);\">Register, login or connect with facebook</a>\n<input type=\"hidden\" value=\"{{ request.path }}\" name=\"next\" />\n</form>\n    \n    \nDjango Jobs\n-----------\nDo you also see the beauty in clean code? Are you experienced with high scalability web apps?\nCurrently we're looking for additional talent over at our Amsterdam office.\nFeel free to drop me a line at my personal email for more information: thierryschellenbach[at]gmail.com"}}, {"pk": 736, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "LSystem2", "license": "PSF", "author": "Constantin Baranov", "author_email": "const@tltsu.ru", "project_url": null, "maintainer_email": "", "home_page": "http://const.tltsu.ru/", "version": "1.6", "platform": "posix", "keywords": "", "summary": "LSystem for Python", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python Software Foundation License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Visualization", "description": "LSystem2 is a new version of LSystem package, which includes\r\na fast C implementation of basic processing of vector LSystem\r\n(Lindenmayer's System), and several extra Python modules:\r\nEPS, Tk, GL (visualization support)."}}, {"pk": 737, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "geomag", "license": "UNKNOWN", "author": "Christopher Weiss", "author_email": "cmweiss@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://geomag.googlecode.com/", "version": "0.9", "platform": "UNKNOWN", "keywords": "magnetic,variation,declination", "summary": "Magnetic variation/declination", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Other Environment\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Utilities", "description": "Magnetic variation/declination\n------------------------------\n\nCalculates magnetic variation/declination for any latitude/longitude/altitude,\nfor any date. Uses the NOAA National Geophysical Data Center, epoch 2010 data."}}, {"pk": 738, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pydap.responses.netcdf", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/responses.html#netcdf", "version": "0.1.3", "platform": "UNKNOWN", "keywords": "netcdf opendap dods dap data science climate oceanography meteorology", "summary": "Netcdf response for Pydap", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Pydap is an implementation of the Opendap/DODS protocol, written from\nscratch. This response enables Pydap to serve data as NetCDF files."}}, {"pk": 739, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PydapSearch", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/", "version": "0.1.1.a", "platform": "UNKNOWN", "keywords": "opendap dods dap data science climate oceanography meteorology", "summary": "Module that implements search functionality on Pydap.", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Internet :: WWW/HTTP :: WSGI\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This module brings a WSGI middleware that bring search functionality to \nthe Pydap Opendap server."}}, {"pk": 740, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "PyAppleSMS", "license": "LGPL", "author": "Michele Ferretti", "author_email": "michele.ferretti@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://www.blackbirdblog.it/progetti/pyapplesms", "version": "1.0", "platform": "Mac OS X", "keywords": "Apple SMS sensor motion laptop", "summary": "Python module for Apple SMS (Sudden Motion Sensor)", "classifiers": "Environment :: MacOS X\nOperating System :: MacOS :: MacOS X\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Software Development :: Libraries\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Hardware", "description": "This module allows you to access in Apple SMS (Sudden Motion Sensor). SMS sensor\r\nare installed by default in all new Apple laptops and it returns x, y, z\r\ncoordinates about laptop movements. For more informations read this page of\r\nWikipedia: http://en.wikipedia.org/wiki/Sudden_Motion_Sensor"}}, {"pk": 741, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "pygoogleearth", "license": "MIT", "author": "Paul Osborne", "author_email": "paul-osborne@bethel.edu", "project_url": null, "maintainer_email": "", "home_page": "http://github.com/posborne/pygoogleearth", "version": "0.0.2", "platform": "UNKNOWN", "keywords": "google earth com api googleearth", "summary": "Python wrapper for Google Earth COM API", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Other Environment\nEnvironment :: Win32 (MS Windows)\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nOperating System :: Microsoft :: Windows\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics\nTopic :: Multimedia :: Graphics :: Presentation\nTopic :: Scientific/Engineering :: GIS\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries", "description": "NOTE: This library is not an official google library!  It is a pythonic\r\nwrapper around the COM32 API provided by Google.\r\n\r\nPyGoogleEarth is a pythonic wrapper around the Google Earth\r\nCOM Interface documented here: http://earth.google.com/comapi/.  It\r\nmaps the functionality provided by the API to python objects and reduces\r\nthe barrier-to-entry put up by using win32com.  In addition to wrapping\r\nthe COM API it also provides some nice additions which make it easier\r\nto manipulate Google Earth from python."}}, {"pk": 742, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.dev", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.dev", "version": "1.14", "platform": "any", "keywords": "utility", "summary": "Scripts used to support PyUtilib development.", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "===================\npyutilib.dev README\n===================\n\nThis Python package includes scripts that are used for \ndeveloping PyUtilib within virtual Python installations.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 743, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "seawater", "license": "MIT", "author": "Filipe Fernandes", "author_email": "ocefpaf@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/seawater/", "version": "2.0.1", "platform": "any", "keywords": "oceanography seawater", "summary": "Seawater Libray for Python", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This python package contains a python translation for two Matlab user\ncontributed toolboxes. (1) the\n`seawater <http://www.cmar.csiro.au/datacentre/ext_docs/seawater.htm>`_ (EOS-80)\nand (2) the `gibbs <http://www.teos-10.org/software.htm>`_ seawater (TEOS-10)."}}, {"pk": 744, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "oldowan.fasta", "license": "MIT", "author": "Ryan Raaum", "author_email": "code@raaum.org", "project_url": null, "maintainer_email": null, "home_page": "http://www.raaum.org/software/oldowan", "version": "1.0.2", "platform": "Any", "keywords": "", "summary": "Read and write FASTA format.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "oldowan.fasta is a small bioinformatic utility to read and write sequence data\nin the FASTA_ format. FASTA is the most commonly used simple file format for\nstoring multiple DNA, RNA, or protein sequences in a single file. It is a\ntext-based, human-readable format.\n\nInstallation Instructions\n=========================\n\nThis package is pure Python and has no dependencies outside of the standard\nlibrary. The easist way to install is using ``easy_install`` from the\nsetuptools_ package.  This usually goes something like this::\n\n\t$ easy_install oldowan.fasta\n\nor on a unix-like system, assuming you are installing to the main Python\n``site-packages`` directory as a non-privileged user, this::\n\n\t$ sudo easy_install oldowan.fasta\n\nYou may also use the standard python distutils setup method. Download the\ncurrent source archive from the file list towards the bottom of this page,\nunarchive it, and install. On Mac OS X and many other unix-like systems, having\ndownloaded the archive and changed to the directory containing this archive in\nyour shell, this might go something like::\n\n\t$ tar xvzf oldowan.fasta*\n\t$ cd oldowan.fasta*\n\t$ python setup.py install\n\nQuick Start\n===========\n\noldowan.fasta has an interface based on the standard Python ``file``.  Import\noldowan.fasta::\n\n  >>> from oldowan.fasta import fasta\n\nRead a FASTA format file::\n\n  >>> for entry in fasta('sequences.fasta', 'r'):\n  ...     print entry['name'], len(entry['sequence'])\n\nA more cumbersome, but equivalent way of doing the above::\n\n  >>> fasta_file = fasta('sequences.fasta', 'r')\n  >>> for entry in fasta_file:\n  ...     print entry['name'], len(entry['sequence'])\n  >>> fasta_file.close()\n\nEven more cumbersome, and if the FASTA file is large, potentially\nmemory-draining version (the previous two methods only read one entry at a time\nfrom the file, this reads the whole file into memory at once)::\n\n  >>> fasta_file = fasta('sequence.fasta', 'r')\n  >>> entries = fasta_file.readentries()\n  >>> fasta_file.close()\n  >>> for entry in entries:\n  ...     print entry['name'], len(entry['sequence'])\n\nRead a string of FASTA format sequences::\n\n  >>> fasta_string = open('sequences.fasta', 'r').read()\n  >>> for entry in fasta(fasta_string, 's'):\n  ...     print entry['name'], len(entry['sequence'])\n\nRead a file object::\n\n  >>> fasta_file = open('sequences.fasta', 'r')\n  >>> for entry in fasta(fasta_file, 'f'):\n  ...     print entry['name'], len(entry['sequence'])\n\nWrite to a file::\n\n  >>> fasta_file = open('sequences.fasta', 'w')\n  >>> fasta_file.write({'name':'Sequence1', 'sequence':'AGCTAGCT'})\n  >>> fasta_file.close()\n\nRelease History\n===============\n\n1.0.0 (August 16, 2008)\n    initial release of module.\n\n1.0.1 (March 25, 2009)\n    bug fix updates\n\n1.0.2 (March 26, 2009)\n    update VERSION info\n\n.. _FASTA: http://en.wikipedia.org/wiki/Fasta_format \n.. _setuptools: http://peak.telecommunity.com/DevCenter/EasyInstall"}}, {"pk": 745, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nrnutils", "license": "CeCILL http://www.cecill.info", "author": "Andrew P. Davison", "author_email": "andrewpdavison@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "https://bitbucket.org/apdavison/nrnutils", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "computational science neuroscience simulation", "summary": "Some tools for use with the NEURON simulator (http://www.neuron.yale.edu/neuron/)", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "UNKNOWN"}}, {"pk": 746, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "textmining", "license": "UNKNOWN", "author": "Christian Peccei", "author_email": "cpeccei@hotmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://www.christianpeccei.com/projects/textmining", "version": "1.0", "platform": "UNKNOWN", "keywords": null, "summary": "Python Text Mining Utilities", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Text Processing :: General\nTopic :: Text Processing :: Linguistic", "description": "This package contains a variety of useful functions for text mining in Python.\nIt focuses on statistical text mining (i.e. the bag-of-words model) and makes it\nvery easy to create a term-document matrix from a collection of documents. This\nmatrix can then be read into a statistical package (R, MATLAB, etc.) for further\nanalysis. The package also provides some useful utilities for finding\ncollocations (i.e. significant two-word phrases), computing the edit distance\nbetween words, and chunking long documents up into smaller pieces.\n\nThe package has a large amount of curated data (stopwords, common names, an\nEnglish dictionary with parts of speech and word frequencies) which allows the\nuser to extract fairly sophisticated features from a document.\n\nThis package does NOT have any natural language processing capabilities such as\npart-of-speech tagging. Please see the Python NLTK for that sort of\nfunctionality (plus much, much more)."}}, {"pk": 747, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ETSDevTools", "license": "BSD", "author": "ETS Developers", "author_email": "enthought-dev@enthought.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.enthought.com/projects/ets_dev_tools.php", "version": "3.1.1", "platform": "Windows,Linux,Mac OS-X,Unix,Solaris", "keywords": null, "summary": "Enthought tools to support Python development.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Software Development :: Libraries", "description": "The ETSDevTools project includes a set of packages that can be used during the\ndevelopment of a software project, for understanding, debugging, testing, and\ninspecting code.\n\n- **Enthought Developer Tool Suite** (enthought.developer): A collection of\n  utilities, designed to ease the development and debugging of Traits-based\n  programs. They can be used as plug-ins to your Envisage application while\n  you are developing it, and then removed when you are ready to release it.\n- **Endo**: A Traits-aware tool for processing API documentation of Python\n  code. It extracts not only docstrings, but also plain comments that\n  immediately precede variable assignments (both module-scope variables and\n  class attributes).\n- **enthought.testing**: Scripts related to running unit tests, based on\n  testoob, and also allowing running test suites in separate processes and\n  aggregating the results.\n- **enthought.debug**: A collection of debugging tools, not to be included in\n  production code. NOTE: These tools are functional, but are not being\n  developed or supported. They have been mainly superceded by the tools\n  in the Enthought Developer Tool Suite.\n\nPrerequisites\n-------------\nYou must have the following libraries installed before building or installing\nETSDevTools:\n\n* `Numpy <http://pypi.python.org/pypi/numpy/1.1.1>`_ version 1.1.0 or later is\n  preferred. Version 1.0.4 will work, but some tests may fail.\n* `setuptools <http://pypi.python.org/pypi/setuptools/0.6c8>`_"}}, {"pk": 748, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyOSC", "license": "GNU Lesser General Public License", "author": "Stock", "author_email": "stock@v2.nl", "project_url": null, "maintainer_email": null, "home_page": "http://trac.v2.nl/wiki/pyOSC", "version": "0.3.5b-5294", "platform": "UNKNOWN", "keywords": "OSC,OpenSoundControl", "summary": "Simple OpenSoundControl module in Pure Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Artistic Software\nTopic :: Communications\nTopic :: Other/Nonlisted Topic\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Scientific/Engineering :: Interface Engine/Protocol Translator\nTopic :: Software Development :: Libraries\nTopic :: System :: Networking", "description": "Simple OpenSoundControl module in Pure Python. Replaces the 'SimpleOSC' module.\n  This implementation is intended to still be 'Simple' to the user, but much more complete\n  (with OSCServer & OSCClient classes) and much more powerful\n  (the OSCMultiClient supports subscriptions & message-filtering,\n  OSCMessage & OSCBundle are now proper container-types)\nThis is a 'Pure Python' implementation, intended to be simple and transparent.\n  If you ar looking for a FAST OSC-implementaion, try the 'pyliblo' package"}}, {"pk": 749, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "Divisi2", "license": "http://www.gnu.org/copyleft/gpl.html", "author": "MIT Media Lab, Software Agents group", "author_email": "conceptnet@media.mit.edu", "project_url": null, "maintainer_email": null, "home_page": "http://divisi.media.mit.edu/", "version": "2.2.0", "platform": "any", "keywords": null, "summary": "Divisi2: Commonsense Reasoning over Semantic Networks", "classifiers": "Intended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: C\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering\nTopic :: Software Development\nTopic :: Text Processing :: Linguistic", "description": "Divisi2 is a library for reasoning by analogy and association over\nsemantic networks, including common sense knowledge. Divisi uses a\nsparse higher-order SVD and can help find related concepts, features,\nand relation types in any knowledge base that can be represented as a\nsemantic network. By including common sense knowledge from ConceptNet,\nthe results can include relationships not expressed in the original\ndata but related by common sense. See http://divisi.media.mit.edu/ for\nmore info."}}, {"pk": 750, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pygpiv", "license": "GNU General Public License (GPL)", "author": "Gerber van der Graaf", "author_email": "gerber_graaf@users.sourceforge.net", "project_url": null, "maintainer_email": null, "home_page": "http://gpiv.sourceforge.net/", "version": "1.0.0", "platform": "UNKNOWN", "keywords": "science engineering fluid mechanics experiment piv particle image velocimetry", "summary": "Particle Image Velocimetry module", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: Dutch\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "Python module, wrapped from Libgpiv, for Particle Image Velocimetry. The module is intended for developers on the PIV technique itself and for fluid dynamics researchers and engineers who feel limited by the Gpiv GUI program and the command line programs from the Gpivtools package. So, those may write their own 'quick hacks' easely by using the Python scripting language for rapid development."}}, {"pk": 751, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MetagenomeDB", "license": "MIT/X11 License\nCopyright (c) 2010 Aurelien Mazurie\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.", "author": "Aurelien Mazurie", "author_email": "ajmazurie@oenone.net", "project_url": null, "maintainer_email": null, "home_page": "https://github.com/BioinformaticsCore/MetagenomeDB", "version": "0.2.2", "platform": "UNKNOWN", "keywords": null, "summary": "Metagenome sequences and annotations database", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.6\nTopic :: Database :: Front-Ends\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "MetagenomeDB\n============\n\nNote: the most up-to-date documentation is accessible at http://cores.montana.edu/bioinformatics/tools/MetagenomeDB/\n\nMetagenomeDB is a Python_-based toolkit designed to easily store, retrieve and annotate metagenomic sequences. MetagenomeDB act as an abstraction layer on top of a MongoDB_ database. It provides an API to create and modify and connect two types of objects, namely sequences and collections:\n\n- **sequences** (``Sequence`` class) can be reads, contigs, PCR clones, etc.\n- **collections** (``Collection`` class) represents sets of sequences; e.g., reads resulting from the sequencing of a sample, contigs assembled from a set of reads, PCR library\n\nAny object can be annotated using a dictionary-like syntax::\n\n\t# first, we import the library\n\timport MetagenomeDB as mdb\n\n\t# then we create a new Sequence object with two\n\t# (mandatory) properties, 'name' and 'sequence'\n\ts = mdb.Sequence({\"name\": \"My sequence\", \"sequence\": \"atgc\"})\n\n\t# the object can now be annotated\n\tprint s[\"length\"]\n\ts[\"type\"] = \"read\"\n\n\t# once modified, the object need to be committed\n\t# to the database for the modifications to remain\n\ts.commit()\n\nObjects of type ``Sequence`` or ``Collection`` can be connected to each other in order to represent various metagenomic datasets. Examples include, but are not limited to:\n\n- collection of reads resulting from a sequencing run (relationship between multiple ``Sequence`` objects and one ``Collection``)\n- set of contigs resulting from the assembly of a set of reads (relationship between two ``Collection`` objects)\n- reads that are part of a contig (relationship between multiple ``Sequence`` objects and one ``Sequence``)\n- sequence that is similar to another sequence (relationship between two ``Sequence`` objects)\n- collection that is part of a bigger collection (relationship between two ``Collection`` objects)\n\nThe result is a network of sequences and collection, which can be explored using dedicated methods; i.e.g., ``Collection.list_sequences()``, ``Sequence.list_collections()``, ``Sequence.list_related_sequences()``. Each one of those methods allow for sophisticated filters using the MongoDB `querying syntax <http://www.mongodb.org/display/DOCS/Advanced+Queries>`_::\n\n\t# list all collections of type 'collection_of_reads'\n\t# the sequence 's' belong to\n\tcollections = s.list_collections({\"type\": \"collection_of_reads\"})\n\t\n\t# list all sequences that also belong to these collections\n\t# with a length of at least 50 bp\n\tfor c in collections:\n\t\tprint c.list_sequences({\"length\": {\"$gt\": 50}})\n\nMetagenomeDB also provides a set of command-line tools to import nucleotide sequences, protein sequences, BLAST and FASTA alignment algorithms output, and ACE assembly files. Other tools are provided to add or remove multiple objects, or to annotate them.\n\nKeywords\n--------\n\nMetagenomic, Bioinformatics, Python, MongoDB\n\nContact\n-------\n\nAurelien Mazurie, ajmazurie@oenone.net\n\nGetting started\n---------------\n\nMetagenomeDB relies on another Python library to function, Pymongo_ (version 1.9 or above). The latest version of Pymongo must be installed, for example by typing ``sudo easy_install Pymongo`` on the command line.\n\nThat's it. The only other requirement is, of course, a working MongoDB_ server, either on your computer or on a computer that can be accessed through TCP/IP.\n\nMetagenomeDB can be installed using two methods:\n\nUsing GitHub\n''''''''''''\n\nAll versions of MetagenomeDB, including the latest developer releases, can be downloaded at https://github.com/BioinformaticsCore/MetagenomeDB\n\nOnce the archive in your computer, installing it can be done by typing ``sudo easy_install [path to your archive]`` in a console (see the ``easy_install`` documentation: http://packages.python.org/distribute/easy_install.html).\n\nIf you want more control (such as requesting the library and the tools to be installed in specific directories), you should first unzip the archive, then type ``sudo python setup.py`` plus any needed option from the archive's content directory (see the ``setup.py`` documentation: http://docs.python.org/install/index.html). For example, to ensure the various mdb-* tools are installed in /usr/local/bin/ you can type ``sudo python setup.py install --install-scripts=/usr/local/bin/``.\n\nGitHub is the preferred source if you are interested in the most recent, albeit potentially unstable, releases of MetagenomeDB.\n\nUsing PyPI\n''''''''''\n\nAll production-ready versions of MetagenomeDB are registered against the PyPI_ package manager. Thanks to this, you can install the toolkit by typing ``sudo easy_install MetagenomeDB`` on the command line.\n\nFinal step\n''''''''''\n\nBy default MetagenomeDB will read a file named ``.MetagenomeDB`` in your home directory to know how to access the MongoDB database. A template file named ``doc/installation/MetagenomeDB_configuration.txt`` is provided. Change its name to ``.MetagenomeDB``, move it in your home directory, then update it with your own parameters.\n\nOptionally, you can provide those information when importing MetagenomeDB in your script::\n\n\timport MetagenomeDB as mdb\n\n\tmdb.connect(host = \"localhost\", port = 1234, database = \"MyDatabase\")\n\nFrom then you can store and retrieve objects::\n\n\tc = mdb.Collection.find_one({\"name\": \"my_collection\"})\n\n\tfor sequence in c.list_sequences():\n\t\tprint sequence[\"name\"], sequence[\"sequence\"]\n\n.. _Python: http://www.python.org/\n.. _MongoDB: http://www.mongodb.org/\n.. _Pymongo: http://api.mongodb.org/python\n.. _PyPI: http://pypi.python.org/"}}, {"pk": 752, "model": "importing.pypicache", "fields": {"maintainer": "Raffi Enficiaud", "name": "Yayi", "license": "Boost", "author": "Raffi Enficiaud", "author_email": "raffi.enficiaud@free.fr", "project_url": null, "maintainer_email": "raffi.enficiaud@free.fr", "home_page": "http://raffi.enficiaud.free.fr", "version": "0.07", "platform": "", "keywords": "multidimensional images, multispectral images, mathematical morphology, distance, segmentation, erosion, dilation, opening, closing, hit-or-miss, connected components", "summary": "Image processing and mathematical morphology toolbox", "classifiers": "Development Status :: 3 - Alpha\nOperating System :: MacOS :: MacOS X\nOperating System :: Microsoft :: Windows :: Windows NT/2000\nOperating System :: POSIX :: Linux\nProgramming Language :: C++\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering :: Image Recognition\nTopic :: Scientific/Engineering :: Mathematics", "description": "Yayi is a open-source image processing framework which particularly focuses on Mathematical Morphology operators. It is released under the very permissive Boost licence. The core of Yayi is entirely written in C++, mainly using templatized code which enables a high level of genericity. It implements some of the main concepts of Mathematical Morphology into an efficient and proven design. Yayi aims at providing robust, efficient and flexible algorithms for image analysis, but also reference algorithms for Mathematical Morphology. \r\n\r\nThe python interface of Yayi provides a simple way for using the main notions and functions of mathematical morphology. The export uses the boost.python framework."}}, {"pk": 753, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.opt", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/coopr/coopr.opt", "version": "2.5", "platform": "any", "keywords": "optimization", "summary": "Coopr generic optimization interfaces", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "================\ncoopr.opt README\n================\n\nThis Python package includes generic interfaces for optimization solvers.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * coopr-forum@googlegroups.com\n    - The main list for help and announcements\n  * coopr-developers@googlegroups.com\n    - Where developers of Coopr discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 754, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "ProxyHTTPServer", "license": "Public domain", "author": "", "author_email": "", "project_url": null, "maintainer_email": "", "home_page": "", "version": "0.0.1", "platform": "", "keywords": "ProxyHTTPServer Proxy HTTP Server from the creator of PyWebRun", "summary": "ProxyHTTPServer -- from the creator of PyWebRun", "classifiers": "Development Status :: 2 - Pre-Alpha\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Information Technology\nIntended Audience :: Other Audience\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nIntended Audience :: Telecommunications Industry\nLicense :: Public Domain\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering\nTopic :: Security\nTopic :: Software Development :: Libraries\nTopic :: System :: Logging\nTopic :: System :: Networking :: Monitoring\nTopic :: Utilities", "description": "::\r\n\r\n\r\nFILES LIST\r\n----------\r\nsrc/ProxyHTTPServer.py  proxy based on ThreadingTCPServer and BaseHTTPServer\r\nsrc/logger.py           proxy based on ProxyHTTPServer\r\nsrc/test.py             web server for proxy testing\r\nREADME.txt\r\n\r\n\r\nDEPENDENCES\r\n-----------\r\nPython 2.5.1\r\n\r\n\r\nTUTORIAL\r\n--------\r\nType in your console:\r\npython ProxyHTTPServer.py\r\n\r\nIt run a local proxy server:\r\nServing HTTP on 0.0.0.0 port 8000 ...\r\n\r\nYou must configure your browser to use this proxy:\r\nHTTP: 127.0.0.1\r\nPORT: 8000\r\n\r\nYou can use others ports:\r\npython ProxyHTTPServer.py 8001\r\n\r\nThe first test is to browse on web.\r\nThe second is to run the test server:\r\npython test.py 8080\r\n\r\nYou must browse on:\r\nhttp://localhost:8080/\r\n\r\n\r\nLOGGER\r\n------\r\nType in your console:\r\npython logger.py\r\n\r\nConfigure your browser to use this proxy.\r\nBrowse on http://www.python.org\r\n\r\nThe logger proxy will make a HTML file, like this:\r\ne7e3879e-9aa2-11dc-b850-444553540000.html\r\n\r\nSee the top file with a text editor:\r\n\r\nREQUEST GET\r\nhttp://www.python.org/\r\n[...headers...]\r\n[None with GET]\r\n\r\nRESPONSE 200\r\n[...headers...]\r\n\r\n[...HTML...]"}}, {"pk": 755, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cinfony", "license": "BSD", "author": "Noel O'Boyle", "author_email": "baoilleach@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.googlecode.com/p/cinfony", "version": "1.0", "platform": "Any.", "keywords": null, "summary": "cinfony: a common API to several cheminformatics toolkits", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Software Development :: Libraries :: Python Modules", "description": "cinfony is a Python library that provides a common API to several\nopen source cheminformatics toolkits."}}, {"pk": 756, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "byCycleCore", "license": "Free For Home Use", "author": "Wyatt L Baldwin, byCycle.org", "author_email": "wyatt@byCycle.org", "project_url": null, "maintainer_email": null, "home_page": "http://bycycle.org/", "version": "0.4a0.dev-r1054", "platform": "UNKNOWN", "keywords": "bicycle bike cycyle trip planner route finder", "summary": "byCycle Core Services", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Education\nTopic :: Scientific/Engineering :: GIS", "description": "Address normalization, geocoding, routing and other GIS-related services. We\nstill have not decided on a license, but it will most likely end up being the\nGPL."}}, {"pk": 757, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "scikits.cuda", "license": "BSD", "author": "Lev Givon", "author_email": "lev@columbia.edu", "project_url": null, "maintainer_email": "", "home_page": "http://github.com/lebedov/scikits.cuda/", "version": "0.03", "platform": "Any that support the package requirements.", "keywords": "CUDA, numpy, scipy, scikit, GPU, nvidia, lapack, blas, CULA", "summary": "Python interface to GPU-powered libraries", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "This SciKit (toolkit for `SciPy <http://www.scipy.org>`_) provides Python interfaces to a subset of the functions in the CUDA, CUDART, CUBLAS, and CUFFT libraries distributed as part of `NVIDIA's CUDA Programming Toolkit <http://www.nvidia.com/cuda>`_, as well as interfaces to select functions in the basic and premium versions of the `CULA Toolkit <http://www.culatools.com>`_. In contrast to most existing Python wrappers for these libraries (many of which only provide a low-level interface to the actual library functions), this package uses `PyCUDA <http://mathema.tician.de/software/pycuda/>`_ to provide high-level functions comparable to those in the `NumPy <http://numpy.scipy.org>`_ package."}}, {"pk": 758, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "sidc-gui", "license": "BSD", "author": "Richard Marko", "author_email": "rissko@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/sorki/sidc_gui", "version": "0.2", "platform": "UNKNOWN", "keywords": null, "summary": "Sudden ionospheric disturbance colletor (sidc) GUI", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: X11 Applications\nIntended Audience :: Science/Research\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Visualization", "description": "sidc-gui\n=========\n\nSudden ionospheric disturbance colletor (sidc) GUI.\n\nFeatures:\n----------\n - `sidc <http://github.com/sorki/sidc>`_ data plotting\n - query running sidc instance info\n - live plot\n\nRequirements:\n--------------\n - python 2.6\n - psutil 0.1.3\n - wxPython 2.8\n - matplotlib 0.99.1.1\n\n Note: version numbers are just informative, sidc-gui should work fine with latest versions of the requirements.\n\nInstallation:\n--------------\n - install sidc-gui (`easy_install sidc-gui` or `pip install sidc-gui`)\n - install requirements\n - run `sidc_gui`"}}, {"pk": 759, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "SciTools", "license": "", "author": "Hans Petter Langtangen, Johannes Ring, Ilmar Wilbers, and Rolv Erlend Bredesen", "author_email": "scitools@googlegroups.com", "project_url": null, "maintainer_email": "", "home_page": "http://scitools.googlecode.com", "version": "0.8", "platform": "", "keywords": "", "summary": "Python library for scientific computing", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development", "description": "SciTools is a Python package containing lots of useful tools for scientific\r\ncomputing in Python. The package is built on top of other widely used packages\r\nsuch as NumPy, SciPy, ScientificPython, Gnuplot, etc."}}, {"pk": 760, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mark", "license": "AGPL", "author": "Open Knowledge Foundation", "author_email": "okfn-help@lists.okfn.org", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/mark/", "version": "0.2", "platform": "UNKNOWN", "keywords": "rdf rdflib", "summary": "RDF Bookmarking Utilities", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Affero General Public License v3\nOperating System :: POSIX\nProgramming Language :: Python :: 2.6\nTopic :: Internet\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Software Development :: Libraries :: Python Modules", "description": "RDF Bookmarking Utilities"}}, {"pk": 761, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "ProDy", "license": "GPLv3", "author": "Ahmet Bakan", "author_email": "ahb12 at pitt dot edu", "project_url": null, "maintainer_email": null, "home_page": "http://www.csb.pitt.edu/ProDy", "version": "0.7", "platform": "UNKNOWN", "keywords": "protein,dynamics,elastic network model,Gaussian network model,anisotropic network model,essential dynamics analysis,principal component analysis,Protein Data Bank,PDB,GNM,ANM,PCA", "summary": "A Python Package for Protein Dynamics Analysis", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Chemistry", "description": "TUTORIAL, EXAMPLES, and DOCUMENTATION\n-------------------------------------\n\nhttp://www.csb.pitt.edu/ProDy \n\nSYNOPSIS\n--------\n\nProDy is a free and open-source Python package for analyzing protein structural \ndynamics. It allows for quantitative analysis of heterogeneous experimental \nstructural datasets and comparison with theoretically predicted conformational \ndynamics. It is designed and developed by Ahmet Bakan in Bahar lab at the \nUniversity of Pittsburgh.\n\nThe following are some of the main features:\n\n**Examination and analysis of structural variability observed in experiments:**\n\n  * Fast and flexible parsing of PDB files\n  * Powerful atom selections and contact identification\n  * Matching, superposing, and comparing multiple structures/chains\n  * PCA of X-ray structures, NMR models and mixed structural datasets from Blast search\n\n**Prediction and analysis of protein dynamics using theory and simulation:**\n\n  * Normal Mode Analysis using the Anisotropic network model (ANM)\n  * Gaussian network model (GNM) analysis\n  * Distance and property dependent force constant functions\n  * Essential dynamics analysis (EDA) of MD snapshots\n  * Comparative analysis and visualization of dynamics\n\nLICENSE\n-------\n  \nProDy is available under GNU General Public License version 3. \nSee LICENSE.txt for more details. \n\nBiopython (http://biopython.org/) Blast and KDTree packages and pairwise2 \nmodule are distributed with the ProDy package. Biopython is developed by The \nBiopython Consortium and is available under the Biopython license \n(http://www.biopython.org/DIST/LICENSE).\n\nThe pyparsing (http://pyparsing.wikispaces.com/) module is distributed with \nthe ProDy package. Pyparsing is developed by Paul T. McGuire and is available \nunder the MIT license (http://www.opensource.org/licenses/mit-license.php).\n\nDOWNLOADS & INSTALLATION\n------------------------\n  \n* http://www.csb.pitt.edu/ProDy/getprody.html\n* INSTALL.txt\n\nCHANGES\n-------\n\n* http://www.csb.pitt.edu/ProDy/changes.html\n* CHANGES.txt\n\nSOURCE\n------\n\n* http://github.com/abakan/ProDy\n\nEMAILING LIST\n-------------\n\n* http://groups.google.com/group/prody-dev\n\nREPORT ISSUES\n-------------\n\n* https://github.com/abakan/ProDy/issues"}}, {"pk": 762, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "Pattern", "license": "BSD", "author": "Tom De Smedt", "author_email": "tom@organisms.be", "project_url": null, "maintainer_email": "", "home_page": "http://www.clips.ua.ac.be/pages/pattern", "version": "1.5", "platform": "", "keywords": "", "summary": "web mining module", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP :: Indexing/Search\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Text Processing :: Linguistic\nTopic :: Text Processing :: Markup :: HTML", "description": "Pattern is a web mining module for Python 2.4+. It bundles tools for data retrieval (Google + Twitter + Wikipedia API, web spider, HTML DOM parser), text analysis (rule-based shallow parser, WordNet interface, syntactical + semantical n-gram search algorithm, tf-idf + cosine similarity + LSA metrics) and data visualization (graph networks)."}}, {"pk": 763, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "eke.committees", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/eke-committees", "version": "0.0.0", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer committees", "summary": "EDRN Committee list and membership information for the EDRN Knowledge Environment", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "**************\neke.committees\n**************\n\nThis product, ``eke.committees``, provides display and RDF ingest of committee\ninformation into the EDRN Knowledge Environment (EKE_).  EDRN uses the EKE to\nmake it easy to discover, share, search for, and retrieve all of EDRN's\ncollective knowledge, including cancers and other diseases, biomarkers,\nspecimens, investigators, participants, studies, protocols, and-as in the case\nof this product-committee information.\n\nAlthough intended for the EDRN public portal, it can be installed in any\nPlone_ compatible site.\n\nThis software is developed by the `EDRN Informatics Center`_  at JPL_,\noperated by the California Institute of Technology, for NCI_.\n\n.. References:\n.. _EDRN Informatics Center: http://cancer.jpl.nasa.gov/\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _EKE: http://cancer.jpl.nasa.gov/documents/applications/knowledge-environment\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://cancer.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``eke.committees`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        eke.committees\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        eke.committees\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.  For more\ndetails about specific issue IDs listed below, consult the issue tracker at\nhttps://oodt.jpl.nasa.gov/jira/browse/CA.\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.  Creation of this project was spurred on by these\nissues:\n\n* CA-591 - Broken links on Committees pages\n* CA-718 - Replace manually maintained committee information with RDF ingest\n\n\nCopyright\n=========\n\nCopyright 2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 764, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "eke.ecas", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/eke-ecas", "version": "1.0.1", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers eke ecas datasets data management", "summary": "EDRN Catalog and Archive Service for the EDRN Knowledge Environment", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Database\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "********\neke.ecas\n********\n\nThis product, ``eke.ecas``, provides display and RDF ingest of science data\nfrom the EDRN_ Catalog and Archive Service (ECAS_) into the EDRN Knowledge\nEnvironment (EKE_).  EDRN uses the EKE to make it easy to discover, share,\nsearch for, and retrieve all of EDRN's collective knowledge, including cancers\nand other diseases, biomarkers, specimens, investigators, participants,\nstudies, protocols, and-as in the case of this product-science data.\n\nAlthough intended for the EDRN public portal, it can be installed in any\nPlone_ compatible site.\n\nThis software is developed by the `EDRN Informatics Center`_  at JPL_,\noperated by the California Institute of Technology, for NCI_.\n\n.. References:\n.. _ECAS: http://cancer.jpl.nasa.gov/documents/applications/catalog-and-archive-service\n.. _EDRN Informatics Center: http://cancer.jpl.nasa.gov/\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _EKE: http://cancer.jpl.nasa.gov/documents/applications/knowledge-environment\n.. _JPL: http://www.jpl.nasa.gov/\n.. _NCI: http://cancer.gov/\n.. _Plone: http://plone.org/\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``eke.ecas`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        eke.ecas\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        eke.ecas\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.  For more\ndetails about specific issue IDs listed below, consult the issue tracker at\nhttps://oodt.jpl.nasa.gov/jira/browse/CA.\n\n1.0.1 - Marked Up\n-----------------\n\nThis release addresses the only issue below:\n\n* CA-733 - Ingest of science data should treat custodian field as plain text,\n  not marked up HTML\n\n\n1.0.0 - Freedom!\n----------------\n\nThis following sole issue is the only one addressed by this release:\n\n* CA-654 - Modify \"Lock\" Icon on Science Data Tab\n\n\n0.0.4 - To Be Named At Release Time\n-----------------------------------\n\nThis release addresses the following issues:\n\n* https://oodt.jpl.nasa.gov/jira/browse/CA-575 - Compute PI of a dataset by going\n  from dataset to protocol to lead site to PI at site instead of dataset to sites\n  to PIs at sites.\n* https://oodt.jpl.nasa.gov/jira/browse/CA-576 - Datasets without Protocols\n  should not be displayed on the Science Data tab\n* https://oodt.jpl.nasa.gov/jira/browse/CA-523 - Create search indexes; in\n  particular, this updates the related protocol so that searching for a dataset\n  by name will also match the related protocol.\n\n\n0.0.3 - I say Tomato...\n-----------------------\n\nThis release addresses the following issues:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-512 - Improve indexing on searches related to \n  eCAS data sets  \n\n\n0.0.2\n-----\n\nThis release addresses the following issues:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-501 - Disclaimer needed on\n  dataset folders.\n* http://oodt.jpl.nasa.gov/jira/browse/CA-502 - Show all datasets but prompt\n  for login based on permissions\n* http://oodt.jpl.nasa.gov/jira/browse/CA-510 - Lock box for science data and\n  biomarkers should disappear if a user has access to the object\n\n\n0.0.1 - You Say Potato...\n-------------------------\n\nThis release addresses the following issues:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-463 - Change \"Body Systems\" under\n  Science Data Tab Contents to Organ\n* http://oodt.jpl.nasa.gov/jira/browse/CA-492 - Portal dataset view only seems\n  to respect QAState (and not AccessGrantedTo).\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 765, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PythonNURBS", "license": "GPL-3", "author": "Oliver Borm", "author_email": "oli.borm@web.de", "project_url": null, "maintainer_email": null, "home_page": "http://pypi.python.org/pypi/PythonNURBS", "version": "0.3", "platform": "UNKNOWN", "keywords": null, "summary": "PythonNURBS is the Python language binding for the NURBS++ library.", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nTopic :: Scientific/Engineering :: Physics", "description": "UNKNOWN"}}, {"pk": 766, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "totalopenstation", "license": "GNU GPLv3", "author": "Stefano Costa", "author_email": "steko@iosa.it", "project_url": null, "maintainer_email": null, "home_page": "http://tops.berlios.de/", "version": "0.2.0dev", "platform": "UNKNOWN", "keywords": "survey geodimeter", "summary": "Download and export survey data from your total station", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: X11 Applications\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "====================\n Total Open Station\n====================\n\nTotal Open Station (TOPS for friends) is a free software program for\ndownloading and processing data from total station devices, written in\nthe Python programming language.\n\nThis is a task which is usually done by proprietary, dedicated and\nWindows\u2122-only software, but TOPS is different by nature, because:\n\n- it is *free software* released under the GNU GPLv3 license;\n- it works on *any* operating system, including mobile platforms like\n  OpenMoko;\n- it is designed to support as many devices and formats as possible, all\n  within the same program, opposed to having one program per device.\n\nEvery model has its own quirks, but TOPS uses a modular structure and\nkeeps the downloading of data logically separated from its processing,\nthus enabling exporting data to a variety of output formats, even at a\nlater moment. Archiving of raw data is made easy by using plain text\nfiles.\n\nThe application icons are copyright by Lapo Calamandrei 2008.\n\nGUI\n===\n\nThe ``totalopenstation-gui`` module is a simple, yet complete\ngraphical user interface for Total Open Station that allows to\ndownload, open and save raw data and export into the available output\nformats. It is currently based on Tkinter and works on all major\nplatforms (tested on GNU/Linux and Microsoft Windows).\n\nCLI\n===\n\nThe ``totalopenstation-cli-connector`` module is a command line\nuser interface to download and save raw data, while its companion\n``totalopenstation-cli-parser`` is responsible for parsing and\nexporting data.\n\nDocumentation\n=============\n\nDocumentation is available at in the ``docs`` subdirectory of this\npackage and online at http://tops.berlios.de/ with an user guide,\ndetails on the application structure, supported models and other\nstuff."}}, {"pk": 767, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "neuronvisio", "license": "GPLv3", "author": "Michele Mattioni", "author_email": "mattioni@ebi.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://mattions.github.com/neuronvisio/", "version": "0.5.2", "platform": "UNKNOWN", "keywords": "neuron,gui,pylab,3D,visualization", "summary": "NeuronVisio is a Graphical User Interface for NEURON simulator enviroment", "classifiers": "Development Status :: 4 - Beta\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Visualization", "description": "Neuronvisio\n===========\n\nWhat is it\n----------\n\nNeuronVisio is a Graphical User Interface for `NEURON simulator enviroment \n<http://www.neuron.yale.edu/neuron/>`_. \nNeuronVisio connect with NEURON using the new python NEURON interface.\n\nFeatures\n--------\n\n- 3D visualization of the model with the possibility to change it runtime\n- Creation of vectors to record any variables present in the section \n- Pylab integration to plot directly the result of the simulation\n- Exploration of the timecourse of any variable among time using a color \ncoded scale\n- the GUI runs in its own thread so it's possible to use the console \n(strongly suggested to run through ipython)\n\n\nMore info are available on the homepage: http://mattions.github.com/neuronvisio/\n\nOffline Documentation\n---------------------\n\nTo create offline documentation similar to the one online you will need \n`sphinx http://sphinx.pocoo.org/` installed.\n\nMove in the doc directory::\n    \n    cd doc\n    \nand then launch::\n\n    sphinx-build . html\n\nIn the html directory you will have the online doc."}}, {"pk": 768, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "edrnsite.policy", "license": "Proprietary", "author": "Sean Kelly", "author_email": "sean.kelly@jpl.nasa.gov", "project_url": null, "maintainer_email": null, "home_page": "http://cancer.jpl.nasa.gov/products/edrnsite-policy", "version": "1.0.5", "platform": "UNKNOWN", "keywords": "web zope plone edrn cancer biomarkers policy", "summary": "EDRN Public Portal Site Policy and Component Orchestration", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nFramework :: Plone\nIntended Audience :: Healthcare Industry\nIntended Audience :: Science/Research\nLicense :: Other/Proprietary License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "***************\nedrnsite.policy\n***************\n\nThis is the \"policy\" product for the public portal of the Early Detection\nResearch Network (EDRN_).  This product, intended for Plone_, specifies no\ncustom content types or look-and-feel, but instead specifies minimum policy\nsettings and orchestrates all other dependent components.  So, to turn a\nPlone_ site into the EDRN public portal, just install this component.\n\nIt was developed by the Informatics Center (IC_), operated by JPL_.\n\n.. References:\n.. _EDRN: http://edrn.nci.nih.gov/\n.. _IC: http://cancer.jpl.nasa.gov/\n.. _JPL: http://www.jpl.nasa.gov/\n.. _Plone: http://plone.org/\n\n\n\nInstallation\n============\n\nUse Buildout_ with the plone.recipe.zope2instance recipe.\n\n* Add ``edrnsite.policy`` to the list of eggs to install, e.g.::\n \n    [buildout]\n    ...\n    eggs =\n        ...\n        edrnsite.policy\n        \n* Tell the plone.recipe.zope2instance recipe to install a ZCML slug::\n  \n    [instance]\n    recipe = plone.recipe.zope2instance\n    ...\n    zcml =\n        edrnsite.policy\n        \n* Re-run buildout, e.g. with::\n  \n    % ./bin/buildout\n        \nYou can skip the ZCML slug if you are going to explicitly include the package\nfrom another package's configure.zcml file.\n\n.. References:\n.. _Buildout: http://www.buildout.org/\n\n\nChangelog\n=========\n\nWhat follows is a history of changes from release to release.  More detail\nabout the issues mentioned here can be found at the issue tracker, at::\n\n    https://oodt.jpl.nasa.gov/jira/browse/CA\n\n\n1.0.5 - NCI Hates Cookies\n-------------------------\n\nThe following issues were addressed in this release:\n\n* CA-743 - Disable Google Analytics\n* CA-742 - Apply fix for CVE-2011-0720\n* CA-597 - Add clock event to update sign-in secret\n\n\n1.0.4 - The Googles, They Do Nothing\n------------------------------------\n\nThe following issue was addressed in this release:\n\n* CA-726 - Google verification now requires specific page content\n\n\n1.0.3 - A Mixed Bag\n-------------------\n\nThe following issues were addressed in this release:\n\n* CA-681 - Fix the word staffers to say just staff\n* CA-698 - \"Structural\" objects appear in searches\n\n\n1.0.2 - Specimen Search\n-----------------------\n\nThis time around, the policy package implements a dynamic search page for EDRN\nspecimens.  (There is no corresponding issue in the issue tracker for this new\nfeature; or if there is, the issue tracker is down as I write this and can't\nconfirm.)\n\nThe following issues are also addressed by this release:\n\n* CA-684 - Breadcrumb links are not correct on specimen search tab\n* CA-667 - Organ and title edits that were added were lost when re-ingesting\n\n\n1.0.1 - Ingest Cleanup\n----------------------\n\nThis release addresses the following:\n\n* CA-649 - Automatic ingest is not updating publication state\n* CA-662 - Remove \"Potential Link Breakage\" message from automatic ingest\n\nIt also adds a dynamic list of EDRN members and allows YouTube videos to be\nembedded in portal pages.  See the issue tracker at\nhttps://oodt.jpl.nasa.gov/jira/browse/CA for more details.\n\n\n1.0.0 - Automation Spam\n-----------------------\n\nThis release addresses several issues: the automatic periodic ingest of RDF\ninformation into the portal from its various information sources.  You can\nread more about this issue at https://oodt.jpl.nasa.gov/jira/browse/CA-528.\n\nIt also adds search and tracking of tissue and other specimens from ERNE, the\nEDRN Resource Network Exchange.\n\nFinally, it reworks the logic by which the emailed portal notices are sent.\nPreviously, any content addition, deletion, modification, or any content\npublication state change would trigger an email to the DMCC.  These included\nall changes during RDF ingest, which could amount to thousands of such\nchanges.\n\nNow, the email notice is sent solely if the user who's doing the change is a\nmember of the \"National Cancer Institute\" group.  For more details on this\nupdate, see https://oodt.jpl.nasa.gov/jira/browse/CA-644.\n\n\n0.0.7 - The Eleventh Hour\n-------------------------\n\nAfter viewing the new look-and-feel for EDRN across a variety of applications,\nmanagement suddenly realizes they don't like it.  This release attempts to\nsatisfy them.  See https://oodt.jpl.nasa.gov/jira/browse/CA-599 for more.\n\n\n0.0.6 - Jackie Hates Our Content\n--------------------------------\n\nIn release 0.0.6 of this component, we've addressed the following issues:\n\n* https://oodt.jpl.nasa.gov/jira/browse/CA-577 - Update the Sample Reference\n  Sets page\n* https://oodt.jpl.nasa.gov/jira/browse/CA-579 - Access to secure web site\n  link goes to wrong URL\n* https://oodt.jpl.nasa.gov/jira/browse/CA-582 - Publications missing authors\n\n\n0.0.5 - Content in Four Part Harmony\n------------------------------------\n\nThe following issues are addressed in this release:\n\n* Content harmonized between the old operational portal (version 2) and beta\n  demonstration portal (version 3 at http://edrn.jpl.nasa.gov/portal3.0).\n* https://oodt.jpl.nasa.gov/jira/browse/CA-379 - Generate email notification\n  to DMCC when portal changes are approved at NCI\n* https://oodt.jpl.nasa.gov/jira/browse/CA-540 - PI not showing for a site\n* https://oodt.jpl.nasa.gov/jira/browse/CA-541 - Add to software repository\n* https://oodt.jpl.nasa.gov/jira/browse/CA-549 - Biological Specimens Link\n  under Resources - Page doesn't exist\n* https://oodt.jpl.nasa.gov/jira/browse/CA-559 - The current EDRN-Wide\n  Collaborations link downloads a protocol search html\n* https://oodt.jpl.nasa.gov/jira/browse/CA-561 - Subscription to a listserv\n  link - page doesn't exist\n* https://oodt.jpl.nasa.gov/jira/browse/CA-563 - Remove CDE Links from Portal\n\n\n0.0.4 - To Be Named At Release Time\n-----------------------------------\n\nThe following issues are addressed in this release:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-526 - Duplicate science-data\n  deployed as part of portal setup\n\n\n0.0.3 - EDRN SC Meeting 2010 RDF-ification\n------------------------------------------\n* http://oodt.jpl.nasa.gov/jira/browse/CA-521 - Load EDRN SC Mar 2010 meeting RDF into portal cache\n* http://oodt.jpl.nasa.gov/jira/browse/CA-498 - Disable mailing of\n  password-reset messages.\n* http://oodt.jpl.nasa.gov/jira/browse/CA-508 - Travel Fellowships out-of-date\n* http://oodt.jpl.nasa.gov/jira/browse/CA-509 - Research Tools need updating\n\n\n0.0.2 - Starting Content & Polish\n---------------------------------\n\nThis release includes a refresh cache of knowledge from the EDRN Catalog and\nArchive Service, the Biomarker Database, and the EDRN DMCC RDF Service.  In\naddition, this release addresses the following issues:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-482 - For Researchers - EDRN\n  Investigators' Publications - Page Doesn't Exist\n* http://oodt.jpl.nasa.gov/jira/browse/CA-481 - Remove CDE Spreadsheet and\n  PDF.  Add CDE Search\n* http://oodt.jpl.nasa.gov/jira/browse/CA-480 - Study Design Guidance Tools\n  page in \"old\" format\n* http://oodt.jpl.nasa.gov/jira/browse/CA-478 - Public, Patients, Advocates -\n  EDRN Informatics link - Page Does Not Exist\n* http://oodt.jpl.nasa.gov/jira/browse/CA-470 - List of \"BDL\" sites point to\n  old DMCC site\n* http://oodt.jpl.nasa.gov/jira/browse/CA-435 - Remove :log in to add comments\n  from public portal pages\n* http://oodt.jpl.nasa.gov/jira/browse/CA-486 - Application Procedure, Receipt\n  Dates, and Review - Contact Investigator Link - Page Doesn't Exist\n\n\n0.0.1 - Content Updates and Broken Links\n----------------------------------------\n\nThe following issues have been addressed in this release:\n\n* http://oodt.jpl.nasa.gov/jira/browse/CA-469 - List of sites on \"About EDRN\"\n  still points to the old site at DMCC\n* http://oodt.jpl.nasa.gov/jira/browse/CA-471 - Under patient advocates, press\n  releases - sorry page doesn't exist...\n* http://oodt.jpl.nasa.gov/jira/browse/CA-467 - PI page does not exist from EC\n  page\n\n\n0.0.0 - Unreleased\n------------------\n\nInitial release into beta.\n\n\nCopyright\n=========\n\nCopyright 2009-2010 by the California Institute of Technology.  ALL RIGHTS\nRESERVED.\n\nThe Software is owned by Caltech/JPL and is protected by United States\ncopyright laws and applicable international treaties and/or conventions.  The\nUnited States Government may have prior rights to use some or all of the\nSoftware as determined under applicable contracts and license agreements with\nCaltech/JPL.\n\nThis software was developed at the Jet Propulsion Laboratory, an operating\ndivision of the California Institute of Technology and is not available for\nuse by any person, organization, or other entity without prior, specific\nwritten permission."}}, {"pk": 769, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "biskit", "license": "UNKNOWN", "author": "Raik Gruenberg, Johan Leckner and others", "author_email": "raik.gruenberg@crg.es", "project_url": null, "maintainer_email": null, "home_page": "http://biskit.pasteur.fr", "version": "2.3.1", "platform": "UNKNOWN", "keywords": null, "summary": "A Python platform for structural bioinformatics", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: MacOS :: MacOS X\nOperating System :: OS Independent\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Physics", "description": "Biskit is a modular, object-oriented Python library for structural\n bioinformatics research. It facilitates the manipulation and analysis\n of macromolecular structures, protein complexes, and molecular\n dynamics trajectories. For efficient number crunching, Biskit objects\n tightly integrate with numpy. Biskit also offers a platform for the\n rapid integration of external programs and new algorithms into complex\n workflows. Calculations are thus often delegated to established\n programs like Xplor, Amber, Hex, Prosa, Fold-X, T-Coffee, Hmmer and\n Modeller; interfaces to further software can be added easily."}}, {"pk": 770, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "nltk", "license": "Apache License, Version 2.0", "author": "Steven Bird, Edward Loper, Ewan Klein", "author_email": "sb@csse.unimelb.edu.au", "project_url": null, "maintainer_email": null, "home_page": "http://www.nltk.org/", "version": "2.0b9", "platform": "UNKNOWN", "keywords": "NLP,CL,natural language processing,computational linguistics,parsing,tagging,tokenizing,syntax,linguistics,language,natural language", "summary": "Natural Language Toolkit", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Information Technology\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Apache Software License\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Human Machine Interfaces\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Text Processing\nTopic :: Text Processing :: Filters\nTopic :: Text Processing :: General\nTopic :: Text Processing :: Indexing\nTopic :: Text Processing :: Linguistic", "description": "The Natural Language Toolkit (NLTK) is a Python package for\nprocessing natural language text.  NLTK requires Python 2.4 or higher."}}, {"pk": 771, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "randomdotorg", "license": "UNKNOWN", "author": "Clovis Fabricio", "author_email": "nosklo at gmail dot com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/randomdotorg/", "version": "0.1.3a1", "platform": "UNKNOWN", "keywords": null, "summary": "random.org number generator interface module", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Plugins\nIntended Audience :: Developers\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "randomdotorg.py is a python module to implement python's random number interface\nby fetching data from random.org, which is is a true random number service\nthat generates randomness via atmospheric noise.\n\nExample of use:\n\n>>> r = randomdotorg.RandomDotOrg()\n>>> r.get_quota() # method to get allowed bit quota for this ip\n999171\n>>> print r.randrange(2, 33, 3)\n14\n\nMethods supported by the standard library random module are supported, except\nfor save/load state and seeding which won't make sense for a true random number\ngenerator."}}, {"pk": 772, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "GChartWrapper", "license": "BSD License", "author": "Justin Quick", "author_email": "justquick@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://code.google.com/p/google-chartwrapper/", "version": "0.9", "platform": "Windows,Linux,Solaris,Mac OS-X,Unix", "keywords": null, "summary": "Python Google Chart Wrapper", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nEnvironment :: Web Environment\nFramework :: Django\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nProgramming Language :: Python :: 2\nProgramming Language :: Python :: 2.3\nProgramming Language :: Python :: 2.4\nProgramming Language :: Python :: 2.5\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.0\nProgramming Language :: Python :: 3.1\nProgramming Language :: Python :: 3.2\nTopic :: Artistic Software\nTopic :: Internet :: WWW/HTTP\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Internet :: WWW/HTTP :: Dynamic Content :: CGI Tools/Libraries\nTopic :: Multimedia\nTopic :: Multimedia :: Graphics\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: Utilities", "description": "Python wrapper for the Google Chart API. \nThe wrapper can render the URL of the Google chart, based on your parameters, \nor it can render an HTML img tag to insert into webpages on the fly. \nMade for dynamic python websites (Django,Zope,CGI,etc.) that need on the fly \nchart generation without any extra modules. Can also grab the PIL Image \ninstance of the chart for manipulation. Works for Python 2 and 3"}}, {"pk": 773, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "topzootools", "license": "UNKNOWN", "author": "Simon Knight", "author_email": "simon.knight@adelaide.edu.au", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/topologyzootools/", "version": "0.0.6", "platform": "UNKNOWN", "keywords": null, "summary": "Processing and conversion tools for Internet Topology Zoo", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nIntended Audience :: Telecommunications Industry\nLicense :: Other/Proprietary License\nOperating System :: MacOS :: MacOS X\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: System :: Networking\nTopic :: System :: Software Distribution", "description": "Processing and conversion tools for Internet Topology Zoo"}}, {"pk": 774, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "Geohash", "license": "GNU Affero General Public License as published by the Free Software Foundation,\r\neither version 3 of the License, or (at your option) any later version.", "author": "Leonard Norrgard", "author_email": "leonard.norrgard@refactor.fi", "project_url": null, "maintainer_email": "", "home_page": "http://www.refactor.fi/software/gis/geohash/", "version": "1.0rc1", "platform": "UNKNOWN", "keywords": "Geohash GIS latitude longitude encode decode Galileo GPS WGS84 coordinates geotagging", "summary": "Module to decode/encode Geohashes to/from latitude and longitude.  See http://en.wikipedia.org/wiki/Geohash", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nLicense :: OSI Approved\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This module provides functions to decode and encode Geohashes to and from\r\nlatitude and longitude coordinates."}}, {"pk": 775, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "DataFile", "license": "LICENSE.txt", "author": "JMA", "author_email": "jeanmichel.arbona@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "UNKNOWN", "version": "0.1.6", "platform": "UNKNOWN", "keywords": null, "summary": "Easy way to read data files", "classifiers": "Development Status :: 2 - Pre-Alpha\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "=========\nData File\n=========\n\nThis package provides an easy way to open a datafile\nby returning a \"modified\" dictionnary (see Guessing) of numpy arrays that corresponds\nto the differents columns.If the column contains strings it will return an array of strings.\n\nBy default it will try to guess the indexation from the commentaries, and if failed will index it \nfrom 0 to n::\n\n\n\t\t #!/usr/bin/env python\n\t\t \n\t\t from datafile.extractfile import dataFile\n\n\t\t f = dataFile(\"./datafile/test/testdocfile.txt\")\n\t\t # the index will be guessed and if not found it will\n\t\t # be indexed from 0 to n\n\t\t \n\t\t f = dataFile(\"./datafile/test/testdocfile.txt\",index=\"auto\")\n\t\t #f will be indexed from 0 to n\n\t\t \t\t \n\t\t #f[\"0\"] will return a numpy array of the first column.\n\t\t #f[\"0\",1] will return a numpy array of the index number 1 of the first column,\n\t\t # if the column is divided in index (ensemble of points separated by one or more space)\n\n\t\t f = dataFile(\"./datafile/test/testdocfile.txt\" , \"A B C D\")\n\t\t #f will be indexed on \"A\" \"B\" \"C\" (if three columns)\n\t\t f = dataFile(\"./datafile/test/testdocfile.txt\" , [\"A\", \"B\",\"C\",\"D\"]\n\t\t #f will be indexed on \"A\" \"B\" \"C\"\n\n\nGuessing\n========\n\nif the datafile contains in the commentaries a line like:\n#Lx(nm) Ly(nm) D(A)\nand the file at three column, it will index the three columns\nwith \"Lx(nm)\" \"Ly(nm)\" , \"D(A)\"::\n\t\t \n\t\t #!/usr/bin/env python\n\t\t f = dataFile(\"./file\")\n\t\t f[\"Lx\"]\n\t\t f[\"x\"]\n\t\t #both are going to return the first column\n\t\t f[\"nm\"]\n\t\t #will return a key error\t \n\n\nMain usage\n==========\n\nI use it with ipython to plot datas and explore them.\nLauching ipython -pylab will launch a ipython with\nmatplotlib loaded.\nAfter loading the file with dataFile you can plot the data\nwith only typping plot(f[\"A\"],f[\"B\"])\n\n\nemail : jeanmichel.arbona@gmail.com"}}, {"pk": 776, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "tilelive", "license": "BSD", "author": "Dane Springmeyer, Tom MacWright", "author_email": "dbsgeo@gmail.com, macwright@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/tmcw/TileLiteLive", "version": "0.1.3.2", "platform": "UNKNOWN", "keywords": "mapnik,gis,geospatial,openstreetmap,tiles,cache", "summary": "Lightweight WSGI tile-server, written in Python, using Mapnik rendering and designed to serve tiles in the OSM/Google scheme.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP :: Dynamic Content\nTopic :: Scientific/Engineering :: GIS\nTopic :: Utilities", "description": "UNKNOWN"}}, {"pk": 777, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "firkin", "license": "GPL", "author": "Florian Diesch", "author_email": "devel@florian-diesch.de", "project_url": null, "maintainer_email": null, "home_page": "http://www.florian-diesch.de/software/firkin/", "version": "0.02", "platform": "UNKNOWN", "keywords": "measurement units convert conversion", "summary": "convert between different measurement units", "classifiers": "Development Status :: 3 - Alpha\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nNatural Language :: German\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries", "description": "What is firkin?\n===============\n\nfirkin is a python module to convert between different measurement\nunits.\n\n\nUsage\n=====\n\nFirst we create an instance of `UnitManager`::\n\n>>> um=UnitManager()\n    \nNext we create two families of units. The first one ist ``liter`` and\nuses ``SIFamily`` to automatically create units with the SI prefixes::\n     \n    >>> um.add(SIFamily(base='l', name='liter'))\n\nNow our ``UnitManager`` knows about fl, pl, nl, ..., Ml, Gl, Tl.\n\nHow many liters are 10000 ml?::\n\n    >>> um.convert_to_unit(1e4, 'ml', 'l')\n    (Decimal(\"10.0000\"), 'l')\n\nNext we create a family by hand::\n    \n    >>> f=Family(name='f', base='gallon')\n    >>> f.add('barrel', 36, 'gallon')\n    >>> f.add('kilderkin', 0.5, 'barrel')\n    >>> f.add('firkin', 0.5, 'kilderkin')\n\nNow we have a family called ``f`` that used gallon as its base and knows about \nbarrel, kilderkin and firkin, too.\n\nHow much gallons is one firkin?::\n\n    >>> f.convert(1, 'firkin', 'gallon')\n    (Decimal(\"9.00\"), 'gallon')\n\nWhat's the best way to express 3 kilderkin?::\n\n    >>> f.autoconvert(3, 'kilderkin')\n    (Decimal(\"1.50\"), 'barrel')\n\nTo convert between family ``f`` and family ``liter`` we need to add ``f`` to\nour ``UnitManager`` and tell how much liters (base unit of family ``liter``) a\ngallon (base unit of family ``f``) is::\n\n    >>> um.add(f, other='liter',  factor=4.54609)\n\nOf course the ``UnitManger`` can convert firkin to gallon, too::\n\n    >>> um.convert_to_unit(1, 'firkin', 'gallon')\n    (Decimal(\"9.00\"), 'gallon')\n\nBut it also can convert firkin to liters::\n\n    >>> um.convert_to_unit(1, 'firkin', 'l')\n    (Decimal(\"40.9148100\"), 'l')\n\nOr find the best way to express one liter in one of the units from\nfamily ``f``::\n\n   >>> um.convert_to_family(1, 'l', 'f')\n   (Decimal(\"0.219969248299\"), 'gallon')\n\nThat works with barrels, too::\n\n   >>> um.convert_to_family(1, 'barrel', 'f')\n   (Decimal(\"1.00\"), 'barrel')"}}, {"pk": 778, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyTerra", "license": "UNKNOWN", "author": "Howard Butler", "author_email": "hobu.inc@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/hobu/pyterra/", "version": "0.8", "platform": "UNKNOWN", "keywords": null, "summary": "Terraserver Module for Python", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: Python Software Foundation License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "UNKNOWN"}}, {"pk": 779, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "quickndirty", "license": "GPL", "author": "wilson freitas", "author_email": "wilson.freitas@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://aboutwilson.net/Quick_and_dirty", "version": "1.02", "platform": "ALL", "keywords": "Random, Stochastic Processes, quick and dirty, simulation", "summary": "Quick and dirty random number generator to Python", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Financial and Insurance Industry\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nProgramming Language :: C\nProgramming Language :: Python\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics", "description": "Python C module that implements the quick and dirty random number generator.\r\nThis release comes with two new methods:\r\n. randint - generates 32bits random integers\r\n. randomseq - generate random sequences\r\n\r\nand more tests:\r\n. central limit theorem\r\n. computing pi with Monte Carlo\r\n. spatial correlations\r\n. and more"}}, {"pk": 780, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "PySieve", "license": "UNKNOWN", "author": "Severin Bannert", "author_email": "severin.bannert@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/dansefatale/PySieve", "version": "0.5.1", "platform": "UNKNOWN", "keywords": null, "summary": "Fast prime factorization using the msieve library", "classifiers": "Intended Audience :: Science/Research\nProgramming Language :: C\nTopic :: Scientific/Engineering :: Mathematics", "description": "==========================================\nPysieve -- fast prime factoring for python\n==========================================\n\nPysieve is a simple wrapper of the msieve prime factorization library.\nIt basically gives you a fast factor command and some utilities.\n\nFor now it is only tested on OSX with python 2.6 and msieve146 but it\nshould work on Linux as well.  It assumes that the msieve library is\ninstalled in a standard location (i.e /usr/local/lib, /usr/lib or on\nOSX with macports /opt/local/lib)\n\nFunctions in the package\n========================\n\n* factor(n): returns a list of the prime factors of n\n\n* dfactor(n): returns a list of distinct prime factors of n (no\n  duplicates)\n\n* facExponents(n): returns a list of tuples, each containing a prime\n  factor of n and its exponent\n\nTODO \n==== \n* _pysieve is installed as seperate package. I somehow can't\n\tdefine it to be a subpackage of pysieve (like pysieve._pysieve)\n\n\nCredits\n=======\n\nThe msieve library can be downloaded at\nhttp://sourceforge.net/projects/msieve/"}}, {"pk": 781, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyformex", "license": "GNU General Public License (GPL)", "author": "Benedict Verhegghe", "author_email": "benedict.verhegghe@ugent.be", "project_url": null, "maintainer_email": null, "home_page": "http://pyformex.org", "version": "0.8.3", "platform": "UNKNOWN", "keywords": null, "summary": "A tool to generate and manipulate complex 3D geometries.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nEnvironment :: X11 Applications :: Qt\nIntended Audience :: Education\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nOperating System :: POSIX\nOperating System :: POSIX :: Linux\nProgramming Language :: C\nProgramming Language :: Python\nTopic :: Multimedia :: Graphics :: 3D Modeling\nTopic :: Multimedia :: Graphics :: 3D Rendering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Scientific/Engineering :: Physics\nTopic :: Scientific/Engineering :: Visualization", "description": "pyFormex is a tool for generating, manipulating and operating on \nlarge geometrical models of 3D structures by sequences of mathematical\ntransformations."}}, {"pk": 782, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "dap.plugins.gdal", "license": "MIT", "author": "Roberto De Almeida", "author_email": "rob@pydap.org", "project_url": null, "maintainer_email": null, "home_page": "http://pydap.org/plugins/gdal.html", "version": "0.1.1", "platform": "UNKNOWN", "keywords": "gdal dap opendap dods data", "summary": "GDAL plugin for pydap server", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "This is a plugin for serving geospatial data in pydap using the\nGeospatial Data Abstraction Library (GDAL).\n      \nThe latest version is available in a `Subversion repository\n<http://pydap.googlecode.com/svn/trunk/plugins/gdal#egg=dap.plugins.gdal-dev>`_."}}, {"pk": 783, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyfeyn", "license": "GPL", "author": "Andy Buckley,Georg von Hippel", "author_email": "pyfeyn@projects.hepforge.org", "project_url": null, "maintainer_email": null, "home_page": "http://projects.hepforge.org/pyfeyn/", "version": "0.3.1", "platform": "UNKNOWN", "keywords": "feynman hep physics particle diagram", "summary": "An easy-to-use Python library to help physicists draw Feynman diagrams.", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Artistic Software\nTopic :: Scientific/Engineering :: Physics", "description": "PyFeyn is a package which makes drawing Feynman diagrams simple and programmatic.\nFeynman diagrams are important constructs in perturbative field theory, so being able to draw them\nin a programmatic fashion is important if attempting to enumerate a large number of diagram\nconfigurations is important. The output quality of PyFeyn diagrams (into PDF or EPS formats)\nis very high, and special effects can be obtained by using constructs from PyX, which PyFeyn\nis based around."}}, {"pk": 784, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "dot2tex", "license": "MIT", "author": "Kjell Magne Fauske", "author_email": "kjellmf@gmail.com", "project_url": null, "maintainer_email": "", "home_page": "http://www.fauskes.net/code/dot2tex/", "version": "2.8.7", "platform": "UNKNOWN", "keywords": "", "summary": "A Graphviz to LaTeX converter", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Visualization\nTopic :: Text Processing :: Markup :: LaTeX\nTopic :: Utilities", "description": "The purpose of dot2tex is to give graphs generated by the graph layout tool\r\nGraphviz_, a more LaTeX friendly look and feel. This is accomplished by:\r\n\r\n- Using native PSTricks_ and `PGF/TikZ`_ commands for drawing arrows,\r\n  edges and nodes.\r\n- Typesetting labels with LaTeX, allowing mathematical notation.\r\n- Using backend specific styles to customize the output.\r\n\r\nDot2tex can also automatically adjust the size of nodes and edge labels to fit\r\nthe output from LaTeX.\r\n\r\n.. _Graphviz: http://www.graphviz.org/\r\n.. _PSTricks: http://tug.org/PSTricks/main.cgi/\r\n.. _PGF/TikZ: http://www.ctan.org/tex-archive/help/Catalogue/entries/pgf.html"}}, {"pk": 785, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "stats-tools", "license": "MIT", "author": "Jonhnny Weslley", "author_email": "jw@jonhnnyweslley.net", "project_url": null, "maintainer_email": null, "home_page": "http://github.com/jweslley/stats-tools", "version": "0.1.0", "platform": "Linux,Unix,Mac OS X,Windows", "keywords": null, "summary": "A set of command-line statistics tools", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nOperating System :: MacOS\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering", "description": "stats-tools - A set of command-line statistics tools\n====================================================\n\n.. contents::\n\nInstallation\n------------\n\nDependencies\n````````````\n * numpy\n * scipy\n\nOn Debian systems, you may install them by running::\n\n  sudo apt-get install python-numpy python-scipy\n\nInstalling stats-tools\n``````````````````````\n\nInstall ``stats-tools`` by using ``easy_install``::\n\n  sudo easy_install stats-tools\n\nOr checkout from git repository::\n\n  git clone git://github.com/jweslley/stats-tools.git\n  cd stats-tools\n  sudo python setup.py install\n\n\nUtilities\n---------\n\n * **min** - Calculate the minimum of a number sequence\n * **max** - Calculate the maximum of a number sequence\n * **mean** - Calculate the mean of a number sequence\n * **median** - Calculate the median of a number sequence\n * **std** - Calculate the standard deviation of a number sequence\n * **var** - Calculate the variance of a number sequence\n * **sum** - Calculate the sum of a number sequence\n * **stats** - Output a summary table including mean, median, mininum, maximum, standard deviation and variance of a number sequence\n * **summary** - Output a summary table including minimum, lower quartile, median, upper quartile, maximum of a number sequence\n * **fivenum** - Calculate Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum) of a number sequence based on 1.5 times the interquartile distance\n\n\nUsage\n-----\n\nAll utilities take as input a file in table format to perform some calculation based on it. A tipical input file is shown below::\n\n  1 2 4\n  3 5 4\n  6 4 6\n  4 5 6\n  9 12 16\n\nConsidering this input file, let's call it ``example1.dat``, you can calculate some statistics like:\n\nThe ``max`` value on the first column::\n\n  max example1.dat\n\nThe ``min`` value on the second column::\n\n  min -c 2 example1.dat\n\nYou still can use negative column numbers to start counting from the right. Thus, the ``sum`` of the values on last column::\n\n  sum -c -1 example1.dat\n\nIf the input file's columns are separated by another character instead of whitespace characters (space, tab, newline, return, formfeed), like CSV files, you can use the ``-s`` option to denote this. The next example outputs a statistical ``summary`` about the second column of the following file (``example2.dat``)::\n\n  \"A\",10,12\n  \"A\",11,14\n  \"B\",5,8\n  \"B\",6,10\n  \"A\",10.5,13\n  \"B\",7,11\n\nCalculating the summary::\n\n  summary -c 2 -s , example2.dat\n\nCommonly, data files may contain a head, i.e., the first line describes the columns, something like the ``example3.dat`` file showed below::\n\n  Year,Make,Model,Description,Price\n  1997,Ford,E350,\"ac abs moon\",3000.00\n  1999,Chevy,\"Venture \"\"Extended Edition\"\"\",\"\",4900.00\n  1999,Chevy,\"Venture \"\"Extended Edition, Very Large\"\"\",\"\",5000.00\n  1996,Jeep,Grand Cherokee,\"MUST SELL!air, moon roof, loaded\",4799.00\n\nThe ``-b`` option remove the first line from calculations. In this case, the mean price of the cars is given by::\n\n  mean -b -s, -c-1 test/example3.dat\n\n\nPiping data\n```````````\n\nAll ``stats-tools`` read data from standard input if no file is passed to them. The following command calculates the max value on the second column containing the word ``bar`` in the file ``foo.dat``::\n\n  grep bar foo.dat | max -c 2\n\n\nBugs and Feedback\n-----------------\n\nIf you discover any bugs or have some idea, feel free to create an issue on GitHub:\n  \n`<http://github.com/jweslley/stats-tools/issues>`_\n\n\nLicense\n-------\n\nMIT license. Copyright (c) 2011 Jonhnny Weslley <http://jonhnnyweslley.net>\n\nSee the LICENSE file provided with the source distribution for full details."}}, {"pk": 786, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "scikits.ann", "license": "GNU Library or Lesser General Public License (LGPL)", "author": "Barry Wark", "author_email": "barrywark@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://scipy.org/scipy/scikits/wiki/AnnWrapper", "version": "0.2.dev-r803", "platform": "UNKNOWN", "keywords": null, "summary": "Approximate Nearest Neighbor library wrapper for Numpy", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nProgramming Language :: Python\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Libraries :: Python Modules", "description": "The ANN module provides a numpy-compatible python wrapper around the \nApproximate Nearest Neighbor library (http://www.cs.umd.edu/~mount/ANN/).\n\n* Installation *\nDownload and build the Approximate Nearest Neighbor library. Modify the ANN section of \nsite.cfg so that ANN_ROOT is the path to the root of the Approximate Nearest Neighbor \nlibrary include/lib tree.\nIf /usr/local/include contains the ANN/ include directory and /usr/local/lib contains \nlibANN.a, then\nANN_ROOT = /usr/local\n\nRun ::\n\n    python setup.py build_ext --inplace build test\n    sudo python setup.py install\n\nfrom within the source directory.\n\n* Usage *\nscikits.ann exposes a single class, kdtree that wraps the Approximate Nearest Neighbor \nlibrary's kd-tree implementation. kdtree has a single (non-constructor) method, knn that \nfinds the indecies (of the points used to construct the kdtree) of the k-nearest neighbors\n and the squared distances to those points. A little example will probably be much \n more enlightening::\n    >>> import scikits.ann as ann\n        \n    >>> import numpy as np\n\n    >>> k=ann.kdtree(np.array([[0.,0],[1,0],[1.5,2]]))\n\n    >>> k.knn([0,.2],1)\n    (array([[0]]), array([[ 0.04]]))\n\n    >>> k.knn([0,.2],2)\n    (array([[0, 1]]), array([[ 0.04,  1.04]]))\n\n    >>> k.knn([[0,.2],[.1,2],[3,1],[0,0]],2)\n    (array([[0, 1],\n           [2, 0],\n           [2, 1],\n           [1, 2]]), array([[ 0.04,  1.04],\n           [ 1.96,  4.01],\n           [ 3.25,  5.  ],\n           [ 1.  ,  6.25]]))\n\n    >>> k.knn([[0,.2],[.1,2],[3,1],[0,0]],3)\n    (array([[ 0,  1,  2],\n           [ 2,  0,  1],\n           [ 2,  1,  0],\n           [ 1,  2, -1]]), array([[  4.00000000e-002,   1.04000000e+000,   5.49000000e+000],\n           [  1.96000000e+000,   4.01000000e+000,   4.81000000e+000],\n           [  3.25000000e+000,   5.00000000e+000,   1.00000000e+001],\n           [  1.00000000e+000,   6.25000000e+000,   1.79769313e+308]]))"}}, {"pk": 787, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "MyProxyWebService", "license": "BSD - See LICENSE file in top-level directory", "author": "Philip Kershaw", "author_email": "Philip.Kershaw@stfc.ac.uk", "project_url": null, "maintainer_email": null, "home_page": "http://proj.badc.rl.ac.uk/ndg/wiki/Security/MyProxyWebService", "version": "0.1.1", "platform": "POSIX,Linux,Windows", "keywords": null, "summary": "MyProxy Web Service", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Console\nEnvironment :: Web Environment\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nIntended Audience :: System Administrators\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX :: Linux\nProgramming Language :: Python\nTopic :: Internet\nTopic :: Scientific/Engineering\nTopic :: Security\nTopic :: Software Development :: Libraries :: Python Modules\nTopic :: System :: Distributed Computing\nTopic :: System :: Systems Administration :: Authentication/Directory", "description": "Provides a simple web service interface to MyProxy.  MyProxy is a Service for\n        managing PKI based credentials which is part of the Globus Toolkit.  Providing\n        a HTTP based interface enables HTTP based clients to connect to a MyProxy server\n        and retrieve credentials.\n        \n        The interface is implemented as a WSGI application which fronts a normal\n        MyProxy server.  myproxy-logon and myproxy-get-trustroots are expressed as web\n        service calls.  The WSGI application forwards the requests on to the MyProxy\n        server over the usual MyProxy protocol.  The web service interface is RESTful\n        using GET and POST operations and the logon interface makes uses of HTTP Basic\n        Auth to pass username and pass-phrase credentials.  The service is hosted over\n        HTTPS.\n        \n        The unit tests include a test application served using paster.  Client scripts\n        are also available which need no specialised installation or applications, only\n        openssl and curl which are typically available on Linux/UNIX based systems."}}, {"pk": 788, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyBioLCCC", "license": "License :: Free for non-commercial use", "author": "Anton Goloborodko", "author_email": "goloborodko.anton@gmail.com", "project_url": null, "maintainer_email": null, "home_page": "http://theorchromo.ru", "version": "1.3.0", "platform": "UNKNOWN", "keywords": null, "summary": "Bindings for the libBioLCCC", "classifiers": "Intended Audience :: Science/Research\nTopic :: Scientific/Engineering :: Bio-Informatics\nTopic :: Scientific/Engineering :: Chemistry\nTopic :: Scientific/Engineering :: Physics", "description": "What is BioLCCC?\n----------------\n\nBioLCCC (Liquid Chromatography of Biomacromolecules at Critical Conditions) is a\nmodel which describes the adsorption of protein molecules on porous media. Its\nmain application is retention time prediction in liquid chromatography, although\nthe list of potential applications can be easily extended. Contrary to the other\nmodels of peptide/protein chromatography, BioLCCC starts from very basic\nassumptions regarding flexibility of a polypeptide chain, the shape of a pore,\ntype of interactions neglected, etc. Given these assumptions, the coefficient of\ndistribution (Kd) of a peptide between the solid and mobile phases can be\nderived using the methods of statistical physics of macromolecules. Finally, the\nretention time of a peptide is calculated from Kd using the basic equation of\ngradient chromatography.\n\nOwing to the physical basis of the BioLCCC model, it contains very few free\nparameters. The retention properties of an amino acid are characterized by a\nsingle number, which is essentially the energy of interaction between the amino\nacid and the surface of solid phase in pure water+ion paring agent. Given this\nsmall number of phenomenological parameters, the BioLCCC model can easily be\nadapted for an arbitrary type of chromatography not limited by phase or solvent\ntypes. Moreover, its extension to peptides with post-translational modifications\nis straightforward as it was shown for the phosphorylated amino acids.\n\nSeveral papers regarding BioLCCC model were published:\n\n1. Liquid Chromatography at Critical Conditions:\u2009 Comprehensive Approach to\nSequence-Dependent Retention Time Prediction, Alexander V. Gorshkov, Irina A.\nTarasova, Victor V. Evreinov, Mikhail M. Savitski, Michael L. Nielsen, Roman A.\nZubarev, and Mikhail V. Gorshkov, Analytical Chemistry, 2006, 78 (22),\n7770-7777. Link: http://dx.doi.org/10.1021/ac060913x.\n\n2. Applicability of the critical chromatography concept to proteomics problems:\nDependence of retention time on the sequence of amino acids, Alexander V.\nGorshkov A., Victor V. Evreinov V., Irina A. Tarasova, Mikhail V. Gorshkov,\nPolymer Science B, 2007, 49 (3-4), 93-107. \nLink: http://dx.doi.org/10.1134/S1560090407030098.\n\n3. Applicability of the critical chromatography concept to proteomics problems:\nExperimental study of the dependence of peptide retention time on the sequence\nof amino acids in the chain, Irina A. Tarasova, Alexander V. Gorshkov, Victor V.\nEvreinov, Chris Adams, Roman A. Zubarev, and Mikhail V. Gorshkov, Polymer\nScience A, 2008, 50 (3), 309. \nLink: http://www.springerlink.com/content/gnh84v62w960747n/.\n\n4. Retention time prediction using the model of liquid chromatography of\nbiomacromolecules at critical conditions in LC-MS phosphopeptide analysis,\nTatiana Yu. Perlova, Anton A. Goloborodko, Yelena Margolin, Marina L.\nPridatchenko, Irina A. Tarasova, Alexander V. Gorshkov, Eugene Moskovets,\nAlexander R. Ivanov and Mikhail V. Gorshkov, Accepted to Proteomics.\nLink: http://dx.doi.org/10.1002/pmic.200900837.\n\nWhat is libBioLCCC?\n-------------------\n\nlibBioLCCC is an open source library, which implements the BioLCCC model in \nC++ programming language. It performs basic BioLCCC-related tasks, such as:\n\n* predicts the retention time of peptides and proteins in given \n  chromatographic conditions;\n* predicts the adsorption properties of protein molecules, namely coefficient of\n  distribution between mobile and solid phase;\n* manages elution conditions and physicochemical constants;\n* calculates masses of peptides and proteins.\n\nlibBioLCCC has a simple and well-documented API.\n\nWhat is pyBioLCCC?\n------------------\n\npyBioLCCC is a set of Python wrappings around libBioLCCC. It allows to invoke\nlibBioLCCC functions from Python programming language.\n\nThe main purpose of pyBioLCCC project is to make libBioLCCC available in a\nprogramming language not so demanding as C++. The choice of Python is dictated\nby several points. Among them are simplicity, the great variety of libraries and\nthe extreme speed of development which could be very well appreciated in the\nmodern scientific world.\n\nWhere can I find more information?\n----------------------------------\n\nThe project documentation is hosted at http://theorchromo.ru/lib. \n\nThe source code of libBioLCCC/pyBioLCCC is open and hosted at\nhttp://hg.theorchromo.ru."}}, {"pk": 789, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pylibftdi", "license": "UNKNOWN", "author": "Ben Bass", "author_email": "benbass@codedstructure.net", "project_url": null, "maintainer_email": null, "home_page": "http://bitbucket.org/codedstructure/pylibftdi", "version": "0.7", "platform": "UNKNOWN", "keywords": null, "summary": "Pythonic interface to FTDI devices using libftdi", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nLicense :: OSI Approved :: MIT License\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nProgramming Language :: Python\nProgramming Language :: Python :: 2.6\nProgramming Language :: Python :: 2.7\nProgramming Language :: Python :: 3\nTopic :: Scientific/Engineering\nTopic :: Software Development :: Embedded Systems\nTopic :: System :: Hardware", "description": "pylibftdi\n=========\n\npylibftdi is a minimal Pythonic interface to FTDI devices using libftdi_.\n\n.. _libftdi: http://www.intra2net.com/en/developer/libftdi/\n\n:Features:\n\n - Supports Python 2 and Python 3\n - Supports parallel and serial devices\n - Support for multiple devices\n - Cross-platform\n\n:Limitations:\n\n - Currently only one port per device is used; I've not tested with dual\n   port devices yet.\n - The API might change prior to reaching a 1.0 release.\n\nUsage\n-----\n\nThe primary interface is the ``Device`` class in the pylibftdi package; this\ngives serial access on relevant FTDI devices (e.g. the UM232R), providing a\nfile-like interface (read, write).  Baudrate is controlled with the ``baudrate``\nproperty.\n\nIf a Device instance is created with ``mode='t'`` (text mode) then read() and\nwrite() can use the given ``encoding`` (defaulting to latin-1). This doesn't\nmake a lot of difference on Python 2 (and can be omitted), but allows easier\nintegration with passing unicode strings between devices in Python 3.\n\nMultiple devices are supported by passing the desired device serial number (as\na string) in the ``device_id`` parameter - this is the first parameter in both\nDevice() and BitBangDevice() constructors.\n\nExamples\n~~~~~~~~\n\n::\n\n    >>> from pylibftdi import Device\n    >>>\n    >>> with Device(mode='t') as dev:\n    ...     dev.baudrate = 115200\n    ...     dev.write('Hello World')\n\nThe pylibftdi.BitBangDevice wrapper provides access to the parallel IO mode of\noperation through the ``port`` and ``direction`` properties.  These provide an\n8 bit IO port including all the relevant bit operations to make things simple.\n\n::\n\n    >>> from pylibftdi import BitBangDevice\n    >>>\n    >>> with BitBangDevice('FTE00P4L') as bb:\n    ...     bb.direction = 0x0F  # four LSB are output(1), four MSB are input(0)\n    ...     bb.port |= 2         # set bit 1\n    ...     bb.port &= 0xFE      # clear bit 0\n\nThere is support for a number of external devices and protocols, specifically\nfor interfacing with HD44780 LCDs using the 4-bit interface.\n\nHistory & Motivation\n--------------------\nThis package is the result of various bits of work using FTDI's\ndevices, primarily for controlling external devices.  Some of this\nis documented on the codedstructure blog, codedstructure.blogspot.com\n\nAt least two other open-source Python FTDI wrappers exist, and each\nof these may be best for some projects.\n\n * ftd2xx_ - ctypes binding to FTDI's own D2XX driver\n * pyftdi_ - a C extension libftdi binding\n \n.. _ftd2xx: http://pypi.python.org/pypi/ftd2xx\n.. _pyftdi: http://git.marcansoft.com/?p=pyftdi.git\n\npylibftdi exists in the gap between these two projects; ftd2xx uses\nthe (closed-source) D2XX driver, but provides a high-level Python\ninterface, while pyftdi works with libftdi but is very low-level.\nThe aim for pylibftdi is to work with the libftdi, but to provide\na high-level Pythonic interface.  Various wrappers and utility\nfunctions are also part of the distribution; following Python's\nbatteries included approach, there are various interesting devices\nsupported out-of-the-box - or at least there will be soon!\n\nPlans\n-----\n * Add more examples: SPI devices, knight-rider effects, input devices, MIDI...\n * Perhaps add support for D2XX driver, though the name then becomes a\n   slight liability ;)\n * General code quality improvements: solid unit tests, decent documentation.\n\nLicense\n-------\n\nCopyright (c) 2010-2011 Ben Bass <benbass@codedstructure.net>\n\npylibftdi is released under the MIT licence; see the file \"LICENSE.txt\"\nfor information.\n\nAll trademarks referenced herein are property of their respective\nholders.\nlibFTDI itself is developed by Intra2net AG.  No association with\nIntra2net is claimed or implied, but I have found their library\nhelpful and had fun with it..."}}, {"pk": 790, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.component.config", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/pyutilib/pyutilib.component.config", "version": "3.3.1", "platform": "any", "keywords": "utility", "summary": "Extensions for configuring components in the PyUtilib Component Architecture", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "================================\npyutilib.component.config README\n================================\n\nThis Python package includes utilities to configure\nthe PyUtilib Component Architecture.  This includes facilities for using\nconfiguration files, controlling logging, and specifying component options.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\n* pyutilib.component.core"}}, {"pk": 791, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "coopr.pysos", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/svn/public/coopr/coopr.pysos", "version": "2.0.5", "platform": "any", "keywords": "optimization", "summary": "Coopr utilities for composing heterogeous models", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "==================\ncoopr.pysos README\n==================\n\nThis Python package defines classes used to define heterogeneous \noptimization formulations (e.g. which integrate spreadsheet calculations\nwith linear programming models).\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * coopr - The root directory for Coopr source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/coopr\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * coopr-forum@googlegroups.com\n    - The main list for help and announcements\n  * coopr-developers@googlegroups.com\n    - Where developers of Coopr discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 792, "model": "importing.pypicache", "fields": {"maintainer": "Karl Norby", "name": "pyxsd", "license": "BSD License", "author": "Karl Norby and Michael Summers", "author_email": "knorby@uchicago.edu", "project_url": null, "maintainer_email": "knorby@uchicago.edu", "home_page": "http://pyxsd.org/", "version": "0.1", "platform": "OS independent", "keywords": "xml, xsd, Schema, materials science, metaprogramming", "summary": "Python XML/Schema processing tool", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Physics\nTopic :: Text Processing :: Markup :: XML", "description": "pyXSD is a free, open source python program that maps xml and xsd(XML Schema)\r\nfiles into python, allowing for easy schema-based validation and transformation\r\nof xml files.\r\n\r\nBenefits:\r\n=========\r\n\r\n* Allows for easy, non-DOM, access to XML and XML Schema from Python\r\n* Minimizes time to make small programs associated with data in an xml file\r\nusing \"transforms\"\r\n* Highly adaptable to particular needs and to specific programs\r\n* Platform independent\r\n\r\nOverview:\r\n=========\r\n\r\n* Generates python classes for all of the types defined in the XSD schema file.\r\nThe generated classes may be written to file.\r\n* Parses the xml file and builds a pythonic object tree according to the\r\ngenerated classes. This tree of maintains the same overall structure of the\r\noriginal xml document.\r\n* Validates the xml file against the schema producing non-fatal errors.  Helps\r\nthe user write a valid xml document, without requiring complete validity.\r\n* Transforms the pythonic objects according to built-in \"transform\" classes and\r\nadd-on classes that the user writes in python.\r\n* Sends pythonic object tree to a writer which produces a transformed xml file.\r\n\r\nFeatures:\r\n\r\n* Transforms allow users to easily adapt pyXSD to vast number of applications\r\n    - Provides a framework and libraries to write transform so the user can more\r\neasily write these transform functions\r\n    - Allows the user to specify the desired transform classes with arguments\r\nand the order in a file so the user can create a sort of custom tool\r\n    - Allows for transforms that can export to other formats, giving pyXSD\r\npowerful flexibility\r\n* The pythonic data tree format uses a very simple structure that allows for an\r\neasily understood API, so that users can easily manipulate this tree in\r\ntransforms and use the writer in other programs\r\n* Can be used as a standalone program at the command line or as a library in\r\nother programs\r\n* Uses the cElementTree library for fast reading of the xml and xsd files\r\n\r\nRequirements:\r\n=============\r\n\r\n* Python 2.3 or later. \r\n* ElementTree library, preferably the c implementation."}}, {"pk": 793, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "gensim", "license": "LGPL", "author": "Radim Rehurek", "author_email": "radimrehurek@seznam.cz", "project_url": null, "maintainer_email": null, "home_page": "http://nlp.fi.muni.cz/projekty/gensim", "version": "0.7.8", "platform": "any", "keywords": "Singular Value Decomposition,Latent Semantic Indexing,SVD,LSA,LSI,LDA,Latent Dirichlet Allocation,VSM,Random Projections,TFIDF", "summary": "Python framework for fast Vector Space Modelling", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\nOperating System :: OS Independent\nProgramming Language :: Python :: 2.5\nTopic :: Scientific/Engineering :: Artificial Intelligence\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Text Processing :: Linguistic", "description": "==============================================\ngensim -- Python Framework for Topic Modelling\n==============================================\n\n\n\nGensim is a Python library for *Vector Space Modelling* with very large corpora.\nTarget audience is the *Natural Language Processing* (NLP) community.\n\n\nFeatures\n---------\n\n* All algorithms are **memory-independent** w.r.t. the corpus size (can process input larger than RAM),\n* **Intuitive interfaces**\n\n  * easy to plug in your own input corpus/datastream (trivial streaming API)\n  * easy to extend with other Vector Space algorithms (trivial transformation API)\n\n* Efficient implementations of popular algorithms, such as online **Latent Semantic Analysis**,\n  **Latent Dirichlet Allocation** or **Random Projections**\n* **Distributed computing**: can run *Latent Semantic Analysis* and *Latent Dirichlet Allocation* on a cluster of computers.\n* Extensive `HTML documentation and tutorials <http://nlp.fi.muni.cz/projekty/gensim/>`_.\n\n\nIf this feature list left you scratching your head, you can first read more about the `Vector\nSpace Model <http://en.wikipedia.org/wiki/Vector_space_model>`_ and `unsupervised\ndocument analysis <http://en.wikipedia.org/wiki/Latent_semantic_indexing>`_ on Wikipedia.\n\nInstallation\n------------\n\nThis software depends on `NumPy and Scipy <http://www.scipy.org/Download>`_, two Python packages for scientific computing.\nYou must have them installed prior to installing `gensim`.\n\nThe simple way to install `gensim` is::\n\n    sudo easy_install gensim\n\nOr, if you have instead downloaded and unzipped the `source tar.gz <http://pypi.python.org/pypi/gensim>`_ package,\nyou'll need to run::\n\n    python setup.py test\n    sudo python setup.py install\n\n\nFor alternative modes of installation (without root priviledges, development\ninstallation, optional install features), see the `documentation <http://nlp.fi.muni.cz/projekty/gensim/install.html>`_.\n\nThis version has been tested under Python 2.5 and 2.6, but should run on any 2.5 <= Python < 3.0.\n\nDocumentation\n-------------\n\nManual for the gensim package is available in `HTML <http://nlp.fi.muni.cz/projekty/gensim/>`_. It\ncontains a walk-through of all its features and a complete reference section.\nIt is also included in the source distribution package.\n\n-------\n\nGensim is open source software, and has been released under the\n`GNU LPGL license <http://www.gnu.org/licenses/lgpl.html>`_.\nCopyright (c) 2010 Radim Rehurek"}}, {"pk": 794, "model": "importing.pypicache", "fields": {"maintainer": "", "name": "tappy", "license": "GPL-2", "author": "Tim Cera", "author_email": "timcera@earthlink.net", "project_url": null, "maintainer_email": "", "home_page": "http://tappy.sourceforge.net", "version": "0.8.1", "platform": "UNKNOWN", "keywords": "", "summary": "Tidal Analysis Program in PYthon", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nNatural Language :: English\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Information Analysis\nTopic :: Scientific/Engineering :: Physics", "description": "TAPPY is a tidal analysis package. It breaks down a record of water\r\nlevels into the tidal component sine waves. It is written in Python and uses the\r\nleast squares optimization and other functions in SciPy. The focus is to make the\r\nmost accurate analysis possible. TAPPY only determines the constituents that are\r\ncalculatable according to the length of the time series."}}, {"pk": 795, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "twMaps", "license": "UNKNOWN", "author": "Wyatt Baldwin, byCycle.org", "author_email": "wyatt@bycycle.org", "project_url": null, "maintainer_email": null, "home_page": "http://wyattbaldwin.com/", "version": "0.1a0.dev-r720", "platform": "UNKNOWN", "keywords": "web maps google widgets toscawidgets toscawidgets.widgets", "summary": "Web map widgets", "classifiers": "Development Status :: 3 - Alpha\nEnvironment :: Web Environment\nFramework :: Paste\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nLicense :: OSI Approved :: MIT License\nNatural Language :: English\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS", "description": "Google Maps widget based on ToscaWidgets. Other map types may be added in\nthe future (e.g., Yahoo Maps). Should work with any templating system\nthat uses ${} style substitution."}}, {"pk": 796, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyutilib.pyro", "license": "BSD", "author": "William E. Hart", "author_email": "wehart@sandia.gov", "project_url": null, "maintainer_email": null, "home_page": "https://software.sandia.gov/trac/pyutilib/pyutilib.pyro", "version": "3.2.1", "platform": "any", "keywords": "utility", "summary": "PyUtilib utilities that use Pyro", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: BSD License\nNatural Language :: English\nOperating System :: Microsoft :: Windows\nOperating System :: Unix\nProgramming Language :: Python\nProgramming Language :: Unix Shell\nTopic :: Scientific/Engineering :: Mathematics\nTopic :: Software Development :: Libraries :: Python Modules", "description": "====================\npyutilib.pyro README\n====================\n\nThis Python package includes utilities that use Pyro.\n\n\n-------\nLicense\n-------\n\nBSD.  See the LICENSE.txt file.\n\n\n------------\nOrganization\n------------\n\n+ Directories\n\n  * pyutilib - The root directory for PyUtilib source code\n\n+ Documentation and Bug Tracking\n\n  * Trac wiki: https://software.sandia.gov/trac/pyutilib\n\n+ Authors\n\n  * See the AUTHORS.txt file.\n\n+ Project Managers\n\n  * William E. Hart, wehart@sandia.gov\n\n+ Mailing List\n\n  * pyutilib-forum@googlegroups.com\n    - The main list for help and announcements\n  * pyutilib-developers@googlegroups.com\n    - Where developers of PyUtilib discuss new features\n\n--------------------\nThird Party Software\n--------------------\n\nNone."}}, {"pk": 797, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "mirpy", "license": "GPL", "author": "Malte Marquarding", "author_email": "Malte.Marquarding@csiro.au", "project_url": null, "maintainer_email": null, "home_page": "http://www.atnf.csiro.au", "version": "0.2.0", "platform": "UNKNOWN", "keywords": "miriad,astronomy,radio astronomy", "summary": "Pure-python miriad CLI wrapper.", "classifiers": "Development Status :: 5 - Production/Stable\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: Unix\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Astronomy\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Introduction\n============\n\nThis package wraps miriad (http://www.atnf.csiro.au/computing/software/miriad/) commands into python functions. It also wraps the documentation for miriad tasks.\n\n*Note* that one exception to the miriad conventions is the keyword/parameter 'in' which can't be used in python. Use something like 'In', 'IN' or '_in' instead.\n\nExample\n=======\n\nSimple\n------\n\n    >>> from mirpy import miriad\n    >>> help(miriad.uvindex)\n    >>> print miriad.uvindex(vis='myvis.uv')\n\n\nAdvanced\n--------\n\nCreate filter function to turn miriad stdout text into something useful.\nThis example is not really useful and just demonstrates the usage. It turns \nthe miriad output string into a list of lines in the string and returns it.\nMore useful examples would be turning some output into python values you can\nwork with later.\n\n    >>> from mirpy import miriad\n    >>> def uvindex_filt(output):\n    ...     return output.split('\\n')\n    >>> # without filter\n    >>> print miriad.uvindex(vis='myvis.uv')\n    >>> # register filter function\n    >>> miriad.set_filer('uvindex', uvindex_filt)\n    >>> # with filter\n    >>> print miriad.uvindex(vis='myvis.uv')"}}, {"pk": 798, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "HTSeq", "license": "UNKNOWN", "author": "Simon Anders", "author_email": "sanders@fs.tum.de", "project_url": null, "maintainer_email": null, "home_page": "http://www-huber.embl.de/users/anders/HTSeq/", "version": "0.4.7p4", "platform": "UNKNOWN", "keywords": null, "summary": "A framework to process and analyze data from high-throughput sequencing (HTS) assays", "classifiers": "Development Status :: 4 - Beta\nIntended Audience :: Developers\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: GNU General Public License (GPL)\nOperating System :: POSIX\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Bio-Informatics", "description": "UNKNOWN"}}, {"pk": 799, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "cobe", "license": "UNKNOWN", "author": "Peter Teichman", "author_email": "peter@teichman.org", "project_url": null, "maintainer_email": null, "home_page": "http://wiki.github.com/pteichman/cobe/", "version": "1.1.2", "platform": "UNKNOWN", "keywords": null, "summary": "A conversation simulator similar to MegaHAL", "classifiers": "Development Status :: 5 - Production/Stable\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: End Users/Desktop\nLicense :: OSI Approved :: MIT License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: Artificial Intelligence", "description": "UNKNOWN"}}, {"pk": 800, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "zgeo.atom", "license": "BSD", "author": "Sean Gillies", "author_email": "sgillies@frii.com", "project_url": null, "maintainer_email": null, "home_page": "http://trac.gispython.org/projects/PrimaGIS/wiki/zgeo.atom", "version": "0.4.1", "platform": "UNKNOWN", "keywords": "gis geography geospatial georss atom atompub", "summary": "Atom syndication and AtomPub with GeoRSS", "classifiers": "Development Status :: 3 - Alpha\nFramework :: Zope3\nIntended Audience :: Developers\nLicense :: OSI Approved :: BSD License\nProgramming Language :: Python\nTopic :: Scientific/Engineering :: GIS\nTopic :: Software Development :: Libraries :: Python Modules", "description": "Provides Atom (RFC 4287) entry, subscription feed, and search feed documents\nannotated with GeoRSS elements. Implements the Atom Publishing Protocol (RFC\n5023).\n\nAtomPub collections can be made of Zope containers using the\n\"atompub-collection\" view. Atom entry representations of contained objects can\nbe made using the \"atom-entry\" view. By registering IFileFactory and IWriteFile\nadapters, one can allow creation and edit of objects via the Atom Publishing\nProtocol.\n\nMajor portions of this work were supported by a grant (to Pleiades_) from the\nU.S. National Endowment for the Humanities (http://www.neh.gov).\n\n.. _Pleiades: http://atlantides.org/trac/pleiades/wiki"}}, {"pk": 801, "model": "importing.pypicache", "fields": {"maintainer": null, "name": "pyxnat", "license": "BSD", "author": "Yannick Schwartz", "author_email": "yannick.schwartz@cea.fr", "project_url": null, "maintainer_email": null, "home_page": "http://packages.python.org/pyxnat/", "version": "0.7.1", "platform": "any", "keywords": null, "summary": "Xnat in Python", "classifiers": "Development Status :: 4 - Beta\nEnvironment :: Console\nIntended Audience :: Developers\nIntended Audience :: Education\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: BSD License\nOperating System :: OS Independent\nProgramming Language :: Python\nTopic :: Internet :: WWW/HTTP\nTopic :: Scientific/Engineering\nTopic :: Utilities", "description": "pyxnat is a simple python library that relies on the REST API provided\nby the XNAT platform since its 1.4 version. XNAT is an extensible database for neuroimaging data. The main objective is to ease communications with an XNAT\nserver to plug-in external tools or python scripts to process the data. It\nfeatures:\n\n    #. resources browsing capabilities\n    #. read and write access to resources\n    #. complex searches\n    #. disk-caching of requested files and resources\n\n.. [#] XNAT home: http://www.xnat.org/\n.. [#] pyxnat documentation: http://packages.python.org/pyxnat/\n.. [#] pyxnat download: http://pypi.python.org/pypi/pyxnat#downloads\n.. [#] pyxnat sources: http://github.com/schwarty/pyxnat\n\n____\n\n    **A short overview**    \n\n    *Setup the connection*\n        >>> from pyxnat import Interface\n        >>> interface = Interface(\n                 server='http://central.xnat.org:8080',\n                 user='login',\n                 password='pass',\n                 cachedir=os.path.join(os.path.expanduser('~'), '.store')\n                 )\n\n    *Browse the resources*\n        >>> interface.select.projects().get()\n        [u'CENTRAL_OASIS_CS', u'CENTRAL_OASIS_LONG', ...]\n\n    *Create new resources*\n        >>> interface.select.project('my_project').create()\n        >>> interface.select.project('my_project').resource('images'\n                              ).file('image.nii').put('/tmp/image.nii')\n\n    *Make complex searches*\n        >>> table = interface.select('xnat:subjectData', \n                                     ['xnat:subjectData/PROJECT', \n                                      'xnat:subjectData/SUBJECT_ID'\n                                      ]\n               ).where([('xnat:subjectData/SUBJECT_ID','LIKE','%'),\n                        ('xnat:subjectData/PROJECT', '=', 'my_project'),\n                        'AND'\n                        ])"}}]
